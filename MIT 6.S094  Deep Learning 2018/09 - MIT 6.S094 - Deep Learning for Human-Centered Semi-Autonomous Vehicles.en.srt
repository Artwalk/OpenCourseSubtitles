1
00:00:02,150 --> 00:00:09,170
The human side of AI,
how do we turn this camera

2
00:00:09,200 --> 00:00:11,370
back in on the human,

3
00:00:12,320 --> 00:00:14,520
we are talking about perception,

4
00:00:14,750 --> 00:00:20,450
how to detect cats and dogs,
pedestrians lanes,

5
00:00:20,520 --> 00:00:24,500
how to steer a vehicle based on the
external environment,

6
00:00:24,670 --> 00:00:29,920
the thing that's really fascinating and
severely understudied,

7
00:00:30,050 --> 00:00:34,750
is the human side,
we talked about the Tesla,

8
00:00:34,900 --> 00:00:39,500
we have cameras in 17 Tesla's
driving around Cambridge

9
00:00:40,300 --> 00:00:45,900
because Tesla is one of the only vehicles
allowing you

10
00:00:46,900 --> 00:00:52,670
to experience in a real way, on the road,
the interaction between the human

11
00:00:52,670 --> 00:00:54,030
and the Machine,

12
00:00:55,730 --> 00:00:57,860
the thing that we don't have,

13
00:00:57,900 --> 00:01:02,650
that deep learning needs
on the human side of

14
00:01:02,650 --> 00:01:05,670
semi-autonomous vehicles
and fully-autonomous vehicles

15
00:01:05,700 --> 00:01:10,500
is video of drivers,
that's what we're collecting,

16
00:01:10,700 --> 00:01:14,570
that's what my work is in,
is looking at billions

17
00:01:14,570 --> 00:01:18,900
of video frames,
of human beings driving

18
00:01:19,100 --> 00:01:22,000
60 miles an hour plus
on the highway

19
00:01:22,330 --> 00:01:24,260
in their semi-autonomous Tesla,

20
00:01:25,590 --> 00:01:28,880
what are the things that we want
to know about the human?

21
00:01:31,270 --> 00:01:37,180
If we were a deep learning therapist,
we’d try to break apart

22
00:01:37,180 --> 00:01:40,620
the different things we can detect
from this raw set of pixels,

23
00:01:41,300 --> 00:01:43,800
we can look here,
from the green to red

24
00:01:43,870 --> 00:01:45,300
is a different detection problem,

25
00:01:45,300 --> 00:01:47,530
a different computer vision
detection problem

26
00:01:47,570 --> 00:01:51,520
green means it's less challenging,

27
00:01:52,320 --> 00:01:56,150
it's feasible,
even under poor lighting conditions,

28
00:01:56,170 --> 00:02:01,670
variable pose, noisy environment,
poor resolution,

29
00:02:02,000 --> 00:02:05,720
red means it's really hard
no matter what you do,

30
00:02:06,250 --> 00:02:09,750
that's starting on the left
with face detection body pose,

31
00:02:10,020 --> 00:02:12,400
one of the best studied
and one of the easier

32
00:02:12,420 --> 00:02:17,020
computer vision problems,
we have huge datasets for these,

33
00:02:17,610 --> 00:02:21,260
then there is micro saccades,
the slight tremors of the eye

34
00:02:21,300 --> 00:02:26,930
that happen at a rate of
a thousand times a second.

35
00:02:28,800 --> 00:02:30,960
All right let's look at—

36
00:02:31,940 --> 00:02:34,470
First, why do we even care

37
00:02:35,120 --> 00:02:36,850
about the human in the car?

38
00:02:37,950 --> 00:02:42,820
One is trust, this trust part is a—
If you think about it,

39
00:02:43,970 --> 00:02:46,900
to build trust
the car needs to have

40
00:02:46,950 --> 00:02:51,200
some awareness of
the biological thing

41
00:02:51,200 --> 00:02:53,050
it's carrying inside,
the human inside,

42
00:02:53,070 --> 00:02:55,120
you assume the car
knows about you,

43
00:02:55,120 --> 00:02:57,400
because you're sitting there
controlling it,

44
00:02:57,670 --> 00:03:01,070
but if you think about it,
almost every single car

45
00:03:01,070 --> 00:03:03,540
on the road today,
has no sensors

46
00:03:03,540 --> 00:03:06,630
with which it's perceiving you,
it knows, some cars

47
00:03:06,630 --> 00:03:09,350
have a pressure sensor
on the steering wheel

48
00:03:09,600 --> 00:03:12,700
and a pressure sensor
or some kind of sensor

49
00:03:12,920 --> 00:03:15,120
detecting that you're sitting
in the seat,

50
00:03:15,520 --> 00:03:17,680
that's the only thing
it knows about you,

51
00:03:17,820 --> 00:03:21,520
that's it,
so how is the car supposed to—

52
00:03:22,400 --> 00:03:25,350
this same car
is driving 70 miles an hour,

53
00:03:25,350 --> 00:03:28,520
on the highway, autonomously,
how is it supposed

54
00:03:28,520 --> 00:03:31,250
to build trust with you
if it doesn't perceive you?

55
00:03:31,750 --> 00:03:33,900
That's one of the
critical things here,

56
00:03:34,360 --> 00:03:36,860
so if I'm constantly
advocating something,

57
00:03:36,880 --> 00:03:39,160
is that we should have
a driver facing camera

58
00:03:39,170 --> 00:03:40,350
in every car,

59
00:03:40,860 --> 00:03:43,210
despite the privacy concerns,

60
00:03:43,350 --> 00:03:46,670
you have a camera on your phone
and you don't have as much

61
00:03:46,700 --> 00:03:51,220
of a privacy concern there,
but despite the privacy concerns,

62
00:03:51,400 --> 00:03:57,350
the safety benefits are huge,
the trust benefits are huge.

63
00:03:59,800 --> 00:04:03,450
Let's start with the easy one,
detecting body pose,

64
00:04:04,200 --> 00:04:05,520
why do we care?

65
00:04:05,950 --> 00:04:08,120
There is a seatbelt design,

66
00:04:09,550 --> 00:04:10,880
there are these dummies,

67
00:04:10,990 --> 00:04:13,650
crash-test dummies,
which we can use

68
00:04:13,660 --> 00:04:18,970
to design the passive
safety systems of our cars,

69
00:04:19,210 --> 00:04:21,930
and they make certain assumptions
about body shapes,

70
00:04:21,970 --> 00:04:26,600
male, female, child, body shapes,
but they also make assumptions

71
00:04:26,620 --> 00:04:29,120
about the position of
your body in the seat,

72
00:04:29,700 --> 00:04:34,200
they have the optimal position,
the position they assume you take,

73
00:04:34,470 --> 00:04:40,100
the reality is, in a Tesla,
when the car is driving itself,

74
00:04:40,570 --> 00:04:44,220
the variability, if you remember
the deformable [unintelligible 00:04:44]

75
00:04:44,350 --> 00:04:47,680
you start doing a little bit more
of that, you start to

76
00:04:47,680 --> 00:04:51,630
reach back in the back seat,
in your purse, your bag,

77
00:04:51,630 --> 00:04:54,100
for your cell phone,
these kinds of things,

78
00:04:54,350 --> 00:04:58,870
that's when the crashes happen,
we to know how often that happens,

79
00:04:58,870 --> 00:05:01,500
the car needs to know
that you're in that position,

80
00:05:01,870 --> 00:05:05,470
that's critical for that
very serious moment

81
00:05:05,470 --> 00:05:07,740
when the actual crash happens,

82
00:05:09,310 --> 00:05:10,560
how do you do?

83
00:05:10,950 --> 00:05:15,450
This is deep learning class,
this is deep learning to the rescue,

84
00:05:16,490 --> 00:05:18,510
whenever you have
these kinds of tasks,

85
00:05:18,520 --> 00:05:21,140
of detecting for example
body poses,

86
00:05:21,170 --> 00:05:24,130
you're detecting points of the shoulders,
points of the head,

87
00:05:24,170 --> 00:05:27,630
five-ten points along the arms,
the skeleton.

88
00:05:29,820 --> 00:05:30,800
How do you do that?

89
00:05:30,800 --> 00:05:34,470
You have a CNN,
convolutional neural network,

90
00:05:34,770 --> 00:05:37,820
that takes its input image
and takes an output,

91
00:05:37,820 --> 00:05:40,430
it's a regressor,
it gives an XY position

92
00:05:40,430 --> 00:05:44,000
of whatever you're looking for,
the left shoulder, right shoulder,

93
00:05:44,120 --> 00:05:46,310
then you have a cascade
of regressors

94
00:05:46,940 --> 00:05:48,330
they give you all of these points,

95
00:05:48,330 --> 00:05:50,780
they give you the shoulders,
the arms and so on,

96
00:05:51,100 --> 00:05:53,820
then you have—
through time on

97
00:05:53,860 --> 00:05:56,110
every single frame
you make that prediction

98
00:05:57,320 --> 00:05:59,420
and then you optimize,

99
00:06:02,010 --> 00:06:04,640
you can make certain
assumptions about physics,

100
00:06:04,640 --> 00:06:08,580
your arm can't be in this place in one frame
and then the next frame

101
00:06:08,580 --> 00:06:10,600
be over here,
it moves smoothly

102
00:06:10,600 --> 00:06:13,120
through space
so under those constraints

103
00:06:13,230 --> 00:06:15,740
you can then minimize the error--

104
00:06:17,500 --> 00:06:19,050
the temporal error

105
00:06:19,240 --> 00:06:23,850
from frame to frame
or you can just dump all the frames,

106
00:06:23,850 --> 00:06:27,000
as if there are different channels
like RGB is three channels,

107
00:06:27,020 --> 00:06:29,150
you can think of those channels
as in time,

108
00:06:29,150 --> 00:06:31,290
you can dump
all those frames together,

109
00:06:31,400 --> 00:06:34,620
and that's what I call
3D convolutional neural networks,

110
00:06:34,650 --> 00:06:37,160
you've dumped them all together
and then you estimate

111
00:06:37,160 --> 00:06:40,150
the body pose
in all the frames at once.

112
00:06:42,680 --> 00:06:45,100
There are some data sets
for sports

113
00:06:45,640 --> 00:06:49,070
and we're building our own—
I don't know who that guy is—

114
00:06:51,440 --> 00:06:57,350
Let's fly through this a little bit,
so what's called gaze classification,

115
00:06:57,600 --> 00:07:00,200
gaze is another word for glance,

116
00:07:01,610 --> 00:07:03,770
it's a classification problem,

117
00:07:04,480 --> 00:07:07,960
here's one of the TAs for this class,

118
00:07:08,600 --> 00:07:11,960
Not here because he's married,
he had to be home,

119
00:07:12,680 --> 00:07:15,050
I know were his priorities are at,
this is on camera,

120
00:07:15,070 --> 00:07:17,830
he should be here,
[chuckles]

121
00:07:17,850 --> 00:07:18,880
There's five cameras,

122
00:07:18,890 --> 00:07:21,980
this is why we're recording in the Tesla.
This is a Tesla vehicle,

123
00:07:22,510 --> 00:07:25,370
in the bottom right,
there's a blue icon

124
00:07:25,370 --> 00:07:29,050
that lights up automatically detected
if it's operating under autopilot,

125
00:07:29,070 --> 00:07:31,450
that means the car is currently
driving itself,

126
00:07:31,450 --> 00:07:33,750
there's five cameras
one on the forward roadway,

127
00:07:33,750 --> 00:07:36,020
one on the instrument cluster,
one on the center stack,

128
00:07:36,030 --> 00:07:37,900
steering wheel,
his face,

129
00:07:37,950 --> 00:07:41,850
then it's a classification problem,
you dump the raw pixels

130
00:07:41,900 --> 00:07:46,820
into a convolutional neural network,
have six classes forward roadway,

131
00:07:46,820 --> 00:07:49,300
you're predicting
where the person is looking,

132
00:07:49,350 --> 00:07:51,930
forward roadway, left, right,

133
00:07:52,760 --> 00:07:54,760
center stack, instrument cluster,

134
00:07:54,770 --> 00:07:58,810
rearview mirror,
and you give millions of frames

135
00:07:58,810 --> 00:08:00,830
for every class, simple.

136
00:08:02,860 --> 00:08:06,200
And It does incredibly well at predicting

137
00:08:06,670 --> 00:08:11,610
where the driver is looking,
the process is the same for majority

138
00:08:11,610 --> 00:08:14,520
of the driver state problems
that have to do with the face,

139
00:08:14,550 --> 00:08:19,450
the face has so much information,
where are you looking, emotion,

140
00:08:19,470 --> 00:08:23,020
drowsiness,
different degrees of frustration,

141
00:08:23,020 --> 00:08:25,900
I'll fly through those as well,
but the process is the same,

142
00:08:25,970 --> 00:08:29,570
there's some pre-processing,
this is in the wild data,

143
00:08:29,620 --> 00:08:32,620
there's a lot of crazy light going on,
there's noises,

144
00:08:32,670 --> 00:08:35,770
vibration from the vehicle,
so first you have to—

145
00:08:35,800 --> 00:08:39,020
video stabilization
you have to remove all that vibration,

146
00:08:39,120 --> 00:08:43,200
all that noise, as best as you can,
there's a lot of algorithms,

147
00:08:43,300 --> 00:08:45,210
non-neural network algorithms,

148
00:08:47,040 --> 00:08:48,410
boring but they work

149
00:08:48,600 --> 00:08:51,930
for removing the noise,
removing the effects of

150
00:08:52,290 --> 00:08:55,650
sudden light variations and
vibrations of the vehicle,

151
00:08:55,670 --> 00:08:58,500
there's the automated calibration,
so you have to estimate

152
00:08:58,550 --> 00:09:01,470
the frame of the camera,
the position of the camera,

153
00:09:01,690 --> 00:09:05,720
and estimate the identity
of the person you're looking at.

154
00:09:06,120 --> 00:09:09,870
The more you can specialize the network
to the identity of the person

155
00:09:09,990 --> 00:09:12,610
and the identity of the car
the person is riding in,

156
00:09:12,650 --> 00:09:16,150
the better the performance for the
different driver state classification.

157
00:09:16,510 --> 00:09:19,290
So you personalize the network,
you have a background model

158
00:09:19,290 --> 00:09:22,050
that works on everyorne
and you specialize each individual,

159
00:09:22,050 --> 00:09:23,330
this is transfer learning,

160
00:09:23,360 --> 00:09:26,750
you specialize each individual network
to that one individual.

161
00:09:27,900 --> 00:09:30,080
There is a face frontalization,

162
00:09:30,800 --> 00:09:34,230
fancy name for the fact that
no matter where they're looking,

163
00:09:34,240 --> 00:09:36,400
you want to transfer that face
so the eyes,

164
00:09:36,470 --> 00:09:39,090
nose are the exact same position
in the image,

165
00:09:39,200 --> 00:09:41,480
that way if you want to look at the eyes

166
00:09:42,640 --> 00:09:45,300
and you want to study the subtle
movement of the eyes

167
00:09:45,320 --> 00:09:46,820
the subtle blinking,

168
00:09:47,020 --> 00:09:50,820
the dynamics of the eyelid,
the velocity of the eyelid,

169
00:09:50,960 --> 00:09:53,790
it's always in the same place
so you can really focus in

170
00:09:53,850 --> 00:09:57,020
remove all effects
of any other motion of the head,

171
00:09:58,376 --> 00:10:01,300
and then you just—
it's the beauty of deep learning,

172
00:10:01,948 --> 00:10:06,870
there is some pre-processing,
because this is real-world data,

173
00:10:06,930 --> 00:10:09,170
but you just dump the raw pixels in,

174
00:10:09,690 --> 00:10:12,720
you dump the raw pixels in and
predict whatever you need.

175
00:10:12,990 --> 00:10:13,800
What do you need?

176
00:10:13,980 --> 00:10:19,640
One is emotion, You can have—
I had a study where people

177
00:10:19,700 --> 00:10:24,180
used a crappy and a good voice
based navigation system,

178
00:10:24,320 --> 00:10:26,682
so the crappy one
got them really frustrated,

179
00:10:26,720 --> 00:10:29,600
and they self-reported it
as the frustrating experience or not

180
00:10:29,600 --> 00:10:32,112
on scale one to 10,
that gives us ground truth,

181
00:10:32,268 --> 00:10:34,900
a bunch of people to used this system,

182
00:10:36,200 --> 00:10:38,450
they put themselves as
frustrated or not,

183
00:10:38,460 --> 00:10:39,830
so then we can predict,

184
00:10:39,900 --> 00:10:42,367
we can train a Convolutional
neural network to predict

185
00:10:42,395 --> 00:10:45,800
is this person frustrated or not,
I think we've seen a video of that,

186
00:10:45,863 --> 00:10:49,650
turns out smiling is a strong
indication of frustration,

187
00:10:49,797 --> 00:10:52,170
you can also predict
drowsiness in this way,

188
00:10:53,140 --> 00:10:56,050
gaze estimation in this way,
cognitive load,

189
00:10:56,440 --> 00:10:59,620
I'll briefly look at that,
the process is all the same,

190
00:10:59,700 --> 00:11:02,898
you detect the face, you find the
landmark points in the face, 

191
00:11:02,922 --> 00:11:05,470
for the face alignment,
face frontalization,

192
00:11:06,180 --> 00:11:10,136
and then you dump the raw pixels in
for classification, step five.

193
00:11:10,230 --> 00:11:11,600
You can use SVM's there

194
00:11:11,656 --> 00:11:13,950
or you can use what
everyone uses now,

195
00:11:13,950 --> 00:11:15,610
convolutional neural networks.

196
00:11:18,080 --> 00:11:21,887
This is the one part where CNN's
still struggle to compete,

197
00:11:22,315 --> 00:11:24,150
is the alignment problem,

198
00:11:25,390 --> 00:11:28,220
this is why I talked about
the Cascade regressors,

199
00:11:28,700 --> 00:11:37,720
is finding the landmarks
on the eyebrows, the nose,

200
00:11:37,720 --> 00:11:42,570
the jawline, the mouth,
there are certain constraints there,

201
00:11:42,890 --> 00:11:47,195
so algorithms that can utilize those
constraints effectively

202
00:11:47,450 --> 00:11:50,969
can often perform better than 
end-to-end regressors

203
00:11:50,980 --> 00:11:54,814
that just don't have any concept
of what a face is shaped like.

204
00:11:55,490 --> 00:11:58,100
There are huge data sets
and we're a part

205
00:11:59,280 --> 00:12:02,000
of the awesome community
that's building those data sets

206
00:12:02,050 --> 00:12:03,647
for face alignment.

207
00:12:04,520 --> 00:12:07,260
This is the TA in its younger form,

208
00:12:10,357 --> 00:12:12,830
this is live in the car,

209
00:12:12,850 --> 00:12:16,500
the real time system predicting
where they're looking,

210
00:12:18,190 --> 00:12:24,190
this is taking slow steps
towards the exciting direction

211
00:12:24,330 --> 00:12:27,600
that machine learning is headed,
which is unsupervised learning,

212
00:12:28,028 --> 00:12:31,620
the less you have
to have humans look to the data

213
00:12:31,620 --> 00:12:33,068
and annotate that data,

214
00:12:33,256 --> 00:12:37,129
the more power these machine
learning algorithms get, 

215
00:12:39,157 --> 00:12:41,760
currently supervised learning
is what's needed,

216
00:12:41,778 --> 00:12:45,250
you need human beings to label
a cat and label a dog,

217
00:12:46,009 --> 00:12:49,901
if you can only have a
human being label 1%, 

218
00:12:50,541 --> 00:12:54,470
one tenth of a percent
of a data set, only the hard cases,

219
00:12:54,498 --> 00:12:56,670
so the machine can come
to the human and be like,

220
00:12:56,670 --> 00:12:59,970
I don't know what I'm
looking at in these pictures,

221
00:13:00,140 --> 00:13:02,250
because of the partial
light occlusions,

222
00:13:02,310 --> 00:13:05,070
we're not good
at dealing with occlusions,

223
00:13:05,390 --> 00:13:07,900
whether it's your own arm
or because of light conditions,

224
00:13:07,950 --> 00:13:09,400
we're not good with

225
00:13:10,110 --> 00:13:12,940
crazy light
drowning out the image,

226
00:13:13,100 --> 00:13:15,290
this is what Google self-driving cars
struggle with

227
00:13:15,290 --> 00:13:17,220
when they're trying
to use their vision sensors,

228
00:13:17,520 --> 00:13:18,960
moving out of frame,

229
00:13:20,010 --> 00:13:22,687
all kinds of occlusion They are really hard

230
00:13:23,610 --> 00:13:25,520
for computer vision algorithms,

231
00:13:26,200 --> 00:13:30,075
and in those cases we want a machine
to step in and say--

232
00:13:30,350 --> 00:13:34,122
and pass that image on to the human,
be like "help me out with this"

233
00:13:34,800 --> 00:13:38,550
and the other corner case is,
in driving for example

234
00:13:38,600 --> 00:13:41,054
90 plus percent of the time
all you're doing is

235
00:13:41,090 --> 00:13:42,978
staring forward at the roadway
the same way,

236
00:13:43,025 --> 00:13:44,809
that's where the Machine shines,

237
00:13:44,950 --> 00:13:48,847
that's where machine automated
annotation shines,

238
00:13:49,360 --> 00:13:51,228
because it's seen that face

239
00:13:51,810 --> 00:13:54,050
for hundreds of millions
of frames already,

240
00:13:54,090 --> 00:13:55,463
in that exact position,

241
00:13:55,630 --> 00:13:58,037
so it can do all the hard work
of annotation for you,

242
00:13:58,280 --> 00:14:00,922
it's in the transition away from those positions

243
00:14:00,950 --> 00:14:02,564
that it needs a little bit of help,

244
00:14:02,610 --> 00:14:06,400
just to make sure that this person
just started looking away

245
00:14:06,530 --> 00:14:10,470
from the road to the rear view,
and you bring those points up,

246
00:14:10,470 --> 00:14:13,800
so you're-- there's a—
using optical flow,

247
00:14:13,820 --> 00:14:17,500
putting the optical flow
in the convolutional neural network,

248
00:14:18,040 --> 00:14:21,720
you use that to predict
when something has changed

249
00:14:21,910 --> 00:14:25,303
when something has changed you bring
that to the machine for annotation

250
00:14:25,320 --> 00:14:27,962
all of this is to build a giant—

251
00:14:28,700 --> 00:14:32,870
Billions of frames annotated data set,
our ground truth,

252
00:14:33,317 --> 00:14:36,970
on which you train your
driver state algorithms,

253
00:14:37,717 --> 00:14:40,420
in this way you can control,
on the x-axis

254
00:14:40,420 --> 00:14:43,200
is the fraction of frames
the human has to annotate,

255
00:14:43,470 --> 00:14:47,120
zero percent on the Left,
ten percent on the right,

256
00:14:47,570 --> 00:14:51,040
and then the accuracy trade-off,
the more the human annotates,

257
00:14:51,040 --> 00:14:53,820
the higher the accuracy,
you approach 100% accuracy,

258
00:14:54,280 --> 00:14:55,491
but you can still do pretty good,

259
00:14:55,524 --> 00:15:00,000
this is for the gaze classification task,

260
00:15:02,748 --> 00:15:06,860
With an 84-- 84 fold to almost towards

261
00:15:06,860 --> 00:15:09,500
the magnitude reduction
in human annotation,

262
00:15:09,570 --> 00:15:11,800
this is the future
of machine learning,

263
00:15:12,380 --> 00:15:15,470
and hopefully one day
no human annotation,

264
00:15:20,330 --> 00:15:25,520
and the result is millions of images
like these video frames,

265
00:15:26,580 --> 00:15:30,120
same thing, driver frustration,
this is what I was talking about,

266
00:15:30,120 --> 00:15:33,020
the frustrated driver
is the one that's on the bottom,

267
00:15:35,060 --> 00:15:36,620
so a lot of movement
of the eyebrows

268
00:15:36,680 --> 00:15:40,597
and a lot of smiling, and that's
true subject after the subject,

269
00:15:41,010 --> 00:15:43,980
And they're Happy, the satisfied,
I don't want to say happy,

270
00:15:43,980 --> 00:15:47,505
the satisfied driver is
cold and stoic,

271
00:15:48,032 --> 00:15:50,305
and that's true for
subject after subject,

272
00:15:50,400 --> 00:15:53,270
because driving is a boring experience
and you want it to stay that way

273
00:15:53,300 --> 00:15:54,583
Yes, question.

274
00:15:58,334 --> 00:16:02,710
Great, great question,
they're not-- 

275
00:16:03,520 --> 00:16:05,374
Absolutely, that's a great question

276
00:16:06,540 --> 00:16:10,032
So these cars owned by MIT,
there is somebody in the back—

277
00:16:18,254 --> 00:16:19,341
The comment was—

278
00:16:19,402 --> 00:16:23,336
my emotions then have nothing to
do with the driving experience.

279
00:16:23,790 --> 00:16:28,170
Yes, let me continue that comment,
your emotions are often—

280
00:16:29,800 --> 00:16:32,650
You're an actor on the stage
for others with your emotion,

281
00:16:32,840 --> 00:16:35,470
when you're alone,
you might not express emotion,

282
00:16:35,740 --> 00:16:39,120
you're really expressing emotion
oftentimes for others,

283
00:16:39,150 --> 00:16:41,720
your frustration is like
"What the heck"

284
00:16:41,930 --> 00:16:44,870
that's for the passenger,
and that's absolutely right,

285
00:16:44,960 --> 00:16:49,770
so one of the cool things
we're doing—

286
00:16:49,800 --> 00:16:53,360
As I said, we now have over a billion
video frames in the Tesla,

287
00:16:53,430 --> 00:16:56,531
We're starting to collected huge
amounts of data in the Tesla,

288
00:16:56,578 --> 00:16:59,600
emotion is a complex thing,

289
00:16:59,849 --> 00:17:00,880
in this case, 

290
00:17:00,880 --> 00:17:03,590
we know the ground truth,
how frustrated they were,

291
00:17:03,630 --> 00:17:06,658
in naturalistic data, when it's just
people driving around, 

292
00:17:06,690 --> 00:17:09,821
we don't know how they're
really feeling at the moment,

293
00:17:09,850 --> 00:17:13,170
we're not asking to enter an app
"how are you feeling right now?"

294
00:17:14,120 --> 00:17:18,850
but we do know certain things,
we know that people sing a lot,

295
00:17:20,620 --> 00:17:22,660
that has to be on paper
at some point,

296
00:17:22,660 --> 00:17:24,900
it's awesome,
people love singing,

297
00:17:25,680 --> 00:17:28,050
so that doesn't happen
in this kind of data,

298
00:17:28,050 --> 00:17:29,550
because there's somebody
singing in the car,

299
00:17:29,700 --> 00:17:32,670
and I think the expression
of frustration is also the same.

300
00:17:44,800 --> 00:17:48,450
Yes. The question is—
or the comment is that

301
00:17:48,900 --> 00:17:52,244
the solo data set is probably
going to be very different 

302
00:17:52,300 --> 00:17:55,331
from a data set that's not solo, with a passenger,

303
00:17:55,355 --> 00:17:57,980
that's very true,
the tricky thing about driving 

304
00:17:58,010 --> 00:18:00,894
this is why it's a huge challenge
for self-driving cars

305
00:18:00,930 --> 00:18:02,268
for the external facing sensors

306
00:18:02,290 --> 00:18:05,825
and for the internal facing sensors
analyzing human behavior,

307
00:18:05,896 --> 00:18:11,300
is 99.9% of driving is the same thing,
it's really boring.

308
00:18:11,369 --> 00:18:14,750
So finding the interesting bits
is actually pretty complicated,

309
00:18:14,780 --> 00:18:18,350
so that has to do with emotion,
that has to do with—

310
00:18:18,520 --> 00:18:22,250
so singing is easy to find,
we can track the mouth pretty well,

311
00:18:22,270 --> 00:18:24,503
so when you're talking of singing
we can find that,

312
00:18:24,530 --> 00:18:27,130
but how do you find
the subtle expressions of emotion?

313
00:18:27,260 --> 00:18:31,120
It's hard, when you're solo.

314
00:18:32,450 --> 00:18:38,580
Cognitive load,
that's a fascinating thing,

315
00:18:38,580 --> 00:18:42,020
I mean, similar emotion
it's a little more concrete

316
00:18:43,240 --> 00:18:47,454
in a sense that there's good science
and ways to measure cognitive load,

317
00:18:47,530 --> 00:18:50,750
cognitive workload,
how occupied your mind is,

318
00:18:51,228 --> 00:18:53,300
mental workload
is another term used,

319
00:18:54,620 --> 00:18:55,948
the window to the soul,

320
00:18:55,967 --> 00:18:59,872
the cognitive workload soul
is the eyes, 

321
00:18:59,890 --> 00:19:01,360
so pupil—

322
00:19:02,080 --> 00:19:04,451
first of all the eyes move in
two different ways

323
00:19:04,480 --> 00:19:07,656
they move in a lot of ways but 
two major ways is saccades,

324
00:19:07,689 --> 00:19:10,480
these are these ballistic movements,
they jump around whenever

325
00:19:10,480 --> 00:19:14,030
you look around the room,
they're actually just jumping around,

326
00:19:14,030 --> 00:19:16,352
when you read
the eyes are jumping around,

327
00:19:18,145 --> 00:19:21,345
Like if all of you just follow
this bottle with your eyes,

328
00:19:21,370 --> 00:19:23,778
your eyes are actually going 
to move smoothly, 

329
00:19:23,790 --> 00:19:25,082
a smooth pursuit.

330
00:19:25,120 --> 00:19:26,748
Somebody actually told me today,

331
00:19:26,760 --> 00:19:30,997
that probably has to do with our 
hunting background as animals,

332
00:19:33,080 --> 00:19:37,450
I don't know how that helps,
like frogs track flies really well,

333
00:19:37,470 --> 00:19:41,230
so you have to like—
Anyway, the point is

334
00:19:41,251 --> 00:19:44,940
there are smooth pursuit movements
where the eyes move smoothly,

335
00:19:45,340 --> 00:19:49,000
and those are all indications
of certain aspects of cognitive load,

336
00:19:49,060 --> 00:19:51,500
and then there are
these very subtle movements,

337
00:19:51,620 --> 00:19:53,880
which are almost imperceptible
for computer vision

338
00:19:53,940 --> 00:19:58,370
and these are micro saccades,
these are tremors of the eye,

339
00:20:00,600 --> 00:20:02,420
a work from here,
from Bill Freeman,

340
00:20:02,420 --> 00:20:08,070
magnifying those subtle movements,
these are taken at 500 frames a second.

341
00:20:12,770 --> 00:20:14,920
So cognitive load—

342
00:20:16,370 --> 00:20:17,520
when the pupil,

343
00:20:17,543 --> 00:20:18,870
that black dot in the middle,

344
00:20:18,889 --> 00:20:20,720
in case you don't know what a pupil is,

345
00:20:20,743 --> 00:20:22,117
in the middle of the eye,

346
00:20:22,150 --> 00:20:25,863
when it gets larger that's an indicative
of high cognitive load,

347
00:20:25,920 --> 00:20:29,223
but it also gets larger 
when the light is dim.

348
00:20:29,265 --> 00:20:31,270
So there's this complex interplay,

349
00:20:31,290 --> 00:20:33,670
so we can't rely in the wild outside,

350
00:20:33,816 --> 00:20:36,865
in the car, or just in general outdoors,

351
00:20:37,195 --> 00:20:38,760
using the pupil size,

352
00:20:38,781 --> 00:20:40,880
even though pupil size
has been used effectively

353
00:20:40,890 --> 00:20:44,950
in a lab to measure cognitive load,
it can't be reliably used in the car,

354
00:20:45,100 --> 00:20:49,940
the same with blinks,
when there's a high cognitive load,

355
00:20:49,940 --> 00:20:53,223
your blink rate decreases
and your blink duration shortens,

356
00:20:55,320 --> 00:20:58,620
I think I'm just repeating
the same thing over and over,

357
00:20:58,750 --> 00:21:02,470
but you can imagine
how we can predict cognitive load,

358
00:21:03,350 --> 00:21:05,976
We extract a video of the eye.

359
00:21:07,265 --> 00:21:13,450
Here is the primary eye of the person
the system is observing,

360
00:21:14,220 --> 00:21:16,950
happens to be the same TA once again.

361
00:21:22,200 --> 00:21:27,400
We take the sequence of 100--
it's 90 images, that's six seconds,

362
00:21:27,400 --> 00:21:30,870
16 frames a second,
15 frames a second,

363
00:21:30,870 --> 00:21:34,970
we dump that into a 3D
convolutional neural network,

364
00:21:35,020 --> 00:21:42,400
that means it's 90 channels,
it's 90 frames, grayscale,

365
00:21:42,450 --> 00:21:47,120
and then the prediction is one of
three classes of cognitive load,

366
00:21:47,741 --> 00:21:51,210
low cognitive load, medium cognitive
load and high cognitive load,

367
00:21:51,250 --> 00:21:53,948
there's ground truth for that,
because we have people--

368
00:21:53,950 --> 00:21:57,030
over 500 different people
do different tasks

369
00:21:57,072 --> 00:22:01,420
of various cognitive load,
and after some frontalization again,

370
00:22:01,720 --> 00:22:06,980
where you see the eyes are traced
no matter where the person looking,

371
00:22:06,980 --> 00:22:09,552
the image of the face is
transposed in such a way that

372
00:22:09,576 --> 00:22:13,040
the corner of the eyes remain
always in the same position,

373
00:22:13,820 --> 00:22:18,450
after the frontalization,
we find the eye,

374
00:22:18,663 --> 00:22:28,070
active appearance models,
find 39 points of the eyelids, the iris,

375
00:22:28,070 --> 00:22:30,000
and four points on the pupil.

376
00:22:33,140 --> 00:22:35,877
Putting all of that into a 3D CNN model,

377
00:22:36,550 --> 00:22:41,087
they're positioned,eye sequence on the left,
3D CNN model in the middle,

378
00:22:41,289 --> 00:22:43,570
cognitive load prediction
on the right.

379
00:22:43,623 --> 00:22:48,220
This code by the way
is freely available online.

380
00:22:50,136 --> 00:22:52,447
All you have to do,
dump a web-cam

381
00:22:54,440 --> 00:22:58,541
from the video stream,
CNN runs faster than real-time,

382
00:22:58,630 --> 00:23:00,061
predicts cognitive load.

383
00:23:01,240 --> 00:23:04,089
Same process as detecting
the identity of the face,

384
00:23:04,090 --> 00:23:06,785
same process as detecting where
the driver is looking,

385
00:23:06,814 --> 00:23:09,072
same process as detecting emotion

386
00:23:09,152 --> 00:23:11,330
and all of those
require very little

387
00:23:11,330 --> 00:23:14,820
hyper parameter tuning on
the convolutional neural networks,

388
00:23:15,120 --> 00:23:19,120
they only require
huge amounts of data.

389
00:23:20,270 --> 00:23:24,200
Why do we care about detecting
what the drivers doing?

390
00:23:24,210 --> 00:23:29,011
I think Eric has mentioned this is--

391
00:23:30,291 --> 00:23:34,640
On the-- Oh man, this is the comeback of the slide,

392
00:23:35,138 --> 00:23:36,640
[laughter]

393
00:23:39,000 --> 00:23:42,442
I was criticized for this being
a very cheesy slide,

394
00:23:43,505 --> 00:23:50,220
in the past towards full automation,

395
00:23:52,020 --> 00:23:56,350
we're likely to take
gradual steps towards that.

396
00:23:57,500 --> 00:24:00,270
I can't, it's enough of that,
this is better—

397
00:24:02,320 --> 00:24:09,557
Especially given that—
This is given today,

398
00:24:09,990 --> 00:24:14,070
our new president,
this is a pickup truck country,

399
00:24:18,010 --> 00:24:20,715
this is a manually
controlled vehicle country,

400
00:24:20,809 --> 00:24:23,700
for quite a little while,
we like control

401
00:24:24,400 --> 00:24:28,983
and control being given
to somebody else,

402
00:24:29,007 --> 00:24:31,430
to the machine,
will be a gradual process,

403
00:24:31,700 --> 00:24:34,900
it's a gradual process of that 
machine earning trust,

404
00:24:35,170 --> 00:24:37,905
and through that process,
the machine,

405
00:24:38,100 --> 00:24:40,851
like the Tesla, like the BMW,

406
00:24:40,983 --> 00:24:43,100
like the Mercedes, the Volvo,

407
00:24:43,120 --> 00:24:45,407
that's now playing with these ideas,

408
00:24:46,122 --> 00:24:49,320
it's going to need to see
what the human is doing,

409
00:24:53,501 --> 00:24:58,200
and for that, to see what
the human is doing,

410
00:24:58,620 --> 00:25:05,350
we have billions of miles of
forward-facing data, what we need,

411
00:25:05,383 --> 00:25:09,010
is billions of miles of
driver facing data as well.

412
00:25:09,915 --> 00:25:12,258
We're in the process of
collecting that,

413
00:25:12,950 --> 00:25:19,770
this is a pitch for automakers
and everybody to buy cars

414
00:25:19,770 --> 00:25:22,250
that have a driver facing camera.

415
00:25:24,750 --> 00:25:28,720
And let me close--

416
00:25:28,720 --> 00:25:34,611
I said we need a lot of data but
I think this class has been—

417
00:25:36,560 --> 00:25:41,960
through your own research you'll find
that we're in the very early stages

418
00:25:43,670 --> 00:25:47,312
of discovering the power
of deep learning,

419
00:25:49,134 --> 00:25:54,329
for example, recently,
 Jean [?] said

420
00:25:56,070 --> 00:26:00,884
that it seems that
the deeper the network,

421
00:26:01,007 --> 00:26:06,400
the better the results
in a lot of really important cases,

422
00:26:07,480 --> 00:26:10,020
even though the data
is not increasing,

423
00:26:10,850 --> 00:26:14,550
why does the deeper network
give better results?

424
00:26:14,700 --> 00:26:17,030
This is a mysterious thing
we don't understand,

425
00:26:17,030 --> 00:26:20,650
there's these hundreds of millions
of parameters,

426
00:26:20,800 --> 00:26:25,350
from them is emerging 
some kind of structure,

427
00:26:25,360 --> 00:26:28,555
some kind of representation of the
knowledge that we're giving it.

428
00:26:29,490 --> 00:26:33,011
One of my favorite examples
of this emergent concept

429
00:26:33,210 --> 00:26:35,472
is the Conway's Game of Life.

430
00:26:38,461 --> 00:26:41,450
For those of you who
knows what this is,

431
00:26:41,570 --> 00:26:44,080
will probably criticize me
for being as cheesy

432
00:26:44,117 --> 00:26:49,160
as the stairway slide,
but I think it's such a simple

433
00:26:49,210 --> 00:26:52,912
and brilliant example
of how-- 

434
00:26:53,420 --> 00:26:55,120
Like a neuron in a neural network

435
00:26:55,130 --> 00:26:57,407
is a really simple computational unit,

436
00:26:57,887 --> 00:27:01,330
and then incredible power emerges
when you combine a lot of them

437
00:27:01,370 --> 00:27:03,595
in a network,
in the same way,

438
00:27:04,423 --> 00:27:07,400
this is called 
the cellular automata,

439
00:27:07,487 --> 00:27:09,420
that's a weird pronunciation,

440
00:27:12,687 --> 00:27:15,807
every single cells is operating
under a simple rule,

441
00:27:15,870 --> 00:27:18,983
you can think of it as 
a cell living and dying,

442
00:27:19,228 --> 00:27:22,230
it's filled in black when it's alive

443
00:27:22,250 --> 00:27:26,969
and white when it's dead,
 if it's alive

444
00:27:27,430 --> 00:27:31,482
and it has two or three neighbors,
it survives to the next time,

445
00:27:32,903 --> 00:27:34,660
otherwise it dies,

446
00:27:35,350 --> 00:27:41,120
and if it has exactly three neighbors,
and it's dead,

447
00:27:41,120 --> 00:27:43,650
it comes back to life,
if it has exactly three neighbors,

448
00:27:43,650 --> 00:27:46,020
that's a simple rule,
whatever,

449
00:27:46,040 --> 00:27:47,660
you can just imagine,
it's just simple—

450
00:27:47,660 --> 00:27:52,000
All is doing, is operating under
this very local process,

451
00:27:52,202 --> 00:27:53,736
same as a neuron.

452
00:27:55,170 --> 00:27:56,960
It's a—
or in the way

453
00:27:56,960 --> 00:27:58,850
we're currently training
neural networks

454
00:27:59,200 --> 00:28:01,727
and there's this local gradient,

455
00:28:01,910 --> 00:28:05,790
we're optimizing over a local gradient,
the same local rules,

456
00:28:06,150 --> 00:28:09,950
and what happens
if you run this system,

457
00:28:10,600 --> 00:28:14,900
operating under really local rules,
what you get on the right,

458
00:28:15,100 --> 00:28:18,470
it's not—
Again, you have to go home,

459
00:28:19,370 --> 00:28:23,388
hopefully no drugs involved,
but you have to open up your mind

460
00:28:24,320 --> 00:28:25,077
[chuckles]

461
00:28:25,360 --> 00:28:27,618
and see how amazing that is,

462
00:28:27,741 --> 00:28:32,920
because what happens is,
it's a local computational unit,

463
00:28:32,950 --> 00:28:35,500
that knows very little
about the world,

464
00:28:35,700 --> 00:28:39,630
but somehow really
complex patterns emerge

465
00:28:39,630 --> 00:28:44,020
and we don't understand why,
in fact under different rules,

466
00:28:44,050 --> 00:28:46,640
incredible patterns emerge,
and it feels like

467
00:28:46,640 --> 00:28:51,500
it's living creatures communicating,
when you just watch it,

468
00:28:51,550 --> 00:28:55,270
not these examples,
this is the original,

469
00:28:55,300 --> 00:28:58,920
they get complex and interesting,
but even in these examples,

470
00:28:58,950 --> 00:29:01,140
these complex geometric
patterns that emerge,

471
00:29:01,140 --> 00:29:03,020
it's incredible,
we don't understand why,

472
00:29:03,050 --> 00:29:05,270
same with neural networks,
we don't understand why,

473
00:29:05,270 --> 00:29:09,500
and we need to in order to see how
these networks will be able to reason.

474
00:29:10,400 --> 00:29:12,850
What's next?

475
00:29:12,850 --> 00:29:17,720
I encourage you to read
the deep learning book,

476
00:29:18,070 --> 00:29:21,181
it's available online,
deeplearningbook.org.

477
00:29:21,870 --> 00:29:24,450
As I mentioned to a few people,
you should--

478
00:29:24,450 --> 00:29:26,470
Well, first there's a ton 
of amazing papers

479
00:29:26,470 --> 00:29:28,170
every day coming out on archive,

480
00:29:29,620 --> 00:29:31,250
I'll put these links up,

481
00:29:31,250 --> 00:29:34,870
but there's a lot of good 
collections of strong papers,

482
00:29:34,870 --> 00:29:38,580
lists of papers, there is 
the literally awesome list,

483
00:29:38,580 --> 00:29:41,720
the awesome deep learning 
papers on GitHub,

484
00:29:41,720 --> 00:29:45,350
it's calling itself awesome,
but it happens to be awesome,

485
00:29:45,920 --> 00:29:50,050
there is a lot of blogs,
it's just amazing,

486
00:29:50,420 --> 00:29:53,450
that's how I recommend you
learn machine learning,

487
00:29:53,550 --> 00:29:57,900
on blogs,
and if you're interested

488
00:29:58,220 --> 00:30:00,970
in the application of deep learning
in the automotive space,

489
00:30:01,170 --> 00:30:03,970
you can come and do 
research in our group,

490
00:30:04,500 --> 00:30:05,920
just email me.

491
00:30:07,570 --> 00:30:09,570
Anyway, we have three winners,

492
00:30:13,220 --> 00:30:16,000
Jeffrey Hu, Michael Gump

493
00:30:17,820 --> 00:30:20,120
how  do you-- Are you here?

494
00:30:21,700 --> 00:30:23,150
How do you say your name?

495
00:30:24,644 --> 00:30:29,411
No, that's not my name
[laughter]

496
00:30:29,420 --> 00:30:34,320
My name is Purna [?]

497
00:30:36,291 --> 00:30:37,058
Oh, I see.
[?]

498
00:30:43,750 --> 00:30:45,150
Well, anyway here--

499
00:30:48,240 --> 00:30:55,628
[applause]

500
00:30:56,350 --> 00:31:04,174
He achieved the stunning speed of--
So this is kind of incredible,

501
00:31:04,207 --> 00:31:05,230
I didn't know
what kind of speed

502
00:31:05,230 --> 00:31:08,550
we were going to be able to achieve,
I thought 73 was unbeatable,

503
00:31:08,550 --> 00:31:09,800
because we played with it
for a while

504
00:31:09,930 --> 00:31:13,150
and we couldn't achieve 73,
we design a deterministic algorithm

505
00:31:13,150 --> 00:31:15,860
that was able to achieve 74
I believe,

506
00:31:16,870 --> 00:31:19,120
meaning like it's cheating,
with the cheating algorithm

507
00:31:19,120 --> 00:31:23,730
that got 74,
folks have come up

508
00:31:24,220 --> 00:31:27,750
with algorithms that have done—
that had beaten 73

509
00:31:27,750 --> 00:31:30,260
and then 74,
so this is really incredible,

510
00:31:30,260 --> 00:31:33,050
and the other two guys—
all three of you

511
00:31:33,050 --> 00:31:38,381
get a free term at the Udacity
self-driving car engineering degree,

512
00:31:38,508 --> 00:31:42,287
Thanks to those guys
for giving that award

513
00:31:42,560 --> 00:31:44,990
and bringing their army of brilliant—

514
00:31:45,200 --> 00:31:47,350
So they have people
who are obsessed about

515
00:31:47,350 --> 00:31:50,910
self-driving cars,
and we've received

516
00:31:50,910 --> 00:31:54,990
over 2,000 submissions
for this competition,

517
00:31:54,990 --> 00:31:58,790
a lot of them from those guys,
they're just brilliant,

518
00:31:58,790 --> 00:32:03,090
it's really exciting to have
such a big community

519
00:32:03,090 --> 00:32:06,350
of deep learning folks
working in this field,

520
00:32:06,350 --> 00:32:10,600
this is for the rest of eternity,
we're going to

521
00:32:10,800 --> 00:32:12,890
change this up a little bit,
but this is actually

522
00:32:12,890 --> 00:32:18,370
the three neural networks,
the three winning neural networks

523
00:32:18,370 --> 00:32:20,740
running side by side,
you can see

524
00:32:20,740 --> 00:32:24,860
the number of cars passed there,
the first place is on the left,

525
00:32:25,400 --> 00:32:28,030
second place, and third place,
and in fact,

526
00:32:28,030 --> 00:32:29,860
the third place it's almost--

527
00:32:29,860 --> 00:32:33,000
right now, second place 
is winning currently,

528
00:32:33,880 --> 00:32:40,800
but that just tells you
the random nature of competition,

529
00:32:40,970 --> 00:32:43,472
sometimes you win,
sometimes loose.

530
00:32:47,240 --> 00:32:52,070
The actual evaluation process
runs through a lot of iterations

531
00:32:52,070 --> 00:32:54,700
and takes the medium evaluation.

532
00:32:56,531 --> 00:32:59,468
With that, let me thank you 
guys so much for—

533
00:32:59,470 --> 00:33:01,460
Wait, we have a question—

534
00:33:01,980 --> 00:33:04,930
are the winning networks online?

535
00:33:05,420 --> 00:33:06,660
Yes.

536
00:33:07,870 --> 00:33:11,160
All three guys
wrote me a note

537
00:33:11,160 --> 00:33:15,618
about how their networks work,
I did not read that note,

538
00:33:15,660 --> 00:33:17,529
[chuckles]

539
00:33:17,630 --> 00:33:20,729
I'll post—This tells you how
crazy this has been,

540
00:33:21,190 --> 00:33:27,444
I'll post the winning networks online,

541
00:33:28,020 --> 00:33:30,432
and I encourage you to
continue competing

542
00:33:30,960 --> 00:33:32,870
and continue submitting networks.

543
00:33:32,890 --> 00:33:36,362
This will run for a while we're
working on a journal paper

544
00:33:36,680 --> 00:33:40,061
for this game.

545
00:33:41,170 --> 00:33:43,689
We're trying to find the
optimal solutions.

546
00:33:44,037 --> 00:33:48,060
Okay. This is the first time
I've ever taught a class,

547
00:33:48,250 --> 00:33:51,850
and the first time obviously
teaching this class,

548
00:33:51,860 --> 00:33:55,530
so thank you so much
for being a part of it.

549
00:33:55,530 --> 00:34:01,670
[Applause]
Thank you to Eric,

550
00:34:04,847 --> 00:34:07,025
if you didn't get a shirt
please come back,

551
00:34:07,250 --> 00:34:11,900
please come down and get a shirt,
just write your email on the note,

552
00:34:11,900 --> 00:34:15,210
on the on the index note.
Thank you.

