1
00:00:00,140 --> 00:00:04,970
好的，大家好，欢迎回来 

2
00:00:02,370 --> 00:00:12,120
很高兴你回来了 

3
00:00:04,970 --> 00:00:15,900
今天我们将推出第一个教程 

4
00:00:12,120 --> 00:00:18,900
第一个项目是深度交通代码 

5
00:00:15,900 --> 00:00:22,740
名为深流量在您的任务是 

6
00:00:18,900 --> 00:00:26,279
用深度解决交通问题

7
00:00:22,740 --> 00:00:27,930
强化学习， 我会说 

8
00:00:26,279 --> 00:00:30,630
关于设计a的内容

9
00:00:27,930 --> 00:00:33,210
网络那里你如何提交自己的 

10
00:00:30,630 --> 00:00:37,440
网络你如何参与 

11
00:00:33,210 --> 00:00:41,360
竞争正如我所说，获胜者得到了一个

12
00:00:37,440 --> 00:00:45,090
非常特别的奖项将在稍后公布 

13
00:00:41,360 --> 00:00:47,579
什么是机器学习几种 类型 

14
00:00:45,090 --> 00:00:50,039
他们像我一样受到监督学习 

15
00:00:47,579 --> 00:00:53,340
昨天提到那是什么意思 

16
00:00:50,039 --> 00:00:55,050
通常在你讨论 谈话时 

17
00:00:53,340 --> 00:00:57,510
关于机器学习 和谈论它 

18
00:00:55,050 --> 00:01:00,930
连续监督学习需要 

19
00:00:57,510 --> 00:01:03,329
一个数据集你知道的基础 

20
00:01:00,930 --> 00:01:07,260
真相你知道输入和 

21
00:01:03,329 --> 00:01:09,740
输出，你提供 给一个 

22
00:01:07,260 --> 00:01:12,600
机器学习算法 以便 

23
00:01:09,740 --> 00:01:14,340
学习输入和输入之间的映射 

24
00:01:12,600 --> 00:01:17,909
以这种方式输出你可以 

25
00:01:14,340 --> 00:01:19,009
概括为进一步的例子

26
00:01:17,909 --> 00:01:22,580
未来 

27
00:01:19,009 --> 00:01:26,400
无监督学习是另一方面 

28
00:01:22,580 --> 00:01:30,900
当你完全 不 知道的时候

29
00:01:26,400 --> 00:01:32,729
关于数据真实性的输出 

30
00:01:30,900 --> 00:01:37,110
你正在 与所有人 一起工作的 是 

31
00:01:32,729 --> 00:01:40,140
数据，你必须找到潜在的 

32
00:01:37,110 --> 00:01:43,320
结构的基本表示

33
00:01:40,140 --> 00:01:45,060
对 您 有意义的数据

34
00:01:43,320 --> 00:01:49,320
完成某项任务 

35
00:01:45,060 --> 00:01:54,000
是半监督数据还是只有 

36
00:01:49,320 --> 00:01:56,009
部分通常非常小的 量 的具有 

37
00:01:54,000 --> 00:01:59,070
被标记为 基本 事实 

38
00:01:56,009 --> 00:02:02,549
仅适用于小部分 

39
00:01:59,070 --> 00:02:05,040
你会想到 外面 的 图像 

40
00:02:02,549 --> 00:02:07,229
在 互联网上然后你想 

41
00:02:05,040 --> 00:02:11,250
关于图像网络每个数据集 

42
00:02:07,229 --> 00:02:14,010
图像标记为该图像的大小 

43
00:02:11,250 --> 00:02:17,939
该数据集 是一个很小的子集 

44
00:02:14,010 --> 00:02:21,870
可用的所有图像

45
00:02:17,939 --> 00:02:23,760
在线，但这是我们正在处理的任务 

46
00:02:21,870 --> 00:02:27,319
与人类 一样 

47
00:02:23,760 --> 00:02:33,329
有兴趣做 机器学习的是 

48
00:02:27,319 --> 00:02:36,180
如何扩大那个的大小 

49
00:02:33,329 --> 00:02:39,840
我们知道的一些数据

50
00:02:36,180 --> 00:02:43,170
自信地和强化 

51
00:02:39,840 --> 00:02:48,680
学习坐落 在 它 之间 的 某个地方 

52
00:02:43,170 --> 00:02:48,680
这是半监督学习的地方 

53
00:02:49,220 --> 00:02:58,170
有一个必须存在的代理人

54
00:02:51,989 --> 00:03:01,409
世界和 那个代理人知道 输入 

55
00:02:58,170 --> 00:03:05,159
世界提供但却非常了解 

56
00:03:01,409 --> 00:03:09,239
除了通过之外，关于那个 世界 

57
00:03:05,159 --> 00:03:12,659
这是偶然的延迟 奖励 

58
00:03:09,239 --> 00:03:15,569
是什么感觉是 人，这 就是 

59
00:03:12,659 --> 00:03:17,700
生活是关于你不 知道什么是好的 

60
00:03:15,569 --> 00:03:21,660
和坏的 ，你种得只是 住它 

61
00:03:17,700 --> 00:03:24,090
每隔一段时间你就会 发现 

62
00:03:21,660 --> 00:03:26,910
这所有的东西 你没有 上周 

63
00:03:24,090 --> 00:03:27,329
加强是非常糟糕的 主意 

64
00:03:26,910 --> 00:03:31,680
学习

65
00:03:27,329 --> 00:03:34,049
从某种意义上来说，这是半监督的 

66
00:03:31,680 --> 00:03:35,940
只有当天的一小部分 

67
00:03:34,049 --> 00:03:38,370
有一些基本的事实 

68
00:03:35,940 --> 00:03:42,959
确定你必须提取 

69
00:03:38,370 --> 00:03:45,989
知识来自于第一个核心 

70
00:03:42,959 --> 00:03:48,150
当前有效的任何东西

71
00:03:45,989 --> 00:03:50,760
在实际中 实际的条款

72
00:03:48,150 --> 00:03:54,780
感觉必须有一些基本的事实 

73
00:03:50,760 --> 00:03:57,319
我们可以 有一些事实 

74
00:03:54,780 --> 00:04:00,419
当我们试图概括和时，坚持下去

75
00:03:57,319 --> 00:04:02,459
多数民众赞成监督学习，即使 在 

76
00:04:00,419 --> 00:04:04,739
强化学习 ，我们 的 唯一 的 事情 

77
00:04:02,459 --> 00:04:06,470
可以依靠的是那个真相 

78
00:04:04,739 --> 00:04:08,430
一种奖励形式

79
00:04:06,470 --> 00:04:12,840
所以标准的监督学习

80
00:04:08,430 --> 00:04:17,310
管道是你有一些原始数据 

81
00:04:12,840 --> 00:04:21,229
输入你 有标签的基本事实 

82
00:04:17,310 --> 00:04:24,750
与 输入匹配的 输出 

83
00:04:21,229 --> 00:04:25,889
然后你运行任何一种

84
00:04:24,750 --> 00:04:28,270
算法是否是神经 

85
00:04:25,889 --> 00:04:30,520
网络或其他人 

86
00:04:28,270 --> 00:04:32,830
提取的处理算法 

87
00:04:30,520 --> 00:04:35,199
您可以从该数据集中获取功能 

88
00:04:32,830 --> 00:04:38,500
想起那张脸 的照片 

89
00:04:35,199 --> 00:04:41,729
算法可以提取鼻子 

90
00:04:38,500 --> 00:04:46,210
眼睛瞳孔的角落 

91
00:04:41,729 --> 00:04:49,659
甚至更低的水平 ， 具有 

92
00:04:46,210 --> 00:04:55,360
之后 我们插入那些图像

93
00:04:49,659 --> 00:04:59,909
功能成一个机器的模型 

94
00:04:55,360 --> 00:04:59,909
学习模型将训练该模型 

95
00:05:00,150 --> 00:05:06,130
然后我们就像 算法一样 

96
00:05:04,389 --> 00:05:10,210
它通过了那次培训 

97
00:05:06,130 --> 00:05:11,889
然后 我们在 我们之后评估 过程 

98
00:05:10,210 --> 00:05:16,180
看到展览这个特别的 

99
00:05:11,889 --> 00:05:21,340
例如，我们 在其他方面 有多好 

100
00:05:16,180 --> 00:05:23,259
任务，当我们重复这个循环时 

101
00:05:21,340 --> 00:05:26,500
模型学会更好地表现

102
00:05:23,259 --> 00:05:29,800
更好地从 原始 数据推广

103
00:05:26,500 --> 00:05:32,560
到我们拥有的标签， 最后 

104
00:05:29,800 --> 00:05:36,310
你可以将该模型 发布 到 

105
00:05:32,560 --> 00:05:39,250
疯狂地实际做预测数据 

106
00:05:36,310 --> 00:05:47,199
从来没有见过， 你不 知道 

107
00:05:39,250 --> 00:05:54,130
关于和那里的任务是要预测的 

108
00:05:47,199 --> 00:05:57,969
标签还可以，所以神经网络是 

109
00:05:54,130 --> 00:05:59,590
这个课程是 关于 它的一个 

110
00:05:57,969 --> 00:06:04,569
具有的机器学习 算法 

111
00:05:59,590 --> 00:06:06,130
事实证明是非常 成功 的 

112
00:06:04,569 --> 00:06:08,199
构建块计算

113
00:06:06,130 --> 00:06:14,639
神经网络的构建块是一个 

114
00:06:08,199 --> 00:06:17,669
神经元感知器是一种神经元 

115
00:06:14,639 --> 00:06:21,779
这是原来的老派神经元 

116
00:06:17,669 --> 00:06:27,759
其中输出为二进制为 0 或1 

117
00:06:21,779 --> 00:06:31,509
它在过程中并不是真正有价值的 

118
00:06:27,759 --> 00:06:37,960
感知器经历了它有没有

119
00:06:31,509 --> 00:06:40,509
多输入和单 输出 

120
00:06:37,960 --> 00:06:43,060
但每个输入都有权重 

121
00:06:40,509 --> 00:06:46,330
他们在左边 显示 了这一点 

122
00:06:43,060 --> 00:06:48,699
七点六点一点 四 点 那些 

123
00:06:46,330 --> 00:06:51,599
权重应用于输入和a 

124
00:06:48,699 --> 00:06:57,849
感知器输入是一个或 零 

125
00:06:51,599 --> 00:07:03,099
二进制和那些权重适用 于 

126
00:06:57,849 --> 00:07:09,060
然后加 在一起每个偏压 

127
00:07:03,099 --> 00:07:13,630
然后将神经元添加到顶部和a 

128
00:07:09,060 --> 00:07:16,030
阈值有一个测试是否 

129
00:07:13,630 --> 00:07:17,919
总和值加偏差低于或

130
00:07:16,030 --> 00:07:20,110
超过 阈值，如果它在上面 

131
00:07:17,919 --> 00:07:21,759
门槛， 但这是一个 

132
00:07:20,110 --> 00:07:25,240
低于阈值时，产生零 

133
00:07:21,759 --> 00:07:27,180
简单它是我们唯一的事情之一 

134
00:07:25,240 --> 00:07:29,919
了解神经网络 

135
00:07:27,180 --> 00:07:37,539
我们可以自信地证明了很多事情 

136
00:07:29,919 --> 00:07:42,000
关于这个神经元，例如我们

137
00:07:37,539 --> 00:07:45,370
知道神经元可以接近 一个 

138
00:07:42,000 --> 00:07:52,570
近似并且它们与NAND门接合

139
00:07:45,370 --> 00:07:55,840
是逻辑运算 逻辑函数 

140
00:07:52,570 --> 00:07:59,229
这个输入有两个 输入 

141
00:07:55,840 --> 00:08:01,930
甲乙这里就图上的点

142
00:07:59,229 --> 00:08:04,210
在左边和桌子上 

143
00:08:01,930 --> 00:08:08,770
显示当该 功能 是什么时 

144
00:08:04,210 --> 00:08:12,039
输入以任何顺序为零 

145
00:08:08,770 --> 00:08:15,969
输出是一个否则它是一个 

146
00:08:12,039 --> 00:08:21,520
关于NAND 门的 一个很酷的事情 是 

147
00:08:15,969 --> 00:08:24,430
它是一个通用门， 你可以 

148
00:08:21,520 --> 00:08:26,949
建立任何一台电脑，你有， 你 

149
00:08:24,430 --> 00:08:30,009
今天你口袋里的手机可以打造 

150
00:08:26,949 --> 00:08:32,320
只是NAND门，所以它是一个 

151
00:08:30,009 --> 00:08:34,719
在功能上完成你可以建立 

152
00:08:32,320 --> 00:08:36,399
如果你有 任何逻辑功能 

153
00:08:34,719 --> 00:08:38,729
以任意 方式将 它们堆叠在一起 

154
00:08:36,399 --> 00:08:41,979
与非门和问题

155
00:08:38,729 --> 00:08:44,229
计算机是由它们构建的 

156
00:08:41,979 --> 00:08:47,949
自下而上 你要设计这些 

157
00:08:44,229 --> 00:08:50,950
与非门电路的这样的很酷 的事情 

158
00:08:47,949 --> 00:08:53,830
这是我们可以做到的感知器 

159
00:08:50,950 --> 00:08:58,690
赚取这个我们可以学习的魔法门 

160
00:08:53,830 --> 00:09:03,580
这个功能 让我们来看看 

161
00:08:58,690 --> 00:09:06,760
我们如何才能做到感知器如何做到

162
00:09:03,580 --> 00:09:10,900
在这里执行NAND操作

163
00:09:06,760 --> 00:09:12,520
如果我们把权重放在 四个 例子中 

164
00:09:10,900 --> 00:09:15,900
关于每个的IMP的负2 

165
00:09:12,520 --> 00:09:18,670
输入和神经元上的偏差为3 

166
00:09:15,900 --> 00:09:23,190
那么如果我们执行相同的操作 

167
00:09:18,670 --> 00:09:28,800
将权重乘以输入 

168
00:09:23,190 --> 00:09:31,750
加上我们 得到 的左上角偏见

169
00:09:28,800 --> 00:09:35,650
当输入为零 且有 

170
00:09:31,750 --> 00:09:38,050
一些偏见我们得到3是 一个 

171
00:09:35,650 --> 00:09:40,990
这是一个正数，意思是 

172
00:09:38,050 --> 00:09:43,720
感知器的输出将为1 

173
00:09:40,990 --> 00:09:47,380
当输入为0和时，右上角 

174
00:09:43,720 --> 00:09:51,820
1 这个总和仍然是一个正数 

175
00:09:47,380 --> 00:09:56,170
再次产生 1等等 但是什么时候 

176
00:09:51,820 --> 00:10:00,270
的输入均为1，则输出是 

177
00:09:56,170 --> 00:10:05,890
负1小于0 

178
00:10:00,270 --> 00:10:09,760
所以虽然这很简单， 但 确实如此 

179
00:10:05,890 --> 00:10:15,700
重要的是要考虑 它是一个 

180
00:10:09,760 --> 00:10:17,380
一种基本的计算方法

181
00:10:15,700 --> 00:10:19,030
在我们谈话时你可以坚持的事实

182
00:10:17,380 --> 00:10:24,820
关于一些神奇的 东西 神经 的 

183
00:10:19,030 --> 00:10:28,810
网络可以做，因为 如果你 比较一个 

184
00:10:24,820 --> 00:10:34,450
与非门电路及其电路

185
00:10:28,810 --> 00:10:37,570
电路中的神经元差异

186
00:10:34,450 --> 00:10:40,540
神经元是我们所认为的 

187
00:10:37,570 --> 00:10:43,570
神经网络可以执行相同的操作 

188
00:10:40,540 --> 00:10:46,930
作为NAND门电路的东西是什么

189
00:10:43,570 --> 00:10:49,360
它也可以做就是你可以学到它

190
00:10:46,930 --> 00:10:53,560
学习任意逻辑功能

191
00:10:49,360 --> 00:10:56,440
作为与非门的任意电路 

192
00:10:53,560 --> 00:11:04,350
可以代表，但它不需要 

193
00:10:56,440 --> 00:11:04,350
人类设计师， 如果你愿意，我们可以进化

194
00:11:05,779 --> 00:11:12,689
所以其中一个关键方面就是其中之一 

195
00:11:09,779 --> 00:11:16,589
感知器的主要缺点是它

196
00:11:12,689 --> 00:11:20,160
我们的输出不是很顺利 

197
00:11:16,589 --> 00:11:22,230
改变输入的重量 和我们 

198
00:11:20,160 --> 00:11:27,199
改变偏见， 我们 稍微 调整 一下 

199
00:11:22,230 --> 00:11:30,480
位这是 非常有可能的是 ，当你得到 

200
00:11:27,199 --> 00:11:33,809
我很容易 制作神经元 

201
00:11:30,480 --> 00:11:37,769
加零，而不是1 1替代 的 

202
00:11:33,809 --> 00:11:40,649
零，所以当我们开始堆叠许多 

203
00:11:37,769 --> 00:11:46,230
这些结合在一起 很难 控制 

204
00:11:40,649 --> 00:11:49,709
现在作为一个整体的东西的输出

205
00:11:46,230 --> 00:11:53,519
制造神经的必要步骤

206
00:11:49,709 --> 00:11:56,879
网络工作，圆形感知器 

207
00:11:53,519 --> 00:11:59,249
不是输出结果 

208
00:11:56,879 --> 00:12:04,410
光滑的它是连续的 

209
00:11:59,249 --> 00:12:07,079
激活功能，它是如此 

210
00:12:04,410 --> 00:12:09,899
使用像一个步骤函数

211
00:12:07,079 --> 00:12:14,490
感知器确实显示在 左侧 

212
00:12:09,899 --> 00:12:20,069
我们使用任何一种 平滑的功能a 

213
00:12:14,490 --> 00:12:23,999
sigmoid输出可以改变的地方

214
00:12:20,069 --> 00:12:30,300
逐渐改变你的 体重 

215
00:12:23,999 --> 00:12:35,839
偏见， 这是一个基本 但 

216
00:12:30,300 --> 00:12:39,870
关键步骤，所以学习是 

217
00:12:35,839 --> 00:12:43,379
通常是 调整这些的过程 

218
00:12:39,870 --> 00:12:45,300
逐渐增加重量，看看它有多少

219
00:12:43,379 --> 00:12:48,240
对网络 的其余部分的作用

220
00:12:45,300 --> 00:12:52,079
你只需要在这里调整刀片 

221
00:12:48,240 --> 00:12:55,199
在那里，看到你有多接近 

222
00:12:52,079 --> 00:12:58,079
在 地上 真理，如果你得到 

223
00:12:55,199 --> 00:13:02,040
更远， 你只需 调整重量 

224
00:12:58,079 --> 00:13:06,540
与你相反的方向 

225
00:13:02,040 --> 00:13:09,089
知道网络简而言之 

226
00:13:06,540 --> 00:13:12,420
今天我们 将主要谈论什么 

227
00:13:09,089 --> 00:13:16,120
在 它的前馈神经网络 

228
00:13:12,420 --> 00:13:23,559
从输入到输出 

229
00:13:16,120 --> 00:13:25,540
没有循环也有这些 

230
00:13:23,559 --> 00:13:29,079
惊人的事情叫做反复神经 

231
00:13:25,540 --> 00:13:32,350
网络他们是惊人的，因为他们 

232
00:13:29,079 --> 00:13:36,910
有记忆他们有状态 的记忆

233
00:13:32,350 --> 00:13:42,069
他们记得时间的动态 

234
00:13:36,910 --> 00:13:44,949
经过的数据但是 

235
00:13:42,069 --> 00:13:49,449
痛苦的是他们真的 

236
00:13:44,949 --> 00:13:52,300
今天很难训练我们会谈论 

237
00:13:49,449 --> 00:13:57,579
喂全神经网络所以让我们看看 

238
00:13:52,300 --> 00:13:59,699
在这个例子中 堆叠a 的例子 

239
00:13:57,579 --> 00:14:05,079
这几个 神经元中只有少数 在一起 

240
00:13:59,699 --> 00:14:07,660
让我们想一下基本任务的任务 

241
00:14:05,079 --> 00:14:10,329
现在著名使用的分类 

242
00:14:07,660 --> 00:14:13,809
数字你有很多的图像

243
00:14:10,329 --> 00:14:18,970
手写的号码，你的任务是

244
00:14:13,809 --> 00:14:22,929
鉴于图像说的是什么数字 

245
00:14:18,970 --> 00:14:24,730
现在在那个图像中 是什么形象 

246
00:14:22,929 --> 00:14:28,029
image是 像素 的集合 

247
00:14:24,730 --> 00:14:32,259
这种情况是28乘28像素，这是一个总数 

248
00:14:28,029 --> 00:14:38,889
这些数字来自0的784个数字

249
00:14:32,259 --> 00:14:40,629
到255和 网络的左边我们 

250
00:14:38,889 --> 00:14:45,389
输入的大小

251
00:14:40,629 --> 00:14:49,329
尽管该图是784个神经元 

252
00:14:45,389 --> 00:14:52,980
这是 输入然后是隐藏的 

253
00:14:49,329 --> 00:14:59,610
图层称为隐藏图层 

254
00:14:52,980 --> 00:15:05,559
因为它没有互动 

255
00:14:59,610 --> 00:15:10,179
输入或输出 

256
00:15:05,559 --> 00:15:12,550
只是一个块使用它的核心 

257
00:15:10,179 --> 00:15:15,490
神经网络的计算能力

258
00:15:12,550 --> 00:15:19,240
网络是 它的 任务 隐藏层 

259
00:15:15,490 --> 00:15:21,730
与形成 的 一个 表示 

260
00:15:19,240 --> 00:15:25,509
数据以这样的方式映射 

261
00:15:21,730 --> 00:15:28,450
输入与 输出 在这种情况下，存在 

262
00:15:25,509 --> 00:15:33,720
是隐藏层中的15个神经元 

263
00:15:28,450 --> 00:15:36,149
输出上有十个值 

264
00:15:33,720 --> 00:15:39,160
对应于每个数字 

265
00:15:36,149 --> 00:15:40,839
有几种方法可以 

266
00:15:39,160 --> 00:15:42,970
建立这种网络 就是这样 

267
00:15:40,839 --> 00:15:45,160
神经网络的神奇之处在于你

268
00:15:42,970 --> 00:15:47,740
你可以在很多方面做到这一点 

269
00:15:45,160 --> 00:15:51,100
需要四个输出来表示值

270
00:15:47,740 --> 00:15:53,350
从零 到 九，但在实践中 

271
00:15:51,100 --> 00:15:56,529
似乎有十个输出工作 

272
00:15:53,350 --> 00:16:00,190
更好，这些如何工作 

273
00:15:56,529 --> 00:16:02,680
输入是输出神经元的五个 

274
00:16:00,190 --> 00:16:05,339
五人的指控真的很兴奋 

275
00:16:02,680 --> 00:16:09,430
我会把一个接近一个的值

276
00:16:05,339 --> 00:16:13,480
从0到1接近1然后 

277
00:16:09,430 --> 00:16:16,540
另一个获得 价值的输出 

278
00:16:13,480 --> 00:16:19,750
希望这接近零 ，什么时候 

279
00:16:16,540 --> 00:16:21,760
他们不是我们调整权重 

280
00:16:19,750 --> 00:16:24,279
他们接近零的方式 

281
00:16:21,760 --> 00:16:26,529
接近一个取决于它是否 

282
00:16:24,279 --> 00:16:30,190
与相关的正确神经元 

283
00:16:26,529 --> 00:16:32,079
图片我们将谈谈细节 

284
00:16:30,190 --> 00:16:38,440
培训过程更明天的时候 

285
00:16:32,079 --> 00:16:41,699
它更有意义，但我们所拥有的 

286
00:16:38,440 --> 00:16:45,190
刚才讨论的是前进的 道路 

287
00:16:41,699 --> 00:16:48,130
通过网络它是 过去的时候 

288
00:16:45,190 --> 00:16:50,920
你接受输入应用重量和 

289
00:16:48,130 --> 00:16:53,800
他们在一起加上偏见 产生了 

290
00:16:50,920 --> 00:16:55,480
输出并检查哪个输出 

291
00:16:53,800 --> 00:16:59,350
产生的最高信心 

292
00:16:55,480 --> 00:17:02,980
号码，然后一旦这些概率 

293
00:16:59,350 --> 00:17:10,030
我们提供了每个数字 

294
00:17:02,980 --> 00:17:13,000
确定以前的渐变

295
00:17:10,030 --> 00:17:15,250
惩罚或奖励 的权重 是 

296
00:17:13,000 --> 00:17:17,559
导致正确或 

297
00:17:15,250 --> 00:17:20,230
不正确的决定和所谓的 

298
00:17:17,559 --> 00:17:21,850
反向传播我们 倒退了 

299
00:17:20,230 --> 00:17:25,030
通过网络应用那些 

300
00:17:21,850 --> 00:17:27,370
惩罚或奖励因为 

301
00:17:25,030 --> 00:17:30,669
激活功能的平滑性

302
00:17:27,370 --> 00:17:34,150
这是一个数学上有效的

303
00:17:30,669 --> 00:17:39,280
操作就是GPIO GPU的地方

304
00:17:34,150 --> 00:17:40,840
例如，数字的步骤 

305
00:17:39,280 --> 00:17:44,710
基本事实

306
00:17:40,840 --> 00:17:53,030
第六个看起来如下 

307
00:17:44,710 --> 00:17:55,610
在 X 的幻灯片中， Y等于 10 

308
00:17:53,030 --> 00:18:00,680
维度向量只有一个 

309
00:17:55,610 --> 00:18:05,210
他们的第六值 是一个 

310
00:18:00,680 --> 00:18:07,370
休息是0，这是事实 

311
00:18:05,210 --> 00:18:10,970
带有损失功能的图像

312
00:18:07,370 --> 00:18:13,790
这里的基本损失函数是

313
00:18:10,970 --> 00:18:17,690
X的平方误差Y 是基本事实 

314
00:18:13,790 --> 00:18:21,760
和a是神经的输出

315
00:18:17,690 --> 00:18:24,680
前向路径产生的网络 

316
00:18:21,760 --> 00:18:28,100
所以，当你输入这个 数字 的的 

317
00:18:24,680 --> 00:18:30,580
6，它输出它输出的 任何东西 

318
00:18:28,100 --> 00:18:34,820
这是 一个10维向量和 

319
00:18:30,580 --> 00:18:37,610
它总结了生产的投入

320
00:18:34,820 --> 00:18:40,490
平方误差是我们的损失 

321
00:18:37,610 --> 00:18:43,580
功能损失功能的目标 

322
00:18:40,490 --> 00:18:48,170
这是用来确定的功能

323
00:18:43,580 --> 00:18:49,850
多少奖励或惩罚背 

324
00:18:48,170 --> 00:18:55,780
在整个过程中传播权重

325
00:18:49,850 --> 00:18:58,010
网络和基本操作

326
00:18:55,780 --> 00:19:01,070
优化损失函数 

327
00:18:58,010 --> 00:19:03,890
最大限度地减少它的完成是损失函数 

328
00:19:01,070 --> 00:19:07,430
有各种渐变变体

329
00:19:03,890 --> 00:19:11,450
希望它有点顺利 

330
00:19:07,430 --> 00:19:14,330
功能，但它是一个高度非线性的 

331
00:19:11,450 --> 00:19:17,600
功能这就是我们无法证明的原因 

332
00:19:14,330 --> 00:19:20,990
关于神经 网络 是它的一个 

333
00:19:17,600 --> 00:19:22,870
高维非常高度非线性

334
00:19:20,990 --> 00:19:28,490
功能，希望足够顺利

335
00:19:22,870 --> 00:19:31,150
梯度下降 可以找到它的地方 

336
00:19:28,490 --> 00:19:33,830
至少是一个好的解决方案的方法 

337
00:19:31,150 --> 00:19:38,600
必须有一些随机因素 

338
00:19:33,830 --> 00:19:41,780
那里没有跳跃 

339
00:19:38,600 --> 00:19:44,510
以 确保它 不会停留在 

340
00:19:41,780 --> 00:19:47,390
这个非常复杂的局部极小 

341
00:19:44,510 --> 00:19:48,980
功能还可以，这是有监督的学习

342
00:19:47,390 --> 00:19:52,550
有投入

343
00:19:48,980 --> 00:19:54,029
这是我们的输出基础事实 

344
00:19:52,550 --> 00:19:55,320
舒适区

345
00:19:54,029 --> 00:19:57,899
我们非常有信心，我们知道什么是

346
00:19:55,320 --> 00:20:01,200
你需要做的就是你

347
00:19:57,899 --> 00:20:02,969
有这个数据集你训练和你 

348
00:20:01,200 --> 00:20:04,950
在那个数据集上培训一个网络和你 

349
00:20:02,969 --> 00:20:07,320
可以评估你可以写一篇论文 

350
00:20:04,950 --> 00:20:10,979
并尝试击败 以前的论文是 

351
00:20:07,320 --> 00:20:13,429
很重要的问题是你何时使用 

352
00:20:10,979 --> 00:20:16,109
那神经网络创造了一个 

353
00:20:13,429 --> 00:20:18,659
你推出智能系统 

354
00:20:16,109 --> 00:20:21,749
在世界和现在的那个系统 

355
00:20:18,659 --> 00:20:24,330
不再使用您的数据集 

356
00:20:21,749 --> 00:20:27,119
它必须存在 于这个 世界中 

357
00:20:24,330 --> 00:20:30,929
不要紧 ，可能是 非常 

358
00:20:27,119 --> 00:20:32,789
不同于地面真相所以 

359
00:20:30,929 --> 00:20:34,969
从监督学习的外卖是 

360
00:20:32,789 --> 00:20:37,919
你知道网络很棒 

361
00:20:34,969 --> 00:20:39,690
记忆但在几分 

362
00:20:37,919 --> 00:20:43,320
他们可能不是哲学的方式

363
00:20:39,690 --> 00:20:47,339
在巨大的推理 概括 

364
00:20:43,320 --> 00:20:49,649
超出数据集的特定风味 

365
00:20:47,339 --> 00:20:53,429
他们受到 了希望的 训练 

366
00:20:49,649 --> 00:20:55,889
我们可以加强学习

367
00:20:53,429 --> 00:21:01,849
扩展我们 在 获得的知识

368
00:20:55,889 --> 00:21:06,839
有监督的方式来到外面的巨大世界

369
00:21:01,849 --> 00:21:11,399
我们 没有基本事实的地方 

370
00:21:06,839 --> 00:21:13,109
如何行动有多好 

371
00:21:11,399 --> 00:21:15,409
某种状态是某种状态还是有多么糟糕

372
00:21:13,109 --> 00:21:19,559
国家这是一种蛮力

373
00:21:15,409 --> 00:21:21,599
推理 ，我会谈论那种 

374
00:21:19,559 --> 00:21:23,609
我的意思是，但感觉 就像是 

375
00:21:21,599 --> 00:21:25,649
接近推理而不是 

376
00:21:23,609 --> 00:21:28,259
记忆是一种很好的 思考方式 

377
00:21:25,649 --> 00:21:31,679
作为记忆 的监督学习 

378
00:21:28,259 --> 00:21:34,019
你只是在考试 和 考试 一样 

379
00:21:31,679 --> 00:21:35,549
很多人都知道 这并不 意味着 

380
00:21:34,019 --> 00:21:41,299
你将 在生活中 获得 成功 

381
00:21:35,549 --> 00:21:45,330
只是因为你得到A等等 

382
00:21:41,299 --> 00:21:50,269
强化学习代理或任何

383
00:21:45,330 --> 00:21:54,839
代理人或任何机器

384
00:21:50,269 --> 00:21:57,269
现存在这个世界上可以运作 

385
00:21:54,839 --> 00:21:59,570
从角度看以下方式 

386
00:21:57,269 --> 00:22:04,259
它可以执行一个行动的年龄 

387
00:21:59,570 --> 00:22:07,049
它可以收到观察结果 

388
00:22:04,259 --> 00:22:07,770
从一个新的形式的行动 

389
00:22:07,049 --> 00:22:09,570
州

390
00:22:07,770 --> 00:22:13,470
它可以获得奖励或 

391
00:22:09,570 --> 00:22:16,080
惩罚你可以 分解每一个 

392
00:22:13,470 --> 00:22:20,250
你可以打破我们的存在 

393
00:22:16,080 --> 00:22:22,620
以这种方式简单化的观点，但它是一个 

394
00:22:20,250 --> 00:22:27,240
方便的一个在计算方面 

395
00:22:22,620 --> 00:22:30,059
从环境方面来说 

396
00:22:27,240 --> 00:22:33,000
环境接收动作发出 

397
00:22:30,059 --> 00:22:34,950
观察所以你的行动发生了变化 

398
00:22:33,000 --> 00:22:40,100
因此，世界必须拥有世界 

399
00:22:34,950 --> 00:22:44,750
改变，然后告诉你它和

400
00:22:40,100 --> 00:22:44,750
给你一个奖励或为它的惩罚 

401
00:22:46,280 --> 00:22:56,670
让我们再关注一个最 

402
00:22:53,100 --> 00:22:58,140
我将尝试传达令人着迷的东西 

403
00:22:56,670 --> 00:23:03,140
为什么这有点迷人

404
00:22:58,140 --> 00:23:10,730
后来是深入思考的工作 

405
00:23:03,140 --> 00:23:14,610
Atari 这是 atari 突破 游戏 

406
00:23:10,730 --> 00:23:16,230
桨必须绕着那个移动 

407
00:23:14,610 --> 00:23:19,190
存在于其中的世界是一个

408
00:23:16,230 --> 00:23:22,770
桨桨的试剂 和 

409
00:23:19,190 --> 00:23:24,990
有一个弹跳球，你尝试 

410
00:23:22,770 --> 00:23:28,410
将您的行动 正确的举措 

411
00:23:24,990 --> 00:23:30,270
向右移动 ，所以你试图 移动 

412
00:23:28,410 --> 00:23:34,410
以这种方式， 球不会得到 

413
00:23:30,270 --> 00:23:37,050
通过 这里 所以这里是一个人的水平 

414
00:23:34,410 --> 00:23:38,700
那个代理人的表现 等等 

415
00:23:37,050 --> 00:23:40,710
这个桨是否必须这样做 

416
00:23:38,700 --> 00:23:44,870
操作这个环境就是这样的 

417
00:23:40,710 --> 00:23:48,120
行动左移每个动作 

418
00:23:44,870 --> 00:23:50,900
改变了 她的世界 状况 

419
00:23:48,120 --> 00:23:54,780
可能看似显而易见但 向右移动 

420
00:23:50,900 --> 00:23:56,670
从视觉上改变世界的状况

421
00:23:54,780 --> 00:23:59,490
其实我们现在看 的 是什么 

422
00:23:56,670 --> 00:24:04,530
幻灯片是 你之前 改变的世界 

423
00:23:59,490 --> 00:24:08,700
眼睛所以 这个小家伙，它得到了 

424
00:24:04,530 --> 00:24:11,670
它得到的奖励或惩罚奖励

425
00:24:08,700 --> 00:24:14,190
以点的形式， 他们费尽 了 

426
00:24:11,670 --> 00:24:17,160
在左上角 的点

427
00:24:14,190 --> 00:24:21,090
视频，然后当球过去 

428
00:24:17,160 --> 00:24:23,580
划桨它受到惩罚 

429
00:24:21,090 --> 00:24:25,679
通过死亡引用 - 取消引用，那是 

430
00:24:23,580 --> 00:24:30,110
剩下的谎言数量

431
00:24:25,679 --> 00:24:32,789
五到四到三降到零 

432
00:24:30,110 --> 00:24:38,220
所以目标是选择任何一个 

433
00:24:32,789 --> 00:24:40,950
最大化未来的行动 

434
00:24:38,220 --> 00:24:45,120
没有奖励什么 的任何知识 

435
00:24:40,950 --> 00:24:47,639
奖励是 在 这个词的 更大意义 

436
00:24:45,120 --> 00:24:50,549
你所拥有的只是瞬间奖励 

437
00:24:47,639 --> 00:24:57,450
或惩罚瞬间反应 

438
00:24:50,549 --> 00:25:00,679
世界对你的行动，这 可以 

439
00:24:57,450 --> 00:25:04,190
被建模为马尔可夫决策过程 

440
00:25:00,679 --> 00:25:06,539
马尔可夫决策过程是一个

441
00:25:04,190 --> 00:25:10,169
在数学上方便构建它 

442
00:25:06,539 --> 00:25:12,869
没有记忆，你得到的是你有一个 

443
00:25:10,169 --> 00:25:15,389
说你现在在你身边 

444
00:25:12,869 --> 00:25:16,950
执行你获得 奖励的作用， 

445
00:25:15,389 --> 00:25:20,970
你发现自己 处于一种新的状态 

446
00:25:16,950 --> 00:25:23,909
你一遍又一遍地重复着你 

447
00:25:20,970 --> 00:25:26,490
从州0开始，你去了州1 

448
00:25:23,909 --> 00:25:28,559
再次重复 行动获得奖励 去 

449
00:25:26,490 --> 00:25:31,139
到下一个状态好吧那就是了

450
00:25:28,559 --> 00:25:32,730
我们在什么时候经营的配方

451
00:25:31,139 --> 00:25:36,649
你处于某种状态，你没有 

452
00:25:32,730 --> 00:25:38,730
记忆 两个 州前 发生的事情 

453
00:25:36,649 --> 00:25:44,580
一切都 在 运行 

454
00:25:38,730 --> 00:25:45,929
瞬间即时瞬间 

455
00:25:44,580 --> 00:25:47,879
什么是的主要组成部分 

456
00:25:45,929 --> 00:25:52,590
强化学习代理 有一个 

457
00:25:47,879 --> 00:25:56,340
这是代理人的政策

458
00:25:52,590 --> 00:26:01,919
广义的代理人的功能 

459
00:25:56,340 --> 00:26:04,649
行为，这意味着包括

460
00:26:01,919 --> 00:26:08,580
了解任何特定国家的情况

461
00:26:04,649 --> 00:26:14,159
什么是我将采取的行动 

462
00:26:08,580 --> 00:26:17,309
一些 概率值函数 是如何的 

463
00:26:14,159 --> 00:26:23,700
好的每个州和行动都在其中 

464
00:26:17,309 --> 00:26:28,529
特殊的状态， 现在有一个模型 

465
00:26:23,700 --> 00:26:29,940
这是一个有点微妙的事情

466
00:26:28,529 --> 00:26:33,029
实际上是最大的问题 

467
00:26:29,940 --> 00:26:34,470
你今天看到的一切都是模特 

468
00:26:33,029 --> 00:26:37,049
是我们如何代表

469
00:26:34,470 --> 00:26:39,269
环境， 今天 我们会看到 一些 

470
00:26:37,049 --> 00:26:42,750
神经网络可以做的惊人的事情 

471
00:26:39,269 --> 00:26:44,850
在相对简单的模型上实现

472
00:26:42,750 --> 00:26:47,159
世界和问题是否 

473
00:26:44,850 --> 00:26:49,529
该模型 可以扩展到现实世界 

474
00:26:47,159 --> 00:26:55,799
其中，人的生命是 在股权 

475
00:26:49,529 --> 00:27:00,210
驾驶的情况让我们来看看 

476
00:26:55,799 --> 00:27:02,879
简单世界他是一个房间里的机器人 

477
00:27:00,210 --> 00:27:07,200
从 左下角 开始 你的目标是 

478
00:27:02,879 --> 00:27:11,600
到达右上角你的可能性 

479
00:27:07,200 --> 00:27:14,700
行动正在向左和向右上升 

480
00:27:11,600 --> 00:27:17,190
现在这个世界可能是确定性的 

481
00:27:14,700 --> 00:27:20,629
这时候你们什么 时候 上去 取 指 

482
00:27:17,190 --> 00:27:26,129
你真的上涨或者 可能 

483
00:27:20,629 --> 00:27:29,820
它是人类生命的非确定性

484
00:27:26,129 --> 00:27:33,029
当你上去的时候，你有时会这样做 

485
00:27:29,820 --> 00:27:35,700
在这种情况下，如果你选择 上去 

486
00:27:33,029 --> 00:27:38,159
向左移动80％ 的时间 

487
00:27:35,700 --> 00:27:38,779
10％的时间，向右移动10％ 

488
00:27:38,159 --> 00:27:42,809
时间

489
00:27:38,779 --> 00:27:45,090
当你到达 右上角时 

490
00:27:42,809 --> 00:27:47,549
得到 +1的奖励，那么你得到的 

491
00:27:45,090 --> 00:27:50,009
从第二块2你 

492
00:27:47,549 --> 00:27:52,259
否定1你 受到惩罚 和每一个 

493
00:27:50,009 --> 00:27:58,049
时间你把你 得到一个轻微的 一步 

494
00:27:52,259 --> 00:28:01,129
惩罚点0 4 确定如此问题 

495
00:27:58,049 --> 00:28:04,289
如果你从 左下角 开始 就是 

496
00:28:01,129 --> 00:28:06,570
这是一个很好的解决方案 

497
00:28:04,289 --> 00:28:10,769
你 在世界上存在的政策

498
00:28:06,570 --> 00:28:15,000
如果世界是确定性的 ， 那就是它 

499
00:28:10,769 --> 00:28:17,519
如果 你选择上去， 你就去吧 

500
00:28:15,000 --> 00:28:23,539
我的意思是我敦促 你去吧 

501
00:28:17,519 --> 00:28:27,840
是的，但如果行动是随机的

502
00:28:23,539 --> 00:28:33,110
我描述的情况并非如此 

503
00:28:27,840 --> 00:28:33,110
以前用8点和 

504
00:28:33,379 --> 00:28:43,860
0.1左右的概率

505
00:28:37,190 --> 00:28:45,990
如果我们现在这是最优政策

506
00:28:43,860 --> 00:28:48,000
用一个 惩罚 每一步 

507
00:28:45,990 --> 00:28:52,200
负2而不是 负 

508
00:28:48,000 --> 00:28:57,150
1:04所以每次你迈出一步 

509
00:28:52,200 --> 00:28:59,120
伤害你会试图去找aa 

510
00:28:57,150 --> 00:29:03,540
积极阻止尽快

511
00:28:59,120 --> 00:29:06,060
这 就是 我的 政策所说的 

512
00:29:03,540 --> 00:29:08,040
如果必须的话，走一个消极的 

513
00:29:06,060 --> 00:29:13,050
只要我 拦住得到一个 

514
00:29:08,040 --> 00:29:17,310
否定 2现在 是每个人 的奖励 

515
00:29:13,050 --> 00:29:20,300
步骤是你可能选择的负0.1 

516
00:29:17,310 --> 00:29:27,300
绕过那个 负面的 一块 a 

517
00:29:20,300 --> 00:29:29,160
稍微绕行以 避免疼痛然后 

518
00:29:27,300 --> 00:29:31,950
你可能会走 更长的路 

519
00:29:29,160 --> 00:29:41,600
用于 每个步骤的奖励上升或 

520
00:29:31,950 --> 00:29:41,600
惩罚下降，我猜，然后 

521
00:29:44,570 --> 00:29:51,440
然后是实际的 

522
00:29:48,870 --> 00:29:55,770
你采取的每一步都是积极的回报

523
00:29:51,440 --> 00:29:57,290
然后你永远不会避免去 

524
00:29:55,770 --> 00:30:02,330
你的终点线 

525
00:29:57,290 --> 00:30:06,510
你只是漫步在我们看到的世界

526
00:30:02,330 --> 00:30:10,110
昨天将是Coast Racer 

527
00:30:06,510 --> 00:30:11,940
选择不完成 比赛的 船 

528
00:30:10,110 --> 00:30:18,660
因为它太有趣了 

529
00:30:11,940 --> 00:30:21,720
在中间获得积分，让我们来吧 

530
00:30:18,660 --> 00:30:26,010
看看这个代理人的世界

531
00:30:21,720 --> 00:30:29,790
在操作是价值函数 

532
00:30:26,010 --> 00:30:32,610
价值功能取决于奖励

533
00:30:29,790 --> 00:30:34,890
未来的话 和那个 

534
00:30:32,610 --> 00:30:37,770
奖励因为 世界 而打折扣 

535
00:30:34,890 --> 00:30:42,570
随机我们不是我们不能指望的 

536
00:30:37,770 --> 00:30:45,600
来自我们的奖励

537
00:30:42,570 --> 00:30:47,760
我们希望它基于的方式 

538
00:30:45,600 --> 00:30:51,990
政策基于我们选择采取行动的方式 

539
00:30:47,760 --> 00:30:55,290
所以那里有一个伽玛 

540
00:30:51,990 --> 00:30:59,179
时间作为奖励更远 

541
00:30:55,290 --> 00:31:02,029
更远的未来 是 打折 

542
00:30:59,179 --> 00:31:04,710
奖励

543
00:31:02,029 --> 00:31:07,260
减少未来的影响

544
00:31:04,710 --> 00:31:11,549
奖励你对当前的评价 

545
00:31:07,260 --> 00:31:15,299
国家，所以你的目标是 发展一个 

546
00:31:11,549 --> 00:31:18,330
最大化 折扣的策略

547
00:31:15,299 --> 00:31:25,590
未来奖这笔金额打折 

548
00:31:18,330 --> 00:31:28,919
总结和强化学习有一个 

549
00:31:25,590 --> 00:31:33,299
想出一个很好的方法

550
00:31:28,919 --> 00:31:38,570
良好的政策 近乎最优的一个 

551
00:31:33,299 --> 00:31:43,110
政策那里有很多有趣的数学

552
00:31:38,570 --> 00:31:45,950
你可以尝试建立一个模型 ， 

553
00:31:43,110 --> 00:31:51,230
优化对这个世界的估计 

554
00:31:45,950 --> 00:31:53,640
你可以试试 monte carlo 

555
00:31:51,230 --> 00:31:57,929
模拟那个世界，看看它是怎样的 

556
00:31:53,640 --> 00:32:01,590
展开并在展开时尝试 

557
00:31:57,929 --> 00:32:06,440
计算最优政策或我们会做什么

558
00:32:01,590 --> 00:32:12,890
今天 要讲 的Q 学习它是一个 

559
00:32:06,440 --> 00:32:18,980
关闭政策的政策方法 

560
00:32:12,890 --> 00:32:22,890
估计我们的政策是 

561
00:32:18,980 --> 00:32:27,390
表示为Q函数 将q 

562
00:32:22,890 --> 00:32:29,970
左边有显示功能是我 

563
00:32:27,390 --> 00:32:37,010
为方程式道歉

564
00:32:29,970 --> 00:32:40,740
我谎称那里会有一些方程式

565
00:32:37,010 --> 00:32:44,760
Q函数的输入是一个状态 

566
00:32:40,740 --> 00:32:49,710
在时间T ft和 您选择的 行动 

567
00:32:44,760 --> 00:32:52,770
采取和 那状态T 和你的目标 是 

568
00:32:49,710 --> 00:32:56,390
在那个州选择一个行动 

569
00:32:52,770 --> 00:32:59,909
在下一步中最大化奖励

570
00:32:56,390 --> 00:33:03,149
和Q 学习做什么，我会 

571
00:32:59,909 --> 00:33:07,080
描述这个过程是否能够 

572
00:33:03,149 --> 00:33:10,649
近似通过经验

573
00:33:07,080 --> 00:33:13,890
最优Q函数是最优函数 

574
00:33:10,649 --> 00:33:19,559
告诉你如何在任何州采取行动 

575
00:33:13,890 --> 00:33:22,350
你必须要生活的世界

576
00:33:19,559 --> 00:33:26,250
你必须模拟你拥有的这个世界 

577
00:33:22,350 --> 00:33:28,440
移动它你必须探索 

578
00:33:26,250 --> 00:33:31,350
为了看到每个 可能的状态尝试 

579
00:33:28,440 --> 00:33:35,190
每一个不同的行动得到奖励得到

580
00:33:31,350 --> 00:33:39,799
惩罚并弄清楚 是什么 

581
00:33:35,190 --> 00:33:44,520
要 做到这一点的最佳事物的使用做 

582
00:33:39,799 --> 00:33:49,380
左边的贝尔曼方程式

583
00:33:44,520 --> 00:33:52,230
输出是估计的新状态 

584
00:33:49,380 --> 00:33:56,429
Q函数估计新状态为 

585
00:33:52,230 --> 00:33:59,880
新动作，这 就是 更新 

586
00:33:56,429 --> 00:34:04,130
统治你学习Q学习的核心

587
00:33:59,880 --> 00:34:09,510
估计旧的估计和添加 

588
00:34:04,130 --> 00:34:15,300
基于0的学习率alpha 

589
00:34:09,510 --> 00:34:20,159
1，他们更新 了评价 

590
00:34:15,300 --> 00:34:22,859
根据你的新奖励表明你 

591
00:34:20,159 --> 00:34:27,840
当时收到所以你到了 

592
00:34:22,859 --> 00:34:30,929
在一定的状态式 T你尝试做的 

593
00:34:27,840 --> 00:34:32,730
行动，然后你得到一定的奖励 

594
00:34:30,929 --> 00:34:37,070
并且你更新你的估计 

595
00:34:32,730 --> 00:34:41,369
基于此规则的状态和操作对 

596
00:34:37,070 --> 00:34:45,800
当学习率为 零， 你不 

597
00:34:41,369 --> 00:34:49,649
在alpha上学习是零，你永远不会改变 

598
00:34:45,800 --> 00:34:55,340
基于新的新世界观

599
00:34:49,649 --> 00:35:00,390
当alpha为1时你输入的证据

600
00:34:55,340 --> 00:35:01,950
每一次改变你评价 你的 

601
00:35:00,390 --> 00:35:06,450
基于新的世界评价

602
00:35:01,950 --> 00:35:09,150
证据，这是关键因素 

603
00:35:06,450 --> 00:35:12,900
首先 要强化学习 

604
00:35:09,150 --> 00:35:14,940
探索然后你先利用你

605
00:35:12,900 --> 00:35:16,740
以非贪婪的方式探索然后你

606
00:35:14,940 --> 00:35:20,190
贪得无厌， 你弄清楚什么是好的 

607
00:35:16,740 --> 00:35:22,740
对你而言， 你继续这样做，如果你 

608
00:35:20,190 --> 00:35:24,420
想先了解一下Atari游戏 

609
00:35:22,740 --> 00:35:27,119
每个州都尝试每一个动作 

610
00:35:24,420 --> 00:35:28,259
搞砸了得到惩罚得到奖励和 

611
00:35:27,119 --> 00:35:29,400
最终你弄清楚是什么 

612
00:35:28,259 --> 00:35:31,259
实际上是正确的做法和 你 

613
00:35:29,400 --> 00:35:35,549
只是继续这样做 ，这就是 你 

614
00:35:31,259 --> 00:35:37,109
赢得了最伟大的世界 

615
00:35:35,549 --> 00:35:39,180
世界上最伟大的人类玩家 

616
00:35:37,109 --> 00:35:42,930
例如，我们将谈论 黄金游戏

617
00:35:39,180 --> 00:35:45,630
关于和你这样做的方式就是你 

618
00:35:42,930 --> 00:35:50,069
有一个epsilon贪婪的政策 

619
00:35:45,630 --> 00:35:52,440
时间概率为 1减去 

620
00:35:50,069 --> 00:35:54,660
epsilon 你表现出最佳的贪婪 

621
00:35:52,440 --> 00:35:57,509
以ε的概率行动你 

622
00:35:54,660 --> 00:36:02,430
执行随机动作随机动作 

623
00:35:57,509 --> 00:36:04,769
是资源管理器 ，所以epsilon 去了 

624
00:36:02,430 --> 00:36:10,259
从一个减少到零，那里有 四个或者 

625
00:36:04,769 --> 00:36:13,049
这里的算法越来越少了 

626
00:36:10,259 --> 00:36:16,140
幻灯片底部非常简单 

627
00:36:13,049 --> 00:36:20,970
那就是算法 版本了 

628
00:36:16,140 --> 00:36:23,880
该方程的伪版本

629
00:36:20,970 --> 00:36:27,769
贝尔曼方程更新你初始化 

630
00:36:23,880 --> 00:36:31,529
你对国家行动对的估计 

631
00:36:27,769 --> 00:36:35,099
任意一个随机数， 这是一个 

632
00:36:31,529 --> 00:36:38,220
你开始玩的重要一点 

633
00:36:35,099 --> 00:36:39,690
或生活或做任何你正在 做的事情 

634
00:36:38,220 --> 00:36:42,329
无论你在做什么

635
00:36:39,690 --> 00:36:46,710
强化学习或驱动你 

636
00:36:42,329 --> 00:36:50,249
没有先入为主的概念 

637
00:36:46,710 --> 00:36:52,259
无论是好的还是坏 的 ，无论你是谁 

638
00:36:50,249 --> 00:36:56,119
选择初始化它 和事实 

639
00:36:52,259 --> 00:36:58,980
它知道任何东西都是惊人的 

640
00:36:56,119 --> 00:37:04,859
嘿，我 想让你记住 那是 

641
00:36:58,980 --> 00:37:08,069
关于 关键 惊人的事情之一

642
00:37:04,859 --> 00:37:12,420
学习， 然后深入神经 

643
00:37:08,069 --> 00:37:15,089
网络版Q 学习了 

644
00:37:12,420 --> 00:37:17,670
算法重复以下步骤

645
00:37:15,089 --> 00:37:23,069
步入世界观察一个初始 

646
00:37:17,670 --> 00:37:24,900
说明你选择一个动作 八 

647
00:37:23,069 --> 00:37:26,759
如果你正在探索将采取行动 

648
00:37:24,900 --> 00:37:29,160
如果你贪婪的话随机行动 

649
00:37:26,759 --> 00:37:31,019
追求你能做到的最好的行动 

650
00:37:29,160 --> 00:37:33,900
是最大化 Q的行动

651
00:37:31,019 --> 00:37:36,839
在你之后观察奖励的功能

652
00:37:33,900 --> 00:37:38,999
采取两个行动和一个新的状态 ，你 

653
00:37:36,839 --> 00:37:40,420
发现自己，然后你 更新 

654
00:37:38,999 --> 00:37:42,190
你的估计

655
00:37:40,420 --> 00:37:44,349
你所拥有的以前的州 

656
00:37:42,190 --> 00:37:48,430
鉴于采取了 这一行动 

657
00:37:44,349 --> 00:37:53,200
贝尔曼方程更新并重复此操作

658
00:37:48,430 --> 00:38:04,960
一遍又一遍，所以他们在底部 

659
00:37:53,200 --> 00:38:14,710
幻灯片 的 是生活的总结 是的 

660
00:38:04,960 --> 00:38:17,829
看 Q函数是的是的，是的 

661
00:38:14,710 --> 00:38:20,470
唯一的问题是问题

662
00:38:17,829 --> 00:38:25,470
功能单一，是的 

663
00:38:20,470 --> 00:38:25,470
它只是一个连续的值 

664
00:38:34,230 --> 00:38:38,820
所以问题是 你 如何 建模 

665
00:38:36,670 --> 00:38:38,820
世界

666
00:38:39,900 --> 00:38:47,920
所以你的模型让 我们开始吧 

667
00:38:44,980 --> 00:38:50,290
非常简单的Atari桨世界

668
00:38:47,920 --> 00:38:51,940
你认为你把它建模为桨 

669
00:38:50,290 --> 00:38:54,910
可以左右移动，有 一些 

670
00:38:51,940 --> 00:39:00,610
块和你 模拟的物理 

671
00:38:54,910 --> 00:39:02,590
球需要 很多专家 

672
00:39:00,610 --> 00:39:05,710
知道那个特定的游戏，所以你 

673
00:39:02,590 --> 00:39:08,920
坐在那里手工制作这个模型

674
00:39:05,710 --> 00:39:12,790
即使是 简单的游戏也很难做到

675
00:39:08,920 --> 00:39:15,490
您可以采取的其他模型正在考虑

676
00:39:12,790 --> 00:39:18,850
这个世界就像人类 一样 

677
00:39:15,490 --> 00:39:23,620
在视觉上将模型作为一组进行

678
00:39:18,850 --> 00:39:26,710
像素 的 只是模型是所有 

679
00:39:23,620 --> 00:39:29,730
你什么都不知道的世界的像素

680
00:39:26,710 --> 00:39:32,440
关于桨或球或物理或

681
00:39:29,730 --> 00:39:35,200
颜色和点他们只是像素

682
00:39:32,440 --> 00:39:37,240
进来那似乎是荒谬的

683
00:39:35,200 --> 00:39:39,640
世界的模型， 但它似乎工作 

684
00:39:37,240 --> 00:39:43,210
对于Atari来说，它似乎 适用 于人类 

685
00:39:39,640 --> 00:39:46,900
当你出生时，你会看到那里的存在 

686
00:39:43,210 --> 00:39:52,090
光进入你的眼睛和你 

687
00:39:46,900 --> 00:39:54,010
据我们所知，没有任何东西 

688
00:39:52,090 --> 00:39:56,890
你没有来 指导和 

689
00:39:54,010 --> 00:40:00,340
你出生了，你知道有人在里面 

690
00:39:56,890 --> 00:40:02,920
世界上有好人和​​坏人 

691
00:40:00,340 --> 00:40:06,850
家伙，它只是你怎么走 都没有 

692
00:40:02,920 --> 00:40:14,290
你得到的是轻音和另一个 

693
00:40:06,850 --> 00:40:17,430
传感器，你可以了解 

694
00:40:14,290 --> 00:40:20,290
你认为的每一件事 

695
00:40:17,430 --> 00:40:22,390
你塑造世界的方式是学到的 

696
00:40:20,290 --> 00:40:24,550
代表，我们将谈论如何 

697
00:40:22,390 --> 00:40:28,210
它学会了一个神经网络 

698
00:40:24,550 --> 00:40:32,530
代表着世界，但如果我们 要 

699
00:40:28,210 --> 00:40:36,220
手模拟世界这是不可能的 

700
00:40:32,530 --> 00:40:39,160
任务 那就是这是 问题 ，如果我们 

701
00:40:36,220 --> 00:40:43,170
那时候 必须用手模拟 世界 

702
00:40:39,160 --> 00:40:45,850
世界更好是一个简单的是啊 

703
00:40:43,170 --> 00:40:48,270
这个问题是一个很好 的问题 

704
00:40:45,850 --> 00:40:50,800
这个模型 的稳健性是什么？ 

705
00:40:48,270 --> 00:40:53,330
这是你代表世界的方式 

706
00:40:50,800 --> 00:40:56,140
这一切都略有不同

707
00:40:53,330 --> 00:40:59,660
从你认为这个世界的方式来看 

708
00:40:56,140 --> 00:41:02,000
就我而言，那不是那么好的研究 

709
00:40:59,660 --> 00:41:04,160
意识到你我的意思是它已经存在了 

710
00:41:02,000 --> 00:41:06,140
令人惊讶的是，如果你构建，如果你有一个

711
00:41:04,160 --> 00:41:07,520
如果你有一个 世界的某些输入 

712
00:41:06,140 --> 00:41:10,370
您可以学习的某个世界模型

713
00:41:07,520 --> 00:41:13,820
任何事情都是令人惊讶的问题 

714
00:41:10,370 --> 00:41:15,740
是的，重要的是我们会谈 

715
00:41:13,820 --> 00:41:17,840
一点点 关于它不是关于 

716
00:41:15,740 --> 00:41:19,010
世界模型， 但奖励功能，如果 

717
00:41:17,840 --> 00:41:22,130
奖励功能略有提升 

718
00:41:19,010 --> 00:41:25,960
不同 的真正的奖励功能 

719
00:41:22,130 --> 00:41:28,520
生活或驾驶或海岸赛跑者 

720
00:41:25,960 --> 00:41:30,920
比你预期 它 有什么不同

721
00:41:28,520 --> 00:41:36,590
那是什么是消极的 

722
00:41:30,920 --> 00:41:41,450
是的，这可能是巨大的，所以有 

723
00:41:36,590 --> 00:41:46,430
另一个问题或者不，我的意思是对不起 

724
00:41:41,450 --> 00:41:49,010
你 可以 问一遍是的 ，你可以 

725
00:41:46,430 --> 00:41:50,720
改变它所以 问题就是这样 

726
00:41:49,010 --> 00:41:52,820
你 随时间 改变 阿尔法值 

727
00:41:50,720 --> 00:42:01,070
当然应该改变阿尔法值 

728
00:41:52,820 --> 00:42:04,070
随着时间的推移， 是的哦，所以问题 是 

729
00:42:01,070 --> 00:42:05,510
什么是 的 复杂的相互作用 

730
00:42:04,070 --> 00:42:07,010
epsilon功能与​​一些学习 

731
00:42:05,510 --> 00:42:10,640
更新

732
00:42:07,010 --> 00:42:14,710
这是100％微调 和 调整到 

733
00:42:10,640 --> 00:42:21,400
特别是学习问题所以你 

734
00:42:14,710 --> 00:42:24,680
当然想要更复杂 的 

735
00:42:21,400 --> 00:42:26,960
世界上的州数量越多 

736
00:42:24,680 --> 00:42:31,220
并且行动的次数越多 

737
00:42:26,960 --> 00:42:33,440
再你有 之前 要 等待 

738
00:42:31,220 --> 00:42:35,810
将沙龙减少到零，但你有 

739
00:42:33,440 --> 00:42:36,740
玩它 ，它是其中之一 

740
00:42:35,810 --> 00:42:38,480
你必须玩的参数

741
00:42:36,740 --> 00:42:40,760
不幸的是，有很多 

742
00:42:38,480 --> 00:42:42,560
他们这就是为什么你不能只是 放弃一个 

743
00:42:40,760 --> 00:42:43,040
强化学习剂进入 

744
00:42:42,560 --> 00:42:49,220
世界 

745
00:42:43,040 --> 00:42:53,860
哦，效果本质上不是没有它只是 

746
00:42:49,220 --> 00:42:55,820
硬币翻转，如果它 是epsilon 2.5 

747
00:42:53,860 --> 00:42:58,130
一半的时间你要去一个 

748
00:42:55,820 --> 00:43:01,220
随机行动，所以不，没有

749
00:42:58,130 --> 00:43:03,350
特别是它不像你会采取的 

750
00:43:01,220 --> 00:43:04,880
最好的行动，然后与一些 

751
00:43:03,350 --> 00:43:06,540
概率取第二个低音等等 

752
00:43:04,880 --> 00:43:09,120
我的意思是 你当然可以这样 做 

753
00:43:06,540 --> 00:43:11,460
但是在简单的配方中有效 

754
00:43:09,120 --> 00:43:12,600
如果你 只是采取随机行动，因为 

755
00:43:11,460 --> 00:43:15,600
你不想有 先入为主 

756
00:43:12,600 --> 00:43:17,340
什么是一个好的行动 尝试时的概念 

757
00:43:15,600 --> 00:43:22,220
你正在探索的重点是 你 

758
00:43:17,340 --> 00:43:26,000
尝试疯狂的东西， 如果它是一个模拟 

759
00:43:22,220 --> 00:43:30,210
好的，这么好的问题 

760
00:43:26,000 --> 00:43:31,860
因此，代表性是重要 的 

761
00:43:30,210 --> 00:43:35,690
我们如何代表 问题 

762
00:43:31,860 --> 00:43:39,840
世界， 所以我们 可以想到这个世界 

763
00:43:35,690 --> 00:43:43,290
例如这个Atari游戏的 分手 

764
00:43:39,840 --> 00:43:46,380
作为移动左， 右桨

765
00:43:43,290 --> 00:43:47,940
和 不同 的精确位置 

766
00:43:46,380 --> 00:43:51,390
你 可以打的 东西 构建这个 

767
00:43:47,940 --> 00:43:53,160
复杂模型这个专家驱动模型 

768
00:43:51,390 --> 00:43:59,310
这必须微调它 

769
00:43:53,160 --> 00:44:03,600
特别的问题，但在实践中 

770
00:43:59,310 --> 00:44:06,060
更复杂的这个模型变得更糟 

771
00:44:03,600 --> 00:44:08,100
那个发展方程更新了

772
00:44:06,060 --> 00:44:10,500
阀门试图构建一个立方体 

773
00:44:08,100 --> 00:44:13,440
每个组合的功能 

774
00:44:10,500 --> 00:44:16,140
国家和行动变得太难了 

775
00:44:13,440 --> 00:44:20,550
因为 那个功能太稀疏了 

776
00:44:16,140 --> 00:44:22,650
如果你想到的话，那就太大了 

777
00:44:20,550 --> 00:44:25,230
以一般的方式看待这个世界

778
00:44:22,650 --> 00:44:27,840
和人类的方式是 一个 

779
00:44:25,230 --> 00:44:30,660
如果你在视觉上集合像素

780
00:44:27,840 --> 00:44:32,760
只需要一个像素这个游戏是一个 

781
00:44:30,660 --> 00:44:38,640
收集八十四八十四 

782
00:44:32,760 --> 00:44:40,640
个像素的图像的 RGB 图像，然后 

783
00:44:38,640 --> 00:44:45,300
你不仅要看当前的图像 

784
00:44:40,640 --> 00:44:47,250
但看的时间轨迹

785
00:44:45,300 --> 00:44:48,600
如果有一个球，这些图像就像 

786
00:44:47,250 --> 00:44:52,110
电影你想知道有关 

787
00:44:48,600 --> 00:44:53,820
运动让 你看起来在四象 所以 

788
00:44:52,110 --> 00:44:59,550
目前图像和三张图像回来了 

789
00:44:53,820 --> 00:45:00,540
并说他们是256 a的 灰度 

790
00:44:59,550 --> 00:45:04,020
灰度 

791
00:45:00,540 --> 00:45:10,460
这是cue表的大小 

792
00:45:04,020 --> 00:45:10,460
q值 函数必须要学习 

793
00:45:10,640 --> 00:45:14,730
无论那个 数字是什么， 但 它是 

794
00:45:12,870 --> 00:45:18,810
肯定比数量 大 

795
00:45:14,730 --> 00:45:19,950
宇宙中的 原子 是 一个大的 

796
00:45:18,810 --> 00:45:22,830
号码如此 

797
00:45:19,950 --> 00:45:27,770
所以你必须长时间运行模拟 

798
00:45:22,830 --> 00:45:30,500
足以触摸至少 几次 

799
00:45:27,770 --> 00:45:34,830
该队列表中的大多数状态

800
00:45:30,500 --> 00:45:37,590
所以你知道一个 清真寺说你可能 

801
00:45:34,830 --> 00:45:40,290
需要跑你知道我们住在一个 

802
00:45:37,590 --> 00:45:44,310
您可能运行的模拟必须运行 

803
00:45:40,290 --> 00:45:49,620
另一个宇宙正义 - 计算D. 

804
00:45:44,310 --> 00:45:53,190
这种 情况下的立方体功能 就是这样 

805
00:45:49,620 --> 00:46:00,180
相反，深度学习的内容 

806
00:45:53,190 --> 00:46:04,050
的 造型世界作为一个提示你表 

807
00:46:00,180 --> 00:46:08,640
估计你试着学习那个功能 

808
00:46:04,050 --> 00:46:10,500
所以从监督的外卖

809
00:46:08,640 --> 00:46:12,440
学习如果你记得它是好的 

810
00:46:10,500 --> 00:46:16,440
记忆时会去记忆数据 

811
00:46:12,440 --> 00:46:21,590
希望为增强与学习

812
00:46:16,440 --> 00:46:24,870
提示提示学习是我们可以扩展的 

813
00:46:21,590 --> 00:46:27,870
我们偶尔得到的奖励 

814
00:46:24,870 --> 00:46:29,970
概括了操作

815
00:46:27,870 --> 00:46:32,580
你在 这个世界领先的行动

816
00:46:29,970 --> 00:46:35,570
达到奖励和深刻的希望 

817
00:46:32,580 --> 00:46:39,390
学习是我们可以移动这个

818
00:46:35,570 --> 00:46:42,150
强化学习系统成

819
00:46:39,390 --> 00:46:46,620
世界并不需要 是 他们 可以 

820
00:46:42,150 --> 00:46:48,930
任意定义可以包括所有 

821
00:46:46,620 --> 00:46:51,780
Atari游戏的像素可以包括 

822
00:46:48,930 --> 00:46:57,960
无人机或机器人发送的所有像素

823
00:46:51,780 --> 00:47:00,120
或汽车但仍需要正式化 

824
00:46:57,960 --> 00:47:04,370
那个世界的定义很多 

825
00:47:00,120 --> 00:47:08,490
当你能够接受时更容易做到 

826
00:47:04,370 --> 00:47:14,220
传感器像图像所以ddq学习 

827
00:47:08,490 --> 00:47:17,330
深刻的版本，而不是学习 

828
00:47:14,220 --> 00:47:22,440
一个可爱的表 提示功能， 我们尝试和 

829
00:47:17,330 --> 00:47:26,460
估计我们试图学习q prime 

830
00:47:22,440 --> 00:47:30,990
使用机器学习它，它会尝试 

831
00:47:26,460 --> 00:47:32,600
学习一些参数这个巨大的复杂

832
00:47:30,990 --> 00:47:35,900
功能

833
00:47:32,600 --> 00:47:39,380
我们试图学习它 和我们的方式 

834
00:47:35,900 --> 00:47:40,970
那就是 我们有一个神经网络 了 

835
00:47:39,380 --> 00:47:43,810
同样 的表现，学会了 

836
00:47:40,970 --> 00:47:46,610
要从图像映射到a的数字 

837
00:47:43,810 --> 00:47:50,060
该图像的分类成 

838
00:47:46,610 --> 00:47:52,880
数字与使用相同类型的网络

839
00:47:50,060 --> 00:47:58,100
采取一种状态和行动 

840
00:47:52,880 --> 00:48:04,850
现在产生Q值是惊人的 

841
00:47:58,100 --> 00:48:10,040
东西没有 一无所知 

842
00:48:04,850 --> 00:48:13,930
正如我用Q表所说的那样

843
00:48:10,040 --> 00:48:16,940
它随机初始化了Q函数 

844
00:48:13,930 --> 00:48:21,440
所以这个深层网络一无所知 

845
00:48:16,940 --> 00:48:24,950
所有它知道的一切都在

846
00:48:21,440 --> 00:48:26,950
模拟世界你获得的奖励 

847
00:48:24,950 --> 00:48:31,850
特定的游戏所以你必须玩 

848
00:48:26,950 --> 00:48:33,730
一次又一次地看到了 

849
00:48:31,850 --> 00:48:36,620
你得到的每 一个 奖励 

850
00:48:33,730 --> 00:48:40,850
迭代的游戏，但在 

851
00:48:36,620 --> 00:48:44,000
开始它什么都不知道，它能够 

852
00:48:40,850 --> 00:48:48,260
学会 比人类 更好 地发挥 

853
00:48:44,000 --> 00:48:49,930
众生这是一篇深刻的心灵论文 

854
00:48:48,260 --> 00:48:54,830
Atari深入强化学习

855
00:48:49,930 --> 00:48:56,540
从2013年开始 ，这 是关键的事情之一 

856
00:48:54,830 --> 00:48:58,610
这让每个人都为此感到 兴奋 

857
00:48:56,540 --> 00:49:04,940
深度学习和人工的作用

858
00:48:58,610 --> 00:49:06,470
智力 是使用共同的 真实 

859
00:49:04,940 --> 00:49:08,900
我将在 明天 谈论的网络 

860
00:49:06,470 --> 00:49:10,730
但它是一个 像香草网络一样的 

861
00:49:08,900 --> 00:49:13,730
我之前谈过的其他任何事情 

862
00:49:10,730 --> 00:49:17,180
今天只是一个普通的 网络需要 

863
00:49:13,730 --> 00:49:19,250
正如我所说和估计的原始像素 

864
00:49:17,180 --> 00:49:21,020
来自原始像素的Q函数 是 

865
00:49:19,250 --> 00:49:25,970
能够参加很多比赛 

866
00:49:21,020 --> 00:49:30,190
不是一个人 与失落更好

867
00:49:25,970 --> 00:49:34,460
我 之前 提到 过的功能

868
00:49:30,190 --> 00:49:37,850
再次非常香草失去了功能 

869
00:49:34,460 --> 00:49:39,470
简单的目标函数第一个

870
00:49:37,850 --> 00:49:44,240
你可能会实现我们有一个 

871
00:49:39,470 --> 00:49:46,339
讲述tensorflow平方误差的错误 

872
00:49:44,240 --> 00:49:50,029
我们 采用这个贝尔曼方程 

873
00:49:46,339 --> 00:49:53,329
我们估计Q是Q函数 

874
00:49:50,029 --> 00:49:57,199
估计国家和行动是

875
00:49:53,329 --> 00:50:00,469
最大的奖励你会得到 采取 任何的 

876
00:49:57,199 --> 00:50:06,289
把你带到任何一个的行动 

877
00:50:00,469 --> 00:50:08,900
未来的状态，你试图采取这一点 

878
00:50:06,289 --> 00:50:12,459
行动观察结果 

879
00:50:08,900 --> 00:50:15,680
行动，如果目标不同 

880
00:50:12,459 --> 00:50:17,779
你 学到的目标 ，您学习 

881
00:50:15,680 --> 00:50:20,059
学习的功能是什么

882
00:50:17,779 --> 00:50:23,209
这种情况下的预期奖励 

883
00:50:20,059 --> 00:50:25,069
与你实际 得到的 不同 

884
00:50:23,209 --> 00:50:30,079
调整它调整你的重量 

885
00:50:25,069 --> 00:50:34,519
网络，这正是这个过程 

886
00:50:30,079 --> 00:50:39,160
通过它我们学习如何存在 于此 

887
00:50:34,519 --> 00:50:45,499
像素世界所以 你要映射状态和 

888
00:50:39,160 --> 00:50:48,949
对算法的Q值的动作为

889
00:50:45,499 --> 00:50:52,489
跟着这就是我们训练它的方式 

890
00:50:48,949 --> 00:50:55,489
给定转换的当前状态

891
00:50:52,489 --> 00:50:57,650
在该州采取的行动是 

892
00:50:55,489 --> 00:51:03,079
你 得到的奖励和 你 的素数 是你的 

893
00:50:57,650 --> 00:51:05,239
你发现自己的状态，所以我们 

894
00:51:03,079 --> 00:51:10,489
替换基本更新规则

895
00:51:05,239 --> 00:51:14,029
以前的伪代码通过前进

896
00:51:10,489 --> 00:51:19,400
通过网络给定的 是 s 

897
00:51:14,029 --> 00:51:22,309
我们看看预测的Q值 

898
00:51:19,400 --> 00:51:24,259
值是我们接下来做的那个动作 

899
00:51:22,309 --> 00:51:28,239
另一个向前传递 

900
00:51:24,259 --> 00:51:35,479
网络，看看我们实际 得到了 什么 

901
00:51:28,239 --> 00:51:38,559
那么如果我们完全离开，我们会惩罚我们 

902
00:51:35,479 --> 00:51:41,479
以某种方式传播权重

903
00:51:38,559 --> 00:51:44,949
下次 我们会 减少 这个 

904
00:51:41,479 --> 00:51:50,630
错误，你重复这个过程和 

905
00:51:44,949 --> 00:51:53,449
这就是 你打你 一个 ，这是一个 

906
00:51:50,630 --> 00:51:55,900
你正在学习的模拟

907
00:51:53,449 --> 00:51:55,900
你自己

908
00:51:56,840 --> 00:52:04,490
并且同样适用于此处的规则 

909
00:52:00,470 --> 00:52:09,070
探索与剥削你 

910
00:52:04,490 --> 00:52:15,230
从一个零或 一个 epsilon开始

911
00:52:09,070 --> 00:52:19,850
你大部分都在探索，然后你 

912
00:52:15,230 --> 00:52:22,400
走向一个零和一个epsilon 

913
00:52:19,850 --> 00:52:25,460
Atari突破 这是深刻的头脑 

914
00:52:22,400 --> 00:52:28,220
纸结果是培训时期和 

915
00:52:25,460 --> 00:52:31,010
y轴上 的 x轴是平均值 

916
00:52:28,220 --> 00:52:34,670
行动价值和平均每个奖励

917
00:52:31,010 --> 00:52:37,780
插曲，我会告诉它为什么类型 的 

918
00:52:34,670 --> 00:52:41,420
惊人的结果，但它是凌乱的， 因为 

919
00:52:37,780 --> 00:52:44,090
有很多技巧，所以它是 

920
00:52:41,420 --> 00:52:46,430
不 只是放入 一堆像素 

921
00:52:44,090 --> 00:52:49,610
一个游戏， 让一个知道的代理人 

922
00:52:46,430 --> 00:52:50,720
如何赢得那场比赛有很多 

923
00:52:49,610 --> 00:52:54,530
预处理

924
00:52:50,720 --> 00:52:57,170
并使用所需的数据

925
00:52:54,530 --> 00:53:02,690
这是不幸的， 因为 真相 

926
00:52:57,170 --> 00:53:05,690
是混乱比希望，但的一个 

927
00:53:02,690 --> 00:53:09,920
所谓的关键技巧被称为 

928
00:53:05,690 --> 00:53:12,320
体验重播，而不是 

929
00:53:09,920 --> 00:53:14,800
让一个经纪人让你学习这个 

930
00:53:12,320 --> 00:53:17,360
学习尝试的大网络 

931
00:53:14,800 --> 00:53:20,180
建立一个好的做事模型 

932
00:53:17,360 --> 00:53:24,050
世界，什么不是，你是谁 

933
00:53:20,180 --> 00:53:26,450
随着经验学习 

934
00:53:24,050 --> 00:53:28,640
重播你跟踪所有的 

935
00:53:26,450 --> 00:53:30,080
你做过的事情，每次都会结束 

936
00:53:28,640 --> 00:53:32,270
有一段时间你回头看看你的 

937
00:53:30,080 --> 00:53:34,520
记忆并拉出一些 旧的 

938
00:53:32,270 --> 00:53:37,760
遇到老好老时间 ， 

939
00:53:34,520 --> 00:53:42,140
再次训练那些而不是 

940
00:53:37,760 --> 00:53:43,880
让代理人自己运行一些 

941
00:53:42,140 --> 00:53:45,770
当地的Optima试图 学习 

942
00:53:43,880 --> 00:53:48,680
游戏 中 非常微妙的 方面 

943
00:53:45,770 --> 00:53:51,440
实际上在 全球意义上并没有得到 

944
00:53:48,680 --> 00:53:54,770
你更远非常赢比赛

945
00:53:51,440 --> 00:53:56,570
同样如此，这是算法 

946
00:53:54,770 --> 00:54:01,220
深度线索 学习算法 

947
00:53:56,570 --> 00:54:04,130
Shido代码我们初始化重播 

948
00:54:01,220 --> 00:54:07,190
记忆再次有这个小技巧

949
00:54:04,130 --> 00:54:09,530
这需要它保持跟踪 

950
00:54:07,190 --> 00:54:11,900
那些在过去发生的事情 

951
00:54:09,530 --> 00:54:14,450
我们初始化动作值函数 

952
00:54:11,900 --> 00:54:17,540
队列随机权重并观察 

953
00:54:14,450 --> 00:54:20,500
初始状态 再次同样 选择一个 

954
00:54:17,540 --> 00:54:24,620
以概率Epsilon行动

955
00:54:20,500 --> 00:54:26,930
探险者， 否则她是最好的 

956
00:54:24,620 --> 00:54:29,180
基于 由 所提供的估计 

957
00:54:26,930 --> 00:54:32,480
神经网络然后进行 

958
00:54:29,180 --> 00:54:36,950
动作观察奖励和商店 

959
00:54:32,480 --> 00:54:39,980
然后在重播记忆中体验

960
00:54:36,950 --> 00:54:45,260
从重播中抽样随机过渡

961
00:54:39,980 --> 00:54:47,720
记忆所以 你 有一定的 概率 

962
00:54:45,260 --> 00:54:50,140
把那些旧时代回去取 

963
00:54:47,720 --> 00:54:53,170
你自己离开了当地的 最低点 

964
00:54:50,140 --> 00:54:58,450
然后你在q网络训练治疗 

965
00:54:53,170 --> 00:55:01,720
使用你的差异

966
00:54:58,450 --> 00:55:07,220
你实际得到的估计数 

967
00:55:01,720 --> 00:55:08,780
你重复这个过程一遍又 一遍，以便 

968
00:55:07,220 --> 00:55:13,160
这是十分钟 后你能做的 

969
00:55:08,780 --> 00:55:17,900
在 左边 的训练 ， 这是非常的 

970
00:55:13,160 --> 00:55:21,710
你得到的一点点训练就是划桨 

971
00:55:17,900 --> 00:55:23,600
几乎没有学到任何东西 

972
00:55:21,710 --> 00:55:25,400
如果你看它就会继续死亡

973
00:55:23,600 --> 00:55:28,520
5至4至3至2比1 

974
00:55:25,400 --> 00:55:31,340
那些是剩下的生命数量

975
00:55:28,520 --> 00:55:37,220
经过2个小时的 单人 训练 

976
00:55:31,340 --> 00:55:42,740
它不会让你学到GPU 

977
00:55:37,220 --> 00:55:46,550
知道不会死点 并学习 

978
00:55:42,740 --> 00:55:49,070
避免球传球 

979
00:55:46,550 --> 00:55:51,700
桨 是伟大的人类 

980
00:55:49,070 --> 00:55:55,700
水平表现真的比 

981
00:55:51,700 --> 00:55:57,470
你认识的一些人 ，但它仍然死亡 

982
00:55:55,700 --> 00:56:01,750
有时候这是非常人性化的 

983
00:55:57,470 --> 00:56:07,850
然后在4小时后它做了一些事情 

984
00:56:01,750 --> 00:56:10,660
真的很神奇， 它会弄清楚如何 获胜 

985
00:56:07,850 --> 00:56:15,440
这是 一种非常 懒惰的游戏 

986
00:56:10,660 --> 00:56:17,510
在整个 街区钻一个洞

987
00:56:15,440 --> 00:56:19,730
顶部并将球 伸到那里 

988
00:56:17,510 --> 00:56:21,740
然后它所有的辛勤工作 

989
00:56:19,730 --> 00:56:23,280
你的概率最小化 

990
00:56:21,740 --> 00:56:26,910
球越过你的球拍 

991
00:56:23,280 --> 00:56:29,940
它只是停留在在在 

992
00:56:26,910 --> 00:56:31,290
阻挡顶部所以它可能是 

993
00:56:29,940 --> 00:56:35,310
你甚至都不会想到的东西 

994
00:56:31,290 --> 00:56:39,630
出去做自己，这是 一个 帮助 

995
00:56:35,310 --> 00:56:43,110
那种暂停这里 交代清楚 

996
00:56:39,630 --> 00:56:46,500
发生了什么事情的输入 

997
00:56:43,110 --> 00:56:49,200
算法是 游戏的 只是像素 

998
00:56:46,500 --> 00:56:51,450
这和人类是一回事 

999
00:56:49,200 --> 00:56:55,500
当他们采取视觉时接受 

1000
00:56:51,450 --> 00:56:58,560
感知，它能够学习 

1001
00:56:55,500 --> 00:57:00,990
这种约束的定义是什么

1002
00:56:58,560 --> 00:57:07,700
奖励和惩罚它能够 

1003
00:57:00,990 --> 00:57:11,280
学会 获得 高额奖励 

1004
00:57:07,700 --> 00:57:14,160
一般的人工智能非常 

1005
00:57:11,280 --> 00:57:16,320
它的小例子，但其一般 的 

1006
00:57:14,160 --> 00:57:19,650
通用也一无所知 

1007
00:57:16,320 --> 00:57:22,710
游戏， 对桨或者一无所知 

1008
00:57:19,650 --> 00:57:25,650
物理学它只需要三个输入 

1009
00:57:22,710 --> 00:57:27,450
游戏，他们做了同样的事情 

1010
00:57:25,650 --> 00:57:33,120
在 Atari 的一堆 不同的 游戏 

1011
00:57:27,450 --> 00:57:37,140
和怎么在这里显示 在该地块上 

1012
00:57:33,120 --> 00:57:40,050
x轴 和一堆不同 

1013
00:57:37,140 --> 00:57:42,960
来自Atari 和 y轴的游戏是 

1014
00:57:40,050 --> 00:57:45,930
百分其中一个 百分百 

1015
00:57:42,960 --> 00:57:48,090
关于人类可以做的最好的事情

1016
00:57:45,930 --> 00:57:50,040
这意味着它是人类的得分 

1017
00:57:48,090 --> 00:57:52,020
会得到关于 那里的 一切 

1018
00:57:50,040 --> 00:57:54,270
中间的一切都在左边 

1019
00:57:52,020 --> 00:57:57,690
这远远超过了人类的水平

1020
00:57:54,270 --> 00:58:00,240
表现低于 平均水平 

1021
00:57:57,690 --> 00:58:04,640
比人类水平 表现 差 

1022
00:58:00,240 --> 00:58:07,650
你可以学到所有这么多的拳击弹球 

1023
00:58:04,640 --> 00:58:09,390
所有这些游戏都不知道 

1024
00:58:07,650 --> 00:58:11,730
关于任何个人的任何事情 

1025
00:58:09,390 --> 00:58:14,010
游戏它 只是把像素 是 

1026
00:58:11,730 --> 00:58:18,720
就好像你把一个人放在一边

1027
00:58:14,010 --> 00:58:26,060
在任何这些游戏背后并问他们 

1028
00:58:18,720 --> 00:58:27,410
学会击败比赛然后 

1029
00:58:26,060 --> 00:58:32,900
在这 方面做了很多改进 

1030
00:58:27,410 --> 00:58:35,330
最近的算法是问题没错 没了 

1031
00:58:32,900 --> 00:58:37,370
没有， 所以问题是他们 

1032
00:58:35,330 --> 00:58:40,490
为游戏定制游戏模型 

1033
00:58:37,370 --> 00:58:42,980
特别的游戏， 没有你的意思 

1034
00:58:40,490 --> 00:58:44,450
当然可以但重点是它 

1035
00:58:42,980 --> 00:58:51,370
并不需要为用户定制 

1036
00:58:44,450 --> 00:58:55,640
游戏，但重要的 是 

1037
00:58:51,370 --> 00:58:56,600
它仍然只在Atari游戏 权利，使 

1038
00:58:55,640 --> 00:59:01,750
这个问题是否存在 

1039
00:58:56,600 --> 00:59:01,750
转移到驾驶 也许不是 

1040
00:59:09,280 --> 00:59:13,910
对你玩游戏 你做的事情 

1041
00:59:12,830 --> 00:59:16,540
不是你没有 

1042
00:59:13,910 --> 00:59:22,790
好吧，是的，你玩游戏的一步

1043
00:59:16,540 --> 00:59:25,510
所以你在一个州采取行动然后 

1044
00:59:22,790 --> 00:59:30,470
你观察到，所以你有 

1045
00:59:25,510 --> 00:59:32,060
模拟我的意思是真的那样 

1046
00:59:30,470 --> 00:59:35,720
这里最大的问题之一 就是你 

1047
00:59:32,060 --> 00:59:43,790
需要模拟， 以便 

1048
00:59:35,720 --> 00:59:46,730
得到基本的事实，这是一个伟大的 

1049
00:59:43,790 --> 00:59:49,750
对评论提出质疑或 评论 

1050
00:59:46,730 --> 00:59:52,370
对于很多 这种 情况来说 就是 这样 

1051
00:59:49,750 --> 00:59:54,770
奖励功能可能不会改变 

1052
00:59:52,370 --> 01:00:00,080
所有这些都取决于 你的行动 疣 

1053
00:59:54,770 --> 01:00:03,890
真的大部分时间都推迟了10 

1054
01:00:00,080 --> 01:00:07,450
20 30步下线 就是 为什么 

1055
01:00:03,890 --> 01:00:11,720
令人惊讶的是，这一切都很有效 

1056
01:00:07,450 --> 01:00:15,410
它正在学习本地学习

1057
01:00:11,720 --> 01:00:17,630
并通过这个模拟过程

1058
01:00:15,410 --> 01:00:21,920
数十万五运行到 的 

1059
01:00:17,630 --> 01:00:25,630
游戏它能够学习 现在做什么 

1060
01:00:21,920 --> 01:00:30,260
这样我以后会得到奖励 

1061
01:00:25,630 --> 01:00:32,330
这是一个如果你 只是暂停看看 

1062
01:00:30,260 --> 01:00:36,880
数学， 这是非常简单的数学和 

1063
01:00:32,330 --> 01:00:36,880
看看结果 令人难以置信 

1064
01:00:37,440 --> 01:00:43,860
所以这有很多改进 

1065
01:00:40,290 --> 01:00:47,940
一个称为一般强化

1066
01:00:43,860 --> 01:00:50,070
学习建筑或大猩猩 

1067
01:00:47,940 --> 01:00:54,510
这在模拟中很酷

1068
01:00:50,070 --> 01:00:55,890
世界至少是 你可以 深入人心 

1069
01:00:54,510 --> 01:00:57,870
强化学习和分配 

1070
01:00:55,890 --> 01:00:59,550
你可以做两个模拟的方式 

1071
01:00:57,870 --> 01:01:03,210
分配方式你可以做到的 

1072
01:00:59,550 --> 01:01:05,790
以分配方式学习，你可以 

1073
01:01:03,210 --> 01:01:07,800
您可以生成经验是 

1074
01:01:05,790 --> 01:01:11,160
什么这种图 的 显示 ，你可以 

1075
01:01:07,800 --> 01:01:16,370
无论是来自人类还是来自 人类 

1076
01:01:11,160 --> 01:01:19,890
仿真所以例如方式 

1077
01:01:16,370 --> 01:01:22,500
alphago深思熟虑团队的方式 

1078
01:01:19,890 --> 01:01:25,440
是打败了他们的游戏 

1079
01:01:22,500 --> 01:01:28,980
从专家游戏中学习

1080
01:01:25,440 --> 01:01:30,750
自己玩， 所以你可以 这样做 

1081
01:01:28,980 --> 01:01:32,130
分布式的方式 ，你可以做到 

1082
01:01:30,750 --> 01:01:35,360
学习分布式方式， 这样你就可以 

1083
01:01:32,130 --> 01:01:39,030
规模和在这种特殊 情况下 

1084
01:01:35,360 --> 01:01:44,100
大猩猩取得了更好的成绩

1085
01:01:39,030 --> 01:01:49,020
比 网络上 的 DQ这部分 

1086
01:01:44,100 --> 01:01:54,000
他们的自然纸 好吧 现在让我吧 

1087
01:01:49,020 --> 01:02:00,060
在这里开车一秒钟 

1088
01:01:54,000 --> 01:02:01,800
强化学习在哪里

1089
01:02:00,060 --> 01:02:05,790
强化学习可以介入和 

1090
01:02:01,800 --> 01:02:08,160
帮助所以这回 开 

1091
01:02:05,790 --> 01:02:10,590
问我昨天问它是开车的 

1092
01:02:08,160 --> 01:02:12,870
更接近国际象棋或每天 

1093
01:02:10,590 --> 01:02:15,600
会话象棋 

1094
01:02:12,870 --> 01:02:17,730
意思是它可以在一个形式化 

1095
01:02:15,600 --> 01:02:19,380
简单的方式，我们可以思考 

1096
01:02:17,730 --> 01:02:21,480
将其视为 避障 

1097
01:02:19,380 --> 01:02:25,280
问题和一旦避障 

1098
01:02:21,480 --> 01:02:28,050
解决了你只需导航它 

1099
01:02:25,280 --> 01:02:30,270
您选择移动的 受限 空间 

1100
01:02:28,050 --> 01:02:34,440
离开它 以前在车道上向右移动 

1101
01:02:30,270 --> 01:02:36,930
您选择加快或减慢以及 

1102
01:02:34,440 --> 01:02:40,350
如果它像国际象棋这样的游戏我们会 

1103
01:02:36,930 --> 01:02:44,460
假设为今天 而不是为了 

1104
01:02:40,350 --> 01:02:47,280
今天明天我们要走了 

1105
01:02:44,460 --> 01:02:50,829
与左边的一个 ，我们要去 

1106
01:02:47,280 --> 01:02:57,859
看看深交通 

1107
01:02:50,829 --> 01:02:59,599
这是这个游戏或模拟的地方 

1108
01:02:57,859 --> 01:03:05,259
目标是达到最高的 平均水平 

1109
01:02:59,599 --> 01:03:10,970
你可以在这条七车道高速公路上行驶 

1110
01:03:05,259 --> 01:03:12,979
充满了汽车，所以作为旁注 

1111
01:03:10,970 --> 01:03:15,170
学生的要求是他们必须的 

1112
01:03:12,979 --> 01:03:16,640
按照我将提供的教程 

1113
01:03:15,170 --> 01:03:21,259
本 演示文稿末尾的链接

1114
01:03:16,640 --> 01:03:23,839
他们要做的就是实现一个目标 

1115
01:03:21,259 --> 01:03:26,920
速度建立一个实现的网络

1116
01:03:23,839 --> 01:03:31,430
速度为每小时 65英里或更高 

1117
01:03:26,920 --> 01:03:33,920
有一个排行榜，你得到 

1118
01:03:31,430 --> 01:03:35,779
提交你提出的模型

1119
01:03:33,920 --> 01:03:37,039
一个按钮的简单的点击，因此所有 的这 

1120
01:03:35,779 --> 01:03:39,670
在浏览器中运行

1121
01:03:37,039 --> 01:03:43,390
还有另一件令人惊奇的事情 

1122
01:03:39,670 --> 01:03:47,739
然后你立即或相对如此 

1123
01:03:43,390 --> 01:03:47,739
让你的方式进步的排行榜 等等 

1124
01:03:48,640 --> 01:03:54,950
让我们来看看 放大这是什么 

1125
01:03:52,220 --> 01:03:59,239
什么是这个世界的 二维 世界 

1126
01:03:54,950 --> 01:04:03,200
交通是它是什么样子 像 

1127
01:03:59,239 --> 01:04:06,469
我们离散的情报系统 

1128
01:04:03,200 --> 01:04:08,029
那个世界变成了一个显示在这里的网格 

1129
01:04:06,469 --> 01:04:10,190
左边 是那个的代表 

1130
01:04:08,029 --> 01:04:11,749
国家有 七个车道和 

1131
01:04:10,190 --> 01:04:15,499
每一个 小巷都被分解成了 

1132
01:04:11,749 --> 01:04:17,539
空间阻挡，如果有车 进去 

1133
01:04:15,499 --> 01:04:21,430
该块的汽车中的长度约为 

1134
01:04:17,539 --> 01:04:27,640
这三个网格块中有三个块 

1135
01:04:21,430 --> 01:04:32,089
然后那个最伟大的场景被占用了 

1136
01:04:27,640 --> 01:04:35,200
那红色的车就是你的意思 

1137
01:04:32,089 --> 01:04:38,450
那是在智能代理中运行的 

1138
01:04:35,200 --> 01:04:42,910
左边是当前的速度 

1139
01:04:38,450 --> 01:04:46,789
红色汽车实际上说麻省理工学院名列前茅

1140
01:04:42,910 --> 01:04:50,989
然后你也算了一下 

1141
01:04:46,789 --> 01:04:53,630
很多车你通过，如果你的网络 

1142
01:04:50,989 --> 01:04:56,140
吮吸而且这个数字将会 得到 

1143
01:04:53,630 --> 01:04:56,140
是否定的 

1144
01:04:58,050 --> 01:05:02,760
你也可以与 一个 下拉改变

1145
01:05:00,060 --> 01:05:07,910
模拟速度从正常开始 

1146
01:05:02,760 --> 01:05:07,910
在右边太快， 所以正常 

1147
01:05:10,040 --> 01:05:16,950
所以你知道的快的速度

1148
01:05:13,050 --> 01:05:19,230
重播模拟上的一个 

1149
01:05:16,950 --> 01:05:27,330
离开正常感觉有点像 

1150
01:05:19,230 --> 01:05:29,430
真正的驱动有一个下拉 的 

1151
01:05:27,330 --> 01:05:31,890
不同的显示 选项 

1152
01:05:29,430 --> 01:05:33,110
默认是没有在 东西方面 

1153
01:05:31,890 --> 01:05:36,270
你在路上展示

1154
01:05:33,110 --> 01:05:39,120
然后有学习输入 

1155
01:05:36,270 --> 01:05:43,080
是同时这整个空间 

1156
01:05:39,120 --> 01:05:48,180
离散你可以选择你的车 

1157
01:05:43,080 --> 01:05:51,090
看到了，你可以选择多远 

1158
01:05:48,180 --> 01:05:54,690
C的头部落后了多远 

1159
01:05:51,090 --> 01:05:56,730
并通过选择它看到了它

1160
01:05:54,690 --> 01:05:58,230
学习输入以可视化学习它

1161
01:05:56,730 --> 01:06:02,550
但你会看到你设置的那个 

1162
01:05:58,230 --> 01:06:06,630
输入是有安全性的 

1163
01:06:02,550 --> 01:06:10,110
系统这是一个 保护 的系统 

1164
01:06:06,630 --> 01:06:14,250
你是我们自己创造的方式 

1165
01:06:10,110 --> 01:06:17,370
这场比赛就是它的 运作 

1166
01:06:14,250 --> 01:06:19,520
如果你有一些相似的东西

1167
01:06:17,370 --> 01:06:23,340
智力， 如果你开车，你有 

1168
01:06:19,520 --> 01:06:26,280
自适应巡航控制在你的 车里 

1169
01:06:23,340 --> 01:06:28,290
在运行时，它得到同样的方式 

1170
01:06:26,280 --> 01:06:31,590
靠近前面的车，它减速 

1171
01:06:28,290 --> 01:06:34,020
你和它 不会让你运行 

1172
01:06:31,590 --> 01:06:38,270
汽车在 你 左边 的右边 

1173
01:06:34,020 --> 01:06:42,120
你离开了路，所以限制了 

1174
01:06:38,270 --> 01:06:44,510
你车的运动能力

1175
01:06:42,120 --> 01:06:46,350
这样一种方式， 你不会打任何人 

1176
01:06:44,510 --> 01:06:48,560
因为那时它必须 模拟 

1177
01:06:46,350 --> 01:06:52,740
碰撞和这将只是一个烂摊子 

1178
01:06:48,560 --> 01:06:54,420
所以它保护你免受那个，所以你

1179
01:06:52,740 --> 01:06:57,360
可以选择可视化该 报价 

1180
01:06:54,420 --> 01:06:59,610
不引用安全系统 

1181
01:06:57,360 --> 01:07:02,730
可视化框然后你也可以

1182
01:06:59,610 --> 01:07:05,160
选择可视化这是完整的地图 

1183
01:07:02,730 --> 01:07:09,090
你得到的完整占用地图 

1184
01:07:05,160 --> 01:07:10,829
你想提供输入 

1185
01:07:09,090 --> 01:07:13,289
网络

1186
01:07:10,829 --> 01:07:16,349
现在每个网格的输入

1187
01:07:13,289 --> 01:07:17,880
这是一个数字，它不仅仅是 零 

1188
01:07:16,349 --> 01:07:23,069
一个 是否有车在那里 

1189
01:07:17,880 --> 01:07:25,949
这是80的最高速度限制 

1190
01:07:23,069 --> 01:07:28,519
每小时英里所以不要去不要 

1191
01:07:25,949 --> 01:07:32,279
疯狂80 英里 一小时的速度限制 

1192
01:07:28,519 --> 01:07:35,939
当它为 空 时阻止 设置为 

1193
01:07:32,279 --> 01:07:40,199
85英里每小时80英里 ，当它的时候 

1194
01:07:35,939 --> 01:07:43,890
占用了它设置 为 的数字 

1195
01:07:40,199 --> 01:07:46,679
汽车的速度， 然后块 

1196
01:07:43,890 --> 01:07:49,229
那辆红色汽车占据了 它 

1197
01:07:46,679 --> 01:07:50,609
说这个数字非常大 

1198
01:07:49,229 --> 01:08:00,739
数量远 高于速度 

1199
01:07:50,609 --> 01:08:05,670
这里的安全系统限制为红色 

1200
01:08:00,739 --> 01:08:10,150
网格 的部分 是不是 

1201
01:08:05,670 --> 01:08:11,359
您的车不能进入 的问题 

1202
01:08:10,150 --> 01:08:21,889
[音乐] 

1203
01:08:11,359 --> 01:08:23,909
那是什么，是的，问题是肯定的 

1204
01:08:21,889 --> 01:08:27,210
我只是第三种选择 

1205
01:08:23,909 --> 01:08:29,759
提到它 ， 这是你的红色汽车 

1206
01:08:27,210 --> 01:08:32,040
本身给自己块 

1207
01:08:29,759 --> 01:08:34,139
在那辆车的下方 设置 为真的 

1208
01:08:32,040 --> 01:08:35,880
高数字是 算法 的一种方式 

1209
01:08:34,139 --> 01:08:41,389
知道学习算法 

1210
01:08:35,880 --> 01:08:48,000
知道这些块是特殊的 

1211
01:08:41,389 --> 01:08:53,839
如果安全系统在这里显示红色 

1212
01:08:48,000 --> 01:08:58,710
汽车不能移动到那些街区所以任何 

1213
01:08:53,839 --> 01:09:00,540
就什么 时候点亮 红色呢 

1214
01:08:58,710 --> 01:09:02,880
意味着汽车不能再加速 了 

1215
01:09:00,540 --> 01:09:04,529
它的前面和块的时候 

1216
01:09:02,880 --> 01:09:06,210
它 用红色左至右亮 

1217
01:09:04,529 --> 01:09:10,579
这意味着你不能变更车道 的 

1218
01:09:06,210 --> 01:09:13,259
在幻灯片的右侧向左或向右 

1219
01:09:10,579 --> 01:09:14,849
你可以 自由地 去找你做任何事情 

1220
01:09:13,259 --> 01:09:18,690
你想那是什么指示 

1221
01:09:14,849 --> 01:09:21,869
所有的街区都是黄色安全的 

1222
01:09:18,690 --> 01:09:24,520
系统说你可以自由选择任何 一个 

1223
01:09:21,869 --> 01:09:28,799
五个动作和五个动作

1224
01:09:24,520 --> 01:09:33,609
我们左移右移留在原地 

1225
01:09:28,799 --> 01:09:36,850
加速或减速和那些 

1226
01:09:33,609 --> 01:09:40,120
动作被赋予 其输入动作 

1227
01:09:36,850 --> 01:09:44,410
是什么产生的是什么

1228
01:09:40,120 --> 01:09:46,510
这里称为大脑吸收的大脑

1229
01:09:44,410 --> 01:09:50,080
当前状态输入最后一个 

1230
01:09:46,510 --> 01:09:55,110
奖励和生产，并结束 学习 

1231
01:09:50,080 --> 01:09:58,780
使用奖励来训练网络 

1232
01:09:55,110 --> 01:10:03,370
向后功能 的回 

1233
01:09:58,780 --> 01:10:06,310
传播，然后问大脑 给出 

1234
01:10:03,370 --> 01:10:08,890
当前状态给它下一个

1235
01:10:06,310 --> 01:10:10,870
向前传递前锋的动作 

1236
01:10:08,890 --> 01:10:13,630
功能你不需要知道

1237
01:10:10,870 --> 01:10:15,910
特别是 这个功能的操作 

1238
01:10:13,630 --> 01:10:17,980
这不是你 需要担心的 事情 

1239
01:10:15,910 --> 01:10:25,150
关于 但你可以， 如果你想要 你可以 

1240
01:10:17,980 --> 01:10:26,650
定制这个学习步骤 

1241
01:10:25,150 --> 01:10:28,270
我现在描述的方式就是那里 

1242
01:10:26,650 --> 01:10:31,000
有 只是右边的代码 几 行 

1243
01:10:28,270 --> 01:10:33,880
在浏览器中 ， 您可以更改 

1244
01:10:31,000 --> 01:10:36,550
它很快就按下了 

1245
01:10:33,880 --> 01:10:38,350
按钮改变模拟或 

1246
01:10:36,550 --> 01:10:40,690
设计您不需要的网络

1247
01:10:38,350 --> 01:10:42,820
有你需要 做的任何特殊硬件 

1248
01:10:40,690 --> 01:10:44,800
任何特别 的东西和教程 

1249
01:10:42,820 --> 01:10:47,200
清楚地概述所有 这些 

1250
01:10:44,800 --> 01:10:50,650
步骤，但 你 真是太棒了 

1251
01:10:47,200 --> 01:10:51,880
可以设计一个深层神经网络 的 

1252
01:10:50,650 --> 01:10:55,830
强化学习 的一部分

1253
01:10:51,880 --> 01:10:59,830
因此，它是一个深入的Q学习代理

1254
01:10:55,830 --> 01:11:03,580
就在浏览器中就 可以了 

1255
01:10:59,830 --> 01:11:08,230
选择哪个车道边变量 

1256
01:11:03,580 --> 01:11:10,060
控制到 你身边有 多少条车道 

1257
01:11:08,230 --> 01:11:12,460
只有当你的价值为零时才能看到

1258
01:11:10,060 --> 01:11:14,380
期待那个价值是你的一个 

1259
01:11:12,460 --> 01:11:17,230
左边 有一条 车道 的 一条 车道 

1260
01:11:14,380 --> 01:11:20,020
右边真正的车道半径

1261
01:11:17,230 --> 01:11:22,570
你的感知 系统 前面的补丁是 

1262
01:11:20,020 --> 01:11:26,680
你在我们身后看到多少补丁 

1263
01:11:22,570 --> 01:11:29,680
你看多远了，等等 

1264
01:11:26,680 --> 01:11:32,470
例如，车道边等于 两个 

1265
01:11:29,680 --> 01:11:33,780
这意味着它看起来 两 到了左边 的两个 

1266
01:11:32,470 --> 01:11:37,400
在右边 

1267
01:11:33,780 --> 01:11:41,420
显然，如果右边两个是 越野 

1268
01:11:37,400 --> 01:11:46,580
它提供了在这些零值

1269
01:11:41,420 --> 01:11:49,070
如果我们将补丁设置为后面的块

1270
01:11:46,580 --> 01:11:52,099
十点钟后面看起来十块补丁 

1271
01:11:49,070 --> 01:11:56,480
从一个补丁开始回来吧 

1272
01:11:52,099 --> 01:11:59,840
从汽车 的前部开始

1273
01:11:56,480 --> 01:12:03,679
攻入评价 为 

1274
01:11:59,840 --> 01:12:07,280
竞争是您在平均速度 

1275
01:12:03,679 --> 01:12:09,679
预定义的时间段等等 

1276
01:12:07,280 --> 01:12:13,369
我们用来收集它的方法 

1277
01:12:09,679 --> 01:12:14,989
当我们重新运行 代理 十运行速度时 

1278
01:12:13,369 --> 01:12:18,469
球三十分模拟比赛的分钟 

1279
01:12:14,989 --> 01:12:23,540
每个中间速度为十

1280
01:12:18,469 --> 01:12:29,659
运行这是完成的分数

1281
01:12:23,540 --> 01:12:31,790
服务器端 ，所以 我们已经 

1282
01:12:29,659 --> 01:12:34,280
为此代码得到了一些

1283
01:12:31,790 --> 01:12:38,179
最近在网上得到了一些宣传 

1284
01:12:34,280 --> 01:12:41,210
不幸的是，这可能是一个危险的

1285
01:12:38,179 --> 01:12:44,090
说 的 是没有作弊可能的，但 

1286
01:12:41,210 --> 01:12:46,190
因为它是在服务器端完成的，我们做到了 

1287
01:12:44,090 --> 01:12:49,580
在JavaScript和它在运行 

1288
01:12:46,190 --> 01:12:52,310
浏览器它希望是一个沙盒所以我们 

1289
01:12:49,580 --> 01:13:00,050
不能做任何棘手的事，但我们敢于你 

1290
01:12:52,310 --> 01:13:03,260
尝试你可以尝试在本地 获得 

1291
01:13:00,050 --> 01:13:05,510
估计， 现在有一个按钮 

1292
01:13:03,260 --> 01:13:07,790
说评价，它会给你一个分数 

1293
01:13:05,510 --> 01:13:14,380
回过头来看你的表现如何 

1294
01:13:07,790 --> 01:13:17,119
进入当前网络按钮是 

1295
01:13:14,380 --> 01:13:19,730
开始评估运行你按下

1296
01:13:17,119 --> 01:13:25,369
按钮它 执行进度条和 它 

1297
01:13:19,730 --> 01:13:29,719
给你小时的速度就可以 了 

1298
01:13:25,369 --> 01:13:31,130
有一个代码框，您可以在其中修改所有

1299
01:13:29,719 --> 01:13:33,190
我提到的变量和 

1300
01:13:31,130 --> 01:13:36,260
教程 详细 阐述这一点 和 

1301
01:13:33,190 --> 01:13:38,380
然后，一旦你准备好你修改一些 

1302
01:13:36,260 --> 01:13:43,969
你可以按的东西应用代码吧 

1303
01:13:38,380 --> 01:13:45,530
重新启动它杀死所有的培训，以 

1304
01:13:43,969 --> 01:13:50,030
你已经完成了这一点或重置 

1305
01:13:45,530 --> 01:13:54,079
它再次 开始 训练所以 说 

1306
01:13:50,030 --> 01:13:57,829
经常有一个保存按钮所以 

1307
01:13:54,079 --> 01:14:02,000
培训是在一个单独的线程中完成的 

1308
01:13:57,829 --> 01:14:05,929
网络工作者是令人兴奋的事情

1309
01:14:02,000 --> 01:14:10,869
使您可以允许 JavaScript 

1310
01:14:05,929 --> 01:14:16,400
令人惊讶的运行，你知道你知道 

1311
01:14:10,869 --> 01:14:19,429
多个CPU内核以并行方式进行 

1312
01:14:16,400 --> 01:14:21,020
这个或那个得分的模拟 

1313
01:14:19,429 --> 01:14:24,739
在训练之外 完成 

1314
01:14:21,020 --> 01:14:28,159
比 实时 快 一千 

1315
01:14:24,739 --> 01:14:31,449
构成第二千个运动 

1316
01:14:28,159 --> 01:14:35,960
第二步这是JavaScript中的全部内容 

1317
01:14:31,449 --> 01:14:38,210
并且净状态被运送到 

1318
01:14:35,960 --> 01:14:41,900
主要模拟不时作为 

1319
01:14:38,210 --> 01:14:44,989
培训继续进行，所以你需要做的就是 

1320
01:14:41,900 --> 01:14:48,949
是按跑 训练，并培养和 

1321
01:14:44,989 --> 01:14:54,070
随着时间的推移 ， 汽车表现得更好 

1322
01:14:48,949 --> 01:14:57,289
我会真正显示它在浏览器 中 

1323
01:14:54,070 --> 01:15:06,190
让我们来看看工作以及莫非要 

1324
01:14:57,289 --> 01:15:06,190
搞砸了我很好，为什么它很奇怪 

1325
01:15:11,530 --> 01:15:15,310
什么可能出错

1326
01:15:26,189 --> 01:15:34,849
所以这是开始 时的游戏

1327
01:15:31,679 --> 01:15:34,849
正在浏览器中运行 

1328
01:15:35,119 --> 01:15:39,479
人工智能 

1329
01:15:36,840 --> 01:15:41,880
女士们，先生们在浏览器中 

1330
01:15:39,479 --> 01:15:45,439
神经网络，所以目前不是

1331
01:15:41,880 --> 01:15:49,979
非常好，它 以每小时2英里的速度行驶 

1332
01:15:45,439 --> 01:15:54,650
并且看着每个人都过去了，那是什么 

1333
01:15:49,979 --> 01:15:58,050
现场直播是失去的功能 

1334
01:15:54,650 --> 01:16:00,929
这是非常不好所以为了 

1335
01:15:58,050 --> 01:16:04,050
火车就像 它说千帧一样 

1336
01:16:00,929 --> 01:16:07,949
第二，你只需按下跑步训练 

1337
01:16:04,050 --> 01:16:09,539
按钮，很快就学会了 

1338
01:16:07,949 --> 01:16:13,949
在您在代码中指定的网络上

1339
01:16:09,539 --> 01:16:17,369
框如何和基于输入和 

1340
01:16:13,949 --> 01:16:21,780
所有我提到的 培训内容 

1341
01:16:17,369 --> 01:16:24,659
完了它学会了怎么做

1342
01:16:21,780 --> 01:16:26,610
我们有目的地放入网络 

1343
01:16:24,659 --> 01:16:28,679
那里的表现并不是很好 

1344
01:16:26,610 --> 01:16:31,439
现在它不会平均这样做 

1345
01:16:28,679 --> 01:16:34,050
好吧，但它确实比站立更好 

1346
01:16:31,439 --> 01:16:39,809
在那里，然后你可以做到 

1347
01:16:34,050 --> 01:16:41,999
开始评估运行以模拟然后 

1348
01:16:39,809 --> 01:16:44,969
这比 实时工作要快得多 

1349
01:16:41,999 --> 01:16:48,590
看它有多好， 这是一个类似的 

1350
01:16:44,969 --> 01:16:50,820
我们采取的评估步骤

1351
01:16:48,590 --> 01:16:52,829
确定你站在哪里 

1352
01:16:50,820 --> 01:16:58,019
排行榜目前的当前平均水平 

1353
01:16:52,829 --> 01:17:01,219
该 10次​​运行模拟的 速度 为56 

1354
01:16:58,019 --> 01:17:06,209
每小时五点六英里

1355
01:17:01,219 --> 01:17:10,650
现在我可以 也许 不是 ，如果 被记录 

1356
01:17:06,209 --> 01:17:12,659
您已登录， 请点击提交您的 

1357
01:17:10,650 --> 01:17:14,400
代码， 如果你没有登录 它说 

1358
01:17:12,659 --> 01:17:19,860
你还没有登录， 请登录 

1359
01:17:14,400 --> 01:17:24,150
提交你的代码，然后你所拥有的一切 

1360
01:17:19,860 --> 01:17:28,619
要做的就是登录观看最无瑕 

1361
01:17:24,150 --> 01:17:33,949
演示在 我的生活，然后按下 

1362
01:17:28,619 --> 01:17:33,949
中期模特再次成功哦男人 

1363
01:17:34,930 --> 01:17:41,060
谢谢你的提交，所以现在 

1364
01:17:37,370 --> 01:17:43,400
我的提交是 作为Lex和 

1365
01:17:41,060 --> 01:17:44,630
我五 十六点五的排行榜 

1366
01:17:43,400 --> 01:17:48,820
六或其他任何 东西 

1367
01:17:44,630 --> 01:17:54,290
所以我敢让你们所有人试图 击败那个 

1368
01:17:48,820 --> 01:17:58,250
所以- 当你玩弄 东西的时候 

1369
01:17:54,290 --> 01:18:00,950
你想保存你可以做的代码

1370
01:17:58,250 --> 01:18:03,080
所以按下保存代码按钮即可 

1371
01:18:00,950 --> 01:18:05,450
保存配置各种 

1372
01:18:03,080 --> 01:18:09,740
JavaScript配置并保存 

1373
01:18:05,450 --> 01:18:12,980
网络布局到文件，然后 你 

1374
01:18:09,740 --> 01:18:18,050
可以从文件加载以及危险它 

1375
01:18:12,980 --> 01:18:19,520
覆盖 你和你的代码 

1376
01:18:18,050 --> 01:18:22,550
按提交按钮提交 

1377
01:18:19,520 --> 01:18:24,440
比赛模式确保你 

1378
01:18:22,550 --> 01:18:27,350
训练我们不训练的网络

1379
01:18:24,440 --> 01:18:30,560
你带我们你提交模型和 

1380
01:18:27,350 --> 01:18:33,590
你必须 按火车才能得到 

1381
01:18:30,560 --> 01:18:36,650
在时间内评估它 回答队列 

1382
01:18:33,590 --> 01:18:39,740
为了得到评估， 这是 面向公众的 

1383
01:18:36,650 --> 01:18:42,050
所以队列可以变得非常 大而且它 

1384
01:18:39,740 --> 01:18:43,700
转到该队列评估它然后

1385
01:18:42,050 --> 01:18:45,590
这取决于你站在你 

1386
01:18:43,700 --> 01:18:51,400
添加到 显示顶部的排行榜 

1387
01:18:45,590 --> 01:18:56,300
您可以经常重新提交的十个条目 

1388
01:18:51,400 --> 01:19:00,230
只有最高分才算好 

1389
01:18:56,300 --> 01:19:04,880
我们正在使用我们现在使用的 代码 

1390
01:19:00,230 --> 01:19:09,560
完成神经网络的实现

1391
01:19:04,880 --> 01:19:11,740
在andrey karpati的 JavaScript中 

1392
01:19:09,560 --> 01:19:17,090
从斯坦福现在开放ai 

1393
01:19:11,740 --> 01:19:18,860
ComNet jf是图书馆，它是什么 

1394
01:19:17,090 --> 01:19:21,140
在那里可视化它也是存在的

1395
01:19:18,860 --> 01:19:24,220
在游戏中可视化是输入

1396
01:19:21,140 --> 01:19:27,350
在这种情况下，网络是135输入 

1397
01:19:24,220 --> 01:19:31,670
所以你也可以不仅仅指定

1398
01:19:27,350 --> 01:19:33,020
不只是你 身后有多远

1399
01:19:31,670 --> 01:19:35,270
看到 向左和您的权利 

1400
01:19:33,020 --> 01:19:41,570
可以指定你的回溯 时间 

1401
01:19:35,270 --> 01:19:44,710
看起来也是如此，所以可视化 

1402
01:19:41,570 --> 01:19:47,360
存在对网络135的输入 

1403
01:19:44,710 --> 01:19:50,780
而且你在

1404
01:19:47,360 --> 01:19:52,639
然后输出回归类似 

1405
01:19:50,780 --> 01:19:55,219
我们看到的那种输出

1406
01:19:52,639 --> 01:19:58,190
有十个输出说的数字 

1407
01:19:55,219 --> 01:20:00,050
如果它在这里是零 到 九 

1408
01:19:58,190 --> 01:20:02,540
输出是五个动作之一 

1409
01:20:00,050 --> 01:20:07,520
左右留在原地加速或 

1410
01:20:02,540 --> 01:20:10,880
放慢战斗 GF设置 就是你 

1411
01:20:07,520 --> 01:20:12,409
如果你可以选择一些输入 

1412
01:20:10,880 --> 01:20:13,429
希望这个东西乱七八糟，这是所有 

1413
01:20:12,409 --> 01:20:15,199
你不需要捣乱的东西

1414
01:20:13,429 --> 01:20:17,060
因为我们已经给你了 

1415
01:20:15,199 --> 01:20:19,250
车道侧变量和前方补丁 

1416
01:20:17,060 --> 01:20:23,030
等等你可以选择 数量 

1417
01:20:19,250 --> 01:20:31,300
动作时间窗口和 

1418
01:20:23,030 --> 01:20:37,070
网络的大小 所以 网络 

1419
01:20:31,300 --> 01:20:39,830
这里定义的是这是 输入 

1420
01:20:37,070 --> 01:20:41,270
所有这些都是输入的大小 

1421
01:20:39,830 --> 01:20:44,090
在教程中只是为了给你一个 

1422
01:20:41,270 --> 01:20:47,590
小纲要有第一个 

1423
01:20:44,090 --> 01:20:52,460
完全连接的层有十个神经元

1424
01:20:47,590 --> 01:20:54,949
有了铁路你激活功能

1425
01:20:52,460 --> 01:20:57,230
我们同样顺利的功能 

1426
01:20:54,949 --> 01:21:01,659
之前和球交谈过 

1427
01:20:57,230 --> 01:21:05,179
输出和回归层 

1428
01:21:01,659 --> 01:21:08,719
还有一堆其他杂乱的选择 

1429
01:21:05,179 --> 01:21:10,460
你可以 在 那里 玩T 但是那些 

1430
01:21:08,719 --> 01:21:12,110
不是我提到 这是 以前生产的 

1431
01:21:10,460 --> 01:21:14,389
真正重要的 是选择 

1432
01:21:12,110 --> 01:21:16,429
那些层的大小 

1433
01:21:14,389 --> 01:21:19,730
你可以建立 自己的层

1434
01:21:16,429 --> 01:21:21,260
干燥的神经网络和实际的 

1435
01:21:19,730 --> 01:21:24,739
学习是落后的 

1436
01:21:21,260 --> 01:21:26,810
传播，然后返回

1437
01:21:24,739 --> 01:21:29,780
通过前进 传球的动作 

1438
01:21:26,810 --> 01:21:32,719
如果你感兴趣的话，网络 

1439
01:21:29,780 --> 01:21:37,610
这种东西有 一个令人惊讶 

1440
01:21:32,719 --> 01:21:42,590
很酷的代码编辑器，这是单片眼镜

1441
01:21:37,610 --> 01:21:44,570
编辑，它只是工作它做了一些

1442
01:21:42,590 --> 01:21:46,400
自动完成等你拿玩 

1443
01:21:44,570 --> 01:21:49,550
它使一切都非常方便

1444
01:21:46,400 --> 01:21:54,320
代码编辑很多这个 

1445
01:21:49,550 --> 01:21:56,030
最终或 游戏的可视化

1446
01:21:54,320 --> 01:21:58,730
我们将进行模拟和模拟 

1447
01:21:56,030 --> 01:22:00,949
谈论明天就是 在 

1448
01:21:58,730 --> 01:22:03,260
浏览器使用HTML 

1449
01:22:00,949 --> 01:22:05,420
五个画布所以这里很简单 

1450
01:22:03,260 --> 01:22:09,380
带帆布的蓝色盒子的规格

1451
01:22:05,420 --> 01:22:15,409
这非常有效且容易 

1452
01:22:09,380 --> 01:22:17,449
和我们 很多 人一起工作 

1453
01:22:15,409 --> 01:22:23,449
对一个非常微妙的人感到兴奋但是 

1454
01:22:17,449 --> 01:22:25,969
你不能 只用v8运行 

1455
01:22:23,449 --> 01:22:28,219
引擎javascript变得超级快 

1456
01:22:25,969 --> 01:22:29,539
你可以训练 自己的 

1457
01:22:28,219 --> 01:22:31,940
浏览器中的网络已经存在 

1458
01:22:29,539 --> 01:22:34,809
令人惊讶，然后与网络工作者一样 

1459
01:22:31,940 --> 01:22:40,489
只要你有一个现代浏览器的铬 

1460
01:22:34,809 --> 01:22:44,449
是可以运行 在 多个进程 

1461
01:22:40,489 --> 01:22:45,709
单独的线程，所以我们可以做很多 的 

1462
01:22:44,449 --> 01:22:47,389
你可以做 可视化的东西

1463
01:22:45,709 --> 01:22:51,409
分开，你可以训练 

1464
01:22:47,389 --> 01:22:53,959
单独的线程非常酷，所以 

1465
01:22:51,409 --> 01:22:56,300
教程深入 了解mit.edu 的汽车 

1466
01:22:53,959 --> 01:23:02,599
交通我们不会把这些链接 放在上面 

1467
01:22:56,300 --> 01:23:05,229
网站因为我们得到了一点点 

1468
01:23:02,599 --> 01:23:08,739
放在黑客新闻的头版 

1469
01:23:05,229 --> 01:23:11,570
我们不希望那些泄漏出去 

1470
01:23:08,739 --> 01:23:15,949
尤其是与声称你 

1471
01:23:11,570 --> 01:23:18,110
不能作弊，虽然很 漂亮 

1472
01:23:15,949 --> 01:23:19,340
在运行 测试方面非常有效 

1473
01:23:18,110 --> 01:23:22,429
一切都在你的机器上运行

1474
01:23:19,340 --> 01:23:24,139
客户方面，你仍然必须拉 

1475
01:23:22,429 --> 01:23:27,019
这里的一些图像和拉一些 

1476
01:23:24,139 --> 01:23:29,179
代码， 所以教程是 在麻省理工学院的汽车 

1477
01:23:27,019 --> 01:23:32,900
整理你削减深度交通和 

1478
01:23:29,179 --> 01:23:35,599
模拟是深度交通 jf所以汽车 

1479
01:23:32,900 --> 01:23:37,820
麻省理工学院我使用flash深度流量jf我 

1480
01:23:35,599 --> 01:23:41,269
鼓励你去那里 玩 

1481
01:23:37,820 --> 01:23:44,059
网络提交您的代码并赢得 

1482
01:23:41,269 --> 01:23:45,409
非常特别的奖品很酷 

1483
01:23:44,059 --> 01:23:49,249
之一，但我们仍在努力 就可以了 

1484
01:23:45,409 --> 01:23:55,340
我发誓所有人都没有奖品 

1485
01:23:49,249 --> 01:23:58,030
是的，让我们暂停一下

1486
01:23:55,340 --> 01:24:01,760
想一想我们今天谈到的是什么 

1487
01:23:58,030 --> 01:24:06,920
所以最好的深层加固 

1488
01:24:01,760 --> 01:24:11,650
学习是 最令人兴奋的 

1489
01:24:06,920 --> 01:24:15,429
成就我认为是 一个 

1490
01:24:11,650 --> 01:24:18,280
当我第一次开始时的游戏

1491
01:24:15,429 --> 01:24:22,600
新人介绍了人工 

1492
01:24:18,280 --> 01:24:24,130
情报据说 它是 

1493
01:24:22,600 --> 01:24:26,140
这场比赛是不可能的 

1494
01:24:24,130 --> 01:24:29,110
对于机器击败因为 

1495
01:24:26,140 --> 01:24:31,420
组合复杂性只是 一个纯粹的问题 

1496
01:24:29,110 --> 01:24:36,699
它的选项 数量 还有很多 

1497
01:24:31,420 --> 01:24:38,050
比国际象棋复杂最多 

1498
01:24:36,699 --> 01:24:40,120
深刻的惊人成就

1499
01:24:38,050 --> 01:24:43,480
强化学习对我来说就是

1500
01:24:40,120 --> 01:24:45,850
为第一个设计alphago 

1501
01:24:43,480 --> 01:24:50,830
时间世界冠军和去了 

1502
01:24:45,850 --> 01:24:53,679
深刻的思想 alphago 和方式打败了

1503
01:24:50,830 --> 01:24:57,460
他们做到了， 这是我觉得 非常 

1504
01:24:53,679 --> 01:25:00,520
如果你开始 与驾驶相关

1505
01:24:57,460 --> 01:25:05,620
以有监督的方式创造第一 

1506
01:25:00,520 --> 01:25:10,020
培训政策网络，以便你采取 

1507
01:25:05,620 --> 01:25:14,980
专家游戏构建网络 

1508
01:25:10,020 --> 01:25:17,650
首先让你看起来不要反对 

1509
01:25:14,980 --> 01:25:22,659
你自己扮演游戏的代理人 

1510
01:25:17,650 --> 01:25:25,000
本身，但他们从专家那里学习

1511
01:25:22,659 --> 01:25:27,580
有一些人的地面实况此 

1512
01:25:25,000 --> 01:25:29,890
人类的基本事实表示 这样 的现实 

1513
01:25:27,580 --> 01:25:32,290
干燥这是 很重要的水平 

1514
01:25:29,890 --> 01:25:35,320
我们开始获得大量数据或 

1515
01:25:32,290 --> 01:25:37,270
司机正在录像， 所以 我们 

1516
01:25:35,320 --> 01:25:39,370
可以对数据 了解 我们在此之前 

1517
01:25:37,270 --> 01:25:42,520
通过模拟 运行代理 

1518
01:25:39,370 --> 01:25:47,710
它学到更大的数量 

1519
01:25:42,520 --> 01:25:55,540
用于模拟的数据集 ，他们做到了 

1520
01:25:47,710 --> 01:26:02,110
只是现在作为一个提醒 ，当时 

1521
01:25:55,540 --> 01:26:04,060
你让代理人自己开车 

1522
01:26:02,110 --> 01:26:05,830
很长一段时间可能是最喜欢的视频

1523
01:26:04,060 --> 01:26:07,690
但我刚刚看到了第二个 

1524
01:26:05,830 --> 01:26:16,960
观看这几个小时，但 它是一个提醒 

1525
01:26:07,690 --> 01:26:20,920
那你不能不相信你 

1526
01:26:16,960 --> 01:26:23,500
首先估计奖励函数 

1527
01:26:20,920 --> 01:26:25,030
是那些安全和富有成效的人 

1528
01:26:23,500 --> 01:26:26,440
为了我们的社会 

1529
01:26:25,030 --> 01:26:28,570
你说的是情报 

1530
01:26:26,440 --> 01:26:31,240
能够在真实中运作的系统

1531
01:26:28,570 --> 01:26:37,270
世界，这只是 一个明确的 

1532
01:26:31,240 --> 01:26:39,220
提醒 一下， 如果有这样的话 

1533
01:26:37,270 --> 01:26:40,990
所有参考文献均可在线获取 

1534
01:26:39,220 --> 01:26:44,440
对于这些幻灯片 我们会提出来 

1535
01:26:40,990 --> 01:26:46,360
我想你可能会有幻灯片

1536
01:26:44,440 --> 01:26:49,260
你想 下来 和 我们 谈谈 

1537
01:26:46,360 --> 01:26:56,290
对于码头或者码头的问题 

1538
01:26:49,260 --> 01:26:58,870
JavaScript问题 就是这样的 问题 

1539
01:26:56,290 --> 01:27:01,210
是你的 可视化是什么

1540
01:26:58,870 --> 01:27:04,330
在深度交通中看到你正在看到一个

1541
01:27:01,210 --> 01:27:06,190
汽车如何移动它的移动 

1542
01:27:04,330 --> 01:27:08,320
基于最新的地图移动为 

1543
01:27:06,190 --> 01:27:10,690
你训练的网络，所以它只是

1544
01:27:08,320 --> 01:27:15,220
为您提供可视化的乐趣 

1545
01:27:10,690 --> 01:27:17,290
你最近训练过的网络好吗 

1546
01:27:15,220 --> 01:27:21,060
所以如果人们有 问题的话

1547
01:27:17,290 --> 01:27:28,920
之后只是有关码头工人的详细信息 

1548
01:27:21,060 --> 01:27:28,920
是的，你想 离线去做 

