1
00:00:00,089 --> 00:00:06,330
今天我们将讨论如何制作 

2
00:00:03,270 --> 00:00:10,820
机器看到计算机视觉， 我们会 

3
00:00:06,330 --> 00:00:14,580
谢谢Claire 说是的和 

4
00:00:10,820 --> 00:00:18,660
今天我们将举办一场比赛 

5
00:00:14,580 --> 00:00:22,920
不像设计的深度交通

6
00:00:18,660 --> 00:00:26,279
探索想法教你概念 

7
00:00:22,920 --> 00:00:28,800
深层强化学习seg融合 

8
00:00:26,279 --> 00:00:30,960
深层动态驾驶场景 

9
00:00:28,800 --> 00:00:33,719
细分竞争，我会 

10
00:00:30,960 --> 00:00:36,719
今天的礼物正处于切入阶段 

11
00:00:33,719 --> 00:00:39,440
无论谁在这方面做得好 

12
00:00:36,719 --> 00:00:42,660
竞争很可能产生一个 

13
00:00:39,440 --> 00:00:46,410
出版物或想法将导致 

14
00:00:42,660 --> 00:00:48,539
也许是感知领域的世界

15
00:00:46,410 --> 00:00:51,329
和运行这个的人一起

16
00:00:48,539 --> 00:00:56,940
或许在 你自己和我 

17
00:00:51,329 --> 00:01:01,920
鼓励你这样做 更多的 猫 

18
00:00:56,940 --> 00:01:06,180
今天的 计算机愿景如今 

19
00:01:01,920 --> 00:01:08,850
深学习多数 

20
00:01:06,180 --> 00:01:11,729
我们如何解释形式的成功

21
00:01:08,850 --> 00:01:14,939
表示理解图像和 

22
00:01:11,729 --> 00:01:18,060
影片使用的显著程度 

23
00:01:14,939 --> 00:01:20,310
神经网络我们的想法 

24
00:01:18,060 --> 00:01:22,939
被谈论的申请 

25
00:01:20,310 --> 00:01:26,670
监督无监督和 

26
00:01:22,939 --> 00:01:29,070
强化学习， 为 

27
00:01:26,670 --> 00:01:33,810
监督的情况下， 是 刚刚 焦点 

28
00:01:29,070 --> 00:01:36,030
今天的过程是相同 的数据 

29
00:01:33,810 --> 00:01:38,490
是必要的注释数据 

30
00:01:36,030 --> 00:01:40,020
人类提供标签的地方 

31
00:01:38,490 --> 00:01:43,040
作为在地面真相

32
00:01:40,020 --> 00:01:47,970
训练过程然后是神经网络

33
00:01:43,040 --> 00:01:51,689
鬼通过那个数据 学习 

34
00:01:47,970 --> 00:01:53,909
从原始感官输入映射到 

35
00:01:51,689 --> 00:01:57,930
地面真相标签，然后概括

36
00:01:53,909 --> 00:01:59,490
或测试数据集和种类 

37
00:01:57,930 --> 00:02:02,520
原始传感器 处理 他们的 

38
00:01:59,490 --> 00:02:06,090
数字我会一次又一次地说这个

39
00:02:02,520 --> 00:02:08,190
这对我们来说是人类的愿景

40
00:02:06,090 --> 00:02:11,009
理所当然地认为这个方面 

41
00:02:08,190 --> 00:02:12,390
我们的能力是 接受原始的感官 

42
00:02:11,009 --> 00:02:13,050
通过我们的眼睛 和信息 

43
00:02:12,390 --> 00:02:16,060
译

44
00:02:13,050 --> 00:02:18,490
但这只是数字而已

45
00:02:16,060 --> 00:02:21,460
你是否是一个专家的计算机视觉 

46
00:02:18,490 --> 00:02:24,670
人或新的给你有到现场 

47
00:02:21,460 --> 00:02:28,420
总是回去冥想是什么 

48
00:02:24,670 --> 00:02:31,120
样的事情机器给出什么 

49
00:02:28,420 --> 00:02:33,790
什么是任务的数据是什么

50
00:02:31,120 --> 00:02:35,130
以便 执行 工作 任务 

51
00:02:33,790 --> 00:02:38,820
你要求它做

52
00:02:35,130 --> 00:02:40,870
也许数据是高度的 

53
00:02:38,820 --> 00:02:41,320
不足以做你想要的 

54
00:02:40,870 --> 00:02:43,030
做

55
00:02:41,320 --> 00:02:46,390
这是我再次提出的问题

56
00:02:43,030 --> 00:02:50,070
再次 我们的图像足够了 

57
00:02:46,390 --> 00:02:50,070
了解你周围的世界 ， 

58
00:02:51,030 --> 00:02:56,470
给出 这些 数字 的数字 

59
00:02:54,400 --> 00:02:59,290
有时候有一个频道 

60
00:02:56,470 --> 00:03:02,350
每个像素都有三个RGB 

61
00:02:59,290 --> 00:03:07,870
有三种不同的颜色任务 

62
00:03:02,350 --> 00:03:11,650
分类或回归产生a 

63
00:03:07,870 --> 00:03:17,170
连续变量或一 组 中 的一个 

64
00:03:11,650 --> 00:03:21,190
类标签 ， 因为 我们必须 前 

65
00:03:17,170 --> 00:03:25,200
小心我们 对什么是直觉 

66
00:03:21,190 --> 00:03:25,200
计算机视觉中的难点和容易 

67
00:03:27,360 --> 00:03:34,840
让我们退一步到 

68
00:03:30,520 --> 00:03:38,170
我们自己的神经网络 的灵感

69
00:03:34,840 --> 00:03:40,510
生物神经网络因为 

70
00:03:38,170 --> 00:03:42,610
人类视觉系统和计算机

71
00:03:40,510 --> 00:03:53,500
视觉系统更多一点 

72
00:03:42,610 --> 00:03:56,950
在这方面类似于此 

73
00:03:53,500 --> 00:03:59,910
和视觉皮层是在层 和用作 

74
00:03:56,950 --> 00:04:02,380
信息从 眼睛 传递到 眼睛 

75
00:03:59,910 --> 00:04:04,690
以使 大脑的部分

76
00:04:02,380 --> 00:04:07,090
原始传感器信息的 感觉 

77
00:04:04,690 --> 00:04:10,390
更高阶 和更高阶的表示 

78
00:04:07,090 --> 00:04:13,209
已形成 这是灵感了 

79
00:04:10,390 --> 00:04:15,880
使用深度神经 网络背后的想法

80
00:04:13,209 --> 00:04:17,560
对于 更高和更高阶的 图像 

81
00:04:15,880 --> 00:04:22,870
通过形式表示形式 

82
00:04:17,560 --> 00:04:25,120
那里的早期层层

83
00:04:22,870 --> 00:04:28,780
那么非常原始和感官信息 

84
00:04:25,120 --> 00:04:30,790
提取连接这些边的边 

85
00:04:28,780 --> 00:04:33,040
形成那些边缘以形成更复杂的 

86
00:04:30,790 --> 00:04:35,169
功能，最后进入 

87
00:04:33,040 --> 00:04:38,710
我们的高阶语义意义 

88
00:04:35,169 --> 00:04:41,220
希望从这些图像 中获取 

89
00:04:38,710 --> 00:04:43,360
计算机视觉深度学习很难 

90
00:04:41,220 --> 00:04:45,190
我会再说一遍 

91
00:04:43,360 --> 00:04:47,919
光照变化是

92
00:04:45,190 --> 00:04:51,270
最大的挑战 或至少一个 

93
00:04:47,919 --> 00:04:55,240
在驾驶的最大挑战之一

94
00:04:51,270 --> 00:04:59,530
用于可见光相机的姿势 

95
00:04:55,240 --> 00:05:01,870
我也会改变对象的可变性

96
00:04:59,530 --> 00:05:04,830
讨论 geoff的 一些进展 

97
00:05:01,870 --> 00:05:07,419
希顿和胶囊网络 的想法 

98
00:05:04,830 --> 00:05:09,790
与神经网络一样

99
00:05:07,419 --> 00:05:13,260
目前有用的计算机视觉不是 

100
00:05:09,790 --> 00:05:17,050
善于表示变量姿势 

101
00:05:13,260 --> 00:05:20,530
图像中的这些对象和这个2d 

102
00:05:17,050 --> 00:05:23,890
颜色和纹理的平面看起来非常

103
00:05:20,530 --> 00:05:27,640
对象是数字上不同的

104
00:05:23,890 --> 00:05:29,560
旋转，并且该对象是错位 和 

105
00:05:27,640 --> 00:05:32,440
以不同的方式塑造可变形的 

106
00:05:29,560 --> 00:05:36,280
将截断 cat inraclass 

107
00:05:32,440 --> 00:05:38,620
分类的可变性 

108
00:05:36,280 --> 00:05:41,020
这个任务 今天 就是一个 例子 

109
00:05:38,620 --> 00:05:43,270
各地要介绍一些 

110
00:05:41,020 --> 00:05:44,620
网络上 有 过去的十年 

111
00:05:43,270 --> 00:05:46,360
一些人获得了成功

112
00:05:44,620 --> 00:05:50,260
直觉和洞察力使这些 

113
00:05:46,360 --> 00:05:52,660
网络工作分类有一个

114
00:05:50,260 --> 00:05:54,760
课堂内有很多变化

115
00:05:52,660 --> 00:05:59,080
两者之间 的 差异很小

116
00:05:54,760 --> 00:06:01,300
所有这些课程都是最重要的猫 

117
00:05:59,080 --> 00:06:04,090
他们看起来是狗的底部 

118
00:06:01,300 --> 00:06:06,610
非常不同，另一个 我会说 

119
00:06:04,090 --> 00:06:07,270
驾驶中的第二大问题 

120
00:06:06,610 --> 00:06:08,740
知觉

121
00:06:07,270 --> 00:06:11,080
可见光相机的感知

122
00:06:08,740 --> 00:06:14,790
部分对象时的遮挡

123
00:06:11,080 --> 00:06:18,250
由于三维而被遮挡 

124
00:06:14,790 --> 00:06:21,850
我们这个世界的本质一些对象 

125
00:06:18,250 --> 00:06:24,760
别人面前，他们闭塞 了 

126
00:06:21,850 --> 00:06:27,040
背景对象，但我们仍然 

127
00:06:24,760 --> 00:06:29,560
负责识别对象的时间 

128
00:06:27,040 --> 00:06:33,550
只有部分是可见的，有时是可见的 

129
00:06:29,560 --> 00:06:35,260
那部分告诉你那里的猫 非常 

130
00:06:33,550 --> 00:06:37,510
这里几乎看不到

131
00:06:35,260 --> 00:06:45,130
我们的任务是对猫进行分类

132
00:06:37,510 --> 00:06:47,320
只有一只耳朵可以看到 腿部和 耳朵 

133
00:06:45,130 --> 00:06:49,060
我们将要 谈论 的哲学层面 

134
00:06:47,320 --> 00:06:53,410
关于我们竞争的动机 

135
00:06:49,060 --> 00:06:57,570
这里有一只打扮成猴子的猫 

136
00:06:53,410 --> 00:07:02,440
在哲学 层面 上 吃香蕉 

137
00:06:57,570 --> 00:07:07,110
我们大多数人都明白发生了什么 

138
00:07:02,440 --> 00:07:13,170
事实上这是一个神经网络 

139
00:07:07,110 --> 00:07:13,170
今天成功地将此分类 

140
00:07:13,260 --> 00:07:21,970
将此视频视为猫而非 

141
00:07:18,840 --> 00:07:25,530
背景情况的幽默 和 

142
00:07:21,970 --> 00:07:29,350
事实上， 你可以说它是一只猴子 

143
00:07:25,530 --> 00:07:31,330
缺少什么，缺少什么 是 

144
00:07:29,350 --> 00:07:35,470
动态信息的时间性 

145
00:07:31,330 --> 00:07:37,630
动态的场景就是这样

146
00:07:35,470 --> 00:07:40,180
在许多感知工作中缺失

147
00:07:37,630 --> 00:07:43,210
到目前为止已经完成 了 

148
00:07:40,180 --> 00:07:45,610
自动驾驶汽车空间 

149
00:07:43,210 --> 00:07:46,840
可见光相机，我们正在 寻找 

150
00:07:45,610 --> 00:07:49,680
扩大这一点 

151
00:07:46,840 --> 00:07:52,720
这 就是灵魂融合的全部意义 

152
00:07:49,680 --> 00:07:54,880
图像分类管道有一个 

153
00:07:52,720 --> 00:07:59,410
bin里面有不同的类别

154
00:07:54,880 --> 00:08:01,510
每一类猫狗杯子帽子那些垃圾箱 

155
00:07:59,410 --> 00:08:04,540
每个 和 每个都有很多例子

156
00:08:01,510 --> 00:08:06,340
一个新的例子到来时你的任务 

157
00:08:04,540 --> 00:08:09,460
沿着你从未见过的那个 

158
00:08:06,340 --> 00:08:11,580
bin中的图像与它相同 

159
00:08:09,460 --> 00:08:15,160
机器学习任务 之前和 

160
00:08:11,580 --> 00:08:17,410
一切都依赖于那些数据 

161
00:08:15,160 --> 00:08:19,130
被 称为的基本事实

162
00:08:17,410 --> 00:08:22,610
人类

163
00:08:19,130 --> 00:08:26,150
大赦是手写的玩具数据集 

164
00:08:22,610 --> 00:08:29,150
数字经常用作例子 和 Koko 

165
00:08:26,150 --> 00:08:31,880
safar imagenet的地方和很多其他 

166
00:08:29,150 --> 00:08:34,400
令人难以置信的丰富的数据集的数据集 的 

167
00:08:31,880 --> 00:08:37,370
成千上万 的图像 

168
00:08:34,400 --> 00:08:40,510
那里代表 着人们的面孔 

169
00:08:37,370 --> 00:08:43,669
这些都是不同的对象 

170
00:08:40,510 --> 00:08:47,510
用于测试算法的地面实况数据

171
00:08:43,669 --> 00:08:50,540
以及竞争架构

172
00:08:47,510 --> 00:08:54,080
相互评估见远十 

173
00:08:50,540 --> 00:08:56,870
最简单的玩具数据集之一 

174
00:08:54,080 --> 00:08:59,600
十个类别的小图标 

175
00:08:56,870 --> 00:09:01,970
飞机汽车鸟猫鹿狗 

176
00:08:59,600 --> 00:09:03,830
对于我们的课程船和卡车是 

177
00:09:01,970 --> 00:09:05,540
常用来探索一些 

178
00:09:03,830 --> 00:09:07,670
我们将基本的卷积神经网络

179
00:09:05,540 --> 00:09:09,740
讨论所以让我们想出一个非常好的 

180
00:09:07,670 --> 00:09:12,620
琐碎的分类器来解释 

181
00:09:09,740 --> 00:09:15,050
我们怎么能去 了解它 的概念

182
00:09:12,620 --> 00:09:17,150
事实上，这可能是你开始思考的 

183
00:09:15,050 --> 00:09:19,310
关于如何 对 图像 进行分类 的方法 

184
00:09:17,150 --> 00:09:20,870
不知道这些 技术中的任何一种 

185
00:09:19,310 --> 00:09:23,900
也许 你会采取的方法 

186
00:09:20,870 --> 00:09:26,300
你会按顺序减去图像吗？ 

187
00:09:23,900 --> 00:09:28,070
要知道猫的形象是 

188
00:09:26,300 --> 00:09:30,440
不同于狗的形象如果到 

189
00:09:28,070 --> 00:09:32,300
给出这两个 图像 时比较它们 

190
00:09:30,440 --> 00:09:34,880
什么是你的方式是什么

191
00:09:32,300 --> 00:09:37,820
比较他们你可以做到的一种方式 

192
00:09:34,880 --> 00:09:40,220
你只需减去它然后总结所有 

193
00:09:37,820 --> 00:09:42,440
像素明智的图像差异

194
00:09:40,220 --> 00:09:46,460
只是减去图像的强度

195
00:09:42,440 --> 00:09:48,200
如果是那个意图 ，就像素一样加以总结 

196
00:09:46,460 --> 00:09:50,590
如果这个差异 非常高 

197
00:09:48,200 --> 00:09:53,210
指图像非常 不同 

198
00:09:50,590 --> 00:09:57,640
使用该指标我们可以看看 C for 

199
00:09:53,210 --> 00:10:00,170
10 并用它作为分类器说 

200
00:09:57,640 --> 00:10:02,570
基于这种差异功能我 

201
00:10:00,170 --> 00:10:07,880
要找到 10个箱子中的一个 

202
00:10:02,570 --> 00:10:12,290
那个有新的形象

203
00:10:07,880 --> 00:10:14,570
最低差异在此找到一个图像 

204
00:10:12,290 --> 00:10:16,820
数据集最像图像我 

205
00:10:14,570 --> 00:10:21,740
把它放在同一个箱子里 

206
00:10:16,820 --> 00:10:23,540
这样的图像 如果我们 有 10个班级 

207
00:10:21,740 --> 00:10:27,350
只是翻硬币我们的准确性 

208
00:10:23,540 --> 00:10:29,600
使用我们的图像，分类器将是 10％ 

209
00:10:27,350 --> 00:10:31,400
我们实际上可以做的差异分类器

210
00:10:29,600 --> 00:10:32,970
比随机好多 了好多 了 

211
00:10:31,400 --> 00:10:36,530
优于10％ 

212
00:10:32,970 --> 00:10:40,400
我们可以做到38 ％的准确率 

213
00:10:36,530 --> 00:10:46,710
这是我们的第一个分类器

214
00:10:40,400 --> 00:10:48,620
分类器K最近的邻居 让我们 

215
00:10:46,710 --> 00:10:52,230
把我们的分类器提升到一个全新的水平 

216
00:10:48,620 --> 00:10:54,420
而不是将它比作战斗 

217
00:10:52,230 --> 00:10:57,210
试图找到一个图像

218
00:10:54,420 --> 00:11:01,230
我们试图找到最接近我们的数据集 

219
00:10:57,210 --> 00:11:03,570
K最接近并说出什么是上课 

220
00:11:01,230 --> 00:11:06,150
他们中的大多数属于 我们 

221
00:11:03,570 --> 00:11:09,570
取k并将其增加1到2 

222
00:11:06,150 --> 00:11:14,460
到3到4到5 ，看看它是如何 变化的 

223
00:11:09,570 --> 00:11:16,200
七年 邻居 的问题 

224
00:11:14,460 --> 00:11:22,640
这种方法下的最佳选择

225
00:11:16,200 --> 00:11:28,410
对于CFR 10，我们实现了 30％的 准确性 

226
00:11:22,640 --> 00:11:30,210
人的水平为 95％ 的准确度，并 用 

227
00:11:28,410 --> 00:11:38,490
卷积神经网络将得到 

228
00:11:30,210 --> 00:11:42,000
非常接近100％，这就是你要去的地方 

229
00:11:38,490 --> 00:11:44,490
网络照亮了 这个弯曲的任务 

230
00:11:42,000 --> 00:11:47,970
这一切都是从这个基础开始的 

231
00:11:44,490 --> 00:11:52,890
每个计算单元信号

232
00:11:47,970 --> 00:11:57,360
信号加权加总偏差 

233
00:11:52,890 --> 00:11:59,160
并把一个输入 到 非线性 

234
00:11:57,360 --> 00:12:02,640
激活功能， 产生一个 

235
00:11:59,160 --> 00:12:06,830
输出非线性激活函数

236
00:12:02,640 --> 00:12:11,700
是所有这些放在一起的关键

237
00:12:06,830 --> 00:12:13,410
越来越多的隐藏层形成了深层次 

238
00:12:11,700 --> 00:12:16,590
神经网络和深层神经网络

239
00:12:13,410 --> 00:12:19,320
正如我们所讨论的那样，对网络进行了培训

240
00:12:16,590 --> 00:12:21,450
采取前进传球和例子 

241
00:12:19,320 --> 00:12:23,490
车库与标签看到有多接近 

242
00:12:21,450 --> 00:12:26,400
那些标签是真实的 

243
00:12:23,490 --> 00:12:29,280
真相然后惩罚权重 

244
00:12:26,400 --> 00:12:31,440
这导致了错误的决定 

245
00:12:29,280 --> 00:12:34,770
并奖励所产生的重量 

246
00:12:31,440 --> 00:12:39,960
正确决定 10 的情况 

247
00:12:34,770 --> 00:12:44,780
示例 网络 的输出 是 

248
00:12:39,960 --> 00:12:48,330
输入的不同值

249
00:12:44,780 --> 00:12:52,290
手写数字从0到9 为 10 

250
00:12:48,330 --> 00:12:54,990
那些我们希望我们的网络 

251
00:12:52,290 --> 00:12:58,590
分类 什么的这个形象 

252
00:12:54,990 --> 00:13:02,460
手写的数字是1是0 1 2 3 

253
00:12:58,590 --> 00:13:06,690
到 9 它经常 做 的 方式 是 

254
00:13:02,460 --> 00:13:11,060
有十个 网络 输出 和 

255
00:13:06,690 --> 00:13:13,620
输出中的每个神经元都是 

256
00:13:11,060 --> 00:13:17,850
负责得到 真正的兴奋 

257
00:13:13,620 --> 00:13:20,210
当它的号码 被召唤时 ，每个人 

258
00:13:17,850 --> 00:13:24,300
别的应该 不会兴奋 

259
00:13:20,210 --> 00:13:25,710
因此 班级 的 数量 是 

260
00:13:24,300 --> 00:13:30,120
输出数量就是这样的 

261
00:13:25,710 --> 00:13:32,910
通常完成，你分配一个类 

262
00:13:30,120 --> 00:13:36,020
输入图像基于最高的 

263
00:13:32,910 --> 00:13:38,580
产生最高输出的神经元

264
00:13:36,020 --> 00:13:42,540
但这是一个完全连接的网络 

265
00:13:38,580 --> 00:13:46,080
我们已经在周一讨论有 

266
00:13:42,540 --> 00:13:48,300
深入学习了许多技巧 

267
00:13:46,080 --> 00:13:53,100
使事情的工作 ，使培训成为 多 

268
00:13:48,300 --> 00:13:55,410
在大班问题上更有效率

269
00:13:53,100 --> 00:13:58,290
那里有很多课程 

270
00:13:55,410 --> 00:13:59,520
表示时的 数据 集 

271
00:13:58,290 --> 00:14:01,800
神经网络的任务是

272
00:13:59,520 --> 00:14:03,300
学习是非常复杂的，那就是 

273
00:14:01,800 --> 00:14:05,550
卷积神经神经网络

274
00:14:03,300 --> 00:14:08,880
网络介入他们使用的技巧 

275
00:14:05,550 --> 00:14:13,560
空间不变性他们使用这个想法 

276
00:14:08,880 --> 00:14:15,480
在的 左上角猫

277
00:14:13,560 --> 00:14:18,780
图像与底部的猫相同 

278
00:14:15,480 --> 00:14:22,010
图像的右上角，这样我们就可以学习 

279
00:14:18,780 --> 00:14:24,300
整个图像具有相同的功能

280
00:14:22,010 --> 00:14:28,380
这就是卷积操作的地方

281
00:14:24,300 --> 00:14:31,050
步骤而不是完全连接 

282
00:14:28,380 --> 00:14:34,950
这里的网络有第三个 维度 

283
00:14:31,050 --> 00:14:39,240
深度所以这个神经元中的块

284
00:14:34,950 --> 00:14:42,890
网络作为输入拍摄3D体积和 

285
00:14:39,240 --> 00:14:42,890
输出产生了3d卷 

286
00:14:47,130 --> 00:14:54,150
的图像的窗口和滑动件的切片 

287
00:14:51,180 --> 00:14:55,590
它应用相同的精确 

288
00:14:54,150 --> 00:14:59,040
权重， 我们将通过 一个 例子 

289
00:14:55,590 --> 00:15:01,200
与完全相同的确切权重 

290
00:14:59,040 --> 00:15:04,620
连接网络的边缘 

291
00:15:01,200 --> 00:15:08,280
用于 将输入 映射 到输出 

292
00:15:04,620 --> 00:15:10,800
用于映射 图像的 这个切片 

293
00:15:08,280 --> 00:15:15,980
这个窗口的图像输出

294
00:15:10,800 --> 00:15:19,650
你 可以做很多这样的 事情 

295
00:15:15,980 --> 00:15:22,620
卷积过滤很多层 

296
00:15:19,650 --> 00:15:24,540
什么样的不同的选择

297
00:15:22,620 --> 00:15:27,270
您在图像中寻找的功能 

298
00:15:24,540 --> 00:15:30,210
你滑过什么样的窗户 

299
00:15:27,270 --> 00:15:32,660
为了提取各种各样的东西 

300
00:15:30,210 --> 00:15:36,870
各种 边缘各种高阶 

301
00:15:32,660 --> 00:15:39,120
图像中的图案非常 

302
00:15:36,870 --> 00:15:41,610
重要的是参数

303
00:15:39,120 --> 00:15:45,120
每个这些滤波器的 所述 子集 

304
00:15:41,610 --> 00:15:48,360
图像这些窗口是共享的， 如果 

305
00:15:45,120 --> 00:15:50,040
定义猫的功能非常有用 

306
00:15:48,360 --> 00:15:52,320
它的左上角很有用 

307
00:15:50,040 --> 00:15:54,660
在右上角它对每一个都很有用 

308
00:15:52,320 --> 00:15:56,640
图像方面这是诀窍 

309
00:15:54,660 --> 00:16:00,720
这使得卷积神经网络 

310
00:15:56,640 --> 00:16:04,620
节省了很多参数减少 了很多 

311
00:16:00,720 --> 00:16:07,050
参数显着的重用 

312
00:16:04,620 --> 00:16:13,770
跨越特征的空间共享

313
00:16:07,050 --> 00:16:15,750
图像的空间深度

314
00:16:13,770 --> 00:16:20,280
这些3d 卷的数量是 

315
00:16:15,750 --> 00:16:23,220
过滤步幅是跳过 

316
00:16:20,280 --> 00:16:26,550
过滤步长你有多少像素 

317
00:16:23,220 --> 00:16:31,680
将过滤器应用到的时跳过

318
00:16:26,550 --> 00:16:33,360
输入和填充是

319
00:16:31,680 --> 00:16:36,720
他们填充 的 零填充 

320
00:16:33,360 --> 00:16:41,790
卷积之外的输入

321
00:16:36,720 --> 00:16:44,819
图层让我们来看一个例子 

322
00:16:41,790 --> 00:16:46,350
左边这里和幻灯片现在 

323
00:16:44,819 --> 00:16:48,990
在线提供，您 可以关注他们 

324
00:16:46,350 --> 00:16:52,949
沿着我将逐步通过 这个例子 

325
00:16:48,990 --> 00:16:56,249
在左边 这里 是输入音量 

326
00:16:52,949 --> 00:16:59,309
左列 是三个通道

327
00:16:56,249 --> 00:17:02,399
输入三个 块三个 方块 

328
00:16:59,309 --> 00:17:07,890
有三个渠道，有 

329
00:17:02,399 --> 00:17:14,130
内的那些信道， 然后数

330
00:17:07,890 --> 00:17:17,699
我们有一个红色的过滤器，其中两个是两个 

331
00:17:14,130 --> 00:17:20,339
具有偏差的滤波器通道和我们 

332
00:17:17,699 --> 00:17:24,630
那些过滤器各有三个 

333
00:17:20,339 --> 00:17:26,939
其中一个是尺寸三乘三 

334
00:17:24,630 --> 00:17:29,850
我们做的是，我们通过采取这三个 

335
00:17:26,939 --> 00:17:32,309
要学习的三个过滤器

336
00:17:29,850 --> 00:17:34,890
这些是我们的变量我们的权重 

337
00:17:32,309 --> 00:17:38,220
我们必须学习，然后我们滑动它

338
00:17:34,890 --> 00:17:41,520
整个图像以产生所述 输出 上 

339
00:17:38,220 --> 00:17:44,279
右侧的绿色所以通过应用 

340
00:17:41,520 --> 00:17:46,350
在红色过滤器中有两个 

341
00:17:44,279 --> 00:17:49,529
每一个都有 一个 

342
00:17:46,350 --> 00:17:53,399
每个输入通道我们从左边开始 

343
00:17:49,529 --> 00:17:55,890
从输入音量开到右边 

344
00:17:53,399 --> 00:18:00,990
左边的输出音量为 绿色 

345
00:17:55,890 --> 00:18:02,399
右边你可以看看它 

346
00:18:00,990 --> 00:18:04,890
如果你现在自己拉起幻灯片 

347
00:18:02,399 --> 00:18:09,870
看不到屏幕上的数字 但是 

348
00:18:04,890 --> 00:18:13,049
操作是在。上执行的

349
00:18:09,870 --> 00:18:14,520
输入产生单值的 

350
00:18:13,049 --> 00:18:18,659
突出显示在绿色 和 

351
00:18:14,520 --> 00:18:23,340
输出， 我们滑动这个卷积没有 

352
00:18:18,659 --> 00:18:29,779
沿着图像过滤， 大步进入 

353
00:18:23,340 --> 00:18:34,130
这种跳过跳过的情况

354
00:18:29,779 --> 00:18:39,990
他们总结到 了右边 的两个 

355
00:18:34,130 --> 00:18:42,540
绿色的通道输出就是它 

356
00:18:39,990 --> 00:18:44,190
卷积操作这 

357
00:18:42,540 --> 00:18:47,190
什么叫卷积层 

358
00:18:44,190 --> 00:18:51,090
神经网络和这里的参数 

359
00:18:47,190 --> 00:18:53,070
除了偏差是 读取值 

360
00:18:51,090 --> 00:18:56,070
中间就是我们想要的 

361
00:18:53,070 --> 00:18:58,410
学习，有很多有趣的东西 

362
00:18:56,070 --> 00:19:00,840
招数我们今天要讨论的顶部 

363
00:18:58,410 --> 00:19:03,420
那些，但这是核心 

364
00:19:00,840 --> 00:19:06,120
空间不变的共享 

365
00:19:03,420 --> 00:19:09,780
卷积的参数

366
00:19:06,120 --> 00:19:13,890
神经网络能够 有效地进行 

367
00:19:09,780 --> 00:19:16,280
学习和找到模式和图像 

368
00:19:13,890 --> 00:19:18,960
更多地建立你的直觉 

369
00:19:16,280 --> 00:19:22,410
关于卷积这里是一个输入图像

370
00:19:18,960 --> 00:19:25,440
在左边和右边 

371
00:19:22,410 --> 00:19:26,940
身份过滤器产生你的输出

372
00:19:25,440 --> 00:19:29,460
看到右边然后有 

373
00:19:26,940 --> 00:19:33,360
不同的方式你 可以不同的种类 

374
00:19:29,460 --> 00:19:35,520
你可以 提取的边缘

375
00:19:33,360 --> 00:19:38,370
激活或生成的激活 映射 

376
00:19:35,520 --> 00:19:40,860
在右边看到所以申请时

377
00:19:38,370 --> 00:19:44,100
带有边缘检测的滤波器

378
00:19:40,860 --> 00:19:46,309
过滤到你左边的图像 

379
00:19:44,100 --> 00:19:50,730
以白色生产的是 那些部件 

380
00:19:46,309 --> 00:19:56,580
激活卷积的结果

381
00:19:50,730 --> 00:19:57,990
这些过滤器，所以你可以做任何种类 

382
00:19:56,580 --> 00:20:02,280
过滤器就是我们想要的 

383
00:19:57,990 --> 00:20:05,010
学习任何一种边缘 

384
00:20:02,280 --> 00:20:06,570
你可以移动的那种模式 

385
00:20:05,010 --> 00:20:08,790
这个窗口以及显示的方式 

386
00:20:06,570 --> 00:20:11,100
在这里你沿着 图像和你 滑动 

387
00:20:08,790 --> 00:20:13,679
产生你在右边看到的输出 

388
00:20:11,100 --> 00:20:15,420
并取决于你有多少过滤器 

389
00:20:13,679 --> 00:20:18,450
在每个级别 你都有很多 

390
00:20:15,420 --> 00:20:21,030
这样的切片VC就在右侧输入上 

391
00:20:18,450 --> 00:20:24,390
左边的输出 如果你的话 

392
00:20:21,030 --> 00:20:26,400
有几十个过滤器，你有几十个 

393
00:20:24,390 --> 00:20:31,260
每个用右边的图像 

394
00:20:26,400 --> 00:20:32,970
不同的结果 显示每个 

395
00:20:31,260 --> 00:20:36,179
个别过滤器模式是

396
00:20:32,970 --> 00:20:38,700
发现并且我们学会了什么样的模式 

397
00:20:36,179 --> 00:20:41,520
有用的寻找， 以便 执行 

398
00:20:38,700 --> 00:20:43,950
作为任务的分类任务 

399
00:20:41,520 --> 00:20:45,810
为神经网络学习这些 

400
00:20:43,950 --> 00:20:48,240
过滤器

401
00:20:45,810 --> 00:20:54,360
并且过滤器越来越高 

402
00:20:48,240 --> 00:20:57,200
表示的顺序从去 

403
00:20:54,360 --> 00:21:02,850
高语义的非常基本的边缘 

404
00:20:57,200 --> 00:21:05,430
意味着跨越整个图像和

405
00:21:02,850 --> 00:21:07,680
花费图像的能力可以在 

406
00:21:05,430 --> 00:21:09,450
传统上有 几种 方式 

407
00:21:07,680 --> 00:21:15,380
通过max pooling成功完成 

408
00:21:09,450 --> 00:21:19,080
通过统一取得产出 

409
00:21:15,380 --> 00:21:23,430
卷积操作和减少 

410
00:21:19,080 --> 00:21:25,350
通过压缩来解析该 字节 

411
00:21:23,430 --> 00:21:27,120
该信息通过例如采取 

412
00:21:25,350 --> 00:21:33,440
最大值最大值 

413
00:21:27,120 --> 00:21:36,510
激活因此减少了

414
00:21:33,440 --> 00:21:38,340
它 有利于空间分辨率

415
00:21:36,510 --> 00:21:41,160
我们将 在场景中 讨论的效果

416
00:21:38,340 --> 00:21:43,740
细分，但它有益于 

417
00:21:41,160 --> 00:21:45,860
找到更高阶的表示和 

418
00:21:43,740 --> 00:21:49,080
将图像组合在一起的图像 

419
00:21:45,860 --> 00:21:50,970
将功能结合在一起形成一个 

420
00:21:49,080 --> 00:21:56,090
我们试图识别的 实体 

421
00:21:50,970 --> 00:21:57,990
分类好，以便形成一个 

422
00:21:56,090 --> 00:21:59,610
卷积Yool网络这样的 

423
00:21:57,990 --> 00:22:01,950
卷积层叠在上面 

424
00:21:59,610 --> 00:22:03,810
彼此是唯一的补充 

425
00:22:01,950 --> 00:22:06,330
神经网络， 使一 

426
00:22:03,810 --> 00:22:08,640
卷积神经网络然后在

427
00:22:06,330 --> 00:22:12,630
结束完全连接的层或 

428
00:22:08,640 --> 00:22:15,000
任何其他架构都允许 我们 

429
00:22:12,630 --> 00:22:20,640
应用特定域名 

430
00:22:15,000 --> 00:22:25,700
让我们像网作为案例研究 的 

431
00:22:20,640 --> 00:22:27,000
图像网络数据集图像网络 

432
00:22:25,700 --> 00:22:30,390
挑战

433
00:22:27,000 --> 00:22:32,790
任务是我的分类

434
00:22:30,390 --> 00:22:35,760
提到第一个图像网是 

435
00:22:32,790 --> 00:22:39,140
数据集中最大的 一个 

436
00:22:35,760 --> 00:22:44,730
图像 的世界有14万张图片 

437
00:22:39,140 --> 00:22:47,280
21000个类别和很多深度 ，以 

438
00:22:44,730 --> 00:22:50,870
我提到的很多类别 

439
00:22:47,280 --> 00:22:50,870
1200奶奶史密斯苹果 

440
00:22:52,419 --> 00:22:58,070
这些允许- 这些允许更新 

441
00:22:55,400 --> 00:23:00,410
网络学习富人

442
00:22:58,070 --> 00:23:02,210
姿势照明中的表示

443
00:23:00,410 --> 00:23:03,970
变异性和类内类 

444
00:23:02,210 --> 00:23:07,250
特定事物的变化

445
00:23:03,970 --> 00:23:10,940
像格兰尼史密斯这样的特殊课程 

446
00:23:07,250 --> 00:23:13,130
苹果让我们期待通过各种 

447
00:23:10,940 --> 00:23:13,910
网络让我们讨论它们让我们看看

448
00:23:13,130 --> 00:23:16,429
见解

449
00:23:13,910 --> 00:23:19,610
它始于Alex网络的第一个 

450
00:23:16,429 --> 00:23:21,860
真正成功的GPU 训练神经 

451
00:23:19,610 --> 00:23:23,809
在图像网上实现了一个网络

452
00:23:21,860 --> 00:23:31,039
比去年大幅提升

453
00:23:23,809 --> 00:23:35,630
并转移到 VGG净净谷歌 疟疾 

454
00:23:31,039 --> 00:23:42,530
Lynnette RESNET 看到你的图像和 

455
00:23:35,630 --> 00:23:44,720
安妮特在2017年 的数字将 再次 出现 

456
00:23:42,530 --> 00:23:48,049
显示的准确性是基于 

457
00:23:44,720 --> 00:23:51,049
前五个错误率我们得到五个 猜测 

458
00:23:48,049 --> 00:23:52,970
如果你猜到它就是一个或零 

459
00:23:51,049 --> 00:23:55,250
如果五个中的一个 是正确的，你得到一个 

460
00:23:52,970 --> 00:24:03,710
否则 就是一个特别的 猜测 

461
00:23:55,250 --> 00:24:05,720
它是零，人为错误是五

462
00:24:03,710 --> 00:24:08,750
当人类试图实现时，指出一点

463
00:24:05,720 --> 00:24:11,299
同样尝试执行相同的任务 

464
00:24:08,750 --> 00:24:13,700
作为机械师的空气任务 

465
00:24:11,299 --> 00:24:15,679
是人类注释的五点一点

466
00:24:13,700 --> 00:24:18,049
基于的图像执行

467
00:24:15,679 --> 00:24:22,370
二元分类格兰尼 史密斯苹果 

468
00:24:18,049 --> 00:24:24,230
或不是猫或不是实际的 任务 

469
00:24:22,370 --> 00:24:27,230
机器必须执行和 那个 

470
00:24:24,230 --> 00:24:29,539
人类的竞争必须执行给定 

471
00:24:27,230 --> 00:24:33,919
图像提供 众多之一 

472
00:24:29,539 --> 00:24:38,870
人为错误下的课程5.1％ 

473
00:24:33,919 --> 00:24:44,860
将其在2015年超过由RESNET 到 

474
00:24:38,870 --> 00:24:47,620
实现4％的误差，让我们来吧 

475
00:24:44,860 --> 00:24:49,090
与Alex网格我将放大 后期 

476
00:24:47,620 --> 00:24:53,860
他们有一些有趣的网络

477
00:24:49,090 --> 00:24:56,710
见解， 但 亚历克斯网和vgg网两个 

478
00:24:53,860 --> 00:25:02,860
落在一个非常类似的架构非常 

479
00:24:56,710 --> 00:25:08,170
整个深度均匀的vgg网 

480
00:25:02,860 --> 00:25:10,450
2014年是卷积卷积池 

481
00:25:08,170 --> 00:25:13,410
卷积池卷积池 

482
00:25:10,450 --> 00:25:15,730
并在最后完全连接层

483
00:25:13,410 --> 00:25:17,380
有一种美丽 

484
00:25:15,730 --> 00:25:19,390
这些简单均匀

485
00:25:17,380 --> 00:25:21,520
架构因为你可以做到 

486
00:25:19,390 --> 00:25:24,730
它越来越 深，使它变得非常 

487
00:25:21,520 --> 00:25:27,580
适合在图层中实现 

488
00:25:24,730 --> 00:25:29,919
堆栈的方式和任何深刻的 

489
00:25:27,580 --> 00:25:32,020
学习框架很干净 

490
00:25:29,919 --> 00:25:35,350
美丽 在这种情况下 要理解 

491
00:25:32,020 --> 00:25:37,090
例如，吉娜 是16 或19层，138 

492
00:25:35,350 --> 00:25:38,410
百万参数不多 

493
00:25:37,090 --> 00:25:40,780
优化和这些参数

494
00:25:38,410 --> 00:25:42,460
因此 参数的数量 是 

495
00:25:40,780 --> 00:25:44,710
远高于网络 

496
00:25:42,460 --> 00:25:49,419
尽管没有层次，但它紧随其后 

497
00:25:44,710 --> 00:25:52,450
大型谷歌网推出了 

498
00:25:49,419 --> 00:25:55,530
初始模块开始做一些

499
00:25:52,450 --> 00:25:58,150
有趣的事情与 小 

500
00:25:55,530 --> 00:25:59,940
这些网络中的模块

501
00:25:58,150 --> 00:26:04,450
允许培训更多 

502
00:25:59,940 --> 00:26:07,870
高效而有效的理念背后 

503
00:26:04,450 --> 00:26:11,530
此处显示的初始模块包含 

504
00:26:07,870 --> 00:26:14,290
前一层在底部和 

505
00:26:11,530 --> 00:26:18,850
卷积层在这里用

506
00:26:14,290 --> 00:26:24,429
在顶部生成的初始模块

507
00:26:18,850 --> 00:26:26,919
它是否使用了不同 大小 的想法 

508
00:26:24,429 --> 00:26:29,980
卷积为...提供不同的价值

509
00:26:26,919 --> 00:26:33,720
网络 较小的卷积是 

510
00:26:29,980 --> 00:26:37,840
能够捕获 或传播前进 

511
00:26:33,720 --> 00:26:41,980
特点是 非常局部的 高 

512
00:26:37,840 --> 00:26:44,470
纹理中的分辨率更大 

513
00:26:41,980 --> 00:26:48,309
卷积更好 

514
00:26:44,470 --> 00:26:50,020
代表并捕获并高度捕捉 

515
00:26:48,309 --> 00:26:52,780
抽象的功能更高阶 

516
00:26:50,020 --> 00:26:55,600
功能所以背后的想法 

517
00:26:52,780 --> 00:26:58,360
初始模块就是说得好 

518
00:26:55,600 --> 00:26:58,759
反对选择和高位 

519
00:26:58,360 --> 00:27:01,219
对 

520
00:26:58,759 --> 00:27:03,679
调整过程 或架构设计 

521
00:27:01,219 --> 00:27:06,499
过程选择哪个卷积大小

522
00:27:03,679 --> 00:27:08,809
我们要 一起去 ，为什么不能做所有的 

523
00:27:06,499 --> 00:27:11,989
他们在一起 ，而几个一起 

524
00:27:08,809 --> 00:27:14,089
谷歌网模型就是这样的 

525
00:27:11,989 --> 00:27:17,089
一个接一个三乘三， 五 

526
00:27:14,089 --> 00:27:19,039
与旧信托五次合并 

527
00:27:17,089 --> 00:27:23,599
max pooling的朋友还留在了 

528
00:27:19,039 --> 00:27:24,709
在那里已经失去了 更多的 青睐 

529
00:27:23,599 --> 00:27:28,449
随着时间的推移 ， 更多 的图像 

530
00:27:24,709 --> 00:27:31,279
分类 任务和结果是 

531
00:27:28,449 --> 00:27:35,899
如果 需要 的 参数 更少 

532
00:27:31,279 --> 00:27:37,909
你选择这些开始的位置 

533
00:27:35,899 --> 00:27:40,759
模块正确的数量 

534
00:27:37,909 --> 00:27:48,259
要求 达到更高的参数

535
00:27:40,759 --> 00:27:51,940
性能远低于res net one 

536
00:27:48,259 --> 00:27:51,940
迄今为止最受欢迎的

537
00:27:53,559 --> 00:28:01,429
架构，我们将讨论 

538
00:27:56,349 --> 00:28:05,509
现场分割也出现 了 

539
00:28:01,429 --> 00:28:08,509
使用残余块的想法

540
00:28:05,509 --> 00:28:10,429
最初鼓舞人心的观察

541
00:28:08,509 --> 00:28:14,109
并不一定适用于它 

542
00:28:10,429 --> 00:28:17,299
结果却是 网络深度 

543
00:28:14,109 --> 00:28:20,509
增加表现力这些 

544
00:28:17,299 --> 00:28:23,029
残余块允许你有很多 

545
00:28:20,509 --> 00:28:27,499
更深层的网络，我将解释为什么在 

546
00:28:23,029 --> 00:28:28,999
这里的第二个， 但他们的想法是 

547
00:28:27,499 --> 00:28:32,419
工作得那么 好，因为网络是如此 

548
00:28:28,999 --> 00:28:35,259
更深层次， 使关键的事情 

549
00:28:32,419 --> 00:28:38,299
这些块如此有效是一样的

550
00:28:35,259 --> 00:28:40,729
这让人联想到的想法

551
00:28:38,299 --> 00:28:43,690
我希望 复发神经 网络 

552
00:28:40,729 --> 00:28:48,169
我们 有机会谈论 这个问题 

553
00:28:43,690 --> 00:28:51,199
他们的训练要容易得多 

554
00:28:48,169 --> 00:28:54,379
采取一个简单的块重复和

555
00:28:51,199 --> 00:28:57,829
结束，他们 传递输入 

556
00:28:54,379 --> 00:29:00,649
没有转变与 

557
00:28:57,829 --> 00:29:04,460
转化它 以学习的能力 

558
00:29:00,649 --> 00:29:08,179
学习过滤器学习权重

559
00:29:04,460 --> 00:29:12,139
所以你被允许每个人都允许 

560
00:29:08,179 --> 00:29:14,990
图层不仅要承担处理 

561
00:29:12,139 --> 00:29:17,480
以前的图层， 但要接受 

562
00:29:14,990 --> 00:29:21,350
错误的 转换数据和学习的东西 

563
00:29:17,480 --> 00:29:24,200
学习新东西的新能力 

564
00:29:21,350 --> 00:29:27,470
允许您拥有更深入的网络 

565
00:29:24,200 --> 00:29:34,129
并且这个块的简单性允许 

566
00:29:27,470 --> 00:29:36,950
为了更有效的培训状态 

567
00:29:34,129 --> 00:29:40,909
2017年的艺术作品 受到挤压 

568
00:29:36,950 --> 00:29:42,950
激发网络， 不像 

569
00:29:40,909 --> 00:29:44,809
前一年会看到你的形象 

570
00:29:42,950 --> 00:29:46,999
简单地采用整体方法和 

571
00:29:44,809 --> 00:29:51,399
结合了许多 成功的方法 

572
00:29:46,999 --> 00:29:55,039
采取边际改善自身净 

573
00:29:51,399 --> 00:29:57,049
至少得到了显着的改善

574
00:29:55,039 --> 00:30:02,480
百分比我认为有 25％ 

575
00:29:57,049 --> 00:30:07,309
误差从4％减少到3 

576
00:30:02,480 --> 00:30:09,200
百分之东西 那样 使用 

577
00:30:07,309 --> 00:30:12,249
很简单的想法 ，我认为 是 

578
00:30:09,200 --> 00:30:16,190
重要的是提 一个简单的见解 

579
00:30:12,249 --> 00:30:19,399
它为每个 频道添加了一个参数

580
00:30:16,190 --> 00:30:22,490
卷积层

581
00:30:19,399 --> 00:30:25,869
卷积块所以网络可以 

582
00:30:22,490 --> 00:30:29,450
现在调整每个频道的权重 

583
00:30:25,869 --> 00:30:31,009
基于的每个特征图的基础 

584
00:30:29,450 --> 00:30:34,309
根据 输入的 内容 

585
00:30:31,009 --> 00:30:36,710
网络这是一种 带走的东西 

586
00:30:34,309 --> 00:30:38,299
想想任何一个网络 

587
00:30:36,710 --> 00:30:42,590
谁 谈论任何架构 

588
00:30:38,299 --> 00:30:44,240
很多时候你的反复神经

589
00:30:42,590 --> 00:30:47,629
网络和卷积神经网络

590
00:30:44,240 --> 00:30:50,960
网络有很大的技巧 

591
00:30:47,629 --> 00:30:53,240
减少批量 参数 的数量

592
00:30:50,960 --> 00:30:55,460
他们使用的那种低悬的水果 

593
00:30:53,240 --> 00:30:57,320
空间不变量是时间 不变量 

594
00:30:55,460 --> 00:31:00,889
减少参数的数量 

595
00:30:57,320 --> 00:31:03,289
代表输入数据 但它们也是 

596
00:31:00,889 --> 00:31:05,570
留下某些不参数化的东西 

597
00:31:03,289 --> 00:31:07,940
他们不允许网络学习它 

598
00:31:05,570 --> 00:31:10,039
在这种情况下允许网络学习 

599
00:31:07,940 --> 00:31:11,929
对每个人的加权 

600
00:31:10,039 --> 00:31:14,539
通道，因此每个 单独的 

601
00:31:11,929 --> 00:31:17,359
过滤器是你学到的东西 

602
00:31:14,539 --> 00:31:18,359
与过滤器一起使用它

603
00:31:17,359 --> 00:31:20,399
巨大的提振

604
00:31:18,359 --> 00:31:22,799
关于这个很酷的事情就是它 

605
00:31:20,399 --> 00:31:24,719
适用于任何 这种 架构 

606
00:31:22,799 --> 00:31:26,779
块的那 是什么的 

607
00:31:24,719 --> 00:31:31,699
挤压和激励块是 

608
00:31:26,779 --> 00:31:35,399
适用于任何架构和

609
00:31:31,699 --> 00:31:37,769
因为很明显它 只是简单地 

610
00:31:35,399 --> 00:31:39,779
permit 提高选择哪个的能力 

611
00:31:37,769 --> 00:31:42,659
过滤你去与基于内容 

612
00:31:39,779 --> 00:31:45,059
我认为 这是一个微妙但至关重要的事情 

613
00:31:42,659 --> 00:31:48,509
它非常酷，适合未来的研究 

614
00:31:45,059 --> 00:31:49,889
它激发了思考还能做些什么 

615
00:31:48,509 --> 00:31:52,259
在您自己的网络中进行参数化

616
00:31:49,889 --> 00:31:54,539
还有什么可以被控制 的 一部分 

617
00:31:52,259 --> 00:31:57,359
学习过程包括招聘 

618
00:31:54,539 --> 00:32:00,329
高阶超参数 

619
00:31:57,359 --> 00:32:02,069
培训的哪些方面和 

620
00:32:00,329 --> 00:32:04,139
网络的架构可以是一部分 

621
00:32:02,069 --> 00:32:14,309
学习的 ，这是这是什么 

622
00:32:04,139 --> 00:32:17,359
网络启发了另一个网络 

623
00:32:14,309 --> 00:32:19,919
自90年代以来 一直处于发展阶段 

624
00:32:17,359 --> 00:32:21,419
与杰夫辛顿，但真的收到了 

625
00:32:19,919 --> 00:32:24,209
已发表收到 

626
00:32:21,419 --> 00:32:28,679
重点关注2017年我不会 

627
00:32:24,209 --> 00:32:31,949
进入这里的细节 ， 我们将 

628
00:32:28,679 --> 00:32:35,489
在线发布

629
00:32:31,949 --> 00:32:37,079
关于胶囊网络的视频是一个 

630
00:32:35,489 --> 00:32:41,759
有点太技术 但 他们 

631
00:32:37,079 --> 00:32:43,019
激励很重要的一点 ， 我们 

632
00:32:41,759 --> 00:32:46,139
应该总是深思熟虑 

633
00:32:43,019 --> 00:32:48,899
学习什么时候才能成功 

634
00:32:46,139 --> 00:32:52,169
考虑一下我提到的内容 

635
00:32:48,899 --> 00:32:54,239
猫 在哲学上吃香蕉 

636
00:32:52,169 --> 00:32:57,719
和 你必须 的数学 水平 

637
00:32:54,239 --> 00:33:00,929
考虑这些网络的假设 

638
00:32:57,719 --> 00:33:03,899
通过这些假设做出什么

639
00:33:00,929 --> 00:33:05,699
他们扔掉由于这样的神经网络

640
00:33:03,899 --> 00:33:08,239
卷积神经网络的空间

641
00:33:05,699 --> 00:33:10,499
网络由于 其空间 不变量 

642
00:33:08,239 --> 00:33:15,629
扔掉 有关信息 

643
00:33:10,499 --> 00:33:17,189
层次结构 之间 的关系

644
00:33:15,629 --> 00:33:19,379
简单和 复杂之间 

645
00:33:17,189 --> 00:33:21,959
对象所以面对左边和 

646
00:33:19,379 --> 00:33:24,209
右边的脸看起来 一样 

647
00:33:21,959 --> 00:33:27,929
完成神经网络的存在 

648
00:33:24,209 --> 00:33:32,020
眼睛和鼻子和嘴巴是 

649
00:33:27,929 --> 00:33:33,760
是什么使得中心方面 

650
00:33:32,020 --> 00:33:36,310
分类任务适用于 

651
00:33:33,760 --> 00:33:39,370
卷积网络 将在哪里发射 

652
00:33:36,310 --> 00:33:42,520
并说这绝对是一张脸但是 

653
00:33:39,370 --> 00:33:43,360
丢失的空间关系 

654
00:33:42,520 --> 00:33:45,820
忽视

655
00:33:43,360 --> 00:33:49,390
这意味着有很多 

656
00:33:45,820 --> 00:33:53,190
对此的影响，但对于像这样的事情 

657
00:33:49,390 --> 00:33:55,870
摆脱信息丢失的变异 

658
00:33:53,190 --> 00:33:59,020
我们 完全 扔掉 了 

659
00:33:55,870 --> 00:34:02,320
并希望 汇集操作 

660
00:33:59,020 --> 00:34:04,690
正在执行这些网络是有能力的 

661
00:34:02,320 --> 00:34:06,610
把所有东西都整合在一起 

662
00:34:04,690 --> 00:34:08,770
想出了 这些功能 

663
00:34:06,610 --> 00:34:10,060
射击 的不同部分 

664
00:34:08,770 --> 00:34:12,149
面对 再拿出 总 

665
00:34:10,060 --> 00:34:14,230
这是一个没有脸的分类

666
00:34:12,149 --> 00:34:16,300
代表真正的关系 

667
00:34:14,230 --> 00:34:19,570
在低级别的这些功能之间

668
00:34:16,300 --> 00:34:21,250
和低水平的高水平 

669
00:34:19,570 --> 00:34:24,880
简单和等级的层次结构 

670
00:34:21,250 --> 00:34:27,270
复杂程度这 是一个超级刺激的 

671
00:34:24,880 --> 00:34:29,320
现在这个领域有希望激发 

672
00:34:27,270 --> 00:34:32,760
我们如何设计自己的发展

673
00:34:29,320 --> 00:34:37,390
能够 学习这个 的网络 

674
00:34:32,760 --> 00:34:44,350
旋转方向不变性为 

675
00:34:37,390 --> 00:34:46,570
好吧，所以我 提到你拿这些 

676
00:34:44,350 --> 00:34:49,419
你网络中的组合 切断了 

677
00:34:46,570 --> 00:34:52,300
最后一层，以申请一个 

678
00:34:49,419 --> 00:34:53,710
特定领域，这 就是我们所要做的 

679
00:34:52,300 --> 00:34:55,810
做完全卷积神经

680
00:34:53,710 --> 00:35:01,200
网络我们的任务 

681
00:34:55,810 --> 00:35:03,790
将像素级别的图像分割 为 

682
00:35:01,200 --> 00:35:07,780
提醒这些网络 通过 

683
00:35:03,790 --> 00:35:11,920
卷积过程确实如此

684
00:35:07,780 --> 00:35:13,540
产生热图的 不同部分 

685
00:35:11,920 --> 00:35:15,640
网络越来越兴奋了 

686
00:35:13,540 --> 00:35:17,800
图像的不同方面和 

687
00:35:15,640 --> 00:35:19,780
所以它可以用来进行本地化 

688
00:35:17,800 --> 00:35:23,050
检测不仅仅是分类 

689
00:35:19,780 --> 00:35:27,070
图像，但本地化对象和他们 

690
00:35:23,050 --> 00:35:29,970
可以在像素级别这样做 

691
00:35:27,070 --> 00:35:32,830
卷积层正在做

692
00:35:29,970 --> 00:35:36,670
编码过程他们带走了富人 

693
00:35:32,830 --> 00:35:39,010
图像和图像中的原始感官信息 

694
00:35:36,670 --> 00:35:42,100
将它们编码为可解释的集合

695
00:35:39,010 --> 00:35:44,260
然后可以表示特征表示

696
00:35:42,100 --> 00:35:45,410
可用于 分类 ，但我们可以 

697
00:35:44,260 --> 00:35:48,020
然后使用它 

698
00:35:45,410 --> 00:35:51,440
kotor up样本信息和 

699
00:35:48,020 --> 00:35:52,730
完全生成这样的地图 

700
00:35:51,440 --> 00:35:55,490
卷积神经网络

701
00:35:52,730 --> 00:35:58,190
分割语义 场景分割 

702
00:35:55,490 --> 00:36:00,440
图像分割的 目标是 

703
00:35:58,190 --> 00:36:03,140
相对于整个图像要划分

704
00:36:00,440 --> 00:36:05,270
将每个像素分类为其像素 

705
00:36:03,140 --> 00:36:08,300
每个颜色的水平分割 

706
00:36:05,270 --> 00:36:10,340
单个像素与那个像素是什么 

707
00:36:08,300 --> 00:36:15,040
像素属于这个2d的对象

708
00:36:10,340 --> 00:36:19,340
2d投影的图像空间

709
00:36:15,040 --> 00:36:21,290
在三维世界的形象中如此 

710
00:36:19,340 --> 00:36:27,170
事情是有很多 

711
00:36:21,290 --> 00:36:28,850
过去 三年的进步但是 

712
00:36:27,170 --> 00:36:31,850
它仍然非常困难

713
00:36:28,850 --> 00:36:36,710
问题，如果你认为 如果 你 认为 

714
00:36:31,850 --> 00:36:40,340
- 这就是 使用 的数据量

715
00:36:36,710 --> 00:36:43,790
训练和像素级别的任务 

716
00:36:40,340 --> 00:36:46,130
百万像素这里有数百万 像素 

717
00:36:43,790 --> 00:36:47,750
负责有科学家的任务 

718
00:36:46,130 --> 00:36:52,580
单一标签这是一个非常困难的 

719
00:36:47,750 --> 00:36:54,650
问题为什么这 很有趣 

720
00:36:52,580 --> 00:36:57,490
试图解决的重要问题

721
00:36:54,650 --> 00:37:00,920
反对围绕猫的边界框

722
00:36:57,490 --> 00:37:03,260
好吧，只要精确的边界 

723
00:37:00,920 --> 00:37:05,690
对象很重要， 当然是医学 

724
00:37:03,260 --> 00:37:07,970
看待成像和应用时的应用

725
00:37:05,690 --> 00:37:13,040
特别是例如检测

726
00:37:07,970 --> 00:37:15,650
检测医学中的肿瘤

727
00:37:13,040 --> 00:37:22,100
不同器官的成像 

728
00:37:15,650 --> 00:37:24,080
当物体在机器人中驾驶时 

729
00:37:22,100 --> 00:37:26,090
参与它是一个完成所有的场景 

730
00:37:24,080 --> 00:37:29,300
那些车辆行人骑自行车的我们 

731
00:37:26,090 --> 00:37:31,550
需要能够不只是 松散 

732
00:37:29,300 --> 00:37:33,890
估计我们需要的对象

733
00:37:31,550 --> 00:37:37,250
能够拥有确切的界限和 

734
00:37:33,890 --> 00:37:39,410
然后可能通过数据融合 

735
00:37:37,250 --> 00:37:41,930
将传感器融合在一起 

736
00:37:39,410 --> 00:37:44,180
融合这些丰富的纹理信息 

737
00:37:41,930 --> 00:37:46,130
关于行人骑自行车者和车辆

738
00:37:44,180 --> 00:37:48,740
为我们提供的 激光雷达数据 

739
00:37:46,130 --> 00:37:50,750
世界的三维地图或 

740
00:37:48,740 --> 00:37:52,370
同时具有语义的意义 

741
00:37:50,750 --> 00:37:55,450
不同的对象和他们的确切 

742
00:37:52,370 --> 00:37:55,450
三维位置

743
00:37:58,890 --> 00:38:05,350
很多这项 工作 的 成功 有很多 

744
00:38:03,880 --> 00:38:07,600
语义分割中的工作

745
00:38:05,350 --> 00:38:10,260
从完全卷积开始

746
00:38:07,600 --> 00:38:12,670
用于语义分割的网络

747
00:38:10,260 --> 00:38:14,320
FCN就是FCN的名字来源 

748
00:38:12,670 --> 00:38:17,590
从2014年11月起 

749
00:38:14,320 --> 00:38:19,090
现在通过这里的几篇论文给出 

750
00:38:17,590 --> 00:38:23,050
你是一个直觉领域

751
00:38:19,090 --> 00:38:27,690
走了，这又怎么会让我们陷入困境 

752
00:38:23,050 --> 00:38:29,650
FCM的细分竞争

753
00:38:27,690 --> 00:38:31,630
重新利用预先训练过的图像网 

754
00:38:29,650 --> 00:38:34,090
捕获 训练过的网 

755
00:38:31,630 --> 00:38:37,720
分类整个图像中的内容

756
00:38:34,090 --> 00:38:41,440
图像并完全切断 

757
00:38:37,720 --> 00:38:43,960
连接层然后添加解码器

758
00:38:41,440 --> 00:38:49,420
在那里采样的零件

759
00:38:43,960 --> 00:38:52,480
此处显示的图像生成热图

760
00:38:49,420 --> 00:38:55,630
与大花猫的其中一个热图 

761
00:38:52,480 --> 00:38:58,090
猫在 图像中它慢得多 

762
00:38:55,630 --> 00:39:02,520
比输入更粗糙的分辨率 

763
00:38:58,090 --> 00:39:05,410
图片1/8充其量 

764
00:39:02,520 --> 00:39:10,810
跳过连接以改善粗糙度 

765
00:39:05,410 --> 00:39:12,550
如果， 采样有一些 技巧 

766
00:39:10,810 --> 00:39:14,500
你做的最 幼稚的做法 向上 

767
00:39:12,550 --> 00:39:16,660
抽样将非常粗糙 

768
00:39:14,500 --> 00:39:19,540
因为那是整个问题 

769
00:39:16,660 --> 00:39:22,930
神经网络 编码部分就是你 

770
00:39:19,540 --> 00:39:25,270
抛弃所有 无用的数据 

771
00:39:22,930 --> 00:39:27,130
YouTube上最重要的方面 是 

772
00:39:25,270 --> 00:39:28,390
代表那个图像让你投掷 

773
00:39:27,130 --> 00:39:31,390
远离了很多信息 

774
00:39:28,390 --> 00:39:35,500
然后必须形成高分辨率 

775
00:39:31,390 --> 00:39:39,040
图像 所以你有一些技巧 

776
00:39:35,500 --> 00:39:42,070
跳过一些最后的汇集

777
00:39:39,040 --> 00:39:45,280
操作进去类似的方式，这 

778
00:39:42,070 --> 00:39:46,540
是残差块去 去 

779
00:39:45,280 --> 00:39:51,370
产出越来越高 

780
00:39:46,540 --> 00:39:55,360
结束段的分辨率热图 

781
00:39:51,370 --> 00:39:58,180
在2015年将此应用于驾驶 

782
00:39:55,360 --> 00:40:01,990
背景和真正把它带到小猫 

783
00:39:58,180 --> 00:40:03,760
数据集和已经都表现出了很大 的 

784
00:40:01,990 --> 00:40:06,280
有趣的结果，并真正探索 

785
00:40:03,760 --> 00:40:08,430
编码器解码器或配方 

786
00:40:06,280 --> 00:40:08,430
问题

787
00:40:09,000 --> 00:40:14,200
真正巩固了这个地方 

788
00:40:12,460 --> 00:40:18,490
编码器/解码器框架 

789
00:40:14,200 --> 00:40:20,680
分割任务扩张卷积 

790
00:40:18,490 --> 00:40:22,330
我带你了解一些组件 

791
00:40:20,680 --> 00:40:27,190
这对于国家来说至关重要

792
00:40:22,330 --> 00:40:30,580
本 领域扩张卷积所以 

793
00:40:27,190 --> 00:40:33,850
卷积操作作为汇集

794
00:40:30,580 --> 00:40:38,230
操作会降低分辨率

795
00:40:33,850 --> 00:40:40,540
显着和扩张的卷积

796
00:40:38,230 --> 00:40:45,270
有一定的 gritting作为 

797
00:40:40,540 --> 00:40:50,350
在那里可视化维护着 

798
00:40:45,270 --> 00:40:54,700
局部高分辨率纹理而 

799
00:40:50,350 --> 00:40:55,920
还是捕捉 空间窗 

800
00:40:54,700 --> 00:40:59,410
必要 

801
00:40:55,920 --> 00:41:04,330
它被称为扩张卷积层

802
00:40:59,410 --> 00:41:07,420
这证明是2015年的一篇论文 

803
00:41:04,330 --> 00:41:15,220
在上 采样 高好得多

804
00:41:07,420 --> 00:41:19,720
分辨率图像深度实验室与v1 

805
00:41:15,220 --> 00:41:23,040
v2 Navi 3添加了条件随机 

806
00:41:19,720 --> 00:41:25,990
这是最后一块的 

807
00:41:23,040 --> 00:41:28,140
这里 有 最先进的 谜题 

808
00:41:25,990 --> 00:41:33,460
今天很多成功的网络 

809
00:41:28,140 --> 00:41:37,060
做分段不是所有发布的 

810
00:41:33,460 --> 00:41:39,640
使用CRF的过程有条件随机 

811
00:41:37,060 --> 00:41:41,980
田野和他们所做的是他们顺利

812
00:41:39,640 --> 00:41:43,990
分割向上 样品 

813
00:41:41,980 --> 00:41:46,300
由FCN产生的细分

814
00:41:43,990 --> 00:41:52,300
通过查看底层图像 

815
00:41:46,300 --> 00:41:55,030
强度，这是关键方面

816
00:41:52,300 --> 00:41:56,980
你今天成功的方法

817
00:41:55,030 --> 00:41:59,260
编码器解码器框架完全

818
00:41:56,980 --> 00:42:00,850
在您的网络中完成它取代 

819
00:41:59,260 --> 00:42:03,790
完全连接的层与 

820
00:42:00,850 --> 00:42:07,420
卷积层反卷积

821
00:42:03,790 --> 00:42:12,430
层和随着时间的进展 ，从 

822
00:42:07,420 --> 00:42:17,140
2014 年至今为常，而不是潜在的 

823
00:42:12,430 --> 00:42:20,620
从alex net到 vgg net的网络 

824
00:42:17,140 --> 00:42:22,450
现在ResNet已经成为其中之一 

825
00:42:20,620 --> 00:42:24,390
这些改进的原因

826
00:42:22,450 --> 00:42:27,460
能够执行分割 

827
00:42:24,390 --> 00:42:30,250
所以他们很自然地反映了 imagenet 

828
00:42:27,460 --> 00:42:32,290
挑战性能以 适应这些 

829
00:42:30,250 --> 00:42:34,930
网络因此是最先进的 用途 

830
00:42:32,290 --> 00:42:38,500
ResNet或类似网络 有条件 

831
00:42:34,930 --> 00:42:42,480
用于平滑的随机字段

832
00:42:38,500 --> 00:42:45,040
输入图像强度和扩张 

833
00:42:42,480 --> 00:42:47,560
卷积维持着 

834
00:42:45,040 --> 00:42:50,710
计算成本但增加了 

835
00:42:47,560 --> 00:42:54,609
整个上采样的分辨率 

836
00:42:50,710 --> 00:42:57,790
中间特征地图和那 

837
00:42:54,609 --> 00:43:03,670
把我们带到了技术状态， 我们 

838
00:42:57,790 --> 00:43:07,540
用于产生图像 以产生 

839
00:43:03,670 --> 00:43:09,400
比赛的图像存在 

840
00:43:07,540 --> 00:43:12,790
你看到 舞蹈采样 了吗？ 

841
00:43:09,400 --> 00:43:15,640
卷积而不是双线性

842
00:43:12,790 --> 00:43:20,099
抽样你做上采样学习 

843
00:43:15,640 --> 00:43:23,109
关于你学习升级过滤器

844
00:43:20,099 --> 00:43:26,650
这是真正的底部 

845
00:43:23,109 --> 00:43:28,900
使它在那里工作的关键部分应该 

846
00:43:26,650 --> 00:43:31,060
是一个主题在这里 有时在 

847
00:43:28,900 --> 00:43:33,400
最大的补充他们可以做到这一点 

848
00:43:31,060 --> 00:43:34,930
参数化的一个方面 

849
00:43:33,400 --> 00:43:37,089
他们认为理所当然的网络 

850
00:43:34,930 --> 00:43:41,800
让网络了解这方面

851
00:43:37,089 --> 00:43:43,720
而另一个 我 不确定有多重要 

852
00:43:41,800 --> 00:43:46,240
这是成功， 但它是一个 

853
00:43:43,720 --> 00:43:49,210
酷少添加是混合扩张 

854
00:43:46,240 --> 00:43:52,000
正如我所表明的那样卷积

855
00:43:49,210 --> 00:43:55,390
卷积的可视化 

856
00:43:52,000 --> 00:43:57,819
在输入中分散一点点 

857
00:43:55,390 --> 00:44:00,940
从输入到输出的步骤 

858
00:43:57,819 --> 00:44:02,710
那个扩张的卷积滤波器的时候

859
00:44:00,940 --> 00:44:06,390
他们改变了它会更顺畅

860
00:44:02,710 --> 00:44:09,579
结果，因为它保持 不变 

861
00:44:06,390 --> 00:44:12,250
某些输入像素获得了很多 

862
00:44:09,579 --> 00:44:15,460
更多的关注比其他人如此 失去 

863
00:44:12,250 --> 00:44:19,440
偏袒是所取得的成就 

864
00:44:15,460 --> 00:44:21,819
使用可变的不同膨胀率

865
00:44:19,440 --> 00:44:24,130
这些是两个技巧，但真的是 

866
00:44:21,819 --> 00:44:28,480
最大的一个是 参数化 

867
00:44:24,130 --> 00:44:29,800
向上变换过滤好 了，这就是 

868
00:44:28,480 --> 00:44:31,240
我们这就是我们以前的样子 

869
00:44:29,800 --> 00:44:33,310
生成那些数据，那就是我们 

870
00:44:31,240 --> 00:44:35,740
如果你有的话， 为 你 提供 代码 

871
00:44:33,310 --> 00:44:38,320
有兴趣参加精神观 

872
00:44:35,740 --> 00:44:39,369
这里的另一个方面是一切

873
00:44:38,320 --> 00:44:43,270
我们已经谈过 了 

874
00:44:39,369 --> 00:44:46,359
分类到分割 ，以 

875
00:44:43,270 --> 00:44:49,869
理解图像是有的 

876
00:44:46,359 --> 00:44:53,580
有关时间 的 信息 

877
00:44:49,869 --> 00:44:56,080
现场的动态被扔掉 

878
00:44:53,580 --> 00:44:58,330
为了机器人的驾驶环境 

879
00:44:56,080 --> 00:45:00,099
比赛 和我们想 和做 什么 

880
00:44:58,330 --> 00:45:02,650
用于分割的灵魂融合 

881
00:45:00,099 --> 00:45:04,690
动态场景分割上下文 

882
00:45:02,650 --> 00:45:06,640
当你试图解释发生了什么

883
00:45:04,690 --> 00:45:12,190
随着时间的推移在场景中使用它 

884
00:45:06,640 --> 00:45:14,619
因此，信息时间至关重要 

885
00:45:12,190 --> 00:45:18,520
像素的运动是必不可少的，通过 

886
00:45:14,619 --> 00:45:23,500
那时候那个了解 那些 

887
00:45:18,520 --> 00:45:25,780
物体通过三维空间移动

888
00:45:23,500 --> 00:45:28,960
它的2d投影图像 

889
00:45:25,780 --> 00:45:32,980
令人着迷，我们有很多 设置 

890
00:45:28,960 --> 00:45:37,750
那些开放性问题 所以流动是什么 

891
00:45:32,980 --> 00:45:39,839
作为一个起点非常有帮助 

892
00:45:37,750 --> 00:45:44,619
帮助我们了解这些像素如何移动 

893
00:45:39,839 --> 00:45:49,570
流动光流密集光流是 

894
00:45:44,619 --> 00:45:51,940
我们最好的计算

895
00:45:49,570 --> 00:45:57,369
近似每个像素的位置 

896
00:45:51,940 --> 00:46:00,580
图像一并移入 

897
00:45:57,369 --> 00:46:03,670
之后暂时下面的图片 

898
00:46:00,580 --> 00:46:06,490
每秒30帧中有两个图像

899
00:46:03,670 --> 00:46:09,490
有一个图像时间为零 另一个 

900
00:46:06,490 --> 00:46:11,619
是33.3毫秒 后和 

901
00:46:09,490 --> 00:46:14,109
idents光流是我们最好的估计

902
00:46:11,619 --> 00:46:17,770
如何输入图像中的每个像素 

903
00:46:14,109 --> 00:46:20,109
移动到输出图像中的光学 

904
00:46:17,770 --> 00:46:22,690
每个像素的流量产生一个 

905
00:46:20,109 --> 00:46:24,820
我们认为像素的方向

906
00:46:22,690 --> 00:46:27,910
移动和移动的距离大小

907
00:46:24,820 --> 00:46:30,060
这使我们能够获取信息 

908
00:46:27,910 --> 00:46:34,180
我们检测到第一帧和

909
00:46:30,060 --> 00:46:37,480
尝试传播转发这是 

910
00:46:34,180 --> 00:46:39,700
竞争 是试图分割 一个 

911
00:46:37,480 --> 00:46:46,680
图像并传播该信息

912
00:46:39,700 --> 00:46:48,780
转发手动注释a 

913
00:46:46,680 --> 00:46:50,310
图像所以这种着色书 

914
00:46:48,780 --> 00:46:53,930
每个单独着色的注释

915
00:46:50,310 --> 00:46:59,640
最先进的 数据集中的 像素 

916
00:46:53,930 --> 00:47:02,280
用于驾驶城市景观需要1.5 

917
00:46:59,640 --> 00:47:04,860
第九和1.5小时 90分钟 

918
00:47:02,280 --> 00:47:08,610
每个90分钟的着色 

919
00:47:04,860 --> 00:47:11,070
图像这是非常长的时间 这 

920
00:47:08,610 --> 00:47:13,470
为什么今天不存在 数据集 

921
00:47:11,070 --> 00:47:17,640
在这堂课中我们要 创作 

922
00:47:13,470 --> 00:47:22,740
这些图像 的分割 之一 

923
00:47:17,640 --> 00:47:25,860
透过时间通过视频这么久

924
00:47:22,740 --> 00:47:28,410
每个帧都完整的视频

925
00:47:25,860 --> 00:47:32,670
分段，这仍然是一个开放的问题 

926
00:47:28,410 --> 00:47:37,380
我们需要解决流量问题 

927
00:47:32,670 --> 00:47:39,270
我们也为您提供此服务 

928
00:47:37,380 --> 00:47:46,370
计算机最先进的流程使用 

929
00:47:39,270 --> 00:47:50,070
流量净值2.0因此流量净值在2015年5月 

930
00:47:46,370 --> 00:47:53,280
用神经网络来学习 

931
00:47:50,070 --> 00:47:55,350
光流密集的光流和

932
00:47:53,280 --> 00:47:58,140
它2种这样做

933
00:47:55,350 --> 00:48:00,800
建筑流动网络 流动 

934
00:47:58,140 --> 00:48:03,990
简单流网核流网见 

935
00:48:00,800 --> 00:48:06,120
简单的就是拿两个 

936
00:48:03,990 --> 00:48:08,490
图像所以 这里的任务 是什么 

937
00:48:06,120 --> 00:48:10,170
有两个图像，你想要的 

938
00:48:08,490 --> 00:48:12,240
从这两个图像中产生它们 

939
00:48:10,170 --> 00:48:15,360
三十三岁的时候跟着对方

940
00:48:12,240 --> 00:48:17,430
点三毫秒和你的 

941
00:48:15,360 --> 00:48:19,710
任务是产生密集的输出

942
00:48:17,430 --> 00:48:21,420
光流如此简单 

943
00:48:19,710 --> 00:48:24,510
架构你只是堆叠它们 

944
00:48:21,420 --> 00:48:26,910
每个 都是RGB，所以它产生一个 

945
00:48:24,510 --> 00:48:28,920
有六个通道输入网络 

946
00:48:26,910 --> 00:48:31,230
很多卷积，最后是它

947
00:48:28,920 --> 00:48:33,450
在同种工艺的的

948
00:48:31,230 --> 00:48:35,760
将您的网络完全卷积到 

949
00:48:33,450 --> 00:48:39,630
然后产生光流

950
00:48:35,760 --> 00:48:42,090
流网相关结构在哪里

951
00:48:39,630 --> 00:48:44,160
你分别进行 一些卷积 

952
00:48:42,090 --> 00:48:49,390
在使用相关 层 之前 

953
00:48:44,160 --> 00:48:53,710
结合功能地图 

954
00:48:49,390 --> 00:48:56,530
在不同的数据集和 

955
00:48:53,710 --> 00:49:01,540
不同的应用程序 所以流网2.0 

956
00:48:56,530 --> 00:49:04,180
2016年12月是其中之一 

957
00:49:01,540 --> 00:49:06,550
最先进的框架代码库 

958
00:49:04,180 --> 00:49:09,610
我们用来生成的所有数据 

959
00:49:06,550 --> 00:49:12,820
show结合了流网阿萨姆流 

960
00:49:09,610 --> 00:49:15,150
净C并改善初始 流量 

961
00:49:12,820 --> 00:49:18,670
净产生更平滑的流场 

962
00:49:15,150 --> 00:49:21,700
保留精细运动细节 

963
00:49:18,670 --> 00:49:24,280
对象的边缘并运行 

964
00:49:21,700 --> 00:49:26,290
非常有效地取决于 

965
00:49:24,280 --> 00:49:29,380
架构有一些变种

966
00:49:26,290 --> 00:49:33,280
八到一百四十 帧a 

967
00:49:29,380 --> 00:49:35,560
第二个和那个过程

968
00:49:33,280 --> 00:49:37,510
基本上是一个共同的

969
00:49:35,560 --> 00:49:40,810
各种应用 深度学习是 

970
00:49:37,510 --> 00:49:46,000
将这些网络堆叠在一起 

971
00:49:40,810 --> 00:49:48,670
我们这里非常有趣的方面

972
00:49:46,000 --> 00:49:51,160
仍在探索并再次适用于 

973
00:49:48,670 --> 00:49:53,350
在这种情况下所有深入学习它 

974
00:49:51,160 --> 00:49:57,010
似乎有一个强有力的作用 

975
00:49:53,350 --> 00:49:58,930
采用稀疏的小多数据集

976
00:49:57,010 --> 00:50:01,150
并按顺序进行训练 

977
00:49:58,930 --> 00:50:04,180
它被用于组的那些数据

978
00:50:01,150 --> 00:50:06,630
训练过程中非常看重 这 

979
00:50:04,180 --> 00:50:06,630
很有意思

980
00:50:07,050 --> 00:50:13,150
所以使用flow net 2.0这里是数据 

981
00:50:11,050 --> 00:50:16,840
设置我们正在做供精极度紧张 

982
00:50:13,150 --> 00:50:19,150
融合竞争的汽车，mit.edu 

983
00:50:16,840 --> 00:50:24,870
斜线精神融合首先是原始的 

984
00:50:19,150 --> 00:50:32,920
视频我们以高清晰度驾驶 

985
00:50:24,870 --> 00:50:37,350
1080p 和8k 360视频原始视频 

986
00:50:32,920 --> 00:50:37,350
在剑桥附近开车

987
00:50:37,480 --> 00:50:45,670
我们为一个人提供了基本的事实 

988
00:50:41,590 --> 00:50:48,010
训练集为该训练集 

989
00:50:45,670 --> 00:50:50,170
每个单帧 30帧的第二 

990
00:50:48,010 --> 00:50:53,410
我们正在提供细分框架 

991
00:50:50,170 --> 00:50:57,340
框架到框架分段 

992
00:50:53,410 --> 00:51:01,690
机械土耳其人我们也提供 

993
00:50:57,340 --> 00:51:02,830
我提到 的网络输出

994
00:51:01,690 --> 00:51:05,770
他们对我们的分割状态 

995
00:51:02,830 --> 00:51:10,810
那个非常接近的 网络 

996
00:51:05,770 --> 00:51:15,400
事实但仍然没有 和我们的任务 

997
00:51:10,810 --> 00:51:17,500
这是有趣的事情是 我们的 

998
00:51:15,400 --> 00:51:20,440
任务是把 这个 输出 

999
00:51:17,500 --> 00:51:23,460
网络很好，有两种选择 

1000
00:51:20,440 --> 00:51:27,910
获取 此网络 的 输出 和 

1001
00:51:23,460 --> 00:51:30,580
使用其他网络来帮助你 

1002
00:51:27,910 --> 00:51:33,310
更好地传播信息 

1003
00:51:30,580 --> 00:51:37,390
此分割 的 这个 输出 

1004
00:51:33,310 --> 00:51:39,460
网络确实只需要一个帧 

1005
00:51:37,390 --> 00:51:41,710
逐帧， 它没有使用 

1006
00:51:39,460 --> 00:51:43,960
时间信息都是如此 

1007
00:51:41,710 --> 00:51:46,180
问题是我们可以找出一种方法可以 

1008
00:51:43,960 --> 00:51:48,940
我们想出使用时间的技巧 

1009
00:51:46,180 --> 00:51:53,609
用于改善此细分的信息 

1010
00:51:48,940 --> 00:51:53,609
所以看起来更像 是这种细分 

1011
00:51:54,330 --> 00:51:57,880
我们也是 

1012
00:51:56,020 --> 00:52:00,730
提供从帧到光的光流

1013
00:51:57,880 --> 00:52:03,490
帧到帧所以基于光流 

1014
00:52:00,730 --> 00:52:10,570
在每个人的 2.00流动

1015
00:52:03,490 --> 00:52:14,560
像素移动好 ，形成 一个 seg 

1016
00:52:10,570 --> 00:52:18,250
融合竞争10000图像和 

1017
00:52:14,560 --> 00:52:23,860
任务是提交我们有启动的代码 

1018
00:52:18,250 --> 00:52:26,470
Python中的代码和github上的代码

1019
00:52:23,860 --> 00:52:28,570
原始视频接收 

1020
00:52:26,470 --> 00:52:30,240
训练奠定了基础的真相 

1021
00:52:28,570 --> 00:52:32,710
从最先进的分割

1022
00:52:30,240 --> 00:52:34,920
分割网络 光流 

1023
00:52:32,710 --> 00:52:38,290
来自最先进的光流

1024
00:52:34,920 --> 00:52:40,570
网络 并将其 结合在一起 

1025
00:52:38,290 --> 00:52:43,000
提高左下角的东西 

1026
00:52:40,570 --> 00:52:47,410
试图实现的细分

1027
00:52:43,000 --> 00:52:50,470
基本事实， 右上角没关系 

1028
00:52:47,410 --> 00:52:56,380
我 明天 要 感谢你 

1029
00:52:50,470 --> 00:52:59,560
下午1 点是 Stata 32的 两个方式 

1030
00:52:56,380 --> 00:53:01,090
下周将有三个下一个讲座 

1031
00:52:59,560 --> 00:53:03,670
关于深刻学习的感觉 

1032
00:53:01,090 --> 00:53:05,740
人类了解人类和我们 

1033
00:53:03,670 --> 00:53:08,800
将仅 在线发布讲座 

1034
00:53:05,740 --> 00:53:11,810
胶囊网络和甘斯将军 

1035
00:53:08,800 --> 00:53:14,980
对抗网络非常感谢你 

1036
00:53:11,810 --> 00:53:14,980
[掌声] 

