1
00:00:01,260 --> 00:00:02,180
Alright.  Hello everybody.

2
00:00:03,540 --> 00:00:04,880
Hopefully you can hear me well.

3
00:00:05,640 --> 00:00:05,940
Yes?

4
00:00:06,360 --> 00:00:06,720
Yes.

5
00:00:06,980 --> 00:00:07,300
Great!

6
00:00:08,500 --> 00:00:12,600
So, welcome to Course 6.S094.

7
00:00:13,700 --> 00:00:15,360
Deep Learning for Self-Driving Cars.

8
00:00:16,540 --> 00:00:21,340
We will introduce to you the methods of deep learning,

9
00:00:21,440 --> 00:00:27,060
of deep neural networks using the guiding case study of building self-driving cars.

10
00:00:28,880 --> 00:00:31,180
My name is Lex Fridman.

11
00:00:32,160 --> 00:00:35,300
You get to listen to me for a majority of these lectures

12
00:00:36,580 --> 00:00:42,040
and I am part of an amazing team with some brilliant TAs.

13
00:00:42,080 --> 00:00:43,060
Would you say brilliant?

14
00:00:43,780 --> 00:00:44,080
(CHUCKLES)

15
00:00:46,920 --> 00:00:47,740
Dan Brown.

16
00:00:48,560 --> 00:00:49,300
You guys want to stand up?

17
00:00:49,960 --> 00:00:50,800
They're in the front row.

18
00:00:51,240 --> 00:00:53,880
Spencer, William Angell.

19
00:00:54,780 --> 00:00:56,440
Spencer Dodd and all the way in the back.

20
00:00:57,860 --> 00:01:01,440
The smartest and the tallest person I know, Benedict Jenik.

21
00:01:03,580 --> 00:01:16,840
Well you see there on the left of the slide is a visualization of one of the two projects that one of the two simulations, games that we'll get to go through.

22
00:01:18,040 --> 00:01:24,320
We use it as a way to teach you about deep reinforcement learning but also as a way to excite you.

23
00:01:25,800 --> 00:01:27,820
By challenging you to compete against others

24
00:01:28,220 --> 00:01:33,260
if you wish to in a special prize yet to be announced.

25
00:01:33,900 --> 00:01:34,980
Super secret prize.

26
00:01:36,420 --> 00:01:45,380
So you can reach me and the TA's at deepcars@MIT.edu if you have any questions about the tutorials, about the lecture, about anything at all.

27
00:01:47,380 --> 00:01:50,780
The website cars.mit.edu has the lecture content.

28
00:01:51,260 --> 00:01:57,800
Code tutorials, again like today, the lectures slides for today are already up in PDF form.

29
00:01:58,960 --> 00:02:07,720
The slides themselves, if you want to see them just e-mail me but there are over a gigabyte in size because they're very heavy in videos so I'm just posting the PDS.

30
00:02:10,000 --> 00:02:15,800
And there will be lecture videos available a few days after the lectures were given.

31
00:02:15,800 --> 00:02:18,860
So speaking of which there is a camera in the back.

32
00:02:19,200 --> 00:02:26,700
This is being videotaped and recorded but for the most part the camera is just on the speaker.

33
00:02:27,340 --> 00:02:28,580
So you shouldn't have to worry.

34
00:02:29,100 --> 00:02:34,340
If that kind of thing worries you then you could sit on the periphery of the classroom

35
00:02:34,880 --> 00:02:40,140
or maybe I suggest sunglasses and a moustache, fake mustache, would be a good idea.

36
00:02:40,780 --> 00:02:43,400
There is a competition for the game that you see on the left.

37
00:02:43,940 --> 00:02:45,720
I'll describe exactly what's involved

38
00:02:47,160 --> 00:02:49,820
in order to get credit for the course you have to

39
00:02:50,700 --> 00:02:56,160
design a neural network that drives the car just above the speed limit sixty five miles an hour.

40
00:02:56,900 --> 00:02:59,680
But if you want to win, we need to go a little faster than that.

41
00:03:03,180 --> 00:03:05,480
So who's this class is for?

42
00:03:07,440 --> 00:03:08,960
You may be new to programming,

43
00:03:09,400 --> 00:03:10,460
new to machine learning,

44
00:03:10,920 --> 00:03:11,660
new to robotics,

45
00:03:12,440 --> 00:03:16,440
or you're an expert in those fields but want to go back to the basics.

46
00:03:18,120 --> 00:03:21,260
So what you will learn is an overview of deep reinforcement learning,

47
00:03:22,520 --> 00:03:23,860
of convolutional neural networks,

48
00:03:24,680 --> 00:03:25,860
recurring neural networks

49
00:03:26,720 --> 00:03:31,820
and how these methods can help improve each of the components of autonomous driving -

50
00:03:32,120 --> 00:03:40,220
perception, visual perception, localization, mapping, control planning and the detection of driver state.

51
00:03:42,560 --> 00:03:43,720
Okay, two projects.

52
00:03:44,300 --> 00:03:46,700
Code named "DeepTraffic" is the first one.

53
00:03:47,720 --> 00:03:50,440
There is, in this particular formulation of it,

54
00:03:50,440 --> 00:03:52,440
there is seven lanes.

55
00:03:52,440 --> 00:03:54,440
It's a top view.

56
00:03:55,800 --> 00:03:59,380
It looks like a game but I assure you it's very serious.

57
00:04:00,720 --> 00:04:03,260
It is the agent in red,

58
00:04:04,400 --> 00:04:07,820
the car in red is being controlled by a neural network and we'll explain

59
00:04:08,320 --> 00:04:15,000
how you can control and design the various aspects, the various parameters of this neural network

60
00:04:16,340 --> 00:04:19,040
and it learns in the browser.

61
00:04:19,860 --> 00:04:21,720
So this, we're using ConvNet.JS

62
00:04:22,040 --> 00:04:26,980
which is a library that is programmed by Andrej Karpathy in javascript.

63
00:04:27,760 --> 00:04:32,920
So amazingly we live in a world where you can train in a matter of minutes

64
00:04:33,420 --> 00:04:35,220
a neural network in your browser.

65
00:04:36,040 --> 00:04:37,560
And we'll talk about how to do that.

66
00:04:37,860 --> 00:04:38,880
The reason we did this

67
00:04:39,400 --> 00:04:46,080
is so that there is very few requirements to get you up and started with neural networks.

68
00:04:46,620 --> 00:04:50,580
So in order to complete this project for the course,

69
00:04:51,540 --> 00:04:54,420
you don't need any requirements except to have a Chrome browser.

70
00:04:56,260 --> 00:05:00,360
And to win the competition you don't need anything except the Chrome browser.

71
00:05:02,500 --> 00:05:05,000
The second project code name "DeepTesla"

72
00:05:06,840 --> 00:05:07,500
or "Tesla"

73
00:05:09,160 --> 00:05:13,000
is using data from a Tesla vehicle

74
00:05:14,440 --> 00:05:15,580
of the forward road way

75
00:05:16,040 --> 00:05:17,520
and using end-to-end learning

76
00:05:17,880 --> 00:05:22,200
taking the image and putting into convolutional neural networks

77
00:05:22,800 --> 00:05:23,860
that directly maps

78
00:05:24,500 --> 00:05:27,760
"or aggressor" that maps to a steering angle.

79
00:05:28,680 --> 00:05:30,440
So all it takes is a single image

80
00:05:30,860 --> 00:05:33,580
and it predicts a steering angle for the car.

81
00:05:34,280 --> 00:05:36,480
We have data for the car itself

82
00:05:36,920 --> 00:05:38,660
and you get to build a neural network

83
00:05:39,220 --> 00:05:41,700
that tries to do better,

84
00:05:42,300 --> 00:05:44,900
tries to steer better or at least as good as the car.

85
00:05:46,660 --> 00:05:47,000
Okay.

86
00:05:48,220 --> 00:05:51,580
Let's get started with the question,

87
00:05:53,320 --> 00:05:57,180
with the thing that we understand so poorly at this time

88
00:05:57,860 --> 00:05:59,520
because it's so shot in mystery

89
00:05:59,680 --> 00:06:01,640
but it fascinates many of us.

90
00:06:02,640 --> 00:06:04,700
And that is the question of:  "What is intelligence?"

91
00:06:06,520 --> 00:06:14,120
This is from a March 1996 Time magazine.

92
00:06:14,120 --> 00:06:17,800
And the question:  "Can machines think?"

93
00:06:17,800 --> 00:06:20,980
is answered below with, "they already do."

94
00:06:22,120 --> 00:06:24,760
So what if anything is special about the human mind?

95
00:06:26,060 --> 00:06:27,720
It's a good question for 1996,

96
00:06:28,100 --> 00:06:29,920
a good question for 2016,

97
00:06:30,440 --> 00:06:31,300
2017 now,

98
00:06:32,280 --> 00:06:32,980
and the future.

99
00:06:33,720 --> 00:06:35,240
And there's two ways to ask that question.

100
00:06:35,820 --> 00:06:37,780
One is the special purpose version.

101
00:06:39,160 --> 00:06:44,320
Can an artificial intelligence system achieve a well defined,

102
00:06:46,140 --> 00:06:49,220
specifically, formally defined finite set of goals?

103
00:06:50,520 --> 00:06:52,420
And this little diagram

104
00:06:53,060 --> 00:06:57,320
from a book that got me into artificial intelligence as a bright-eyed high school student

105
00:06:58,320 --> 00:07:00,280
they are artificial intelligence to modern approach.

106
00:07:02,220 --> 00:07:08,420
This is a beautifully simple diagram of a system.

107
00:07:09,060 --> 00:07:10,220
It exists in an environment.

108
00:07:10,860 --> 00:07:15,360
It has a set of sensors that do the perception.

109
00:07:16,400 --> 00:07:17,640
It takes those sensors in.

110
00:07:18,260 --> 00:07:19,160
It does something magical.

111
00:07:19,160 --> 00:07:20,460
There's a question mark there.

112
00:07:21,180 --> 00:07:24,960
And with a set of affectors acts in the world, manipulates objects in that world,

113
00:07:27,000 --> 00:07:29,620
and so special purpose.

114
00:07:30,360 --> 00:07:30,800
We can,

115
00:07:32,120 --> 00:07:33,060
under this formulation,

116
00:07:33,160 --> 00:07:35,360
as long as the environment is formally defined,

117
00:07:35,780 --> 00:07:36,540
well defined;

118
00:07:36,880 --> 00:07:39,100
as long as a set of goals are well defined.

119
00:07:39,600 --> 00:07:40,900
As long as the set of actions,

120
00:07:41,560 --> 00:07:42,060
sensors,

121
00:07:42,600 --> 00:07:47,800
and the ways that the perception carries itself out as well defined.

122
00:07:48,500 --> 00:07:50,200
We have good algorithms

123
00:07:50,520 --> 00:07:51,560
which will talk about

124
00:07:52,360 --> 00:07:54,880
that can optimize for those goals.

125
00:07:55,580 --> 00:07:56,440
The question is,

126
00:07:56,960 --> 00:07:58,560
if we inch along this path,

127
00:08:00,980 --> 00:08:04,000
will we get closer to the general formulation,

128
00:08:04,000 --> 00:08:08,420
to the general purpose version of what artificial intelligence is?

129
00:08:10,000 --> 00:08:12,580
Can it achieve poorly defined,

130
00:08:12,580 --> 00:08:13,920
unconstrained set of goals

131
00:08:14,360 --> 00:08:16,800
with an unconstrained, poorly defined set of actions

132
00:08:17,740 --> 00:08:22,920
and unconstrained, poorly defined utility functions rewards.

133
00:08:24,460 --> 00:08:26,320
This is what human life is about.

134
00:08:26,320 --> 00:08:28,640
This is what we do pretty well most days.

135
00:08:30,440 --> 00:08:36,960
Exist in an undefined, full of uncertainty, world.

136
00:08:38,800 --> 00:08:39,240
So, okay.

137
00:08:39,600 --> 00:08:42,920
We can separate tasks into three different, categories,

138
00:08:43,700 --> 00:08:44,320
formal tasks.

139
00:08:45,060 --> 00:08:45,920
This is the easiest.

140
00:08:47,180 --> 00:08:50,340
It doesn't seem so, it didn't seem so at the birth of artificial intelligence

141
00:08:50,840 --> 00:08:52,480
but that's in fact true if you think about it.

142
00:08:52,860 --> 00:08:54,200
The easiest is the formal tasks,

143
00:08:54,800 --> 00:08:56,800
playing board games, theory improving.

144
00:08:58,040 --> 00:09:02,340
All the kind of mathematical logic problems that can be formally defined.

145
00:09:04,300 --> 00:09:05,980
Then there is the expert tasks.

146
00:09:07,060 --> 00:09:12,080
So this is where a lot of the exciting breakthroughs have been happening

147
00:09:12,720 --> 00:09:14,480
where machine learning methods,

148
00:09:15,120 --> 00:09:16,080
data driven methods,

149
00:09:16,760 --> 00:09:20,060
can help aid or improve on

150
00:09:20,540 --> 00:09:22,060
the performance of our human experts.

151
00:09:22,880 --> 00:09:25,740
This means medical diagnosis, hardware design,

152
00:09:26,340 --> 00:09:26,900
scheduling,

153
00:09:27,740 --> 00:09:30,760
and then there is the thing that we take for granted.

154
00:09:30,760 --> 00:09:31,700
The trivial thing.

155
00:09:31,700 --> 00:09:37,000
The thing that we do so easily every day when we wake up in the morning.

156
00:09:37,880 --> 00:09:39,920
The mundane tasks of everyday speech,

157
00:09:40,580 --> 00:09:41,520
of written language,

158
00:09:42,320 --> 00:09:43,940
of visual perception,

159
00:09:44,880 --> 00:09:49,340
of walking which we'll talk about in today's lecture

160
00:09:49,620 --> 00:09:51,800
is a fascinatingly difficult task

161
00:09:52,960 --> 00:09:54,260
on object manipulation.

162
00:09:55,840 --> 00:09:58,680
So the question is that we're asking here,

163
00:09:59,140 --> 00:10:00,740
before we talk about deep learning,

164
00:10:01,060 --> 00:10:02,940
before we talk about the specific methods,

165
00:10:03,180 --> 00:10:09,260
we really want to dig in and try to see what is it about driving,

166
00:10:11,500 --> 00:10:12,840
how difficult is driving.

167
00:10:14,440 --> 00:10:17,540
Is it more like chess which you see on the left there

168
00:10:17,660 --> 00:10:19,760
where we can formally define a set of lanes,

169
00:10:19,760 --> 00:10:26,040
a set of actions and formulate it as there's five set of actions - you can change your lane,

170
00:10:26,040 --> 00:10:27,360
you can avoid obstacles.

171
00:10:27,800 --> 00:10:30,120
You can formally define an obstacle.

172
00:10:30,120 --> 00:10:32,320
You can the formally define the rules of the road.

173
00:10:33,040 --> 00:10:37,080
Or is there something about natural language,

174
00:10:37,700 --> 00:10:40,300
something similar to everyday conversation about driving

175
00:10:40,620 --> 00:10:43,340
that requires a much higher degree of reasoning,

176
00:10:44,200 --> 00:10:46,200
of communication,

177
00:10:47,580 --> 00:10:48,360
of learning,

178
00:10:49,260 --> 00:10:52,160
of existing in this under-actuated space.

179
00:10:52,580 --> 00:10:55,460
Is it a lot more than just left lane,

180
00:10:55,760 --> 00:10:56,560
right lane,

181
00:10:57,280 --> 00:10:57,660
speed up,

182
00:10:57,880 --> 00:10:58,400
slow down?

183
00:11:00,580 --> 00:11:02,940
So let's look at it as a chess game.

184
00:11:03,340 --> 00:11:04,380
Here's the chess pieces.

185
00:11:05,360 --> 00:11:10,080
What are the sensors we get to work with on an autonomous vehicle?

186
00:11:11,280 --> 00:11:12,880
And we get a lot more in-depth on this

187
00:11:13,260 --> 00:11:14,520
especially with the guest speakers

188
00:11:14,860 --> 00:11:15,820
who built many of these.

189
00:11:17,380 --> 00:11:18,120
There's radar.

190
00:11:18,120 --> 00:11:19,140
There's the Rays sensors.

191
00:11:19,280 --> 00:11:20,280
Radar lidar.

192
00:11:20,860 --> 00:11:24,280
They give you information about the obstacles in their environment.

193
00:11:25,820 --> 00:11:28,140
They'll help localize the obstacles in the environment.

194
00:11:28,780 --> 00:11:30,140
There's the visible light camera

195
00:11:30,680 --> 00:11:34,600
and stereo vision that gives you texture information,

196
00:11:35,180 --> 00:11:38,180
that helps you figure out not just where the obstacles are

197
00:11:38,380 --> 00:11:39,200
but what they are,

198
00:11:39,880 --> 00:11:41,180
helps to classify those,

199
00:11:42,080 --> 00:11:45,300
has to understand their subtle movements.

200
00:11:47,260 --> 00:11:49,660
Then there is the information about the vehicle itself,

201
00:11:50,460 --> 00:11:54,240
about the trajectory and the movement of the vehicle that comes from the GPS

202
00:11:54,560 --> 00:11:55,540
an IMU sensors.

203
00:11:57,040 --> 00:12:00,280
And there is the rich state of the vehicle itself.

204
00:12:00,460 --> 00:12:01,320
What is it doing?

205
00:12:02,240 --> 00:12:04,120
What are all the individual systems doing

206
00:12:04,680 --> 00:12:06,560
that comes from the canned network.

207
00:12:08,120 --> 00:12:11,080
And there is one of the less studied

208
00:12:11,080 --> 00:12:14,640
but fascinating to us on the research side is audio.

209
00:12:15,580 --> 00:12:16,920
The sounds of the road

210
00:12:18,020 --> 00:12:20,160
that provide the rich context

211
00:12:21,400 --> 00:12:22,400
of a wet road.

212
00:12:22,660 --> 00:12:25,340
The sound of a road that when it stop raining

213
00:12:25,800 --> 00:12:26,620
but it's still wet,

214
00:12:27,080 --> 00:12:27,960
the sound that it makes.

215
00:12:30,200 --> 00:12:31,280
The screeching tire

216
00:12:31,640 --> 00:12:32,840
and honking.

217
00:12:33,160 --> 00:12:34,940
These are all fascinating signals as well.

218
00:12:35,620 --> 00:12:38,180
And the focus of the research in our group,

219
00:12:39,200 --> 00:12:40,980
the thing that's really much

220
00:12:42,060 --> 00:12:44,480
under-investigated

221
00:12:44,940 --> 00:12:46,740
is the internal facing sensors.

222
00:12:47,480 --> 00:12:48,200
The driver,

223
00:12:49,280 --> 00:12:52,140
sensing the state of the driver,

224
00:12:52,380 --> 00:12:53,340
were they looking?

225
00:12:53,440 --> 00:12:55,040
Are they sleepy?

226
00:12:55,800 --> 00:12:57,140
The emotional state.

227
00:12:57,380 --> 00:12:58,500
Are they in the seat at all?

228
00:13:00,580 --> 00:13:01,800
And the same with audio.

229
00:13:03,120 --> 00:13:06,300
That comes from the visual information and the audio information.

230
00:13:08,400 --> 00:13:09,060
More than that.

231
00:13:10,340 --> 00:13:11,160
Here are the tasks.

232
00:13:11,460 --> 00:13:13,640
If you were to break into modules the tasks

233
00:13:13,640 --> 00:13:16,280
of what it means to build a self-driving vehicle.

234
00:13:18,040 --> 00:13:19,700
First, you want to know where you are.

235
00:13:19,700 --> 00:13:20,380
Where am I.

236
00:13:21,000 --> 00:13:22,260
Localization and mapping.

237
00:13:22,400 --> 00:13:24,820
You want to map the external environment.

238
00:13:25,920 --> 00:13:27,260
Figure out where all the different

239
00:13:27,260 --> 00:13:29,640
obstacles are,

240
00:13:30,260 --> 00:13:31,260
all the entities are,

241
00:13:31,460 --> 00:13:34,120
and use that estimate of the environment

242
00:13:34,400 --> 00:13:36,260
to then figure out where I am,

243
00:13:36,760 --> 00:13:38,020
where the robot is.

244
00:13:39,140 --> 00:13:40,460
Then there is scene understanding.

245
00:13:42,040 --> 00:13:44,600
It's understanding not just the positional aspects

246
00:13:44,600 --> 00:13:48,200
of the external environment and the dynamics of it

247
00:13:48,820 --> 00:13:51,080
but also what those entities are.

248
00:13:51,420 --> 00:13:52,860
Is it a car?  Is it a pedestrian?

249
00:13:53,240 --> 00:13:53,980
Is it a bird?

250
00:13:56,560 --> 00:13:57,800
There is movement planning.

251
00:13:58,060 --> 00:14:01,560
Once you have kind of figured out to the best of your abilities

252
00:14:02,720 --> 00:14:06,200
your position and the position of other entities in this world,

253
00:14:06,700 --> 00:14:08,980
it's figuring out a trajectory through that world.

254
00:14:10,460 --> 00:14:11,240
And finally,

255
00:14:12,340 --> 00:14:14,980
once you've figured out how to move about safely

256
00:14:14,980 --> 00:14:17,220
and effectively through the world

257
00:14:17,220 --> 00:14:20,540
it's figuring out what the human that's on board is doing

258
00:14:21,360 --> 00:14:22,740
because as I will talk about

259
00:14:23,200 --> 00:14:25,660
the path to a self-driving vehicle

260
00:14:26,400 --> 00:14:28,740
and that is, hence, our focus on Tesla

261
00:14:30,260 --> 00:14:34,440
may go through semi-autonomous vehicles.

262
00:14:35,360 --> 00:14:40,880
Where the vehicle must not only drive itself

263
00:14:40,880 --> 00:14:42,680
but effectively hand over control

264
00:14:43,520 --> 00:14:44,200
from the car

265
00:14:45,640 --> 00:14:46,360
to the human

266
00:14:46,360 --> 00:14:46,800
and back.

267
00:14:49,100 --> 00:14:50,300
Ok, quick history.

268
00:14:51,020 --> 00:14:54,000
Well, there's a lot of fun stuff from the eighty's and ninety's but

269
00:14:57,700 --> 00:15:02,660
the big breakthroughs came in the second DARPA Grand Challenge

270
00:15:03,540 --> 00:15:05,120
with Stanford Stanley,

271
00:15:05,320 --> 00:15:06,520
when they won the competition.

272
00:15:06,520 --> 00:15:08,440
One of five cars that finished.

273
00:15:09,020 --> 00:15:13,700
This was an incredible accomplishment in a desert race.

274
00:15:16,160 --> 00:15:18,720
A fully autonomous vehicle was able to complete the race

275
00:15:20,900 --> 00:15:21,740
in record time.

276
00:15:27,820 --> 00:15:32,000
The DARPA Urban Challenge in 2007

277
00:15:33,240 --> 00:15:37,560
where the task was no longer a race to the desert

278
00:15:38,440 --> 00:15:40,240
but through an urban environment

279
00:15:41,440 --> 00:15:46,560
and CMU's "Boss" with GM won that race

280
00:15:48,920 --> 00:15:52,300
and a lot of that work went directly into the

281
00:15:54,260 --> 00:16:00,640
acceptance and large major industry players

282
00:16:00,640 --> 00:16:02,520
taking on the challenge of building these vehicles.

283
00:16:04,520 --> 00:16:07,940
Google, now "Waymo" self-driving car.

284
00:16:09,120 --> 00:16:13,640
Tesla with its "Autopilot" system and now "Autopilot 2" system.

285
00:16:14,740 --> 00:16:17,380
Uber with its testing in Pittsburgh.

286
00:16:18,960 --> 00:16:20,540
And there's many other companies

287
00:16:20,540 --> 00:16:23,200
including one of the speakers for this course

288
00:16:23,200 --> 00:16:24,020
of nuTonomy

289
00:16:25,000 --> 00:16:29,860
that are driving the wonderful streets of Boston.

290
00:16:32,120 --> 00:16:34,000
Ok.  So let's take a step back.

291
00:16:35,400 --> 00:16:39,540
We have, if we think about the accomplishments in the DARPA Challenge,

292
00:16:40,600 --> 00:16:45,380
and if you look at the accomplishments of the Google self-driving car

293
00:16:46,180 --> 00:16:49,980
which essentially boils the world down into a chess game.

294
00:16:52,800 --> 00:16:56,640
It uses incredibly accurate sensors

295
00:16:57,080 --> 00:16:59,460
to build a three dimensional map of the world,

296
00:16:59,900 --> 00:17:01,880
localize itself effectively in that world

297
00:17:02,100 --> 00:17:03,320
and move about that world

298
00:17:06,220 --> 00:17:08,460
in a very well-defined way.

299
00:17:12,220 --> 00:17:13,700
Now, what if driving...

300
00:17:14,540 --> 00:17:18,640
The open question is:  if driving is more like a conversation,

301
00:17:19,500 --> 00:17:21,220
like in natural language conversation,

302
00:17:22,200 --> 00:17:24,200
how hard is it to pass the Turing Test?

303
00:17:24,900 --> 00:17:25,640
The Turing Test,

304
00:17:26,580 --> 00:17:28,820
as the popular current formulation is,

305
00:17:29,360 --> 00:17:33,080
can a computer be mistaken for a human being

306
00:17:33,080 --> 00:17:34,540
in more than thirty percent of the time?

307
00:17:35,040 --> 00:17:37,620
When a human is talking behind a veil,

308
00:17:38,160 --> 00:17:40,180
having a conversation with their computer or a human,

309
00:17:40,180 --> 00:17:43,880
can they mistake the other side of that conversation

310
00:17:44,880 --> 00:17:47,880
for being a human when it's in fact a computer.

311
00:17:50,880 --> 00:17:55,540
And the way you would, in a natural language,

312
00:17:55,620 --> 00:17:59,780
build a system that has successfully passes the Turing Test is,

313
00:18:00,920 --> 00:18:02,920
the natural language processing part

314
00:18:02,920 --> 00:18:05,240
to enable it to communicate successfully?

315
00:18:05,780 --> 00:18:09,060
So, general language and interpret language,

316
00:18:10,100 --> 00:18:13,300
then you represent knowledge the state of the conversation

317
00:18:13,760 --> 00:18:14,760
transferred over time.

318
00:18:15,960 --> 00:18:18,460
And the last piece and this is the hard piece,

319
00:18:18,760 --> 00:18:20,100
is the automated reasoning,

320
00:18:22,200 --> 00:18:22,980
is reasoning.

321
00:18:24,660 --> 00:18:29,480
Can we teach machine learning methods to reason?

322
00:18:30,220 --> 00:18:33,820
That is something that will propagate through our discussion

323
00:18:34,480 --> 00:18:40,360
because as I will talk about the various methods,

324
00:18:41,020 --> 00:18:42,900
the various deep learning methods,

325
00:18:43,320 --> 00:18:48,080
neural networks are good at learning from data

326
00:18:49,360 --> 00:18:52,780
but they're not yet, there is no good mechanism for reasoning.

327
00:18:54,320 --> 00:18:56,420
Now reasoning could be just something

328
00:18:56,420 --> 00:19:00,200
that we tell ourselves we do to feel special.

329
00:19:00,840 --> 00:19:03,860
Better to feel like we're better than machines.

330
00:19:04,320 --> 00:19:06,160
Reasoning may be simply

331
00:19:06,960 --> 00:19:09,600
something as simple as learning from data.

332
00:19:11,520 --> 00:19:13,100
We just need a larger network.

333
00:19:14,260 --> 00:19:18,040
Or there could be a totally different mechanism required

334
00:19:18,040 --> 00:19:21,460
and we'll talk about the possibilities there.

335
00:19:23,340 --> 00:19:23,540
Yes.

336
00:19:26,400 --> 00:19:33,160
(Inaudible question from one of the attendees)

337
00:19:33,300 --> 00:19:37,260
No, it's very difficult to find these kind of situations in the United States.

338
00:19:37,620 --> 00:19:38,500
So the question was,

339
00:19:38,660 --> 00:19:42,260
for this video, is it in the United States or not?

340
00:19:42,660 --> 00:19:46,720
I believe it's in Tokyo.

341
00:19:47,520 --> 00:20:00,120
So India, as is a few European countries, are much more towards the direction

342
00:20:00,120 --> 00:20:04,600
of natural language versus chess.

343
00:20:05,540 --> 00:20:11,180
In the United States, generally speaking, we follow rules more concretely.

344
00:20:11,340 --> 00:20:13,100
The quality of roads is better.

345
00:20:13,320 --> 00:20:14,840
The marking on the roads is better.

346
00:20:15,240 --> 00:20:17,140
So there's less requirements there.

347
00:20:17,140 --> 00:20:28,960
(Inaudible question from one of the attendees)

348
00:20:28,960 --> 00:20:30,740
These cars are are driving on one side?

349
00:20:36,360 --> 00:20:36,900
I see.

350
00:20:37,660 --> 00:20:40,100
I just-  Okay, you're right.

351
00:20:40,100 --> 00:20:40,840
It is because, yeah-

352
00:20:41,480 --> 00:20:43,800
So, but it's certainly not the United States.

353
00:20:47,080 --> 00:20:48,140
I spent quite a bit of googling

354
00:20:48,380 --> 00:20:51,280
trying to find in the United States and it is difficult.

355
00:20:55,480 --> 00:20:57,080
So let's talk about

356
00:20:59,000 --> 00:21:02,060
the recent breakthroughs in machine learning

357
00:21:02,640 --> 00:21:05,100
and what is at the core of those breakthroughs

358
00:21:06,580 --> 00:21:07,500
is neural networks

359
00:21:09,560 --> 00:21:11,980
that have been around for a long time

360
00:21:12,300 --> 00:21:13,900
and I will talk about what has changed.

361
00:21:14,640 --> 00:21:16,380
What are the cool new things

362
00:21:17,220 --> 00:21:18,380
and what hasn't changed

363
00:21:19,080 --> 00:21:20,380
and what are its possibilities.

364
00:21:20,940 --> 00:21:24,980
But first a neuron, crudely,

365
00:21:26,980 --> 00:21:30,040
is a computational building block of the brain.

366
00:21:30,540 --> 00:21:33,940
I know there's a few folks here, neuroscience folks,

367
00:21:36,280 --> 00:21:38,540
this is hardly a model.

368
00:21:39,700 --> 00:21:42,220
It is mostly an inspiration

369
00:21:43,400 --> 00:21:46,840
and so the human neuron

370
00:21:48,500 --> 00:21:50,680
has inspired the artificial neuron

371
00:21:51,480 --> 00:21:54,040
the computational building block of a neural network,

372
00:21:54,280 --> 00:21:56,120
of an artificial neural network.

373
00:21:57,320 --> 00:21:58,660
I have to give you some context.

374
00:22:01,500 --> 00:22:02,640
These neurons,

375
00:22:02,920 --> 00:22:05,260
for both artificial and human brains,

376
00:22:05,980 --> 00:22:06,920
are interconnected.

377
00:22:08,120 --> 00:22:08,980
And the human brain,

378
00:22:08,980 --> 00:22:16,040
there's about, I believe 10,000 outgoing connections from every neuron

379
00:22:17,720 --> 00:22:21,420
on average and they're interconnected to each other,

380
00:22:23,740 --> 00:22:27,240
are the largest current, as far as I'm aware,

381
00:22:27,980 --> 00:22:33,280
artificial neural network, has 10 billion of those connections.

382
00:22:33,660 --> 00:22:34,220
Synapses.

383
00:22:35,580 --> 00:22:39,580
Our human brain, to the best estimate that I'm aware of,

384
00:22:40,360 --> 00:22:44,860
has 10,000X that.

385
00:22:46,220 --> 00:22:50,740
So one hundred to one thousand trillion synapses.

386
00:22:55,760 --> 00:22:59,220
Now what is an artificial neuron?

387
00:23:00,880 --> 00:23:02,840
That is the building block of a neural network.

388
00:23:04,700 --> 00:23:05,840
It takes a set of inputs.

389
00:23:07,440 --> 00:23:11,540
It puts a weight on each of those inputs, sums them together,

390
00:23:13,160 --> 00:23:18,960
applies a bias value on each neuron

391
00:23:19,720 --> 00:23:21,620
and using an activation function

392
00:23:21,840 --> 00:23:23,620
that takes its input,

393
00:23:25,040 --> 00:23:29,700
that sum plus the bias and it squishes it together

394
00:23:30,380 --> 00:23:32,840
to produce a zero to one signal.

395
00:23:38,860 --> 00:23:41,200
And this allows us a single neuron

396
00:23:43,520 --> 00:23:46,460
to take a few inputs and produces an output

397
00:23:47,180 --> 00:23:50,200
a classification for example, a zero one.

398
00:23:51,500 --> 00:23:56,760
And then we'll talk about, simply, it can

399
00:23:58,160 --> 00:23:59,580
serve as a linear classifier

400
00:24:00,560 --> 00:24:01,900
so it can draw a line.

401
00:24:02,500 --> 00:24:06,820
It can learn to draw a line between, like what you'd seen here,

402
00:24:06,820 --> 00:24:10,460
between the blue dots and the yellow dots.

403
00:24:11,000 --> 00:24:15,340
And that's exactly what we'll do in the iPython Notebook that I'll talk about

404
00:24:17,940 --> 00:24:22,100
but the basic algorithm is you initialize the weights

405
00:24:22,900 --> 00:24:28,800
on the inputs and you compute the output.

406
00:24:30,060 --> 00:24:32,900
You perform this previous operation I talked about sum up

407
00:24:33,840 --> 00:24:34,800
and compute the output.

408
00:24:35,920 --> 00:24:40,440
And if the output does not match the ground truth,

409
00:24:41,700 --> 00:24:44,600
The expected output, the output it should produce,

410
00:24:45,720 --> 00:24:47,480
the weights are punished accordingly

411
00:24:48,840 --> 00:24:51,820
and will talk through a little bit of the math of that.

412
00:24:54,280 --> 00:25:00,420
And this process is repeated until the perceptron does not make any more mistakes.

413
00:25:04,680 --> 00:25:09,720
Now here's the amazing thing about neural networks.

414
00:25:10,300 --> 00:25:12,020
There are several and I'll talk about them.

415
00:25:13,480 --> 00:25:21,480
One on the mathematical side is the universality of neural networks

416
00:25:21,940 --> 00:25:25,640
with just a single layer if you stack them together, a single hidden layer,

417
00:25:27,220 --> 00:25:29,560
the inputs on the left, the outputs on the right.

418
00:25:30,540 --> 00:25:32,840
And in the middle there is a single hidden layer,

419
00:25:33,280 --> 00:25:39,140
it can closely approximate any function.  Any function.

420
00:25:40,640 --> 00:25:42,940
So this is an incredible property

421
00:25:45,540 --> 00:25:51,040
that with a single layer any function you could think of,

422
00:25:52,460 --> 00:25:56,600
that you could think of driving as a function.

423
00:25:56,600 --> 00:25:57,880
It takes its input,

424
00:25:59,360 --> 00:26:01,420
the world outside as output

425
00:26:03,080 --> 00:26:04,160
to control the vehicle.

426
00:26:04,780 --> 00:26:08,720
There exists a neural network out there that can drive perfectly.

427
00:26:09,800 --> 00:26:11,860
It's a fascinating mathematical fact.

428
00:26:17,320 --> 00:26:21,720
So we can think of this then these functions as a special purpose function,

429
00:26:21,980 --> 00:26:23,120
special purpose intelligence.

430
00:26:23,620 --> 00:26:26,040
You can take, say as input,

431
00:26:27,360 --> 00:26:30,120
the number of bedrooms, the square feet,

432
00:26:31,020 --> 00:26:33,820
the type of neighborhood.

433
00:26:34,140 --> 00:26:35,100
Those are the three inputs.

434
00:26:36,380 --> 00:26:40,980
It passes that value through to the hidden layer.

435
00:26:41,700 --> 00:26:42,860
And then one more step.

436
00:26:43,340 --> 00:26:47,780
It produces the final price estimate for the house or for the residence.

437
00:26:49,540 --> 00:26:53,520
And we can teach a network to do this pretty well in a supervised way.

438
00:26:53,680 --> 00:26:54,880
This is supervised learning.

439
00:26:55,600 --> 00:26:57,960
You provide a lot of examples

440
00:26:58,180 --> 00:27:00,840
where you know the number of bedrooms, the square feet,

441
00:27:01,360 --> 00:27:02,440
the type of neighborhood

442
00:27:04,120 --> 00:27:08,620
and then you also know the final price of the house or the residence.

443
00:27:09,560 --> 00:27:14,380
And then you can, as I'll talk about through a process of back propagation,

444
00:27:14,380 --> 00:27:20,220
teach these networks to make this prediction pretty well.

445
00:27:22,420 --> 00:27:25,920
Now some of the exciting breakthroughs recently

446
00:27:27,420 --> 00:27:30,060
have been in the general purpose intelligence.

447
00:27:31,840 --> 00:27:35,840
This is is from Andrej Karpathy who is now at OpenAI.

448
00:27:38,000 --> 00:27:45,420
I would like to take a moment here to try to explain how amazing this is.

449
00:27:46,480 --> 00:27:47,540
This is a game of "pong".

450
00:27:49,340 --> 00:27:53,960
If you're not familiar with "pong", there are two paddles

451
00:27:54,700 --> 00:27:58,220
and you're trying to bounce the ball back

452
00:27:59,480 --> 00:28:05,600
and in such a way that prevents the other guy from bouncing the ball back at you.

453
00:28:10,920 --> 00:28:13,740
The artificial intelligence agent is on the right in green

454
00:28:14,160 --> 00:28:16,760
and up top is the score 8-1.

455
00:28:17,660 --> 00:28:20,500
Now this takes about three days to train

456
00:28:20,960 --> 00:28:22,900
on a regular computer, this network.

457
00:28:23,800 --> 00:28:26,420
What is this network doing?

458
00:28:27,180 --> 00:28:28,280
It's called the Policy Network.

459
00:28:29,060 --> 00:28:31,880
The input is the raw pixels.

460
00:28:33,440 --> 00:28:40,900
There's slightly a process and also you take the difference between two frames

461
00:28:41,320 --> 00:28:43,680
but it's basically the raw pixel information.

462
00:28:44,520 --> 00:28:45,260
That's the input.

463
00:28:46,400 --> 00:28:48,420
There's a few hidden layers

464
00:28:49,100 --> 00:28:52,180
and the output is the single probability of moving up.

465
00:28:54,920 --> 00:29:04,880
That's it.  That's the whole system and what it's doing is, it learns.

466
00:29:06,180 --> 00:29:09,940
You don't know at any one moment,

467
00:29:11,300 --> 00:29:13,100
you don't know what the right thing to do is.

468
00:29:13,620 --> 00:29:15,360
Is it to move up?  Is it's moved down?

469
00:29:15,900 --> 00:29:19,820
You only know what the right thing to do is

470
00:29:20,120 --> 00:29:22,920
by the fact that eventually you win or lose the game.

471
00:29:24,640 --> 00:29:29,620
So this is the amazing thing here is, there's no supervised learning.

472
00:29:30,520 --> 00:29:35,820
There's no universal fact about anyone stay being good or bad.

473
00:29:36,320 --> 00:29:38,580
And anyone actually being good or bad in the state

474
00:29:39,640 --> 00:29:44,000
but if you punish or reward every single action you took,

475
00:29:44,580 --> 00:29:47,920
every single action you took, for an entire game

476
00:29:48,520 --> 00:29:53,240
based on the result. So no matter what you did, if you won the game,

477
00:29:54,080 --> 00:29:55,480
the end justifies the means.

478
00:29:56,640 --> 00:30:03,080
If you won the game, every action you took in every every action state pair gets rewarded.

479
00:30:03,080 --> 00:30:05,240
If you lost the game, it gets punished.

480
00:30:06,600 --> 00:30:10,340
And this process, with only two hundred thousand games

481
00:30:10,740 --> 00:30:17,160
where the system just simulates the games, it can learn to beat the computer.

482
00:30:18,980 --> 00:30:22,880
This system knows nothing about "pong", nothing about games,

483
00:30:24,280 --> 00:30:25,800
this is general intelligence.

484
00:30:27,460 --> 00:30:31,340
Except for the fact, that it's just a game "pong".

485
00:30:32,920 --> 00:30:40,040
And I will talk about how this can be extended further,

486
00:30:40,040 --> 00:30:41,280
why this is so promising

487
00:30:41,980 --> 00:30:47,100
and why we should proceed with caution.

488
00:30:48,580 --> 00:30:53,560
So again, there's a set of actions you take up, down, up, down,

489
00:30:53,560 --> 00:30:54,900
based on the output of the network.

490
00:30:54,900 --> 00:30:57,740
There's a threshold given the probability of moving up,

491
00:30:57,740 --> 00:31:00,240
you move up or down based on the output of the network.

492
00:31:03,300 --> 00:31:04,560
And you have a set of states

493
00:31:06,100 --> 00:31:09,180
and every single state action pair is rewarded if there's a win

494
00:31:09,760 --> 00:31:11,800
and it's punished if there's a loss.

495
00:31:16,700 --> 00:31:21,860
When when you go home, think about how amazing that is

496
00:31:22,160 --> 00:31:24,080
and if you don't understand why that's amazing,

497
00:31:25,240 --> 00:31:26,540
spend some time on it.

498
00:31:27,400 --> 00:31:28,180
It's incredible.

499
00:31:28,780 --> 00:31:35,660
(Inaudible question from one of the attendees)

500
00:31:35,660 --> 00:31:36,500
Sure, sure thing.

501
00:31:36,880 --> 00:31:40,540
The question was:  "What is supervised learning?

502
00:31:40,540 --> 00:31:42,360
What is unsupervised learning?  What's the difference?"

503
00:31:43,140 --> 00:31:45,560
So supervised learning is,

504
00:31:45,560 --> 00:31:48,940
when people talk about machine learning they mean supervised learning most of the time.

505
00:31:49,560 --> 00:31:51,280
Supervised learning is

506
00:31:55,160 --> 00:31:58,640
learning from data, is learning from example.

507
00:31:59,020 --> 00:32:03,740
When you have a set of inputs and a set of outputs that you know are correct or

508
00:32:03,740 --> 00:32:04,540
called Ground Truth.

509
00:32:06,640 --> 00:32:09,740
So you need those examples, a large amount of them,

510
00:32:10,160 --> 00:32:12,520
to train any of the machine learning algorithms

511
00:32:13,060 --> 00:32:17,240
to learn to then generalize that to future examples.

512
00:32:23,880 --> 00:32:31,860
Actually, there's a third one called Reinforcement Learning where the Ground Truth is sparse.

513
00:32:32,780 --> 00:32:37,920
The information about when something is good or not,

514
00:32:37,920 --> 00:32:41,280
the ground truth only happens every once in a while, at the end of the game.

515
00:32:41,780 --> 00:32:42,840
Not every single frame.

516
00:32:43,580 --> 00:32:46,920
And unsupervised learning is when you have no information

517
00:32:47,420 --> 00:32:48,460
about the outputs.

518
00:32:49,280 --> 00:32:51,640
They are correct or incorrect.

519
00:32:54,020 --> 00:33:01,180
And it is the excitement of the deep learning community is unsupervised learning,

520
00:33:02,080 --> 00:33:05,440
but it has achieved no major breakthroughs at this point.

521
00:33:06,720 --> 00:33:09,800
I'll talk about what the future of deep learning is

522
00:33:10,200 --> 00:33:13,540
and a lot of the people that are working in t he field are excited by it.

523
00:33:14,220 --> 00:33:19,640
But right now, any interesting accomplishment has to do with supervised learning.

524
00:33:20,020 --> 00:33:24,980
(Partially inaudible question from one of the attendees)

525
00:33:25,140 --> 00:33:32,460
And the wrong one is just has the [00:33:29] (Inaudible) solution like looking at the philosophy.

526
00:33:33,160 --> 00:33:40,820
So basically, the reinforcement learning here is learning from somebody who has certain hopes

527
00:33:41,680 --> 00:33:48,620
and how can that be guaranteed that it would generalize to somebody else?

528
00:33:52,440 --> 00:33:56,340
So the question was this:

529
00:33:58,280 --> 00:34:01,680
the green paddle learns to play this game successfully

530
00:34:01,680 --> 00:34:06,160
against this specific one brown paddle operating under specific kinds of rules.

531
00:34:06,600 --> 00:34:11,760
How do we know it can generalize to other games, other things and it can't.

532
00:34:13,240 --> 00:34:15,860
But the mechanism by which it learns generalizes.

533
00:34:17,140 --> 00:34:19,120
So as long as you let it play,

534
00:34:23,720 --> 00:34:28,380
as long as you let it play in whatever world you wanted it to succeed in long enough,

535
00:34:29,500 --> 00:34:34,640
it will use the same approach to learn to succeed in that world.

536
00:34:34,640 --> 00:34:38,660
The problem is this works for worlds you can simulate well.

537
00:34:40,500 --> 00:34:45,400
Unfortunately, one of the big challenges of neural networks

538
00:34:45,960 --> 00:34:48,160
is they're not currently efficient learners.

539
00:34:49,200 --> 00:34:50,760
We need a lot of data to learn anything.

540
00:34:51,320 --> 00:34:55,160
Human beings need one example often times

541
00:34:55,640 --> 00:34:57,920
and they learn very efficiently from that one example.

542
00:35:00,840 --> 00:35:04,320
And again I'll talk about that as well, it's a good question.

543
00:35:05,260 --> 00:35:07,720
So the drawbacks of neural networks.

544
00:35:09,320 --> 00:35:12,100
So if you think about the way a human being would approach this game,

545
00:35:12,960 --> 00:35:16,720
this game of "pong", it would only need a simple set of instructions.

546
00:35:17,320 --> 00:35:21,900
You're in control of a paddle and you can move it up and down.

547
00:35:23,020 --> 00:35:27,920
And your task is to bounce the ball past the other player controlled by AI.

548
00:35:30,280 --> 00:35:34,700
Now the human being would immediately, they may not win the game

549
00:35:34,700 --> 00:35:36,740
but they would immediately understand the game

550
00:35:37,240 --> 00:35:39,660
and would be able to successfully play it well enough

551
00:35:40,540 --> 00:35:42,940
to pretty quickly learn to beat the game.

552
00:35:44,340 --> 00:35:46,600
But they would need to have a concept of control.

553
00:35:46,920 --> 00:35:49,880
What it means to control a paddle, need to have a concept of a paddle,

554
00:35:50,160 --> 00:35:52,660
need to have a concept of moving up and down

555
00:35:53,240 --> 00:35:55,540
and a ball and bouncing,

556
00:35:55,540 --> 00:36:00,180
they have to know, they have to have at least a loose concept of real world physics

557
00:36:00,700 --> 00:36:04,640
that they can then project that real world physics on to the two dimensional world.

558
00:36:04,900 --> 00:36:10,000
All of these concepts are concepts that you come to the table with.

559
00:36:10,820 --> 00:36:11,980
That's knowledge.

560
00:36:13,480 --> 00:36:19,760
And the kind of way you transfer that knowledge from your previous experience,

561
00:36:19,760 --> 00:36:23,320
from childhood to now when you come to this game,

562
00:36:24,340 --> 00:36:27,180
that something is called reasoning.

563
00:36:28,440 --> 00:36:29,620
Whatever reasoning means.

564
00:36:31,180 --> 00:36:34,060
And the question is whether through this same kind of process,

565
00:36:35,960 --> 00:36:41,620
you can see the entire world as a game of "pong"

566
00:36:43,280 --> 00:36:50,020
and reasoning is simply the ability to simulate that game in your mind

567
00:36:51,500 --> 00:36:55,720
and learn very efficiently, much more efficiently, than 200,000 innovations.

568
00:36:58,120 --> 00:37:01,920
The other challenge of deep neural networks and machine learning broadly

569
00:37:01,920 --> 00:37:05,340
is you need big data and efficient learners as I said.

570
00:37:06,640 --> 00:37:08,840
And that data also need to be supervised data.

571
00:37:09,140 --> 00:37:15,160
You need to have Ground Truth which is very costly for annotation.

572
00:37:16,860 --> 00:37:19,660
A human being looking at a particular image, for example,

573
00:37:19,660 --> 00:37:23,040
and labeling that as something as a cat or dog,

574
00:37:23,040 --> 00:37:24,940
whatever objects is in the image,

575
00:37:25,320 --> 00:37:26,180
that's very costly.

576
00:37:28,100 --> 00:37:36,160
And particularly for neural networks there's a lot of parameters to tune.

577
00:37:36,900 --> 00:37:38,140
There's a lot of hyper-parameters.

578
00:37:38,820 --> 00:37:41,900
You need to figure out the network structure first.

579
00:37:42,300 --> 00:37:44,140
How does this network look, how many layers?

580
00:37:44,300 --> 00:37:45,160
How many hidden nodes?

581
00:37:48,520 --> 00:37:52,360
What type of activation function for each node?

582
00:37:52,680 --> 00:37:54,180
There's a lot of hyper-parameters there

583
00:37:54,480 --> 00:37:56,040
and then once you've built your network,

584
00:37:57,620 --> 00:38:00,420
there's parameters for how you teach that network.

585
00:38:01,000 --> 00:38:04,780
There's learning rate, loss function - meaning bad size -

586
00:38:05,180 --> 00:38:08,980
number of training iterations, gradient updates moving

587
00:38:09,820 --> 00:38:13,620
and selecting even the optimizer with which

588
00:38:13,620 --> 00:38:19,920
you solve the various differential equations involved.

589
00:38:25,740 --> 00:38:30,040
It's a topic of many research paper, certainly it's rich enough for research papers,

590
00:38:30,400 --> 00:38:31,760
but it's also really challenging.

591
00:38:33,000 --> 00:38:35,080
It means you can't just pop the network down

592
00:38:35,080 --> 00:38:36,700
it will solve the problem generally.

593
00:38:38,360 --> 00:38:42,660
And defining a good lost function,

594
00:38:43,240 --> 00:38:45,280
or in the case of "pong" or games,

595
00:38:45,480 --> 00:38:49,400
a good reward function is difficult.

596
00:38:49,980 --> 00:38:54,640
So here's a game, this is a recent result from OpenAI,

597
00:38:57,720 --> 00:39:03,220
I'm teaching a network to play the game of coast runners.

598
00:39:03,440 --> 00:39:04,840
And the goal of coast runners

599
00:39:07,960 --> 00:39:13,220
is you're in a boat the task is to go around the track

600
00:39:14,800 --> 00:39:18,940
and successfully complete a race against other people you're racing against.

601
00:39:19,920 --> 00:39:23,080
Now this network is an optimal one.

602
00:39:23,920 --> 00:39:27,000
And what is figured out that actually in the game,

603
00:39:29,520 --> 00:39:33,040
it gets a lot of points for collecting certain objects along the path.

604
00:39:33,040 --> 00:39:40,640
So you see it's figured out to go in a circle and collect those those green turbo things.

605
00:39:42,540 --> 00:39:47,320
And what is figured out is you don't need to complete the game to earn the award.

606
00:39:56,880 --> 00:40:01,460
And despite being on fire and hitting the wall and going through this whole process,

607
00:40:01,460 --> 00:40:05,700
it's actually achieved at least the local optima

608
00:40:06,000 --> 00:40:10,060
given the reward function of maximizing the number of points.

609
00:40:11,540 --> 00:40:16,860
And so it's figured out a way to earn a higher reward

610
00:40:16,860 --> 00:40:20,220
while ignoring the implied bigger picture goal of finishing the race

611
00:40:20,580 --> 00:40:24,320
which us as humans understand much better.

612
00:40:26,280 --> 00:40:29,300
This raises, for self-driving cars, ethical questions.

613
00:40:31,320 --> 00:40:33,640
Besides other quick questions.

614
00:40:33,640 --> 00:40:34,320
(CHUCKLING)

615
00:40:34,320 --> 00:40:38,880
We could watch this for hours and it will do that for hours and that's the point:

616
00:40:43,960 --> 00:40:54,400
It's hard to teach, it's hard to encode the formally defined utility function under which

617
00:40:54,400 --> 00:40:56,300
an intelligent system needs to operate.

618
00:40:56,580 --> 00:40:58,780
And that's made obvious even in a simple game.

619
00:40:59,640 --> 00:41:01,480
And so what is -  Yup, question.

620
00:41:01,480 --> 00:41:09,680
(Inaudible question from one of the attendees)

621
00:41:09,680 --> 00:41:14,480
So the question was:  "what's an example of a local optimum that an autonomous car,

622
00:41:14,760 --> 00:41:18,720
similar to the cost racer, what would be the example in the real world for an autonomous vehicle?

623
00:41:19,840 --> 00:41:22,680
And it's a touchy subject.

624
00:41:24,640 --> 00:41:27,100
But it would certainly have to be involved

625
00:41:30,160 --> 00:41:34,480
the choices we make under near crashes and crashes.

626
00:41:35,160 --> 00:41:37,780
The choices a car makes want to avoid.

627
00:41:38,340 --> 00:41:41,120
For example, if there's a crash imminent

628
00:41:41,260 --> 00:41:42,780
and there's no way you can stop

629
00:41:43,780 --> 00:41:47,940
to prevent the crash, do you keep the driver safe

630
00:41:48,200 --> 00:41:50,980
or do you keep the other people safe.

631
00:41:51,880 --> 00:42:03,220
And there has to be some, even if you don't choose to acknowledge it,

632
00:42:03,900 --> 00:42:06,640
even if it's only in the data and the learning that you do,

633
00:42:06,920 --> 00:42:08,820
there's an implied reward function there.

634
00:42:10,160 --> 00:42:12,560
And we need to be aware of that reward function is

635
00:42:12,820 --> 00:42:14,640
because it may find something.

636
00:42:14,880 --> 00:42:17,680
Until you actually see it, we won't know it.

637
00:42:17,680 --> 00:42:23,540
Once we see it, we realize that oh that was a bad design

638
00:42:24,040 --> 00:42:25,140
and that's the scary thing.

639
00:42:25,140 --> 00:42:27,700
It's hard to know ahead of time what that is.

640
00:42:30,840 --> 00:42:38,600
So the recent breakthroughs from deep learning came several factors.

641
00:42:38,600 --> 00:42:41,700
First is the compute, Moore's Law.

642
00:42:42,120 --> 00:42:45,300
CPUs are getting faster, hundred times faster, every decade.

643
00:42:46,940 --> 00:42:48,100
Then there's GPU use.

644
00:42:49,140 --> 00:42:55,080
Also the ability to train neural networks and GPUs and now ASICs

645
00:42:56,380 --> 00:43:02,200
has created a lot of capabilities in terms of energy efficiency

646
00:43:02,680 --> 00:43:07,980
and being able to train larger networks more efficiently.

647
00:43:12,120 --> 00:43:15,660
Well, first of all in the in the 21st Century there's digitized data.

648
00:43:16,380 --> 00:43:18,480
There's larger data sets of digital data

649
00:43:19,360 --> 00:43:23,200
and now there is that data is becoming more organized,

650
00:43:23,200 --> 00:43:27,900
not just vaguely available data out there on the internet,

651
00:43:28,320 --> 00:43:30,960
it's actual organized data sets like Imagenet.

652
00:43:31,440 --> 00:43:34,980
Certainly for natural languages there's large data sets.

653
00:43:36,440 --> 00:43:39,840
There is the algorithm innovations, Backprop.

654
00:43:40,240 --> 00:43:43,380
Back propagation, Convolutional Neural Networks, LSTMs.

655
00:43:43,840 --> 00:43:49,420
All these different architectures for dealing with specific types of domains and tasks.

656
00:43:50,560 --> 00:43:53,780
There is the huge one, is infrastructure.

657
00:43:54,340 --> 00:43:57,020
It's on the software and the hardware side.

658
00:43:57,200 --> 00:44:01,140
There's Git, Ability to Share and Open Source Way software.

659
00:44:02,200 --> 00:44:10,220
There are pieces of software that make robotics and make machine learning easier.

660
00:44:10,640 --> 00:44:12,040
ROS, TensorFlow.

661
00:44:12,780 --> 00:44:15,260
There is Amazon Mechanical Turk

662
00:44:16,640 --> 00:44:21,280
which allows for efficient, cheap annotation of large scale data sets.

663
00:44:22,240 --> 00:44:28,800
As AWS and the cloud hosting, machine learning hosting the data and the compute.

664
00:44:30,280 --> 00:44:34,940
And then there's a financial backing of large companies - Google, Facebook, Amazon.

665
00:44:36,060 --> 00:44:38,680
But really nothing is changed.

666
00:44:39,300 --> 00:44:42,220
There really has not been any significant breakthroughs.

667
00:44:43,800 --> 00:44:46,140
Convolutional networks have been around since the 90s,

668
00:44:46,660 --> 00:44:48,500
neural networks has been around since the 60s.

669
00:44:49,980 --> 00:44:51,840
There's been a few improvements

670
00:44:53,700 --> 00:44:56,920
but the hope is, that's in terms of methodology,

671
00:44:57,940 --> 00:45:00,020
the compute has really been the work horse.

672
00:45:01,040 --> 00:45:05,420
The ability to do the hundred fold improvement every decade,

673
00:45:07,740 --> 00:45:12,000
holds promise and the question is whether that reasoning thing I talked about,

674
00:45:13,580 --> 00:45:15,360
all you need is a larger network.

675
00:45:15,860 --> 00:45:16,860
That is the open question.

676
00:45:19,940 --> 00:45:22,460
Some terms for deep learning.

677
00:45:23,200 --> 00:45:29,740
First of all deep learning, is a PR term for neural networks.

678
00:45:31,660 --> 00:45:38,920
It is a term for utilising  deep neural networks

679
00:45:38,920 --> 00:45:40,660
for neural networks to have many layers.

680
00:45:42,160 --> 00:45:46,600
It is symbolic term for the newly gained capabilities that compute has brought us.

681
00:45:48,240 --> 00:45:50,100
That training on GPUs have brought us.

682
00:45:52,200 --> 00:45:54,320
So deep learning is a subset of machine learning.

683
00:45:54,320 --> 00:45:56,840
There's many other methods that are still effective.

684
00:45:59,020 --> 00:46:04,660
The terms that will come up in this class is, first of all, Multilayer Perceptron (MLP)

685
00:46:05,240 --> 00:46:07,340
Deep neural networks (DNN), Recurrent neural networks (RNN),

686
00:46:07,800 --> 00:46:13,380
LSTM (Long Short-Term Memory) Networks, CNN and ConvNet (Convolutional neural networks),

687
00:46:14,440 --> 00:46:15,340
Deep Belief Networks.

688
00:46:16,180 --> 00:46:21,840
And the operational come up is Convolutional, Pooling, Activation functions and Backpropagation.

689
00:46:25,400 --> 00:46:26,020
Yes, you've got a question?

690
00:46:34,280 --> 00:46:41,200
(Inaudible question from one of the attendees)

691
00:46:49,340 --> 00:46:53,640
So the question was, what is the purpose of the different layers in neural network?

692
00:46:54,120 --> 00:46:56,720
What is the need of one configuration versus another?

693
00:46:57,900 --> 00:47:01,420
So a neural network, having several layers,

694
00:47:02,900 --> 00:47:08,340
it's the only thing you have an understanding of, is the inputs and the outputs.

695
00:47:09,500 --> 00:47:12,740
You don't have a good understanding about what these layer does.

696
00:47:14,280 --> 00:47:16,740
They are mysterious things, neural networks.

697
00:47:17,800 --> 00:47:21,520
So I'll talk about how, with every layer, it forms a higher level.

698
00:47:23,360 --> 00:47:26,540
A higher order representation of the input.

699
00:47:27,020 --> 00:47:30,040
So it's not like the first layer does localization,

700
00:47:30,040 --> 00:47:31,680
the second layer does path planning,

701
00:47:32,120 --> 00:47:36,960
the third layer does navigation - how you get from here to Florida -

702
00:47:37,620 --> 00:47:40,860
or maybe it does, but we don't know.

703
00:47:42,360 --> 00:47:47,440
So we know we're beginning to visualize neural networks for simple tasks

704
00:47:48,080 --> 00:47:51,020
like for ImageNet classifying cats versus dogs.

705
00:47:51,620 --> 00:47:56,040
We can tell what is the thing that the first layer does, the second layer, the third layer

706
00:47:56,440 --> 00:47:57,100
and we look at that.

707
00:47:57,560 --> 00:48:02,600
But for driving, as the input provide just the images the output the steering.

708
00:48:03,480 --> 00:48:05,140
It's still unclear what you learned

709
00:48:07,180 --> 00:48:10,100
partially because we don't have neural networks that drive successfully yet.

710
00:48:11,820 --> 00:48:12,360
(Points to a member of the class)

711
00:48:15,220 --> 00:48:18,880
(Inaudible question)

712
00:48:21,180 --> 00:48:31,240
So the question was, does a neural network generate layers over time, like does it grow it?

713
00:48:33,760 --> 00:48:38,160
That's one of the challenges, that a neural network is pre-defined.

714
00:48:38,160 --> 00:48:41,640
The architecture, the number of nodes, the number of layers. 
That's all fixed.

715
00:48:42,560 --> 00:48:46,060
Unlike the human brain where the neurons die and are born all the time.

716
00:48:46,820 --> 00:48:49,740
A neural Network is pre-specified, that's it.

717
00:48:49,740 --> 00:48:52,240
That's all you get and if you want to change that,

718
00:48:52,240 --> 00:48:54,100
you have to change that and then retrain everything.

719
00:48:55,160 --> 00:48:55,680
So it's fixed.

720
00:48:57,980 --> 00:49:00,800
So what I encourage you is to proceed with caution

721
00:49:01,240 --> 00:49:06,920
because there's this feeling when you first teach a network with very little effort,

722
00:49:07,660 --> 00:49:13,560
how to do some amazing tasks like classify a face versus non-face,

723
00:49:13,560 --> 00:49:18,120
or  your face versus other faces or cats versus dogs, its an incredible feeling.

724
00:49:19,760 --> 00:49:23,620
And then there's definitely this feeling that I'm an expert

725
00:49:24,940 --> 00:49:31,460
but what you realize is we don't actually understand how it works.

726
00:49:32,580 --> 00:49:35,740
And getting it to perform well for more generalized task,

727
00:49:36,020 --> 00:49:38,660
for larger scale data sets, for more useful applications,

728
00:49:39,160 --> 00:49:41,160
requires a lot of hyper-parameter tuning.

729
00:49:41,660 --> 00:49:43,900
Figuring out how to tweak little things here and there

730
00:49:44,280 --> 00:49:48,020
and still in the end, you don't understand why it work so damn well.

731
00:49:52,640 --> 00:49:59,060
So deep learning, these deep neural network architectures is representation learning.

732
00:50:00,860 --> 00:50:05,020
This is the difference between traditional machine learning methods where,

733
00:50:09,340 --> 00:50:14,500
for example, for the task of having an image here is the input.

734
00:50:14,800 --> 00:50:18,160
The input to the network here is on the bottom, the output up on top,

735
00:50:19,080 --> 00:50:24,680
and the input is a single image of a person in this case.

736
00:50:26,840 --> 00:50:33,520
And so the input, specifically, is all the pixels in that image.

737
00:50:33,900 --> 00:50:37,260
RGB, the different colors of the pixels in the image.

738
00:50:38,740 --> 00:50:47,960
And over time, what a network does is build a multiverse solutional representation of this data.

739
00:50:48,580 --> 00:50:55,320
The first layer learns the concept of edges, for example.

740
00:50:56,140 --> 00:51:01,080
The second layer starts to learn composition of those edges, corners, contours.

741
00:51:02,140 --> 00:51:05,600
Then it starts to learn about object parts.

742
00:51:06,620 --> 00:51:12,480
And finally, actually provide a label for the entities that are in the input.

743
00:51:14,240 --> 00:51:16,640
And this is the difference in traditional machine learning methods

744
00:51:17,200 --> 00:51:22,460
where the concepts like edges and corners and contours

745
00:51:23,040 --> 00:51:30,820
are manually pre-specified by human beings, human experts, for that particular domain.

746
00:51:35,400 --> 00:51:42,940
And representation matters because figuring out a line

747
00:51:43,640 --> 00:51:46,480
for the Cartesian coordinates of this particular data set

748
00:51:47,060 --> 00:51:49,260
where you want to design a machine learning system

749
00:51:49,780 --> 00:51:54,640
that tells the difference between green triangles and blue circles is difficult.

750
00:51:55,620 --> 00:51:57,660
There is no line that separates them cleanly.

751
00:52:00,000 --> 00:52:04,120
And if you were to ask a human being, a human expert in the field.

752
00:52:04,380 --> 00:52:12,360
to try to draw that line they would probably do a Ph. D. on it and still not succeed.

753
00:52:13,900 --> 00:52:17,260
But a neural network can automatically figure out

754
00:52:18,400 --> 00:52:22,900
to remap that input into polar coordinates

755
00:52:23,460 --> 00:52:28,680
where the representation is such that it's an easily, linearly separable data set.

756
00:52:32,600 --> 00:52:36,800
And so, deep learning is a subset of representation learning,

757
00:52:37,000 --> 00:52:41,520
is a subset of machine learning and a key subset artificial intelligence.

758
00:52:45,320 --> 00:52:47,600
Now, because of this,

759
00:52:48,720 --> 00:52:53,480
because of its ability to compute an arbitrary number of features

760
00:52:54,200 --> 00:52:55,820
that are at the core of the representation.

761
00:52:57,160 --> 00:52:59,560
So if you are trying to detect a cat in an image,

762
00:53:00,600 --> 00:53:08,120
you're not specifying 215 specific features of cat ears and whiskers and so on

763
00:53:08,560 --> 00:53:12,060
that a human expert will specify you allow and you'll know

764
00:53:12,060 --> 00:53:14,220
it discover tens of thousands of such features,

765
00:53:15,460 --> 00:53:17,880
which maybe for cats you are an expert

766
00:53:17,880 --> 00:53:24,960
but for a lot of objects you may never be able to sufficiently provide the features

767
00:53:24,960 --> 00:53:27,700
which successfully will be used for identifying the object.

768
00:53:28,440 --> 00:53:30,700
And so, this kind of representation learning,

769
00:53:31,240 --> 00:53:35,600
one is easy in the sense that all you have to provide is inputs and outputs.

770
00:53:36,320 --> 00:53:40,800
All you need to provide is a data set the care about without [00:53:39] features.

771
00:53:41,960 --> 00:53:49,200
And two, because of it's ability to construct arbitrarily sized representations,

772
00:53:50,200 --> 00:53:52,320
deep neural networks are hungry for data.

773
00:53:52,780 --> 00:53:54,860
The more data we give them,

774
00:53:55,560 --> 00:53:59,040
the more they are able to learn about this particular data set.

775
00:54:03,200 --> 00:54:06,220
So let's look at some applications.

776
00:54:08,800 --> 00:54:13,900
First, some cool things that deep neural networks have been able to accomplish up to this point.

777
00:54:14,260 --> 00:54:15,100
Let me go through them.

778
00:54:16,240 --> 00:54:17,380
First, the basic one.

779
00:54:19,500 --> 00:54:30,420
AlexNet is for-  ImageNet is a famous data set and a competition of classification,

780
00:54:30,420 --> 00:54:34,220
localization where the task is given an image,

781
00:54:34,480 --> 00:54:38,120
identify what are the five most likely things in that image

782
00:54:38,600 --> 00:54:41,400
and what is the most likely and you have to do so correctly.

783
00:54:41,720 --> 00:54:43,860
So on the right, there's an image of a leopard

784
00:54:44,100 --> 00:54:47,020
and you have to correctly classify that that is in fact the leopard.

785
00:54:48,300 --> 00:54:52,100
So they're able to do this pretty well given a specific image.

786
00:54:53,740 --> 00:54:55,240
Determine that it's a leopard.

787
00:54:56,860 --> 00:55:01,740
And we started, what's shown here on the x-axis is years

788
00:55:02,140 --> 00:55:04,880
on the y-axis is error in classification.

789
00:55:05,840 --> 00:55:11,120
So starting from 2012 on the left with AlexNet and today

790
00:55:14,480 --> 00:55:21,840
the errors decreased from 16% and 40% before then with traditional methods

791
00:55:22,280 --> 00:55:24,220
have decreased to <4%.

792
00:55:24,640 --> 00:55:25,980
So human level performance,

793
00:55:25,980 --> 00:55:29,940
if I were to give you this picture of a leopard

794
00:55:30,320 --> 00:55:35,740
is a 4% of those pictures of leopards you would not say it's a leopard.

795
00:55:36,240 --> 00:55:37,540
That's human level performance.

796
00:55:37,920 --> 00:55:43,220
So for the first time in 2015, convolutional neural networks are performed human beings.

797
00:55:43,840 --> 00:55:47,920
That in itself is incredible.  That is something that seemed impossible.

798
00:55:48,500 --> 00:55:53,100
And now is because it's done is not as impressive.

799
00:55:55,740 --> 00:55:58,780
But I just want to get to why this is so impressive

800
00:55:59,420 --> 00:56:02,520
because computer vision is hard.

801
00:56:03,200 --> 00:56:06,920
Now we as human beings have evolved visual perception over millions of years,

802
00:56:07,240 --> 00:56:08,240
hundreds of millions of years.

803
00:56:10,240 --> 00:56:15,200
So we take it for granted but computer vision is really hard, visual perception is really hard.

804
00:56:15,560 --> 00:56:17,040
There's illumination variability.

805
00:56:17,300 --> 00:56:18,440
So it's the same object.

806
00:56:19,120 --> 00:56:23,520
The only way we are telling you a thing is from the shade, the reflection of light from that surface.

807
00:56:24,980 --> 00:56:28,320
It could be the same object with drastically, in terms of pixels,

808
00:56:28,320 --> 00:56:34,160
drastically different looking shapes and we still know it's the same object.

809
00:56:35,540 --> 00:56:37,760
There is post-variability in occlusion.

810
00:56:38,600 --> 00:56:41,140
Probably my favorite caption for an image

811
00:56:42,460 --> 00:56:46,880
for a figure in a academic paper is deformable and truncated cat.

812
00:56:48,800 --> 00:56:54,680
These are pictures, you know cats are famously deformable.

813
00:56:54,800 --> 00:56:56,340
They can take a lot of different shapes.

814
00:56:56,340 --> 00:56:58,100
(LAUGHTER)

815
00:56:59,540 --> 00:57:06,420
Its arbitrary poses are possible so you have to have computer vision

816
00:57:06,420 --> 00:57:09,640
to know it's still the same objects, still the same class of objects,

817
00:57:10,260 --> 00:57:15,660
given all the variability in the pose and occlusions is a huge problem.

818
00:57:16,040 --> 00:57:17,460
We still know it's an object.

819
00:57:18,240 --> 00:57:21,080
We still know it's a cat even when parts of it are not visible.

820
00:57:21,480 --> 00:57:23,400
And sometimes large parts of it are not visible.

821
00:57:24,900 --> 00:57:27,180
And then there's all the inter-class variability.

822
00:57:28,420 --> 00:57:32,020
Inter-class, all of these on the top two rows are cats.

823
00:57:32,840 --> 00:57:34,520
Many of them look drastically different.

824
00:57:35,200 --> 00:57:39,860
And the top bottom two rows are dogs also look drastically different.

825
00:57:40,820 --> 00:57:43,180
And yet some of the dogs look like cats,

826
00:57:43,740 --> 00:57:45,180
some of the cats look like dogs.

827
00:57:45,880 --> 00:57:48,640
And as human beings are pretty good at telling the difference

828
00:57:49,060 --> 00:57:51,940
and we want computer vision to do better than that.

829
00:57:53,260 --> 00:57:58,680
It's hard.  So how is this done?  This is done with convolutional neural networks.

830
00:57:59,340 --> 00:58:00,980
The input to which is a raw image.

831
00:58:01,440 --> 00:58:05,520
Here's an input on the left of a number three

832
00:58:07,020 --> 00:58:10,400
and I'll talk about through convolutional layers

833
00:58:12,040 --> 00:58:15,840
that image is processed past through convolutional layers

834
00:58:16,560 --> 00:58:19,300
maintain spatial information.

835
00:58:21,740 --> 00:58:28,420
On the output, in this case predicts which of the images

836
00:58:28,420 --> 00:58:31,060
what number is shown in the image.

837
00:58:31,060 --> 00:58:33,060
0, 1, 2 through 9.

838
00:58:34,940 --> 00:58:41,900
And so, these networks, everybody's using the same kind of network to determine exactly that.

839
00:58:41,900 --> 00:58:43,740
Input is an image, output is a number.

840
00:58:44,640 --> 00:58:49,420
And in the case of probability, that is a leopard.  What is that number?

841
00:58:50,600 --> 00:58:54,160
Then there is segmentation built on top of these convolution neural networks

842
00:58:54,600 --> 00:59:00,620
where you chop off the end and convolutionise the network.

843
00:59:00,620 --> 00:59:02,940
You chop off the end where the output is a heat map.

844
00:59:04,000 --> 00:59:10,420
So you can have, instead of a detector for a cat, you can do a cat heat map

845
00:59:11,120 --> 00:59:16,240
where it's the part of the image, the output heat map gets excited,

846
00:59:16,680 --> 00:59:18,960
the neurons in that output get excited

847
00:59:19,360 --> 00:59:24,740
in the spatially excited, in the parts of the image that contain a tabby cat.

848
00:59:25,880 --> 00:59:31,080
And this kind of process can be used to segment the image into different objects, a horse.

849
00:59:31,080 --> 00:59:33,820
So the original input on the left is a woman on a horse

850
00:59:33,820 --> 00:59:39,460
and the output is a fully segmented image of knowing where is the woman, where is the horse.

851
00:59:41,760 --> 00:59:44,720
And this kind of process can be used for object detection

852
00:59:44,880 --> 00:59:47,600
which is the task of detecting an object in an image.

853
00:59:49,180 --> 00:59:52,760
Now the traditional method with convolutional neural networks

854
00:59:53,240 --> 00:59:56,800
and in general computer vision is the sliding window approach.

855
00:59:57,200 --> 01:00:01,260
We have a detector, like the leopard detector, where you slide through the image

856
01:00:01,460 --> 01:00:03,520
to find where in that image is the leopard.

857
01:00:06,300 --> 01:00:08,680
This, the segmenting approach,

858
01:00:09,380 --> 01:00:13,500
the R-CNN approach, is efficiently segmenting the image

859
01:00:13,500 --> 01:00:16,380
in such a way that it can propose different parts of the image

860
01:00:16,840 --> 01:00:20,060
that are likely to have a leopard, or in this case a cowboy,

861
01:00:22,240 --> 01:00:27,340
and that drastically reduces the computational requirements of the object detection task.

862
01:00:32,400 --> 01:00:41,000
And so these networks, this is currently one of the best networks for the ImageNet task of localization

863
01:00:41,280 --> 01:00:52,140
is the Deep residual networks.  They're deep.  So VGG-19 is one of the famous ones.

864
01:00:55,500 --> 01:00:59,060
You started to get above twenty layers in many cases,

865
01:00:59,540 --> 01:01:01,940
thirty four layers is the rise in that one.

866
01:01:03,940 --> 01:01:09,180
So the lesson there is, the deeper you go the more representation power you have,

867
01:01:09,180 --> 01:01:12,620
the higher accuracy but you need more data.

868
01:01:16,780 --> 01:01:19,420
Other applications, colorization of images.

869
01:01:21,560 --> 01:01:29,000
So this again, input is a single image and output is a single image.

870
01:01:30,120 --> 01:01:35,720
So you can take a black and white video from a film, from an old film,

871
01:01:36,000 --> 01:01:41,260
and recolor it.  And all you need to do to train that network in the supervised way

872
01:01:41,500 --> 01:01:45,700
is provide modern films and convert them to grayscale.

873
01:01:46,180 --> 01:01:53,860
So now you have arbitrarily sized data sets, data sets of gray scale to color.

874
01:01:56,380 --> 01:02:02,720
And you're able to, with very little effort on top of it, to successfully

875
01:02:03,220 --> 01:02:05,220
well, somewhat successful recolor images.

876
01:02:07,280 --> 01:02:11,980
Again, Google Translate does image translation in this way, image to image.

877
01:02:12,880 --> 01:02:19,520
It first perceives, here in German I believe, famous German correct me if I'm wrong,

878
01:02:19,520 --> 01:02:21,900
dark chocolate written in German on a box.

879
01:02:22,720 --> 01:02:27,740
So this can take this image, detect different letters convert them to text,

880
01:02:28,180 --> 01:02:32,140
translate the text and then using the image to image mapping

881
01:02:34,680 --> 01:02:41,560
map the letters, the translated letters, back onto the box and you could do this in real time on video.

882
01:02:45,500 --> 01:02:50,020
So what we've talked about up to this point on the left are "vanilla" neural networks,

883
01:02:50,720 --> 01:02:54,840
convolutional neural networks, that map a single input, a single output,

884
01:02:54,980 --> 01:02:58,540
a single image to a number, single image another image.

885
01:02:59,540 --> 01:03:01,660
Then there is recurrent neural networks, the map.

886
01:03:02,220 --> 01:03:03,960
This is the more general formulation,

887
01:03:03,960 --> 01:03:05,440
they map a sequence of images

888
01:03:05,980 --> 01:03:07,260
or a sequence of words

889
01:03:07,760 --> 01:03:10,580
or a sequence of any kind to another sequence.

890
01:03:12,680 --> 01:03:17,020
And these networks are able to do incredible things with natural language,

891
01:03:17,780 --> 01:03:22,080
with video, and any type of series of data.

892
01:03:22,180 --> 01:03:30,260
For example, you can convert text to hand written digits, with hand written text.

893
01:03:31,360 --> 01:03:37,160
Here, you type in and you can do this online, type in deep learning for self-driving cars

894
01:03:37,500 --> 01:03:44,400
and it will use an arbitrary handwriting style to generate the words "deep learning for self-driving cars".

895
01:03:45,940 --> 01:03:47,760
This is done using recurring neural networks.

896
01:03:49,440 --> 01:03:57,160
We can also take Char-RNNs they're called, it's character level recurring neural networks

897
01:03:57,720 --> 01:03:59,460
that train on a data set

898
01:04:01,020 --> 01:04:09,060
an arbitrary text data set and learn to generate text one character at a time.

899
01:04:10,180 --> 01:04:16,180
So there is no preconceived syntactical semantic structure that's provided to the network.

900
01:04:16,640 --> 01:04:17,720
It learns that structure.

901
01:04:19,360 --> 01:04:25,180
So for example, you can train it on Wikipedia articles like in this case.

902
01:04:25,960 --> 01:04:35,380
And it's able to generate successfully not only text that makes some kind of grammatical sense at least

903
01:04:36,500 --> 01:04:43,600
but also keep perfect syntactic structure for Wikipedia, for Markdown, editing,

904
01:04:43,860 --> 01:04:45,840
for late tack editing and so on.

905
01:04:47,260 --> 01:04:53,040
This text as "naturalism and decision for the majority of Arab countries capitalide."

906
01:04:53,480 --> 01:04:57,860
Whatever that means, "was grounded by the Irish language by John Clare," and so on.

907
01:04:58,480 --> 01:05:03,140
These are sentences. If you didn't know better, that might sound correct.

908
01:05:03,640 --> 01:05:12,720
And it does so and you pause one character at a time so these aren't words being generated.

909
01:05:13,280 --> 01:05:17,360
This is one character, you start with the beginning three letters "nat",

910
01:05:18,580 --> 01:05:23,900
you generate "u" completely without knowing of the word naturalism.

911
01:05:25,780 --> 01:05:26,740
This is incredible.

912
01:05:28,980 --> 01:05:35,660
You can do this to start a sentence and let the neural network complete that sentence.

913
01:05:36,500 --> 01:05:42,040
So for example if you start the sentence with "life is" or "life is about" actually,

914
01:05:43,820 --> 01:05:49,760
it will complete it with a lot of fun things.  "The weather."  "Life is about kids."

915
01:05:51,160 --> 01:05:56,900
"Life is about the true love of Mr Mom", "is about the truth now."

916
01:05:57,740 --> 01:06:01,180
And this is from [01:05:59], the last two,

917
01:06:01,420 --> 01:06:05,040
if you start with "the meaning of life," it can complete that with

918
01:06:05,040 --> 01:06:09,640
"the meaning of life is literary recognition" may be true for some of us here.

919
01:06:12,520 --> 01:06:13,380
Publish or perish.

920
01:06:14,700 --> 01:06:18,660
And "the meaning of life is the tradition of ancient human reproduction."

921
01:06:18,840 --> 01:06:19,960
(LAUGHTER)

922
01:06:20,360 --> 01:06:22,560
Also true for some of us here.  I'm sure.

923
01:06:25,700 --> 01:06:27,160
Okay, so what else can you do?

924
01:06:27,160 --> 01:06:33,100
You can, this has been very exciting recently is image capture recognition.  No, generation, I'm sorry.

925
01:06:34,020 --> 01:06:41,200
Image capture generation is important for large data sets of images.

926
01:06:41,500 --> 01:06:45,020
What we want to be able to determine what's going on inside those images.

927
01:06:45,600 --> 01:06:50,500
Specially for search, if you want to find a man sitting in a college with a dog,

928
01:06:50,780 --> 01:06:53,380
you type it into Google and it's able to find that.

929
01:06:55,620 --> 01:07:02,360
So here shown in black text a man sitting on a couch with a dog is generated by the system.

930
01:07:02,700 --> 01:07:07,240
A man sitting in a chair with a dog in his lap is generated by a human observer.

931
01:07:08,100 --> 01:07:12,720
And again these annotations are done by detecting the different obstacles,

932
01:07:12,720 --> 01:07:15,060
the different objects in the scene.

933
01:07:15,760 --> 01:07:20,540
So segmenting the scene detecting on the right there's a woman, a crowd, a cat,

934
01:07:20,540 --> 01:07:22,720
a camera, holding, purple.

935
01:07:23,100 --> 01:07:29,300
All of these words are being detected then a syntactically correct sentence is generated,

936
01:07:29,880 --> 01:07:32,920
a lot of them, and then you order which sentence is the most likely.

937
01:07:33,420 --> 01:07:38,260
And in this way you can generate very accurate labeling of the images,

938
01:07:40,580 --> 01:07:41,720
captions for the images.

939
01:07:42,140 --> 01:07:47,600
And you can do the same kind of process for image question answering.

940
01:07:49,420 --> 01:07:52,960
You can ask how many for quantity, how many chairs are there?

941
01:07:54,980 --> 01:07:59,340
You can ask about location, where are the ripe bananas?

942
01:08:01,040 --> 01:08:02,580
You can ask about the type of object.

943
01:08:03,100 --> 01:08:05,420
What is the object in the chair?  It's a pillow.

944
01:08:08,940 --> 01:08:11,000
And these are, again, using the recurring neural networks.

945
01:08:15,040 --> 01:08:20,120
You could do the same thing with video captions generation,

946
01:08:20,620 --> 01:08:22,980
video captions description generation.

947
01:08:23,520 --> 01:08:26,400
So looking at a sequence of images as opposed to just a single image.

948
01:08:27,180 --> 01:08:30,200
What is the action going on in this situation?

949
01:08:30,760 --> 01:08:34,700
This is the difficult task.  There's a lot of work in it, in this area.

950
01:08:35,460 --> 01:08:38,980
On the left is correct descriptions of a man is do stunts on his bike

951
01:08:39,540 --> 01:08:42,600
or a herd a zebra are walking in the field and on the right,

952
01:08:43,220 --> 01:08:45,240
there's a small bus running into a building.

953
01:08:45,960 --> 01:08:53,580
You know it's talking about relevant entities but just doing an incorrect description.

954
01:08:54,160 --> 01:08:59,440
A man is cutting a piece of a pair of a paper.

955
01:09:02,600 --> 01:09:11,060
So the words are correct.  Perhaps, but so you're close, but mostly are.

956
01:09:11,660 --> 01:09:13,240
One of the interesting things 

957
01:09:16,840 --> 01:09:18,840
you can do with a recurring neural networks

958
01:09:19,520 --> 01:09:22,800
is if you think about the way we look at images, human beings look at images,

959
01:09:23,280 --> 01:09:30,360
is we only have a small phobia with which we focus in a scene.

960
01:09:30,720 --> 01:09:33,600
So right now you're periphery is very distorted.

961
01:09:33,600 --> 01:09:37,440
The only thing, if you're looking at the slides, you're looking at me

962
01:09:38,000 --> 01:09:39,400
that's the only thing that's in focus.

963
01:09:40,280 --> 01:09:42,640
Majority of everything else is out of focus.

964
01:09:43,360 --> 01:09:47,560
So we can use the same kind of concept to try to teach a neural network to steer around the image.

965
01:09:48,240 --> 01:09:51,100
Both for perception and generation of those images.

966
01:09:51,720 --> 01:09:55,860
This is important first on the general artificial intelligence point

967
01:09:56,500 --> 01:10:02,880
of it being just fascinating that we can selectively steer our attention

968
01:10:03,260 --> 01:10:05,200
but also it's important for things like drones.

969
01:10:05,640 --> 01:10:08,320
They have to fly at high speeds in an environment

970
01:10:08,320 --> 01:10:11,960
where three hundred plus frames a second, you have to make decisions.

971
01:10:12,540 --> 01:10:17,520
So you can't possibly localize yourself or perceive the world around yourself successfully

972
01:10:18,720 --> 01:10:20,380
if you have to interpret the entire scene.

973
01:10:20,980 --> 01:10:28,700
So we can do is you can steer, for example here shown, is reading a house number

974
01:10:29,700 --> 01:10:32,000
by steering around an image.

975
01:10:34,700 --> 01:10:37,800
You can do the same task for reading and for writing.

976
01:10:38,440 --> 01:10:42,880
So reading numbers here, and this data set on the left, is reading numbers.

977
01:10:43,320 --> 01:10:51,120
We can also selectively steer a network around an image to generate that image

978
01:10:51,900 --> 01:10:57,940
starting with a blurred image first and then getting more and more higher resolution

979
01:10:58,480 --> 01:10:59,800
as the steering goes on.

980
01:11:02,280 --> 01:11:10,120
Work here at MIT is able to map video to audio.

981
01:11:11,560 --> 01:11:18,120
So head stuff for the drumstick silent video and able to generate the sound

982
01:11:18,840 --> 01:11:22,160
that would drumstick hitting that particular object makes.

983
01:11:23,740 --> 01:11:28,040
So you can get texture information from that impact.

984
01:11:32,820 --> 01:11:38,620
So here is the video of a human soccer player playing soccer

985
01:11:39,260 --> 01:11:44,940
and a state-of-the-art machine playing soccer.

986
01:11:48,860 --> 01:11:51,260
And, well let me give it some time,

987
01:11:51,940 --> 01:11:52,580
to build up.

988
01:11:59,180 --> 01:12:03,480
(LAUGHTER)

989
01:12:03,480 --> 01:12:10,320
Okay.  So soccer, we take this for granted, but walking is hard.

990
01:12:11,300 --> 01:12:17,340
Object manipulation is hard.  Soccer is harder than chess for us to do much harder.

991
01:12:18,160 --> 01:12:26,280
On your phone now, you can have a chess engine that beats the best players in the world.

992
01:12:28,800 --> 01:12:32,200
And you have to internalize that because the question is,

993
01:12:32,700 --> 01:12:37,380
this is a painful video, the question is:  where does driving fall?

994
01:12:37,980 --> 01:12:40,840
Is it closer to chess or is it closer soccer?

995
01:12:42,040 --> 01:12:46,820
For those incredible, brilliant engineers that worked on the most recent DARPA challenge

996
01:12:47,280 --> 01:12:51,000
this would be a very painful video to watch, I apologize.

997
01:12:53,420 --> 01:12:55,680
This is a video from the DARPA Challenge

998
01:12:56,460 --> 01:12:57,940
(LAUGHTER)

999
01:12:58,120 --> 01:13:00,260
of robots  struggling

1000
01:13:01,640 --> 01:13:06,680
with basic object manipulation and walking tasks.

1001
01:13:09,340 --> 01:13:14,340
So it's mostly a fully autonomous navigation task.

1002
01:13:14,340 --> 01:13:15,080
(LAUGHTER)

1003
01:13:24,060 --> 01:13:32,320
Maybe I'll just let this play for a few moments to let it internalize how difficult this task is,

1004
01:13:33,780 --> 01:13:38,080
of balancing, of planning in an underactuated way.

1005
01:13:38,080 --> 01:13:39,760
We don't have full control of everything.

1006
01:13:40,320 --> 01:13:47,580
When there is a delta between your perception of what you think the world is and what reality is.

1007
01:13:48,640 --> 01:13:54,860
So there, a robot was trying to turn an object that wasn't there.

1008
01:13:59,100 --> 01:14:03,460
And this is an MIT entry that actually successfully, I believe, gotten points for this

1009
01:14:03,460 --> 01:14:07,640
because it got into that area

1010
01:14:07,880 --> 01:14:11,560
(LAUGHTER)

1011
01:14:11,960 --> 01:14:17,260
but as a lot of the teams talked about the hardest part,

1012
01:14:17,260 --> 01:14:23,060
So one of the things the robot had to do is get into a car and drive it and get out of the car.

1013
01:14:23,760 --> 01:14:28,180
And there's a few other manipulation task like walking on unsteady ground,

1014
01:14:28,360 --> 01:14:30,140
it had to drill a hole through a wall.

1015
01:14:30,520 --> 01:14:36,520
All these tasks and what a lot of teams said is the hardest part, the hardest task of all of them,

1016
01:14:36,820 --> 01:14:38,180
is getting out of the car.

1017
01:14:39,180 --> 01:14:44,560
So it's not getting into the car, it's this very task you saw now is the robot getting out of the car.

1018
01:14:44,700 --> 01:14:46,140
These are things we take for granted.

1019
01:14:47,820 --> 01:14:50,740
So in our evaluation of what is difficult about driving,

1020
01:14:50,740 --> 01:14:55,920
we have to remember that some of those things we may take for granted

1021
01:14:55,920 --> 01:15:04,520
in the same kind of way that we take walking for granted, this is more of X paradox.

1022
01:15:06,340 --> 01:15:11,280
Will Hans Moravec from CMU, let me just quickly read that quote:

1023
01:15:11,280 --> 01:15:15,080
"Encoded in the large highly evolved sensory motor portions of the human brain

1024
01:15:15,420 --> 01:15:20,580
is billions of years of experience about the nature of the world and how to survive in it."

1025
01:15:20,960 --> 01:15:28,260
So this is data.  This is big data.  Billions of years and abstract thought which is reasoning.

1026
01:15:29,180 --> 01:15:32,600
The stuff we think is intelligence is perhaps

1027
01:15:32,600 --> 01:15:36,720
less than one hundred thousand years of data old.

1028
01:15:37,840 --> 01:15:39,740
We haven't yet mastered it and so, 

1029
01:15:40,640 --> 01:15:44,140
I'm sorry I'm asserting my own statements in the middle of a quote,

1030
01:15:46,520 --> 01:15:51,640
but it's been very recent that we've learned how to think.

1031
01:15:52,840 --> 01:15:57,760
And so we respected perhaps more than the things we take for granted

1032
01:15:57,760 --> 01:16:03,640
like walking, the visual perception and so on but those may be strictly a matter of data,

1033
01:16:05,080 --> 01:16:08,040
data and training time and network size.

1034
01:16:14,200 --> 01:16:15,860
So walking is hard.

1035
01:16:18,180 --> 01:16:19,760
The question is how hard is driving?

1036
01:16:21,160 --> 01:16:25,540
And that's an important question because the margin of error is small.

1037
01:16:27,760 --> 01:16:34,320
One, there's 1 fatality per 100 million miles.

1038
01:16:35,040 --> 01:16:38,200
That's the number of people that die in car crashes every year,

1039
01:16:38,920 --> 01:16:41,040
1 fatality per 100 million miles.

1040
01:16:42,260 --> 01:16:47,320
That's a point 0.000001% margin of error.

1041
01:16:47,780 --> 01:16:52,140
That's through all the time you spend on the road, that is the error you get.

1042
01:16:52,840 --> 01:16:56,840
More impressed with ImageNet being able to classify a leopard, a cat or a dog

1043
01:16:59,940 --> 01:17:04,560
at above human level performance but this is the margin of error we get with driving.

1044
01:17:05,620 --> 01:17:11,600
And we have to be able to deal with snow, with heavy rain, with big open parking lots,

1045
01:17:12,060 --> 01:17:18,340
with parking garages, any pedestrians that behaves irresponsibly as rarely as that happens

1046
01:17:19,260 --> 01:17:24,800
or just some predictably, again especially in Boston, reflections.

1047
01:17:26,480 --> 01:17:29,960
The ones especially some things you don't think about:

1048
01:17:29,960 --> 01:17:33,020
the lighting variations that blind the cameras.

1049
01:17:35,580 --> 01:17:41,340
(Inaudible question from one of the attendees)

1050
01:17:41,760 --> 01:17:48,100
The question was if that number changes, if you look at just crashes, the fatalities per crash.

1051
01:17:51,720 --> 01:17:57,320
So one of the big things is that cars have gotten really good at crashing and not hurting anybody.

1052
01:17:58,200 --> 01:18:01,320
So the number of crashes is much, much larger than the number of fatalities

1053
01:18:01,440 --> 01:18:04,780
which is a great thing, we've built safer cars.

1054
01:18:05,980 --> 01:18:09,280
But still, you know even one fatality is too many.

1055
01:18:13,280 --> 01:18:19,220
So this is one that Google self-driving car team

1056
01:18:20,920 --> 01:18:28,640
is quite open about their performance since hitting public road,

1057
01:18:29,200 --> 01:18:31,780
this is from a report that shows the number of times

1058
01:18:33,940 --> 01:18:35,600
the driver disengaged

1059
01:18:36,640 --> 01:18:40,120
the car gives up control,

1060
01:18:41,040 --> 01:18:43,180
that it asked the driver to take control back

1061
01:18:43,180 --> 01:18:45,060
or the driver takes control back by force.

1062
01:18:45,640 --> 01:18:49,880
Meaning that they're unhappy with the decision that the car was making

1063
01:18:50,260 --> 01:18:54,540
or it was putting the car or other pedestrians or other cars in unsafe situations.

1064
01:18:55,080 --> 01:18:58,900
And so, if you see over time there's been a total

1065
01:18:59,360 --> 01:19:01,760
from 2014 to 2015

1066
01:19:03,760 --> 01:19:08,460
there's been a total of 341 times on beautiful San Francisco roads

1067
01:19:09,180 --> 01:19:12,780
and I say that seriously because the weather conditions are great there,

1068
01:19:13,500 --> 01:19:17,720
341 times that the driver had to elect to control back.

1069
01:19:19,200 --> 01:19:20,340
So it's a work in progress.

1070
01:19:21,820 --> 01:19:24,840
And let me give you something to think about here.

1071
01:19:25,980 --> 01:19:31,580
This, with neural networks is a big open question.

1072
01:19:31,960 --> 01:19:33,140
The question of robustness.

1073
01:19:35,040 --> 01:19:38,380
So this is an amazing paper, I encourage people to read it.

1074
01:19:38,380 --> 01:19:40,820
There's a couple of papers around this topic.

1075
01:19:41,440 --> 01:19:43,160
Deep neural networks are easily fooled.

1076
01:19:45,280 --> 01:19:52,820
So here are 8 images where, if given to a neural network as input,

1077
01:19:52,820 --> 01:20:00,640
a convolutional  neural network as input, the network with higher than 99.6% confidence says

1078
01:20:01,180 --> 01:20:03,820
that the image, for example the top left, as a robin.

1079
01:20:04,700 --> 01:20:10,500
Next to is a cheetah, then an armadillo, a panda, an electric guitar,

1080
01:20:10,500 --> 01:20:12,500
a baseball, a starfish, a king penguin.

1081
01:20:13,220 --> 01:20:16,360
All of these things are obviously not in the images.

1082
01:20:16,920 --> 01:20:19,000
So the networks can be fooled with noise.

1083
01:20:21,680 --> 01:20:28,980
More importantly, practically for the real world, adding just a little bit of distortion,

1084
01:20:29,220 --> 01:20:37,540
a little bit of noise distortion to the image, can force the network to produce a totally wrong prediction.

1085
01:20:37,840 --> 01:20:41,860
So here's an example, there's 3 columns,

1086
01:20:42,440 --> 01:20:47,820
correct image classification, the slight addition of distortion

1087
01:20:48,720 --> 01:20:53,140
and the resulting prediction of an ostrich for all three images on the left

1088
01:20:54,520 --> 01:20:59,020
and a prediction of an ostrich for all three images on the right.

1089
01:21:00,080 --> 01:21:05,360
This ability to fool networks easily brings up an important point.

1090
01:21:06,540 --> 01:21:14,320
And that point is that there has been a lot of excitement

1091
01:21:15,260 --> 01:21:17,120
about neural networks throughout their history.

1092
01:21:17,740 --> 01:21:20,960
There's been a lot of excitement about artificial intelligence throughout its history

1093
01:21:21,840 --> 01:21:28,040
and not coupling that excitement, not granting that excitement, in the reality

1094
01:21:28,920 --> 01:21:39,720
the real challenges around that has resulted in in crashes, in A.I. winters when funding dried out

1095
01:21:40,340 --> 01:21:44,840
and people became hopeless in terms of the possibilities of artificial intelligence.

1096
01:21:45,360 --> 01:21:51,940
So here is the 1958 New York Times article that said the Navy revealed the embryo of an electronic computer today.

1097
01:21:52,320 --> 01:21:55,620
This is when the first perceptron that I talked about

1098
01:21:55,900 --> 01:21:59,120
was implemented in hardware by Frank Rosenblatt.

1099
01:22:00,060 --> 01:22:04,740
It took 400 pixel image input and it provided a single output.

1100
01:22:06,020 --> 01:22:09,860
Weights were encoded in the hardware potentiometers

1101
01:22:10,320 --> 01:22:12,020
and waves were updated with electric motors.

1102
01:22:12,920 --> 01:22:17,060
Now New York Times wrote, the Navy revealed the embryo vanilla electronic computer today

1103
01:22:17,980 --> 01:22:26,760
that expects will be able to walk, talk, see, write, reproduce itself and be conscious of its existence.

1104
01:22:28,480 --> 01:22:34,200
Dr. Frank Rosenblatt, a research psychologist at the Cornell Aeronautical Laboratory in Buffalo,

1105
01:22:34,700 --> 01:22:39,140
said perceptrons might be fired to the planets as mechanical space explorers.

1106
01:22:40,860 --> 01:22:45,500
This might seem ridiculous but this is the general opinion of the time.

1107
01:22:47,800 --> 01:22:53,420
And as we know now, perceptrons cannot even separate a non-linear function.

1108
01:22:55,640 --> 01:22:57,140
They're just linear classifiers.

1109
01:22:58,100 --> 01:23:04,400
And so this led to 2 major A.I. winters in the 70s, in the late 80s and early 90s.

1110
01:23:08,060 --> 01:23:15,620
The Lighthill Report, in 1973 by the UK government, said there are no part of the field

1111
01:23:15,620 --> 01:23:18,920
of discoveries made so far produced the major impact that was promised.

1112
01:23:19,920 --> 01:23:27,100
So if the hype builds beyond the capabilities of our research,

1113
01:23:28,380 --> 01:23:35,180
reports like this will come and they have the possibility of creating another A.I. winter.

1114
01:23:35,580 --> 01:23:39,980
So I want to pare the optimism, some of the cool things we'll talk about in this class,

1115
01:23:41,360 --> 01:23:43,780
with the reality of the challenges ahead of us.

1116
01:23:49,340 --> 01:23:55,120
The focus of the research community, this is some of the key players in deep learning,

1117
01:23:56,340 --> 01:24:00,880
what are the things that are next for deep learning, the five year vision?

1118
01:24:03,980 --> 01:24:07,600
We want to run on smaller, cheaper mobile devices.

1119
01:24:08,700 --> 01:24:13,320
We want to explore more in the space of unsupervised learning as I mentioned

1120
01:24:13,500 --> 01:24:14,640
and reinforcement learning.

1121
01:24:16,260 --> 01:24:22,560
We want to do things that explore the space of videos more,

1122
01:24:23,040 --> 01:24:27,640
the recurring neural networks, like being able to summarize videos or generate short videos.

1123
01:24:29,360 --> 01:24:34,000
One of the big efforts, especially in the companies we do in large data,

1124
01:24:34,560 --> 01:24:35,760
is multi-modal learning.

1125
01:24:36,120 --> 01:24:40,040
Learning from multiple data sets with multiple sources of data.

1126
01:24:41,860 --> 01:24:46,000
And lastly, making money from these technologies.

1127
01:24:46,460 --> 01:24:51,480
There's a lot of this despite the excitement.

1128
01:24:52,380 --> 01:24:56,840
There has been an inability for the most part to make serious money

1129
01:24:57,600 --> 01:25:02,420
from some of the more interesting parts of deep learning.

1130
01:25:06,160 --> 01:25:13,340
And while I got made fun of by the TAs for including this slide

1131
01:25:13,700 --> 01:25:16,180
because it's shown in so many sort of business type lectures,

1132
01:25:16,680 --> 01:25:20,560
but it is true that we're at the peak of a hype cycle

1133
01:25:20,940 --> 01:25:26,400
and we have to make sure be given the large amount of hype and excited there is,

1134
01:25:27,040 --> 01:25:28,120
we proceed with caution.

1135
01:25:36,020 --> 01:25:45,640
One example of that, let me mention, is we already talked about spoofing the cameras.

1136
01:25:45,920 --> 01:25:47,520
Spoofing the cameras with a little bit of noise.

1137
01:25:47,740 --> 01:25:53,080
So if you think about it, self-driving vehicles operate with a set of sensors

1138
01:25:54,040 --> 01:25:58,200
and they rely on those sensors to convey to accurately capture that information.

1139
01:25:59,040 --> 01:26:06,520
And what happens, not only when the world itself produces noisy visual information,

1140
01:26:07,060 --> 01:26:09,860
but what if somebody actually tries to spoof that data.

1141
01:26:11,020 --> 01:26:14,800
One of the fascinating things have been recently done is spoofing of LIDAR.

1142
01:26:16,100 --> 01:26:22,740
So these LIDAR is a range sense that gives a 3D-point cloud of the objects in the external environment.

1143
01:26:23,820 --> 01:26:30,000
And you're able to successfully do a replay attack where you have the car

1144
01:26:30,760 --> 01:26:34,580
see people in other cars around it when there's actually nothing around it.

1145
01:26:36,040 --> 01:26:40,300
In the same way that you can spoof a camera to see things that are not there.

1146
01:26:42,160 --> 01:26:42,860
A neural network.

1147
01:26:44,260 --> 01:26:48,580
So let me run through some of the libraries that we'll work with

1148
01:26:49,060 --> 01:26:53,420
and they're out there that you my work with if you proceed with deep learning.

1149
01:26:54,700 --> 01:26:58,540
TensorFlow, that is the most popular one these days.

1150
01:26:59,220 --> 01:27:01,540
It's heavily backed and developed by Google.

1151
01:27:03,160 --> 01:27:13,060
It's primarily a python interface and is very good at operating on multiple GPUs.

1152
01:27:14,920 --> 01:27:21,900
There's Keras and also TF Learn and TF Slim which are libraries that operate on top of TensorFlow

1153
01:27:22,280 --> 01:27:28,980
that make it slightly easier, slightly more user friendly interfaces, to get up and running.

1154
01:27:34,320 --> 01:27:39,880
Torch, if you're interested to get in at the lower level

1155
01:27:40,160 --> 01:27:42,700
tweaking of the different parameters of neural networks

1156
01:27:42,700 --> 01:27:44,700
creating your own architectures.

1157
01:27:45,060 --> 01:27:49,080
Torch is excellent for that with it's own Lua interface.

1158
01:27:49,400 --> 01:27:53,920
Lua's a programming language and heavily backed by Facebook.

1159
01:27:54,840 --> 01:27:59,460
There is the old school "theano" which is what I started on a lot of people early on,

1160
01:27:59,460 --> 01:28:04,260
in deep learning started on, as one of the first libraries that supported

1161
01:28:04,260 --> 01:28:06,040
ahead came with GPU support.

1162
01:28:06,720 --> 01:28:11,200
It definitely encourages lower level tinkering, has a python interface.

1163
01:28:12,160 --> 01:28:18,820
And many of these, if not all, rely on Nvidia's library

1164
01:28:19,240 --> 01:28:28,740
for doing some of the low level computations involved with training these neural networks on Nvidia GPUs.

1165
01:28:30,400 --> 01:28:38,520
"mxnet" heavily supported by Amazon and they have officially recently announced

1166
01:28:38,520 --> 01:28:43,660
that they're going to be, their AWS, is going to be all in on the mxnet.

1167
01:28:46,980 --> 01:28:55,260
Neon, recently bought by Intel, started out as a manufacturer of neural network chips

1168
01:28:55,540 --> 01:28:59,820
which is really exciting and it performs exceptionally well.

1169
01:29:00,960 --> 01:29:01,700
I hear good things.

1170
01:29:02,500 --> 01:29:09,080
Caffe, started in Berkeley, also was very popular in Google before Tensorlow came out.

1171
01:29:10,200 --> 01:29:13,700
It's primarily designed for computer vision with ConvNet's

1172
01:29:14,220 --> 01:29:18,420
but has now expanded to all of the domains.

1173
01:29:21,120 --> 01:29:25,320
There is CNTK, used to be known and now called the Microsoft Cognitive Toolkit.

1174
01:29:25,900 --> 01:29:28,120
Nobody calls it that still I'm aware of.

1175
01:29:29,760 --> 01:29:35,820
It says multi GPU support, has its own brain script custom language

1176
01:29:36,720 --> 01:29:37,980
as well as other interfaces.

1177
01:29:39,120 --> 01:29:45,840
And we'll get to play around in this class is, amazingly, deep learning in the browser, right.

1178
01:29:47,180 --> 01:29:54,120
Our favorite is ConvNetJS, what you use, built by Andrej Karpathy from Stanford now OpenAI.

1179
01:29:55,980 --> 01:29:58,480
It's good for explaining the basic concept of neural networks.

1180
01:29:58,940 --> 01:30:03,380
It's fun to play around with.  All you need is a browser and some very few requirements.

1181
01:30:03,880 --> 01:30:06,820
It can't leverage GPUs, unfortunately.

1182
01:30:08,020 --> 01:30:10,440
But for a lot of things that we're doing, you don't need GPUs.

1183
01:30:10,540 --> 01:30:16,460
You'd be able to train a network with very little and relatively efficiently without the [01:30:15] GPUs.

1184
01:30:16,800 --> 01:30:22,180
It has full support for CNNs, RNNs  and even deeper reinforcement learning.

1185
01:30:23,820 --> 01:30:28,280
Keras.js, which seems incredible, we try to use for this class.

1186
01:30:31,200 --> 01:30:35,300
It has GPU support so it runs in the browser with GPU support

1187
01:30:35,580 --> 01:30:39,960
with Open GL or however it works magically

1188
01:30:40,080 --> 01:30:43,960
but we're able to accomplish a lot of things we need without the use of GPUs.

1189
01:30:46,220 --> 01:30:53,780
It's incredible to live in a day and age when it literally, as I'll show on the tutorials,

1190
01:30:54,260 --> 01:30:58,400
it takes just a few minutes to get started with building your own neural network

1191
01:30:58,800 --> 01:31:04,040
that classifies images and a lot of these libraries are friendly in that way.

1192
01:31:04,960 --> 01:31:08,920
So all the references mentioned in this presentation

1193
01:31:08,920 --> 01:31:12,420
are available at this link and the slides are available there as well.

1194
01:31:13,620 --> 01:31:16,380
So I think in the interest of time, let me wrap up.

1195
01:31:16,380 --> 01:31:23,160
Thank you so much for coming in today and tomorrow I'll explain the deep reinforcement learning game

1196
01:31:23,600 --> 01:31:25,620
and the actual competition and how you can win.

1197
01:31:26,400 --> 01:31:27,120
Thanks very much guys.

