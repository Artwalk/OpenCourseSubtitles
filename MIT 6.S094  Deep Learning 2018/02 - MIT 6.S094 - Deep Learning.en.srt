1
00:00:01,080 --> 00:00:05,000
Thank you everyone
for braving the cold, and the snow

2
00:00:05,300 --> 00:00:06,100
To be here

3
00:00:08,020 --> 00:00:12,530
This is 6.S094: Deep Learning for Self-Driving Cars

4
00:00:14,350 --> 00:00:19,000
And, it's a course
 where we cover the topic of Deep learning

5
00:00:19,610 --> 00:00:24,290
Which is a set of techniques,
 that have taken a leap in the last decade

6
00:00:24,580 --> 00:00:27,190
For our understanding

7
00:00:27,190 --> 00:00:30,200
Of what artificial intelligence systems
are capable of doing

8
00:00:30,800 --> 00:00:34,970
And self-driving cars, which is systems,

9
00:00:34,970 --> 00:00:38,170
that can take these techniques, 
and integrate them

10
00:00:38,500 --> 00:00:43,070
In a meaningful, profound way 
 into our daily lives

11
00:00:43,070 --> 00:00:45,000
In a way that transforms society.

12
00:00:46,020 --> 00:00:49,780
So that's why both of these topics,
 are extremely important

13
00:00:49,780 --> 00:00:52,100
And extremely exciting.

14
00:00:52,500 --> 00:00:54,300
My name is Lex Fridman,

15
00:00:54,700 --> 00:00:56,990
And I'm joined by
 an amazing team of engineers,

16
00:00:56,990 --> 00:01:02,830
In Jack Terwilliger, Julia Kindelsberger, Dan Brown

17
00:01:02,840 --> 00:01:04,670
Michael Glazer, Li Ding,

18
00:01:04,670 --> 00:01:08,470
Spencer Dodd and Benedikt Jenik,

19
00:01:08,470 --> 00:01:10,270
Among many others...

20
00:01:10,670 --> 00:01:14,200
We build autonomous vehicles, 
here at MIT,

21
00:01:14,450 --> 00:01:20,310
Not just ones that perceive, 
 and move about the environment,

22
00:01:20,310 --> 00:01:24,240
But ones that interact, communicate, 
and earn the trust,

23
00:01:24,500 --> 00:01:27,870
And understanding of human beings  
 inside the car,

24
00:01:27,870 --> 00:01:29,620
The drivers and the passengers,

25
00:01:29,620 --> 00:01:32,360
And the human beings outside the car

26
00:01:32,480 --> 00:01:36,500
the pedestrians and other drivers
 and cyclists.

27
00:01:39,250 --> 00:01:43,400
The website for this course: 
selfdrivingcars.mit.edu

28
00:01:43,600 --> 00:01:47,440
if you have questions, email at: 
deepcars@mit.edu

29
00:01:47,730 --> 00:01:51,200
Slack: deep-mit

30
00:01:51,780 --> 00:01:55,860
For registered MIT students, 
you have to register on the website

31
00:01:57,090 --> 00:02:01,420
And, by midnight, 
Friday, January 19th

32
00:02:02,460 --> 00:02:05,570
build a neural network, 
and submit it to the competition.

33
00:02:05,600 --> 00:02:08,670
That achieves the speed of 65 miles per hour

34
00:02:08,740 --> 00:02:11,330
On the new deep traffic 2.0

35
00:02:11,550 --> 00:02:14,270
It's much harder and much more interesting

36
00:02:14,300 --> 00:02:17,060
than last year's 
for those of you who participated.

37
00:02:17,950 --> 00:02:20,130
There's three competitions in this class:

38
00:02:20,190 --> 00:02:24,050
Deep Taffic,SegFuse 
 DeepCrash

39
00:02:24,660 --> 00:02:27,230
There's guest speakers, 
that come from:

40
00:02:27,230 --> 00:02:30,800
Waymo, Google, Tesla

41
00:02:31,780 --> 00:02:35,940
And, those are starting new, 
autonomous vehicle startups

42
00:02:36,010 --> 00:02:42,000
In Voyage, NuTonomy and Aurora

43
00:02:43,640 --> 00:02:46,560
And then use a lot today from CES.

44
00:02:48,340 --> 00:02:52,740
And, we have shirts!
For those of you who braved the snow

45
00:02:52,740 --> 00:02:56,050
and continued to do so 
towards the end of the class

46
00:02:56,050 --> 00:02:57,560
there will be free shirts.

47
00:02:57,760 --> 00:03:00,460
Yes, I said free and shirts
 in the same sentence,

48
00:03:00,500 --> 00:03:02,000
You should be here.

49
00:03:03,030 --> 00:03:06,700
Okay. First: The Deep Traffic competition

50
00:03:07,790 --> 00:03:10,880
There's a lot of updates, and we'll 
cover those on Wednesday.

51
00:03:11,240 --> 00:03:13,700
it's a deep reinforcement learning 
competition.

52
00:03:13,810 --> 00:03:17,470
Last year we received
over 18,000 submissions,

53
00:03:18,330 --> 00:03:20,900
This year we're going to go bigger!

54
00:03:23,010 --> 00:03:26,040
Not only can you control one car, 
with your neural network

55
00:03:26,040 --> 00:03:27,600
You can control up to ten

56
00:03:27,800 --> 00:03:30,450
This is multi agent deep renforcement learning.

57
00:03:30,720 --> 00:03:32,050
This is super cool!

58
00:03:34,190 --> 00:03:38,610
Second: SegFuse - Dynamic 
Driving Scene Segmentation competition

59
00:03:39,460 --> 00:03:43,410
Where, you're given the raw video,

60
00:03:44,850 --> 00:03:49,170
The kinematics of the vehicles, 
the movement of the vehicle,

61
00:03:49,770 --> 00:03:51,960
The state-of-the-art segmentation.

62
00:03:52,240 --> 00:03:54,240
For the training set you're given:

63
00:03:54,500 --> 00:03:57,130
Ground truth labels, pixel level labels 

64
00:03:57,130 --> 00:04:00,370
Scene segmentation,
and optical flow.

65
00:04:00,570 --> 00:04:02,600
And with those pieces of data,

66
00:04:02,690 --> 00:04:06,850
You're tasked to try to perform better
than the state-of-the-art

67
00:04:07,040 --> 00:04:09,280
In image based segmentation.

68
00:04:10,450 --> 00:04:12,800
Why is this critical,

69
00:04:13,160 --> 00:04:15,700
And fascinating, 
in an open research problem?

70
00:04:17,000 --> 00:04:21,890
Because, robots that act in this world,

71
00:04:21,890 --> 00:04:24,660
In the physical space, 
not only must interpret,

72
00:04:24,850 --> 00:04:26,880
Use these deep learning methods
to interpret,

73
00:04:26,880 --> 00:04:28,910
The spatial visual characteristics of a scene,

74
00:04:29,210 --> 00:04:32,110
They must also interpret, understand,
 and track

75
00:04:32,330 --> 00:04:34,050
The temporal dynamics of the scene.

76
00:04:34,110 --> 00:04:37,390
This competition is about 
temporal propagaton of information,

77
00:04:37,700 --> 00:04:39,780
Not just scene segmentation.

78
00:04:40,500 --> 00:04:42,900
You must understand the space, 
and time.

79
00:04:44,900 --> 00:04:46,080
And finally

80
00:04:47,400 --> 00:04:48,630
Deep Crash

81
00:04:48,800 --> 00:04:50,750
Where we use deep reinforcement learning,

82
00:04:50,810 --> 00:04:53,300
To slam cars thousands of times,

83
00:04:53,900 --> 00:04:56,180
Here, at MIT, at the gym.

84
00:04:57,450 --> 00:05:02,150
You're given data on a thousand runs,
where car

85
00:05:02,160 --> 00:05:05,110
Or a car knowing nothing
is using a monocular camera's

86
00:05:05,110 --> 00:05:08,210
Single input,
 driving over 30 miles an hour,

87
00:05:08,490 --> 00:05:10,780
Through a scene,
it has very little control through

88
00:05:10,780 --> 00:05:13,300
Very little capability
to localize itself

89
00:05:13,440 --> 00:05:15,100
It must act very quickly.

90
00:05:15,340 --> 00:05:18,740
In that scene you're given 
a thousand runs, to learn anything.

91
00:05:21,480 --> 00:05:24,170
We'll discuss this, 
in the coming weeks.

92
00:05:24,660 --> 00:05:28,900
This competition will result in
four submissions

93
00:05:29,760 --> 00:05:32,380
That; We evaluate everyone's
 in simulation

94
00:05:32,720 --> 00:05:36,160
But the top four submissions,
we put head-to-head at the gym.

95
00:05:36,530 --> 00:05:40,450
And, until there is a winner declared, 
we keep slamming cars

96
00:05:41,460 --> 00:05:42,800
...at 30 miles an hour.

97
00:05:43,260 --> 00:05:47,740
Deep crash,  and also on the website 
is from the last year,

98
00:05:47,970 --> 00:05:50,350
And on GitHub there's DeepTesla.

99
00:05:50,940 --> 00:05:54,020
Which is using the large-scale
naturalistic driving data set

100
00:05:54,020 --> 00:05:57,600
We have to train a neural network 
to do enter and steering

101
00:05:57,970 --> 00:06:00,850
That takes in monocular video 
from the forward roadway,

102
00:06:00,980 --> 00:06:02,740
And produces steering commands,

103
00:06:03,700 --> 00:06:05,350
Steering commands for the car.

104
00:06:07,120 --> 00:06:09,920
Lectures: Today we'll talk about
 deep learning,

105
00:06:10,230 --> 00:06:12,450
Tomorrow we'll talk about
 autonomous vehicles,

106
00:06:12,840 --> 00:06:14,600
Deep RL is on Wednesday,

107
00:06:15,720 --> 00:06:19,090
Driving scene understanding
So segmentation

108
00:06:19,940 --> 00:06:21,040
That's Thursday.

109
00:06:21,880 --> 00:06:24,600
On Friday, we have Sacha Arnoud,

110
00:06:25,280 --> 00:06:27,300
The Director of Engineering at Waymo.

111
00:06:27,550 --> 00:06:30,610
Waymo is one of the companies, 
 that's truly taking

112
00:06:30,740 --> 00:06:33,440
Huge strides in
fully autonomous vehicles.

113
00:06:33,580 --> 00:06:37,330
They're taking the fully L4, L5, 
autonomous vehicle approach.

114
00:06:37,410 --> 00:06:39,040
and it's fascinating to learn,

115
00:06:39,210 --> 00:06:41,400
he's also the head of perception
 for them.

116
00:06:41,910 --> 00:06:45,730
To learn from him; What kind of problems
they're facing?

117
00:06:45,730 --> 00:06:47,700
And what kind of approach 
they're taking on?

118
00:06:47,880 --> 00:06:49,470
We have Emilio Frazzoli,

119
00:06:49,560 --> 00:06:51,310
Who's one of last year's 
speakers

120
00:06:51,540 --> 00:06:55,300
Sertac Karaman said Emilio is 
the smartest person he knows,

121
00:06:55,780 --> 00:06:58,150
So Emilio Frazzoli's the CTO 
of nuTonomy

122
00:06:58,210 --> 00:07:02,750
An autonomous vehicle company,  that was just acquired by Delphi

123
00:07:03,470 --> 00:07:05,970
For a large sum of money.
And they're doing a lot of

124
00:07:05,970 --> 00:07:08,690
incredible work in
Singapore, and here in Boston.

125
00:07:10,570 --> 00:07:13,600
Next Wednesday,  
we are going to talk

126
00:07:13,600 --> 00:07:17,260
about the topic of our research, 
or my personal fascination,

127
00:07:17,260 --> 00:07:20,550
is deep learning for
 driver state sensing.

128
00:07:20,550 --> 00:07:23,380
Understanding the human,
 perceiving everything about the human

129
00:07:23,380 --> 00:07:25,500
being inside the car,
 and outside the car.

130
00:07:26,950 --> 00:07:29,330
One talk, I'm really excited about,

131
00:07:29,550 --> 00:07:31,730
is Oliver Cameron on Thursday.

132
00:07:32,650 --> 00:07:37,020
He is now the CEO of 
autonomous vehicle startup Voyage.

133
00:07:37,170 --> 00:07:41,460
He's previously the director of
 the self-driving car program, for Udacity

134
00:07:41,770 --> 00:07:46,120
He will talk about: how to start 
a self-driving car company,

135
00:07:46,480 --> 00:07:50,630
For those, who said that MIT folks
 are entrepreneurs.

136
00:07:50,740 --> 00:07:53,560
If you want to start one yourself,
he'll tell you exactly how.

137
00:07:54,130 --> 00:07:55,120
It's super cool!

138
00:07:55,700 --> 00:07:57,150
And then, Sterling Anderson!

139
00:07:58,040 --> 00:08:03,320
Who was the director previously,
Tesla Autopilot team.

140
00:08:03,520 --> 00:08:06,040
And now is a co-founder of Aurora,

141
00:08:06,580 --> 00:08:11,290
The self-driving car startup,
that I mentioned,

142
00:08:11,290 --> 00:08:13,700
...that has now partnered,
with  NVIDIA and many others.

143
00:08:14,020 --> 00:08:16,180
So, why self-driving cars?

144
00:08:16,700 --> 00:08:20,730
This class is about applying 
data-driven learning methods,

145
00:08:20,850 --> 00:08:22,740
To the problem of autonomous vehicles.

146
00:08:23,270 --> 00:08:26,190
Why self-driving cars are fascinating,

147
00:08:26,430 --> 00:08:28,110
And an interesting problem space?

148
00:08:30,260 --> 00:08:33,230
Quite possibly, in my opinion,

149
00:08:33,620 --> 00:08:36,950
This is the first wide reaching,
 and profound integration

150
00:08:36,950 --> 00:08:39,490
Of personal robots, in society.

151
00:08:40,180 --> 00:08:43,320
Wide-reaching, because there's 
one billion cars on the road,

152
00:08:43,340 --> 00:08:45,810
Even a fraction of that, will change,

153
00:08:47,040 --> 00:08:50,390
...the face of transportation,
and how we move about this world.

154
00:08:51,600 --> 00:08:54,640
Profound,  and this is an 
important point,

155
00:08:54,870 --> 00:08:56,300
...that's not always understood.

156
00:08:58,160 --> 00:09:02,400
There's an intimate connection,
 between a human,

157
00:09:02,720 --> 00:09:07,060
And a vehicle, when there's 
a direct transfer of control.

158
00:09:07,620 --> 00:09:09,890
It's a direct transfer of control...

159
00:09:10,020 --> 00:09:13,760
That takes that,  his or her life,
into the hands,

160
00:09:13,760 --> 00:09:15,460
Of an artificial intelligence system.

161
00:09:16,160 --> 00:09:17,370
I showed a few quick,

162
00:09:19,010 --> 00:09:23,290
Quick clips here, you can Google 
first time with Tesla autopilot,

163
00:09:23,300 --> 00:09:27,270
On YouTube and watch people, 
 perform that transfer of control,

164
00:09:27,730 --> 00:09:29,320
There's something magical...

165
00:09:29,390 --> 00:09:32,590
About a human and a robot 
working together,

166
00:09:33,200 --> 00:09:37,110
That will transform,
 what artificial intelligence is,

167
00:09:37,110 --> 00:09:38,330
In the 21st century.

168
00:09:38,940 --> 00:09:41,320
And this particular autonomous system,

169
00:09:41,850 --> 00:09:46,410
AI system, self-driving cars, 
 is on the scale.

170
00:09:46,780 --> 00:09:50,110
And the profound,the life-critical  
nature of it,  is profound.

171
00:09:50,170 --> 00:09:54,200
In a way that, it will truly test
  the capabilities of AI.

172
00:09:55,920 --> 00:09:57,920
There'a a personal connection,

173
00:09:58,020 --> 00:10:00,500
That will argue throughout these lectures,

174
00:10:00,500 --> 00:10:01,120
That we cannot escape considering the human being.
That will argue throughout these lectures,

175
00:10:01,120 --> 00:10:03,180
That we cannot escape considering the human being.

176
00:10:03,720 --> 00:10:07,040
That autonomous vehicle, must not only
perceive and control

177
00:10:07,040 --> 00:10:08,720
It's movement
through the environment.

178
00:10:08,730 --> 00:10:12,210
You must also perceive everything 
about the human driver and the passenger

179
00:10:12,310 --> 00:10:15,370
And interact, communicate,
 and build trust with that driver.

180
00:10:20,270 --> 00:10:21,360
Because,...

181
00:10:22,980 --> 00:10:24,180
In my view,

182
00:10:24,620 --> 00:10:27,050
As I will argue throughout
 this course,

183
00:10:27,200 --> 00:10:30,560
An autonomous vehicle is more
 of a personal robot,

184
00:10:31,140 --> 00:10:34,090
than it is a perfect perception 
controled system.

185
00:10:34,570 --> 00:10:37,920
Because, perfect perception 
and control,

186
00:10:38,160 --> 00:10:40,250
For this world, full of humans,...

187
00:10:41,170 --> 00:10:43,190
Is extremely difficult.

188
00:10:43,340 --> 00:10:46,300
And could be, two-three-four decades away.

189
00:10:47,050 --> 00:10:48,320
Full autonomy.

190
00:10:49,220 --> 00:10:52,780
Autonomous vehicles are going to be flawed.

191
00:10:52,910 --> 00:10:54,700
They're going to have flaws...

192
00:10:54,990 --> 00:10:58,900
And we have to design systems, 
that are effectively caught

193
00:10:58,990 --> 00:11:02,020
That effectively transfer control 
to human beings,

194
00:11:02,280 --> 00:11:04,000
When they can't handle the situation.

195
00:11:04,160 --> 00:11:07,520
And that transfer of control... 
Is an...

196
00:11:07,600 --> 00:11:09,850
Is a fascinating opportunity for AI.

197
00:11:13,240 --> 00:11:16,530
Because the obstacle avoidance,

198
00:11:16,740 --> 00:11:21,020
Perception of obstacles, 
and obstacle avoidance,

199
00:11:21,460 --> 00:11:23,080
It's the easy problem.

200
00:11:23,900 --> 00:11:26,340
It's the safe problem. 
Going 30 miles an hour

201
00:11:26,340 --> 00:11:28,860
Navigating through streets of Boston,

202
00:11:29,360 --> 00:11:30,200
It's easy.

203
00:11:30,790 --> 00:11:34,580
It's when you have  to get,
 to work, and you're late.

204
00:11:35,010 --> 00:11:37,250
Or you're sick of the person 
in front of you,

205
00:11:37,250 --> 00:11:40,120
...that you want to go
 in the opposing  lane,

206
00:11:40,120 --> 00:11:40,850
and speed up.

207
00:11:41,570 --> 00:11:44,100
That's human nature. 
And we can't escape it.

208
00:11:44,820 --> 00:11:47,250
Our artificial intelligence systems,

209
00:11:47,640 --> 00:11:50,600
Can't escape human nature, 
they must work with it.

210
00:11:51,040 --> 00:11:53,210
What's shown here, 
is one of the algorithms,

211
00:11:53,210 --> 00:11:55,950
We'll talk about next week,
for cognitive load.

212
00:11:56,590 --> 00:11:58,580
Or we take, the raw,...

213
00:11:58,670 --> 00:12:00,650
3D convolutional neural networks,

214
00:12:00,680 --> 00:12:04,460
Take in the eye region, the blinking, 
and the pupil movement

215
00:12:04,600 --> 00:12:06,580
To determine the cognitive load 
of the driver.

216
00:12:06,950 --> 00:12:09,780
We'll see how we can detect
 everything about the driver,

217
00:12:09,900 --> 00:12:12,210
Where they're looking? Emotion?

218
00:12:12,570 --> 00:12:15,480
Cognitive load? Body pose estimation?

219
00:12:16,330 --> 00:12:17,530
Drowsiness.

220
00:12:18,760 --> 00:12:22,300
The movement towards full autonomy

221
00:12:22,480 --> 00:12:23,690
...is so difficult...

222
00:12:24,260 --> 00:12:25,380
I would argue

223
00:12:25,680 --> 00:12:28,910
That it almost requires
 human level intelligence.

224
00:12:30,020 --> 00:12:31,120
That the....

225
00:12:31,540 --> 00:12:34,970
As I said, 2-3-4 decade out
 journey...

226
00:12:35,060 --> 00:12:38,960
For artificial intelligence researchers,
 to achieve full autonomy

227
00:12:39,060 --> 00:12:42,030
Will require achieving, solving,
 some of the problems

228
00:12:42,040 --> 00:12:45,020
Fundamental problems
of creating intelligence.

229
00:12:46,720 --> 00:12:49,570
And... That's something 
we'll discuss,

230
00:12:49,570 --> 00:12:50,880
In much more depth,

231
00:12:51,020 --> 00:12:52,860
In a broader view in two weeks,

232
00:12:53,210 --> 00:12:55,530
For the artificial general intelligence
 course,

233
00:12:56,210 --> 00:12:58,250
Where we have Andrej Karpathy,
 from Tesla,

234
00:12:58,250 --> 00:13:02,380
Ray Kurzweil, Marc Raibert,
 from Boston Dynamics

235
00:13:03,160 --> 00:13:07,380
Who asked for the dimensions of this room,
 because he's bringing robots

236
00:13:08,490 --> 00:13:10,340
Nothing else was told to me...

237
00:13:11,540 --> 00:13:13,000
It'll be a surprise.

238
00:13:16,140 --> 00:13:17,910
So that is why I argue 
the human centered

239
00:13:17,910 --> 00:13:19,530
Artificial intelligence approach

240
00:13:20,240 --> 00:13:23,320
In every algorithm of a design 
considers the human.

241
00:13:26,260 --> 00:13:29,210
For autonomous vehicle on the left,
 the perception

242
00:13:29,620 --> 00:13:32,900
Scene understanding,
 and the control problem,

243
00:13:32,990 --> 00:13:34,670
As we'll explore through 
the competitions,

244
00:13:34,670 --> 00:13:36,260
And the assignments, of this course

245
00:13:37,110 --> 00:13:39,990
Can handle 90, and increasing

246
00:13:39,990 --> 00:13:43,600
...percent of the cases.
 But it's the 10,

247
00:13:43,840 --> 00:13:48,170
1.1 percent of the cases 
as we get better and better,

248
00:13:48,380 --> 00:13:49,900
That we have to...

249
00:13:50,200 --> 00:13:52,510
We're not able to handle 
through these methods

250
00:13:52,550 --> 00:13:54,640
And that's where the human,
perceiving the human

251
00:13:54,640 --> 00:13:55,630
is really important.

252
00:13:55,840 --> 00:13:57,910
This is the video from last year.

253
00:13:58,200 --> 00:14:00,120
Of Arc de Triomphe 
Thank you

254
00:14:00,170 --> 00:14:01,950
Didn't know it last year, I know now.

255
00:14:02,720 --> 00:14:06,260
That is one of millions of cases,

256
00:14:06,700 --> 00:14:11,780
Where human to human interaction
 is the dominant driver.

257
00:14:12,040 --> 00:14:16,000
Not, the basic perception 
control problem

258
00:14:19,970 --> 00:14:21,960
So why deep learning in this space?

259
00:14:23,690 --> 00:14:25,350
Because deep learning

260
00:14:25,640 --> 00:14:30,830
Is a set of methods, 
that do well from a lot of data.

261
00:14:31,500 --> 00:14:33,340
And to solve these problems

262
00:14:33,470 --> 00:14:35,590
Where human life is at stake,

263
00:14:35,780 --> 00:14:38,410
We have to be able to have techniques

264
00:14:38,410 --> 00:14:41,660
That learn from data, 
learn from real-world data.

265
00:14:41,910 --> 00:14:45,570
This is the fundamental reality
 of artificial intelligent systems

266
00:14:45,570 --> 00:14:47,000
That operate in the real world.

267
00:14:47,060 --> 00:14:49,300
They must learn from real world data.

268
00:14:49,820 --> 00:14:53,150
Whether that's on the left 
for the perception, the control side,

269
00:14:54,750 --> 00:14:57,110
Or on the right, for the human

270
00:14:57,160 --> 00:15:00,050
The perception, and the communication,
Interaction

271
00:15:00,290 --> 00:15:02,890
And collaboration with the human,

272
00:15:03,040 --> 00:15:04,800
And the human robot interaction.

273
00:15:06,640 --> 00:15:07,450
Ok.

274
00:15:08,340 --> 00:15:09,780
So what is deep learning?

275
00:15:13,210 --> 00:15:14,770
It's a set of techniques,

276
00:15:15,200 --> 00:15:17,810
if you allow me the definition,
 of intelligence

277
00:15:17,810 --> 00:15:20,550
Being the ability to accomplish 
complex goals,

278
00:15:21,460 --> 00:15:24,760
Then I would argue,
definition of understanding

279
00:15:25,070 --> 00:15:27,980
Maybe a reasoning is...

280
00:15:28,100 --> 00:15:30,370
The ability to turn complex information

281
00:15:30,470 --> 00:15:33,920
Into simple, useful,
 actionable information.

282
00:15:34,780 --> 00:15:36,650
And that is what deep learning does.

283
00:15:37,740 --> 00:15:40,000
Deep learning is representation learning,

284
00:15:40,720 --> 00:15:42,530
Or feature learning, if you will.

285
00:15:43,200 --> 00:15:45,580
It's able to take raw information,

286
00:15:46,240 --> 00:15:48,000
Raw complicated information,

287
00:15:48,050 --> 00:15:49,570
That's hard to do anything with,

288
00:15:49,850 --> 00:15:53,590
And construct hierarchical representations 
of that information,

289
00:15:53,890 --> 00:15:55,920
To be able to do 
something interesting with it.

290
00:15:56,950 --> 00:15:59,210
It is the branch of artificial intelligence,

291
00:15:59,550 --> 00:16:02,860
Which is most capable and focused,
 on this task.

292
00:16:04,060 --> 00:16:06,180
Forming representations from data,

293
00:16:06,320 --> 00:16:08,350
Whether it's supervised 
or unsupervised,

294
00:16:08,350 --> 00:16:10,620
Whether it's with the help of humans,
 or not;

295
00:16:10,800 --> 00:16:14,610
It's able to construct structure,

296
00:16:14,610 --> 00:16:18,750
Find structure in the data; 
Such that you can extract

297
00:16:18,750 --> 00:16:21,000
Simple, useful, actionable information.

298
00:16:21,690 --> 00:16:22,700
On the left,

299
00:16:23,420 --> 00:16:24,970
From Ian Goodfellow's book,

300
00:16:26,860 --> 00:16:30,150
Is the basic example of 
a misclassification.

301
00:16:30,860 --> 00:16:32,640
The input of the image,

302
00:16:34,100 --> 00:16:36,550
On the bottom, with the raw pixels

303
00:16:36,580 --> 00:16:39,780
And as we go up the stack
 as we go up the layers,

304
00:16:39,900 --> 00:16:42,460
Higher and higher order representations
 are formed.

305
00:16:42,800 --> 00:16:46,320
From edges, to contours
The corners, to object parts

306
00:16:46,410 --> 00:16:47,160
And then finally,

307
00:16:47,160 --> 00:16:50,530
The full object semantic classification, 
of what's in the image

308
00:16:51,660 --> 00:16:53,400
This is representation learning

309
00:16:54,320 --> 00:16:56,070
A favorite example for me

310
00:16:57,550 --> 00:17:00,940
Is, one from four centuries ago.

311
00:17:02,220 --> 00:17:03,820
Our place in the universe,

312
00:17:05,110 --> 00:17:07,200
And representing that place
 in the universe,

313
00:17:07,370 --> 00:17:09,580
Whether it's relative to Earth,

314
00:17:09,780 --> 00:17:11,890
Or relative to the Sun.

315
00:17:13,320 --> 00:17:16,750
On the left is our current belief,

316
00:17:16,980 --> 00:17:20,590
On the right is the one,
 that was held widely,

317
00:17:20,590 --> 00:17:21,960
Four centuries ago

318
00:17:23,280 --> 00:17:26,390
Representation matters!
Because,what's on the right

319
00:17:26,740 --> 00:17:29,340
Is much more complicated
 than what's on the left.

320
00:17:34,420 --> 00:17:36,740
You can think of,
 in a simple case here

321
00:17:36,740 --> 00:17:39,190
When the task is to draw
 a line that separates,

322
00:17:39,190 --> 00:17:40,960
Green triangles and blue circles

323
00:17:41,060 --> 00:17:43,970
In the Cartesian coordinates space,
on the left

324
00:17:44,050 --> 00:17:47,420
The task is much more difficult.
 Impossible, to do well

325
00:17:47,660 --> 00:17:50,540
On the right, it's trivial,
in polar coordinates.

326
00:17:51,400 --> 00:17:53,760
This transformation is exactly

327
00:17:53,880 --> 00:17:56,990
Whan we need to learn,
 this is representation learning.

328
00:17:57,800 --> 00:17:59,060
So you can take the same task,

329
00:17:59,060 --> 00:18:00,800
Of having to draw a line
 that separates

330
00:18:00,800 --> 00:18:02,900
The blue curve, and the 
red curve on the left .

331
00:18:03,980 --> 00:18:07,740
If we draw a straight line,
 it's going to be a high

332
00:18:07,800 --> 00:18:10,840
There's no way to do it
 with zero error.

333
00:18:11,140 --> 00:18:13,000
With 100% accuracy

334
00:18:13,810 --> 00:18:16,180
Shown on the right, is our best attempt.

335
00:18:18,560 --> 00:18:20,320
But what we can do with deep learning,

336
00:18:20,380 --> 00:18:23,160
With a single hidden layer network
 done here,

337
00:18:23,520 --> 00:18:28,010
Is form the topology,
 the mapping of the space,

338
00:18:28,010 --> 00:18:29,500
In such a way, in the middle,

339
00:18:30,080 --> 00:18:32,080
That allows for a straight line to be drawn,

340
00:18:32,080 --> 00:18:34,150
That separates the blue curve, 
and the red curve.

341
00:18:35,140 --> 00:18:37,820
The learning of the function
 in the middle,

342
00:18:38,300 --> 00:18:40,560
Is what we're able to achieve
 with deep learning.

343
00:18:42,380 --> 00:18:45,480
It's taking raw, complicated information,

344
00:18:45,950 --> 00:18:50,630
And making it simple,
 actionable, useful.

345
00:18:51,830 --> 00:18:56,440
And the point is, that,
 this kind of ability to learn,

346
00:18:56,440 --> 00:18:58,150
From raw sensory information

347
00:18:58,320 --> 00:19:01,740
Means that, we can do a lot more,
 with a lot more data.

348
00:19:03,100 --> 00:19:06,300
So, deep learning 
gets better with more data.

349
00:19:09,700 --> 00:19:12,280
And that's important,
 for real world applications.

350
00:19:14,500 --> 00:19:16,420
Where edge cases are everything.

351
00:19:17,140 --> 00:19:21,390
This is us driving, with two
 perception control systems.

352
00:19:21,390 --> 00:19:24,730
One is in Tesla vehicle,
 with the autopilot

353
00:19:25,260 --> 00:19:27,920
Version one system that's
 using a monocular camera,

354
00:19:27,920 --> 00:19:29,490
To perceive the external environment,

355
00:19:29,690 --> 00:19:31,400
And produce control decisions.

356
00:19:31,540 --> 00:19:33,680
And our own, neural network

357
00:19:33,680 --> 00:19:36,850
Running on adjacent TX2,
 that's taking in the same.

358
00:19:36,850 --> 00:19:39,570
With a monocular camera,
 and producing control decisions.

359
00:19:40,810 --> 00:19:44,130
And, the two systems argue,
 and when they disagree

360
00:19:44,180 --> 00:19:47,300
They raise up a flag, to say that
 this is an edge case

361
00:19:47,300 --> 00:19:49,420
That needs human intervention.

362
00:19:50,380 --> 00:19:51,200
There is...

363
00:19:51,710 --> 00:19:54,430
Covering such edge cases,
 using machine learning,

364
00:19:55,000 --> 00:19:59,000
Is the main problem,
 of artificial intelligence, and...

365
00:19:59,540 --> 00:20:00,910
When applied to the real world,

366
00:20:01,110 --> 00:20:02,920
It is the main problem to solve.

367
00:20:04,940 --> 00:20:05,680
Okay.

368
00:20:06,300 --> 00:20:07,650
So what are neural networks?

369
00:20:09,020 --> 00:20:12,040
Inspired very loosely, and I'll discuss

370
00:20:12,210 --> 00:20:13,530
About the key difference 
between,

371
00:20:13,530 --> 00:20:16,520
Our own brains and artificial brains

372
00:20:17,120 --> 00:20:19,690
Because there's a lot of insights,
 in that difference.

373
00:20:20,400 --> 00:20:23,960
But inspired loosely by 
biological neural networks,

374
00:20:23,960 --> 00:20:26,470
Here, as a simulation of a...

375
00:20:26,660 --> 00:20:28,440
Thalamocortical brain network,

376
00:20:28,560 --> 00:20:30,500
Which is only 3 million neurons,

377
00:20:31,240 --> 00:20:34,620
476 million synapses...
 The full human brain,

378
00:20:34,830 --> 00:20:37,380
Is a lot more than that. 
A 100 billion neurons,

379
00:20:37,860 --> 00:20:42,290
...1,000 trillion synapses.

380
00:20:46,300 --> 00:20:48,300
There's inspirational music,
 with this one

381
00:20:48,400 --> 00:20:52,300
That I didn't realize was here,
 it should make you think.

382
00:20:53,370 --> 00:20:56,230
Artificial neural networks,
 yeah... Let's

383
00:20:56,230 --> 00:20:57,300
Just let it play...

384
00:21:00,040 --> 00:21:04,000
The human neural network is,
 a hundred billion neurons, right?

385
00:21:04,070 --> 00:21:06,180
1,000 trillion synapses.

386
00:21:06,980 --> 00:21:09,440
One of the state-of-the-art,

387
00:21:09,720 --> 00:21:12,950
Neural network is ResNet-152,
which has...

388
00:21:13,090 --> 00:21:14,920
60 million synapses.

389
00:21:17,160 --> 00:21:20,220
That's a difference, of about...

390
00:21:20,220 --> 00:21:20,230
A seven order of magnitude difference
That's a difference, of about...

391
00:21:20,230 --> 00:21:22,300
A seven order of magnitude difference

392
00:21:22,460 --> 00:21:26,550
The human brains have,
 10 million times more synapses,

393
00:21:26,550 --> 00:21:28,200
Than artificial neural networks.

394
00:21:29,110 --> 00:21:32,450
Plus or minus one order of magnitude,
depending on the network.

395
00:21:34,160 --> 00:21:36,120
So, what's the difference, between

396
00:21:36,180 --> 00:21:38,940
A biological neuron, and 
an artificial neuron?

397
00:21:40,220 --> 00:21:42,800
The topology of the human brain
 have no layers.

398
00:21:42,820 --> 00:21:45,680
Neural networks are stacked in layers

399
00:21:46,000 --> 00:21:48,000
They're fixed, for the most part.

400
00:21:49,020 --> 00:21:50,700
There is chaos!

401
00:21:51,090 --> 00:21:53,490
Very little structure in our human brain

402
00:21:53,490 --> 00:21:55,990
In terms of how 
neurons are connected.

403
00:21:56,240 --> 00:21:59,820
They're connected, often,
 to 10,000 plus other neurons.

404
00:22:00,070 --> 00:22:02,720
The number of synapses, 
from individual neurons

405
00:22:02,850 --> 00:22:06,210
That are... 
Input into the neuron is huge!

406
00:22:07,530 --> 00:22:11,060
They're asynchronous.
The human brain works asynchronously.

407
00:22:11,230 --> 00:22:13,580
Artificial neural networks work synchronously.

408
00:22:15,450 --> 00:22:19,040
The learning algorithm 
for artificial neuron networks,

409
00:22:19,450 --> 00:22:22,320
The only one, the best one...

410
00:22:22,910 --> 00:22:24,300
Is back propagation.

411
00:22:25,480 --> 00:22:29,340
And we don't know, how human brains learn...

412
00:22:33,160 --> 00:22:37,080
Processing speed,
 this is one of the...

413
00:22:38,090 --> 00:22:41,850
The only benefits we have
 with artificial neural networks is...

414
00:22:42,200 --> 00:22:44,500
Artificial neurons are faster.

415
00:22:45,450 --> 00:22:48,320
But they're also extremely power inefficient,

416
00:22:50,690 --> 00:22:54,070
And... There is a division into stages,

417
00:22:54,070 --> 00:22:56,270
Of training and testing with neural networks.

418
00:22:56,660 --> 00:23:00,820
With biological neural networks,
 as you're sitting here today

419
00:23:00,980 --> 00:23:02,110
They're always learning.

420
00:23:03,270 --> 00:23:07,290
The only profound similarity,
 the inspiring one

421
00:23:07,940 --> 00:23:11,260
The captivating one, is that both are,

422
00:23:11,440 --> 00:23:13,410
Distributed computation at scale.

423
00:23:14,890 --> 00:23:18,950
There is an emergent aspect
 to neural networks,

424
00:23:19,440 --> 00:23:23,620
Where the basic element of computation:
A neuron,

425
00:23:24,230 --> 00:23:26,850
Is simple.
Is extremely simple.

426
00:23:27,120 --> 00:23:30,200
But when connected together,
beautiful

427
00:23:30,580 --> 00:23:34,160
Amazing, powerful approximators 
can be formed.

428
00:23:35,510 --> 00:23:38,190
A neural network is built up
 with these computational units,

429
00:23:38,190 --> 00:23:39,400
They're the inputs,

430
00:23:39,560 --> 00:23:42,390
There's a set of edges, 
with weights on them.

431
00:23:43,230 --> 00:23:44,120
The edges...

432
00:23:44,120 --> 00:23:47,080
The weights are multiplied 
by this input signal,

433
00:23:47,700 --> 00:23:51,810
A bias is added,
 with a nonlinear function.

434
00:23:52,160 --> 00:23:54,870
That determines whether the network
 gets activated or not

435
00:23:54,870 --> 00:23:57,040
Well, the neuron gets 
activated or not.

436
00:23:57,440 --> 00:23:58,560
Visualized here.

437
00:23:59,390 --> 00:24:03,100
And these neurons can be combined
 in a number of ways.

438
00:24:03,340 --> 00:24:05,310
they can form a feed-forward neural network,

439
00:24:05,480 --> 00:24:08,830
Or they can feed back into itself,

440
00:24:09,050 --> 00:24:12,480
To form... To have state memory.

441
00:24:13,450 --> 00:24:15,120
In Recurrent neural networks.

442
00:24:15,570 --> 00:24:19,360
The ones on the left, are the ones 
that are most successful,

443
00:24:19,760 --> 00:24:23,250
For most applications, in computer vision.

444
00:24:24,050 --> 00:24:27,840
The ones on the right are very popular,
and specific.

445
00:24:27,840 --> 00:24:30,380
One temporal dynamics,
 or dynamics time series

446
00:24:30,380 --> 00:24:31,510
of any kind are used.

447
00:24:32,020 --> 00:24:35,450
In fact, the ones on the right,
 are much closer

448
00:24:35,700 --> 00:24:37,650
To the way our human brains are

449
00:24:38,040 --> 00:24:39,400
Than the ones on the left,

450
00:24:40,160 --> 00:24:42,640
But that's why, they're really hard to train.

451
00:24:45,110 --> 00:24:49,250
One beautiful aspect, 
of this emergent power,

452
00:24:49,390 --> 00:24:51,680
For multiple neurons
being connected together

453
00:24:51,850 --> 00:24:53,310
Is the universal property

454
00:24:53,460 --> 00:24:55,250
That with a single hidden layer

455
00:24:55,450 --> 00:24:58,610
These networks can learn any function

456
00:24:58,610 --> 00:25:00,340
Learn to approximate any function.

457
00:25:00,960 --> 00:25:05,200
Which is an important property
to be aware of, because

458
00:25:06,320 --> 00:25:10,800
The limits here, are not in the 
power of the networks

459
00:25:11,090 --> 00:25:14,900
The limit in...
...is in the methods by which

460
00:25:14,920 --> 00:25:17,100
We construct them, and train them.

461
00:25:21,900 --> 00:25:25,860
What kinds of machine learning,
deep learning are there?

462
00:25:26,450 --> 00:25:31,100
We can separate into two categories.

463
00:25:32,080 --> 00:25:33,540
Memorizers,

464
00:25:34,460 --> 00:25:38,790
The approaches, that essentially
memorize patterns in the data.

465
00:25:39,370 --> 00:25:42,150
And approaches that,
 we can loosely say

466
00:25:42,150 --> 00:25:44,790
Are beginning to reason

467
00:25:45,060 --> 00:25:47,850
To generalize over the data,
 with minimal human input.

468
00:25:47,900 --> 00:25:51,310
On top, on the left are the, 
quote/unquote "Teachers",

469
00:25:51,380 --> 00:25:53,780
Is how much human input
 in blue, is needed

470
00:25:53,960 --> 00:25:57,330
To make the method successful
 for supervised learning,

471
00:25:57,480 --> 00:26:00,260
Which is what most of 
deep learning successes come from

472
00:26:00,350 --> 00:26:03,140
Or most of the data is annotated
  by human beings,

473
00:26:03,670 --> 00:26:07,460
The human is at the core of the success.

474
00:26:07,580 --> 00:26:09,580
Most of the data, 
that's part of the training

475
00:26:09,580 --> 00:26:11,480
Needs to be annotated by human beings.

476
00:26:12,160 --> 00:26:16,160
With some additional successes,
coming from augmentation methods,

477
00:26:16,220 --> 00:26:17,780
That extend that...

478
00:26:18,830 --> 00:26:22,450
Extend the data, based on which
 these networks are trained

479
00:26:26,590 --> 00:26:29,310
And the semi-supervised 
reinforcement learning,

480
00:26:29,310 --> 00:26:30,640
And unsupervised methods,

481
00:26:30,640 --> 00:26:32,760
That we'll talk about,
 later in the course,

482
00:26:33,020 --> 00:26:36,990
That's where the near-term successes
 we hope are.

483
00:26:37,400 --> 00:26:39,520
And with the unsupervised learning approaches,

484
00:26:39,520 --> 00:26:41,560
that's where, the true excitement,

485
00:26:41,560 --> 00:26:44,460
About the possibilities
 of artificial intelligence lie.

486
00:26:44,770 --> 00:26:47,470
Being able to make sense, of our world

487
00:26:47,540 --> 00:26:50,560
With minimal input from humans,...

488
00:26:53,360 --> 00:26:59,830
So, we can think of two kinds of
 deep learning impact spaces.

489
00:27:00,120 --> 00:27:02,810
One is a special purpose intelligence.

490
00:27:03,110 --> 00:27:05,940
It's taking a problem,
 formalizing it.

491
00:27:05,990 --> 00:27:09,260
Collecting enough data on it,
 and being able to,

492
00:27:10,260 --> 00:27:15,390
Solve a particular case, 
that provides value.

493
00:27:16,160 --> 00:27:18,770
Of particular interest here
 is a network

494
00:27:18,770 --> 00:27:21,420
That estimates apartment costs
 in the Boston area.

495
00:27:21,560 --> 00:27:23,210
So you could take the
 number of bedrooms,

496
00:27:23,210 --> 00:27:25,130
The square feet, and the neighborhood...

497
00:27:25,290 --> 00:27:28,600
And provide as output, the estimated cost.

498
00:27:28,860 --> 00:27:32,150
On the right is the actual data,

499
00:27:32,380 --> 00:27:35,760
Of apartment cost.
 We're actually standing,

500
00:27:36,760 --> 00:27:41,360
In an area, that has over 3000 dollars
 for a studio apartment

501
00:27:44,160 --> 00:27:46,450
Some of you may be feeling that pain.

502
00:27:47,940 --> 00:27:50,350
And then there's general-purpose intelligence.

503
00:27:50,730 --> 00:27:53,740
Or something that feels like...

504
00:27:53,950 --> 00:27:56,100
Approaching general-purpose intelligence.

505
00:27:56,440 --> 00:27:59,160
Which is reinforcement,
 and unsupervised learning.

506
00:27:59,880 --> 00:28:03,020
Here with Andrej, from Andrej Karpathy's,
 Pong to Pixels.

507
00:28:03,220 --> 00:28:06,270
A system that takes in,
 80 by 80 pixel image

508
00:28:06,370 --> 00:28:08,910
And with no other information is able to beat,

509
00:28:09,050 --> 00:28:10,080
Is able to win at this game.

510
00:28:10,810 --> 00:28:13,460
No information except
 a sequence of images,

511
00:28:13,550 --> 00:28:15,260
Raw sensory information,

512
00:28:15,310 --> 00:28:17,160
The same way, 
the same kind of information,

513
00:28:17,160 --> 00:28:19,760
That human beings take in, from the visual

514
00:28:19,760 --> 00:28:23,550
Audio, touch, sensory data.

515
00:28:23,560 --> 00:28:26,640
The very low-level data,
 and be able to learn to win.

516
00:28:26,780 --> 00:28:28,320
And it's very simplistic,

517
00:28:28,360 --> 00:28:31,350
And it's very artificially constructed world,

518
00:28:31,440 --> 00:28:32,400
But nevertheless,

519
00:28:32,470 --> 00:28:35,320
A world where no feature learning
 is performed.

520
00:28:35,500 --> 00:28:38,320
Only raw sensory information
 is used to win.

521
00:28:38,710 --> 00:28:41,240
With very sparse minimal human input.

522
00:28:42,500 --> 00:28:45,720
We'll talk about that on Wednesday.

523
00:28:46,860 --> 00:28:48,620
With deep reinforcement learning.

524
00:28:50,140 --> 00:28:53,300
So. But for now we'll focus 
on supervised learning.

525
00:28:54,110 --> 00:28:56,230
Where there is input data,

526
00:28:56,420 --> 00:28:58,950
There is a network we're trying to train,

527
00:28:59,340 --> 00:29:01,650
A learning system, 
and there's a correct output,

528
00:29:01,680 --> 00:29:03,600
That's labeled by human beings.

529
00:29:04,180 --> 00:29:07,220
That's the general training process
 for a neural network.

530
00:29:07,690 --> 00:29:09,560
Input data,  labels...

531
00:29:09,790 --> 00:29:13,220
And the training of that network ,
that model.

532
00:29:13,400 --> 00:29:15,160
So that,  in a testing stage,

533
00:29:15,410 --> 00:29:18,100
A new input data,
 that has never seen before,

534
00:29:18,200 --> 00:29:22,500
It's tasked with producing guesses,
 and is evaluated based on that.

535
00:29:23,040 --> 00:29:25,550
For autonomous vehicles,
 that means being released

536
00:29:25,880 --> 00:29:28,890
Either in simulation,
 or in the real world, to operate.

537
00:29:32,220 --> 00:29:35,190
And how they learn,
 how neural networks learn,

538
00:29:35,250 --> 00:29:37,750
Is given, the forward pass,

539
00:29:37,880 --> 00:29:40,970
Of taking the input data,
whether it's from the training stage

540
00:29:42,120 --> 00:29:44,980
In the training stage,
taking the input data,

541
00:29:44,980 --> 00:29:46,300
Producing a prediction.

542
00:29:46,380 --> 00:29:49,240
And then given that 
there's ground truth in the training stage,

543
00:29:49,240 --> 00:29:53,250
We can have a measure of error,
 based on a loss function.

544
00:29:53,250 --> 00:29:54,800
That then punishes...

545
00:29:55,300 --> 00:29:59,090
The synapses, the connections,
 the parameters,

546
00:29:59,180 --> 00:30:04,960
That were involved with making
 that wrong prediction.

547
00:30:07,280 --> 00:30:10,940
And it back propagates the error, 
through those weights.

548
00:30:11,250 --> 00:30:14,000
We'll discuss that in a little bit  
 more detail, in a bit here...

549
00:30:14,900 --> 00:30:16,550
So what can we do with deep learning?

550
00:30:16,720 --> 00:30:18,490
You can do one-to-one mapping.

551
00:30:18,820 --> 00:30:21,170
Really you can think of input 
as being anything,

552
00:30:21,170 --> 00:30:24,000
It can be a number, a vector of number,
a sequence of numbers

553
00:30:24,000 --> 00:30:26,040
A sequence of vector of numbers...

554
00:30:26,260 --> 00:30:28,450
Anything you can think of,
 from images to video,

555
00:30:28,450 --> 00:30:30,930
To audio, to text 
can be represented in this way.

556
00:30:31,090 --> 00:30:34,640
And the output can, the same,
 be a single number,

557
00:30:34,640 --> 00:30:38,190
Or it can be images, 
 video, text, audio.

558
00:30:38,730 --> 00:30:40,580
One-to-one mapping on the bottom,

559
00:30:40,580 --> 00:30:44,330
One-to-many, many-to-one,
 many to many, and...

560
00:30:44,740 --> 00:30:48,540
Many to many with different
starting points for the data.

561
00:30:49,230 --> 00:30:50,570
Asynchronous.

562
00:30:53,440 --> 00:30:55,370
Some quick terms, that will come up

563
00:30:55,470 --> 00:30:58,380
Deep learning is the same as
neural networks,

564
00:30:59,560 --> 00:31:03,280
It's really deep neural networks,
 large neural networks

565
00:31:03,930 --> 00:31:06,630
It's a subset of machine learning,
 that has been

566
00:31:06,740 --> 00:31:09,970
Extremely successful in the past decade.

567
00:31:10,550 --> 00:31:13,100
Multi-layer perceptron,
deep neural network ,

568
00:31:13,190 --> 00:31:14,600
Recurrent neural network

569
00:31:14,740 --> 00:31:17,450
Long short-term memory network 
LSTM

570
00:31:17,640 --> 00:31:20,480
Convolution neural network and
 deep belief networks,

571
00:31:20,480 --> 00:31:22,460
All of these will come up
to the slides...

572
00:31:24,310 --> 00:31:27,080
And, there is specific operations,

573
00:31:27,080 --> 00:31:28,580
Layers within these networks of

574
00:31:28,580 --> 00:31:31,820
Convolution, pooling, activation, 
and back propagation.

575
00:31:31,940 --> 00:31:33,690
This concept that we'll discuss,

576
00:31:35,090 --> 00:31:36,280
In this class.

577
00:31:36,860 --> 00:31:39,880
Activation functions,
there's a lot of variants.

578
00:31:41,190 --> 00:31:43,900
On the left is the activation function,
the left column,

579
00:31:44,180 --> 00:31:46,210
And the x-axis is the input,

580
00:31:46,210 --> 00:31:48,260
On the y-axis is the output.

581
00:31:49,430 --> 00:31:51,600
The sigmoid function,
 the output.

582
00:31:52,100 --> 00:31:54,810
If the font is too small,
the output is...

583
00:31:54,980 --> 00:31:56,900
Not centered at zero.

584
00:31:58,850 --> 00:32:02,200
For the Tanh function,
 it's centered at zero;

585
00:32:02,200 --> 00:32:04,400
But it still suffers from vanishing gradients.

586
00:32:04,890 --> 00:32:07,390
Vanishing gradients is
 when the value,

587
00:32:07,390 --> 00:32:09,900
The input is low or high.

588
00:32:11,800 --> 00:32:15,640
The output of the network,
 as you see in the right column,

589
00:32:15,640 --> 00:32:18,690
There, the derivative of the function
is very low.

590
00:32:18,900 --> 00:32:20,900
So the learning rate is very low.

591
00:32:22,020 --> 00:32:23,260
For ReLU,

592
00:32:25,720 --> 00:32:28,470
Not, it's also not zero centered,

593
00:32:28,660 --> 00:32:31,300
But it does not suffer from 
vanishing gradients.

594
00:32:32,430 --> 00:32:34,700
Back propagation is
 the process of learning

595
00:32:35,010 --> 00:32:37,140
It's the way we take goal from error,

596
00:32:37,290 --> 00:32:38,860
Compute as the loss function,

597
00:32:38,890 --> 00:32:40,610
At the bottom right of the slide,

598
00:32:40,640 --> 00:32:44,540
Taking the actual output of the network
 with a forward pass,

599
00:32:44,630 --> 00:32:47,900
Subtracting it from the ground truth,

600
00:32:48,060 --> 00:32:49,860
Squaring, dividing by two,

601
00:32:49,960 --> 00:32:53,320
And than using that loss function.
that back propagate,

602
00:32:53,600 --> 00:32:57,030
Through, to construct a gradient,
 to back propagate the error.

603
00:32:57,270 --> 00:32:58,880
To the weights that were responsible,

604
00:32:58,880 --> 00:33:01,510
For making either a correct,
or an incorrect decision.

605
00:33:02,600 --> 00:33:05,120
So the subtasks are there,
 there's a forward pass,

606
00:33:05,220 --> 00:33:07,640
There's a backward pass, 
and...

607
00:33:07,760 --> 00:33:10,460
A fraction of the weight's gradient
subtracted from the weight.

608
00:33:10,620 --> 00:33:11,240
That's it!

609
00:33:11,740 --> 00:33:14,780
That process is modular,

610
00:33:14,780 --> 00:33:17,000
So it's local 
to each individual neuron,

611
00:33:17,080 --> 00:33:18,760
Which is why it's extremely,...

612
00:33:18,800 --> 00:33:23,290
We're able to distribute it 
across multiple,

613
00:33:25,790 --> 00:33:28,700
Across the GPU. 
Parallelize across the GPU.

614
00:33:31,060 --> 00:33:34,380
So, learning for a neural network,

615
00:33:34,770 --> 00:33:36,990
These competition units 
are extremely simple.

616
00:33:37,060 --> 00:33:39,200
They're extremely simple to then...

617
00:33:39,360 --> 00:33:41,180
Correct when they make an error,
when they're

618
00:33:41,180 --> 00:33:43,150
Part of a  larger network,
that makes an error.

619
00:33:43,570 --> 00:33:45,320
And, all that boils down to,

620
00:33:45,320 --> 00:33:47,150
Is essentially an optimization problem.

621
00:33:47,180 --> 00:33:50,240
Where the objective,
utility, function is

622
00:33:50,290 --> 00:33:53,290
The loss function, 
and the goal is to minimize it.

623
00:33:53,540 --> 00:33:55,020
And we have to
 update the parameters

624
00:33:55,020 --> 00:33:56,590
The weights, and the synapses,

625
00:33:56,700 --> 00:33:59,200
And the biases to decrease that loss function.

626
00:34:01,880 --> 00:34:04,150
And that loss function is
 highly nonlinear.

627
00:34:06,570 --> 00:34:09,000
Depending on the activation function's 
different properties,

628
00:34:09,000 --> 00:34:10,270
Different issues arise.

629
00:34:10,380 --> 00:34:13,900
There's vanishing gradients,
for sigmoid.

630
00:34:15,330 --> 00:34:17,200
Where the learning can be slow

631
00:34:18,260 --> 00:34:19,860
There's dying ReLU's...

632
00:34:21,500 --> 00:34:24,060
Where the derivative is exactly zero,

633
00:34:24,650 --> 00:34:27,350
For inputs less than zero.

634
00:34:28,430 --> 00:34:30,880
There are solutions to this,
 like leaky ReLU's

635
00:34:30,880 --> 00:34:33,420
And a bunch of details,
 you may discover

636
00:34:33,420 --> 00:34:36,090
When you try to win 
the deep traffic competition

637
00:34:36,380 --> 00:34:37,770
But, for the most part

638
00:34:37,770 --> 00:34:39,880
These are the main 
activation functions

639
00:34:40,480 --> 00:34:45,340
And it's the choice
of the neural network designer

640
00:34:45,340 --> 00:34:47,100
Which one works best...

641
00:34:48,030 --> 00:34:50,160
There's saddle points,
 all the problems

642
00:34:50,160 --> 00:34:52,430
From your miracle,
non-linear optimization

643
00:34:52,430 --> 00:34:54,690
That arise, come up here.

644
00:34:56,460 --> 00:34:58,270
It's hard to break symmetry,

645
00:34:58,950 --> 00:35:01,600
And stochastic gradient descent

646
00:35:02,020 --> 00:35:04,450
Wthout any kind of tricks to it,

647
00:35:04,800 --> 00:35:07,400
Can take a very long time,
to arrive at the minima

648
00:35:09,400 --> 00:35:12,690
One of the biggest problems
in all of machine learning

649
00:35:12,690 --> 00:35:15,100
And certainly deep learning,
 is overfitting

650
00:35:15,720 --> 00:35:18,050
You can think of the blue dots
 and a plot here

651
00:35:18,050 --> 00:35:21,200
As the data, to which we want
 to fit a curve

652
00:35:22,720 --> 00:35:26,100
We want to design a learning system
 that approximates

653
00:35:26,350 --> 00:35:28,720
The regression of this data.

654
00:35:29,460 --> 00:35:32,900
So, in green, is a sine curve

655
00:35:32,900 --> 00:35:34,890
Simple. Fits well.

656
00:35:35,450 --> 00:35:37,880
And then, there's 
a ninth degree polynomial

657
00:35:37,880 --> 00:35:40,880
Which fits even better,
in terms of the error

658
00:35:40,880 --> 00:35:43,370
But it clearly overfits this data

659
00:35:43,370 --> 00:35:45,760
If there's other data

660
00:35:46,700 --> 00:35:49,260
That it has not seen yet
that it has to fit

661
00:35:49,440 --> 00:35:51,410
It's likely to produce a high error

662
00:35:51,410 --> 00:35:53,440
So it's overfitting the training set

663
00:35:54,000 --> 00:35:56,860
This is a big problem
for small data sets

664
00:35:57,710 --> 00:36:00,400
And so we have to fix that,
with regularization

665
00:36:00,800 --> 00:36:03,260
Regularization is a set of methodologies

666
00:36:03,260 --> 00:36:04,760
That prevent overfitting

667
00:36:05,640 --> 00:36:08,650
Learning the training too well, 
in order

668
00:36:08,660 --> 00:36:10,630
And then to
not be able to generalize

669
00:36:10,630 --> 00:36:12,500
To the testing stage

670
00:36:14,450 --> 00:36:16,740
And overfitting,
the main symptom

671
00:36:16,920 --> 00:36:18,920
Is the error decreases
 in training set

672
00:36:18,920 --> 00:36:20,620
But increases in the test set.

673
00:36:22,440 --> 00:36:25,050
So there's a lot of techniques
and traditional machine learning

674
00:36:25,050 --> 00:36:27,360
That deal with this;
Cross validation, and so on...

675
00:36:27,360 --> 00:36:29,470
But because of the cost of training

676
00:36:29,470 --> 00:36:30,740
for neural networks

677
00:36:31,130 --> 00:36:35,170
Its traditional to use
what's called a validation set

678
00:36:35,620 --> 00:36:37,830
So you create a subset of the training

679
00:36:38,200 --> 00:36:39,990
That you keep away

680
00:36:39,990 --> 00:36:41,500
For which you have
the ground truth

681
00:36:41,840 --> 00:36:45,720
And use that, as a representative
 of the testing set.

682
00:36:46,020 --> 00:36:47,000
So you...

683
00:36:47,580 --> 00:36:49,870
Perform early stoppage,
or more realistically

684
00:36:49,870 --> 00:36:52,680
Just save a checkpoint.
Often.

685
00:36:53,770 --> 00:36:56,870
To see how, as the training evolves,

686
00:36:57,270 --> 00:37:01,320
The performance changes
on the validation set,

687
00:37:01,650 --> 00:37:03,560
And so you can stop,
when the performance

688
00:37:03,560 --> 00:37:05,680
In the validation set is
getting a lot worse

689
00:37:05,770 --> 00:37:08,400
It means you're overtraining
on the training set.

690
00:37:11,830 --> 00:37:13,350
In practice, of course,

691
00:37:13,350 --> 00:37:15,120
We run training much longer

692
00:37:15,120 --> 00:37:18,660
And see when,
 what is the best performing

693
00:37:18,950 --> 00:37:21,360
What is the best performing

694
00:37:21,360 --> 00:37:23,310
Snapshot checkpoint of the network?

695
00:37:24,370 --> 00:37:28,190
Dropout, is another very powerful
regularization technique.

696
00:37:28,480 --> 00:37:30,880
Where we randomly remove
part of the network

697
00:37:31,100 --> 00:37:34,140
Randomly remove some of the nodes
in the network

698
00:37:34,840 --> 00:37:37,990
Along, with it's incoming
and outgoing edges

699
00:37:38,450 --> 00:37:39,720
So what that really looks like,

700
00:37:39,720 --> 00:37:42,100
Is a probability of keeping a node.

701
00:37:42,720 --> 00:37:45,170
And in many deep learning 
frameworks today

702
00:37:45,880 --> 00:37:47,590
It comes with a dropout layer

703
00:37:47,630 --> 00:37:49,350
So it's essentially a probability

704
00:37:49,400 --> 00:37:51,550
That's usually greater than 0.5

705
00:37:51,650 --> 00:37:54,200
That a node will be kept.

706
00:37:54,840 --> 00:37:56,210
For the input layer

707
00:37:56,210 --> 00:37:58,530
The probability should be much higher,

708
00:37:58,530 --> 00:38:02,050
Or, more effectively,
what works well is just adding noise

709
00:38:02,140 --> 00:38:03,660
What's the point here?

710
00:38:03,880 --> 00:38:08,400
You want to create enough diversity
in the training data

711
00:38:08,410 --> 00:38:11,550
Such that it is generalizable,
 to the testing.

712
00:38:13,520 --> 00:38:15,670
And as you'll see with
 deep traffic competition,

713
00:38:15,670 --> 00:38:17,870
There's L2 and L1 penalty,

714
00:38:18,040 --> 00:38:20,000
Weight decay, weight penalty

715
00:38:20,460 --> 00:38:24,980
Where, there's a penalisation 
on the weights that get too large

716
00:38:24,980 --> 00:38:27,340
The L2 penalty keeps the weight small

717
00:38:27,340 --> 00:38:29,600
Unless the error derivative is huge

718
00:38:30,520 --> 00:38:32,350
And produces a smoother model,

719
00:38:32,350 --> 00:38:37,350
And prefers to distribute
When there is two similar inputs

720
00:38:37,350 --> 00:38:39,840
It prefers to put 
half the weights on each

721
00:38:39,840 --> 00:38:41,200
Distribute the weights

722
00:38:41,200 --> 00:38:43,900
As opposed to putting the weight
on one of the edges.

723
00:38:45,240 --> 00:38:47,280
Makes the network more robust

724
00:38:47,830 --> 00:38:49,740
L1 penalty has the one benefit

725
00:38:49,740 --> 00:38:51,750
That, for really large weights

726
00:38:52,040 --> 00:38:54,080
They're allowed to be, to stay.

727
00:38:54,410 --> 00:38:57,340
So it allows for a few weights
to remain very large.

728
00:38:57,700 --> 00:38:59,700
These are the regularization techniques

729
00:38:59,800 --> 00:39:01,820
And I wanted to mention them
because they're useful

730
00:39:01,820 --> 00:39:03,950
To some of the competitions,
here in the course.

731
00:39:04,340 --> 00:39:06,720
And I recommend to go to
playground

732
00:39:06,720 --> 00:39:08,470
To tensorflow playground

733
00:39:08,770 --> 00:39:10,890
To play around with
some of these parameters

734
00:39:11,600 --> 00:39:14,120
Where you get to,
online in the browser

735
00:39:14,320 --> 00:39:17,080
Play around with different inputs,
different features

736
00:39:17,080 --> 00:39:20,000
Different number of layers,
and regularization techniques

737
00:39:20,150 --> 00:39:22,880
And to build your intuition
about classification

738
00:39:22,880 --> 00:39:26,220
Regression problems,
 given different input data sets.

739
00:39:28,950 --> 00:39:33,600
So what changed? Why over 
the past many decades

740
00:39:34,120 --> 00:39:37,490
Neural networks that have gone
through two winters

741
00:39:37,690 --> 00:39:39,000
Are now again

742
00:39:39,000 --> 00:39:41,860
Dominating the artificial intelligence
 community

743
00:39:42,620 --> 00:39:45,870
CPUs, GPUs, ASICs,

744
00:39:45,870 --> 00:39:48,340
So, computational power
 has skyrocketed

745
00:39:48,870 --> 00:39:51,300
From Moore's law to GPUs

746
00:39:52,800 --> 00:39:57,200
There is huge data set,
 including ImageNet, and others

747
00:39:58,800 --> 00:40:02,450
There is research;
 Back propagation

748
00:40:02,800 --> 00:40:08,340
In the 80's,
The convolutional neural networks

749
00:40:08,340 --> 00:40:12,240
LSTMs, there's been a lot of
interesting breakthroughs

750
00:40:12,240 --> 00:40:14,450
About how to design these architectures

751
00:40:14,450 --> 00:40:17,300
How to build them, such that
 they're trainable efficiently

752
00:40:17,300 --> 00:40:18,900
Using GPUs.

753
00:40:20,400 --> 00:40:22,400
There is the software infrastructure

754
00:40:22,400 --> 00:40:24,660
From being able to share the data,
or get;

755
00:40:24,990 --> 00:40:28,310
To being able to train networks,
and share code

756
00:40:28,310 --> 00:40:33,000
And effectively view neural networks
 as a stack of layers

757
00:40:33,000 --> 00:40:35,450
As opposed to having to
implement stuff from scratch

758
00:40:35,450 --> 00:40:39,250
With TensorFlow, PyTorch and 
other deep learning frameworks

759
00:40:39,350 --> 00:40:42,960
And there's huge financial backing
from Google, Facebook, and so on...

760
00:40:46,000 --> 00:40:47,360
Deep learning...

761
00:40:49,800 --> 00:40:50,800
..is...

762
00:40:51,320 --> 00:40:56,270
In order to understand,
why it works so well

763
00:40:56,270 --> 00:40:58,000
And where it's limitations are...

764
00:40:58,000 --> 00:41:00,700
We need to understand
where our own intuition comes from

765
00:41:00,700 --> 00:41:02,550
About what is hard,
 and what is easy

766
00:41:03,000 --> 00:41:04,920
The important thing
 about computer vision

767
00:41:04,920 --> 00:41:06,760
Which is a lot of 
what this course is about

768
00:41:06,760 --> 00:41:09,690
Even in deep reinforcement 
learning formulation

769
00:41:10,220 --> 00:41:13,590
Is that visual perception
for us human beings

770
00:41:13,590 --> 00:41:17,270
Was formed 540 million years ago

771
00:41:17,370 --> 00:41:21,950
That's 540 million years 
worth of data

772
00:41:23,210 --> 00:41:24,660
An abstract thought

773
00:41:24,660 --> 00:41:27,420
Is only formed about 
a 100 thousand years ago

774
00:41:28,750 --> 00:41:31,450
That's several orders of magnitude less data

775
00:41:32,220 --> 00:41:34,690
So we can make,
 with the neural networks

776
00:41:34,800 --> 00:41:38,750
Predictions that seemed trivial

777
00:41:40,440 --> 00:41:43,450
Trivial to us human beings

778
00:41:43,650 --> 00:41:48,540
But completely challenging and wrong
to neural networks

779
00:41:48,540 --> 00:41:51,780
Here, on the left,
showing a prediction of a dog

780
00:41:51,800 --> 00:41:54,850
With a little bit of a distortion and noise
 added to the image

781
00:41:54,850 --> 00:41:56,350
Producing the image on the right

782
00:41:56,350 --> 00:41:58,680
And your network is confidently

783
00:41:58,800 --> 00:42:03,040
99 percent plus accuracy,
Predicting that it's an ostrich

784
00:42:05,650 --> 00:42:07,880
And there's all these problems
 to deal with

785
00:42:07,880 --> 00:42:09,930
Whether it's in computer vision data,

786
00:42:09,930 --> 00:42:12,150
Whether it's in text data, audio...

787
00:42:12,150 --> 00:42:15,280
All of this variation arises

788
00:42:15,280 --> 00:42:18,060
In vision,
It's illumination variability

789
00:42:18,550 --> 00:42:21,350
The set of pixels and the numbers
 look completely different

790
00:42:21,350 --> 00:42:22,980
Depending on the lighting conditions

791
00:42:22,980 --> 00:42:24,900
It's the biggest problem in driving

792
00:42:24,900 --> 00:42:27,900
Is, lighting conditions,
lighting variability.

793
00:42:28,080 --> 00:42:29,720
Pose variation

794
00:42:29,850 --> 00:42:33,120
Objects need to be learned from
every different perspective

795
00:42:33,120 --> 00:42:36,000
I'll discuss that for 
when sensing the driver

796
00:42:36,000 --> 00:42:36,840
Most of....

797
00:42:36,840 --> 00:42:40,250
Most of the deep learning work
 that's done in the face

798
00:42:40,250 --> 00:42:43,350
On the human,
 is done on the frontal face

799
00:42:43,350 --> 00:42:44,900
Or semi frontal face.

800
00:42:44,900 --> 00:42:50,160
There's very little work done
 on the full 360 pose

801
00:42:50,160 --> 00:42:52,550
Variability that a human being
could take on.

802
00:42:55,200 --> 00:42:58,300
Intraclass variability
for the classification problem,

803
00:42:58,300 --> 00:42:59,750
For the detection problem...

804
00:42:59,850 --> 00:43:02,120
There is a lot of different
kinds of objects

805
00:43:02,120 --> 00:43:05,370
For cats, dogs, cars,
bicyclists, pedestrians.

806
00:43:07,170 --> 00:43:09,580
So that brings us
to object classification.

807
00:43:09,700 --> 00:43:13,580
And I'd like to take you through
 where deep learning

808
00:43:13,720 --> 00:43:16,830
Has taken big strides
for the past several years

809
00:43:16,830 --> 00:43:19,840
Leading up to this year, to 2018

810
00:43:20,900 --> 00:43:24,200
So let's start at
object classification

811
00:43:24,200 --> 00:43:26,700
Is when you take a single image,

812
00:43:26,700 --> 00:43:28,400
And you have to say...

813
00:43:28,450 --> 00:43:32,300
One class, that's most likely
to belong in that image.

814
00:43:32,950 --> 00:43:36,360
The most famous variant of that
 is the ImageNet competition

815
00:43:36,360 --> 00:43:37,450
ImageNet challenge.

816
00:43:37,450 --> 00:43:40,680
ImageNet data set is a data set
 of 14 million images

817
00:43:40,680 --> 00:43:42,800
With 21,000 categories

818
00:43:43,000 --> 00:43:46,200
And... 
For, say, the category of fruit

819
00:43:46,200 --> 00:43:50,770
There's a total of 
188,000 images of fruit

820
00:43:50,950 --> 00:43:54,400
And there is 1200 images 
of Granny Smith apples.

821
00:43:54,400 --> 00:43:57,100
It gives you a sense, of what
 we're talking about here

822
00:43:58,350 --> 00:44:00,990
So this has been, the source

823
00:44:00,990 --> 00:44:04,080
Of a lot of interesting breakthroughs
in deep learning

824
00:44:04,080 --> 00:44:06,920
And a lot of the excitement,
 in deep learning

825
00:44:07,250 --> 00:44:10,020
It's first,
the big successful network

826
00:44:10,200 --> 00:44:13,500
At least, one that became famous

827
00:44:13,900 --> 00:44:17,080
In deep learning is AlexNet in 2012

828
00:44:17,080 --> 00:44:19,410
That took a leap of...

829
00:44:19,700 --> 00:44:23,000
A significant leap in performance
on the ImageNet challenge.

830
00:44:23,750 --> 00:44:25,880
So it was one of the first neural networks

831
00:44:25,880 --> 00:44:28,080
That was successfully trained
on the GPU

832
00:44:28,080 --> 00:44:30,680
And achieved an incredible
performance boost

833
00:44:30,680 --> 00:44:33,490
Over the previous year
on the ImageNet challenge.

834
00:44:33,700 --> 00:44:35,200
The challenge is:

835
00:44:35,250 --> 00:44:37,200
...and I'll talk about some of these networks...

836
00:44:37,200 --> 00:44:40,760
It's to given a single image,
give five guesses,

837
00:44:40,760 --> 00:44:43,360
And you have five guesses to guess

838
00:44:43,360 --> 00:44:45,300
For one of them to be correct

839
00:44:46,400 --> 00:44:48,880
The human annotation is a question
 often comes up

840
00:44:48,880 --> 00:44:50,550
So how do you know the ground truth?

841
00:44:51,080 --> 00:44:55,750
Human level performance is 
5.1 percent accuracy, on this task.

842
00:44:57,060 --> 00:45:01,840
But, the way the annotation 
for ImageNet is performed, is

843
00:45:01,840 --> 00:45:05,060
There's a Google search,
 where you pull the images

844
00:45:05,060 --> 00:45:08,300
Already labeled for you,
 and then the annotation that

845
00:45:08,300 --> 00:45:10,700
Mechanical Turk, other humans perform

846
00:45:10,700 --> 00:45:13,180
Is just binary: 
Is this a cat, or not a cat

847
00:45:13,580 --> 00:45:15,420
So they're not tasked with performing

848
00:45:15,420 --> 00:45:20,060
The very high-resolution semantic
 labeling of the image.

849
00:45:21,780 --> 00:45:26,230
Okay. So, through, 
from 2012 with AlexNet, to today

850
00:45:27,200 --> 00:45:31,250
And the big transition in 2018
 of the ImageNet challenge

851
00:45:31,250 --> 00:45:33,600
Leaving Stanford and going to Kaggle.

852
00:45:35,140 --> 00:45:37,060
It's sort of a monumental step

853
00:45:37,060 --> 00:45:40,000
Because in 2015 with the ResNet network

854
00:45:40,000 --> 00:45:41,450
Was the first time

855
00:45:41,450 --> 00:45:43,990
That the human level performance 
was exceeded

856
00:45:44,200 --> 00:45:49,500
And I think this is, 
a very important

857
00:45:51,410 --> 00:45:53,800
Map of where deep learning is.

858
00:45:53,800 --> 00:45:56,590
For particularly what I would argue
is a toy example

859
00:45:56,590 --> 00:45:59,400
Despite the fact that it's 14 million images

860
00:45:59,850 --> 00:46:02,800
So we're developing 
state-of-the-art techniques here

861
00:46:02,800 --> 00:46:05,480
And in next stage,
as we are now exceeding

862
00:46:05,480 --> 00:46:07,500
Human level performance, on this task

863
00:46:07,570 --> 00:46:10,450
Is how to take these methods
into the real world.

864
00:46:10,450 --> 00:46:15,450
To perform scene perception,
 to perform driver state perception.

865
00:46:18,400 --> 00:46:21,800
In 2016, and 2017

866
00:46:22,050 --> 00:46:26,160
CUImage and SENnet has
a very unique new addition

867
00:46:26,160 --> 00:46:28,890
To the previous formulations
that has achieved

868
00:46:28,890 --> 00:46:31,950
An accuracy of 2.2 percent error

869
00:46:32,400 --> 00:46:36,550
2.25 percent error on the 
ImageNet classification challenge.

870
00:46:36,600 --> 00:46:38,060
It's an incredible result.

871
00:46:38,450 --> 00:46:41,750
Ok, so you have this
image classification architecture

872
00:46:42,000 --> 00:46:45,620
That takes in a single image,
and produces convolution

873
00:46:45,620 --> 00:46:49,450
And takes it through pooling convolution,
and at the end

874
00:46:49,450 --> 00:46:51,230
Fully connected layers and performs

875
00:46:51,230 --> 00:46:53,350
A classification task,
or regression task.

876
00:46:53,350 --> 00:46:58,750
And you can swap out that layer
to perform any kind of other task

877
00:46:59,000 --> 00:47:01,550
Including with
recurrent neural networks of

878
00:47:01,550 --> 00:47:03,450
Image captioning, and so on...

879
00:47:03,450 --> 00:47:05,840
Or localization of bounding boxes

880
00:47:05,980 --> 00:47:09,500
Or, you can do
 fully convolutional networks

881
00:47:09,500 --> 00:47:12,680
Which we'll talk about on Thursday

882
00:47:13,050 --> 00:47:16,790
Which is when you take an image
 as an input,

883
00:47:16,790 --> 00:47:18,430
And produce an image as an output.

884
00:47:18,560 --> 00:47:21,640
But where the output image, 
 in this case,is a segmentation.

885
00:47:22,140 --> 00:47:26,300
Is, where a color indicates
what the object is.

886
00:47:26,350 --> 00:47:28,650
The category of the object.

887
00:47:28,700 --> 00:47:30,160
So it's pixel level segmentation,

888
00:47:30,160 --> 00:47:32,340
Every single pixel in the image
 is assigned,

889
00:47:32,380 --> 00:47:36,350
A class, a category,
where that pixel belongs to.

890
00:47:37,350 --> 00:47:40,490
This is, the kind of task,

891
00:47:40,600 --> 00:47:45,040
That's overlaid on top of 
other sensory information,

892
00:47:45,040 --> 00:47:46,900
Coming for the car in order to

893
00:47:46,900 --> 00:47:50,090
Perceive the external environment

894
00:47:50,240 --> 00:47:52,920
You can continue to extract information

895
00:47:52,920 --> 00:47:54,230
From images in this way

896
00:47:54,230 --> 00:47:55,950
To produce image to image mapping

897
00:47:55,980 --> 00:47:58,050
For example to colorize images

898
00:47:58,200 --> 00:48:00,900
And take from grayscale images
to color images

899
00:48:04,100 --> 00:48:06,850
Or you can use that kind of 
heat map information

900
00:48:06,850 --> 00:48:08,780
To localize objects in the image

901
00:48:09,020 --> 00:48:12,920
So as opposed to just classifying
that this is an image of a cow

902
00:48:13,080 --> 00:48:16,440
R-CNN, Fast and Faster R-CNN,

903
00:48:16,500 --> 00:48:18,900
And a lot of other localization networks

904
00:48:19,110 --> 00:48:22,010
Allow you to propose different candidates

905
00:48:22,010 --> 00:48:25,020
For where exactly the cow
is located in this image

906
00:48:25,120 --> 00:48:27,700
And thereby being able 
to perform object detection

907
00:48:27,700 --> 00:48:29,500
Not just object classification.

908
00:48:32,440 --> 00:48:35,890
In 2017 there has been
a lot of cool applications

909
00:48:35,890 --> 00:48:37,350
Of these architectures

910
00:48:37,550 --> 00:48:39,600
One of which is background removal

911
00:48:40,260 --> 00:48:42,300
Again mapping from image to image

912
00:48:42,350 --> 00:48:46,150
Ability to remove
 background from selfies

913
00:48:46,450 --> 00:48:52,540
Of humans or human-like
 pictures of faces

914
00:48:53,950 --> 00:48:58,170
The reference is,
with some incredible animations,

915
00:48:58,170 --> 00:48:59,780
Are in the bottom of the slide,

916
00:48:59,880 --> 00:49:01,850
And the slides are now available online

917
00:49:04,900 --> 00:49:06,950
Pix2pixHD

918
00:49:07,950 --> 00:49:10,610
There's been a lot of work in GANs

919
00:49:10,930 --> 00:49:15,650
In Generative Adversarial Networks
In particular in driving

920
00:49:16,800 --> 00:49:20,220
GANs have been used to generate examples

921
00:49:20,220 --> 00:49:24,560
That generate examples
from source data

922
00:49:24,560 --> 00:49:26,110
Whether that's from raw data

923
00:49:26,110 --> 00:49:28,150
Or in this case with pix2pixHD

924
00:49:28,150 --> 00:49:33,010
Is taking coarse semantic labeling
 of the images

925
00:49:33,010 --> 00:49:35,400
Pixel level, and producing

926
00:49:35,700 --> 00:49:40,750
Photorealistic, high-definition
images of the forward roadway

927
00:49:40,900 --> 00:49:44,200
This is an exciting possibility

928
00:49:44,300 --> 00:49:45,740
For being able to generate

929
00:49:45,740 --> 00:49:48,450
A variety of cases
 for self-driving cars

930
00:49:48,560 --> 00:49:50,650
For autonomous vehicles
to be able to learn

931
00:49:50,650 --> 00:49:52,550
To generate, to augment the data

932
00:49:52,750 --> 00:49:55,160
And be able to change the way
different roads look

933
00:49:55,160 --> 00:49:56,200
Road conditions,

934
00:49:56,200 --> 00:49:59,200
To change the way vehicles look
cyclists, pedestrians.

935
00:50:00,400 --> 00:50:02,550
Then we can move on to
recurrent neural networks

936
00:50:02,550 --> 00:50:06,000
Everything I've talked about
was one-to-one mapping

937
00:50:06,000 --> 00:50:08,250
From image to image,
or image to number

938
00:50:08,250 --> 00:50:11,000
Recurrent neural networks
work with sequences

939
00:50:11,350 --> 00:50:15,900
We can use sequences
to generate handwriting

940
00:50:18,900 --> 00:50:22,800
To generate text captions
 from an image

941
00:50:23,280 --> 00:50:26,600
Based on the localization,
as the various detections, in that image.

942
00:50:28,340 --> 00:50:32,200
We can provide
video description generation

943
00:50:32,200 --> 00:50:33,850
So taking a video

944
00:50:34,150 --> 00:50:36,300
And combining
convolutional neural networks

945
00:50:36,300 --> 00:50:37,800
With recurrent neural networks

946
00:50:37,800 --> 00:50:40,550
Using convolutional neural networks
 to extract features

947
00:50:40,550 --> 00:50:41,540
Frame to frame

948
00:50:41,640 --> 00:50:43,700
And using those extracted features

949
00:50:43,900 --> 00:50:49,950
To input into our RDRN ends,
to then generate labeling

950
00:50:50,100 --> 00:50:52,750
A description of what's 
going on in the video

951
00:50:54,850 --> 00:50:57,750
A lot of exciting approaches
for autonomous systems

952
00:50:57,750 --> 00:50:59,650
Especially in drones

953
00:50:59,950 --> 00:51:04,650
Where the time
to make a decision is short

954
00:51:04,650 --> 00:51:07,450
Same with the RC car
traveling 30 miles an hour

955
00:51:07,650 --> 00:51:09,400
Attentional mechanisms

956
00:51:09,400 --> 00:51:11,220
For steering the attention
of the network

957
00:51:11,370 --> 00:51:12,750
Have been very popular

958
00:51:12,880 --> 00:51:16,520
For the localization tasks
and for just saving

959
00:51:16,520 --> 00:51:18,470
How much interpretation of the image

960
00:51:18,470 --> 00:51:20,110
How many pixels
 need to be considered

961
00:51:20,110 --> 00:51:21,400
In the classification task

962
00:51:22,800 --> 00:51:25,850
So we can steer,
we can model the way

963
00:51:25,850 --> 00:51:27,950
A human being looks
around an image

964
00:51:27,950 --> 00:51:28,650
To interpret it

965
00:51:28,650 --> 00:51:30,250
And use the network
to do the same.

966
00:51:30,850 --> 00:51:32,850
And we can use
that kind of steering

967
00:51:33,500 --> 00:51:35,890
To draw images, as well.

968
00:51:41,600 --> 00:51:44,200
Finally the big breakthroughs in 2017

969
00:51:44,300 --> 00:51:48,450
Came from this Pong to Pixels

970
00:51:48,450 --> 00:51:51,520
The reinforcement learning
using sensory data

971
00:51:51,520 --> 00:51:52,650
Raw sensory data

972
00:51:52,760 --> 00:51:54,650
And use reinforcement learning methods

973
00:51:54,700 --> 00:51:57,500
Deep are all methods of which
we'll talk about on Wednesday

974
00:51:57,500 --> 00:51:59,000
I'm really excited about...

975
00:51:59,170 --> 00:52:02,900
The underlying methodology of
deep traffic, and deep crash

976
00:52:03,050 --> 00:52:09,000
Is using neural networks
 as the approximators

977
00:52:09,270 --> 00:52:11,750
Inside reinforcement learning approaches.

978
00:52:12,000 --> 00:52:14,530
So AlphaGo in 2016,
 have achieved

979
00:52:14,530 --> 00:52:16,200
a monumental task.

980
00:52:16,930 --> 00:52:19,000
That when I first started
in artificial intelligence

981
00:52:19,000 --> 00:52:22,420
Was told to me is impossible
for a system to accomplish

982
00:52:22,520 --> 00:52:25,120
Which is to win at the game of Go

983
00:52:25,120 --> 00:52:27,400
Against the top human player
 in the world.

984
00:52:29,240 --> 00:52:33,350
However that method was trained
on human expert positions

985
00:52:34,000 --> 00:52:37,550
The Alphago system, 
was trained on previous games

986
00:52:37,550 --> 00:52:38,990
Played by human experts.

987
00:52:39,650 --> 00:52:42,100
And in an incredible accomplishment

988
00:52:43,010 --> 00:52:45,400
AlphaGo Zero in 2017

989
00:52:46,250 --> 00:52:49,180
Was able to beat AlphaGo,

990
00:52:49,180 --> 00:52:50,850
And many of it's variants

991
00:52:52,500 --> 00:52:57,100
By playing itself,
from zero information 

992
00:52:58,300 --> 00:53:01,150
So no knowledge of human experts

993
00:53:01,800 --> 00:53:06,880
No games, no training data
very little human input

994
00:53:08,270 --> 00:53:10,520
And what more, it was able to generate

995
00:53:10,950 --> 00:53:13,800
Moves, that were surprising
to human experts.

996
00:53:15,300 --> 00:53:19,450
I think it's Einstein
that said that intelligence

997
00:53:19,950 --> 00:53:22,750
That the key mark of intelligence
is imagination.

998
00:53:23,820 --> 00:53:27,150
I think it's beautiful to see
an artificial intelligence system

999
00:53:27,150 --> 00:53:30,550
Come up with something
that surprises human experts

1000
00:53:31,700 --> 00:53:33,000
Truly surprises...

1001
00:53:36,100 --> 00:53:38,750
For the gambling junkies,
DeepStack

1002
00:53:38,850 --> 00:53:40,400
And a few other variants

1003
00:53:40,900 --> 00:53:44,750
Have been used in 2017
to win a heads-up poker.

1004
00:53:45,250 --> 00:53:47,200
Again another incredible result!

1005
00:53:47,380 --> 00:53:50,350
I was always told an artificial intelligence
would be impossible

1006
00:53:50,350 --> 00:53:50,830
For Deep,

1007
00:53:50,830 --> 00:53:53,780
For any machine learning method
 to achieve

1008
00:53:54,500 --> 00:53:56,500
And was able to beat
a professional player

1009
00:53:56,560 --> 00:53:59,950
And several competitors 
have come along since

1010
00:54:00,650 --> 00:54:02,240
We're yet to be able to beat

1011
00:54:02,240 --> 00:54:05,040
To win, in a tournament setting,
so multiple players

1012
00:54:05,040 --> 00:54:07,500
For those unfamiliar
 heads-up poker is one-on-one.

1013
00:54:07,720 --> 00:54:12,200
It's a much much smaller,
easier space to solve.

1014
00:54:12,600 --> 00:54:15,200
There's a lot more human-to-human
 dynamics going on,

1015
00:54:15,350 --> 00:54:16,950
For when there's multiple players.

1016
00:54:17,100 --> 00:54:19,200
But that's the task for 2018

1017
00:54:21,940 --> 00:54:25,320
And the drawbacks!
It's one of my favorite videos

1018
00:54:25,900 --> 00:54:28,900
I show it often, of Coast runners.

1019
00:54:29,550 --> 00:54:32,000
For these deep reinforcement learning 
approaches

1020
00:54:32,050 --> 00:54:35,700
The learning of the reward function

1021
00:54:35,850 --> 00:54:37,910
The definition of the reward function

1022
00:54:38,020 --> 00:54:42,620
Controls how
 the actual system behaves

1023
00:54:42,850 --> 00:54:44,100
And this will come...

1024
00:54:44,850 --> 00:54:47,620
This would be extremely important for us,
with autonomous vehicles

1025
00:54:48,580 --> 00:54:50,850
Here the boat is tasked with

1026
00:54:50,850 --> 00:54:53,620
Gaining the highest number of points,

1027
00:54:53,850 --> 00:54:56,540
And it figures out that it
does not need to race,

1028
00:54:56,540 --> 00:54:58,080
Which is the whole point 
of the game,

1029
00:54:58,300 --> 00:54:59,450
In order to gain points

1030
00:54:59,450 --> 00:55:02,630
But instead, pick up green circles

1031
00:55:02,630 --> 00:55:05,080
That regenerate themselves,
over and over.

1032
00:55:05,880 --> 00:55:06,920
This is the...

1033
00:55:07,400 --> 00:55:11,590
The counterintuitive behavior
of a system

1034
00:55:11,850 --> 00:55:15,110
That would not be expected

1035
00:55:15,110 --> 00:55:16,950
When you first designed
the reward function

1036
00:55:17,110 --> 00:55:19,460
And this is
 a very formal simple system

1037
00:55:19,550 --> 00:55:20,710
Nevertheless

1038
00:55:20,920 --> 00:55:24,750
Is extremely difficult to come up
with a reward  function

1039
00:55:24,900 --> 00:55:27,450
That makes it operate in the way
you expect it to operate

1040
00:55:27,820 --> 00:55:30,980
Very applicable for autonomous vehicles

1041
00:55:31,300 --> 00:55:33,340
Of course in the perception side

1042
00:55:33,420 --> 00:55:35,550
As I and mentioned with
the ostrich and the dog

1043
00:55:36,260 --> 00:55:40,160
A little bit of noise,
with 99.6 percent confidence

1044
00:55:40,160 --> 00:55:41,300
We can predict

1045
00:55:41,400 --> 00:55:44,120
That the noise up top is
a robbing, a cheetah,

1046
00:55:44,120 --> 00:55:45,820
Armadillo, lesser Panda...

1047
00:55:45,820 --> 00:55:49,500
These are outputs from actual 
state-of-the-art neural networks

1048
00:55:51,650 --> 00:55:54,800
Taking in the noise, and
producing a confident prediction

1049
00:55:55,800 --> 00:55:59,020
It should build our intuition,
to understand that we don't

1050
00:55:59,020 --> 00:56:01,050
That the visual characteristics,

1051
00:56:01,050 --> 00:56:04,360
The spatial characteristics of an image

1052
00:56:04,360 --> 00:56:07,480
Did not necessarily convey
the level of hierarchy

1053
00:56:07,480 --> 00:56:09,610
Necessary to function in this world.

1054
00:56:12,100 --> 00:56:15,210
In a similar way,
with a dog and the ostrich

1055
00:56:15,350 --> 00:56:16,950
And everything and an ostrich

1056
00:56:16,950 --> 00:56:20,350
Network confidently,
with a little bit of noise

1057
00:56:20,350 --> 00:56:22,000
Can make the wrong prediction

1058
00:56:22,550 --> 00:56:24,950
Thinking that school bus,
is an ostrich

1059
00:56:25,280 --> 00:56:27,050
And a speaker is an ostrich

1060
00:56:29,100 --> 00:56:33,350
They're easily fooled
But not really...

1061
00:56:33,500 --> 00:56:37,140
Because they perform the task 
that they were trained to do, well

1062
00:56:38,150 --> 00:56:42,200
So we have to make sure
we keep our intuition

1063
00:56:44,100 --> 00:56:47,080
Optimized to the way machines learn

1064
00:56:47,080 --> 00:56:49,000
Not the way humans have learned

1065
00:56:49,400 --> 00:56:52,280
Over the 540 million years of data

1066
00:56:52,280 --> 00:56:53,260
That we've gained

1067
00:56:53,260 --> 00:56:55,700
Through developing the eye
through evolution

1068
00:56:56,400 --> 00:56:58,600
The current challenges
we're taking on

1069
00:56:58,650 --> 00:57:00,260
First: Transfer learning

1070
00:57:00,800 --> 00:57:03,650
There's a lot of success
 in transfer learning

1071
00:57:03,650 --> 00:57:06,120
Between domains that are
 very close to each other

1072
00:57:06,400 --> 00:57:09,140
So, image classification 
from one domain to the next.

1073
00:57:10,570 --> 00:57:12,760
There's a lot of value
in forming representations

1074
00:57:12,760 --> 00:57:14,860
Of the way scenes look,
 in order

1075
00:57:14,860 --> 00:57:16,420
Natural scenes look,

1076
00:57:16,420 --> 00:57:18,650
In order to do scene segmentation

1077
00:57:18,650 --> 00:57:20,160
The driving case, for example.

1078
00:57:20,160 --> 00:57:25,260
But we're not able to do 
any bigger leaps,

1079
00:57:25,360 --> 00:57:27,360
In the way it would perform 
transfer learning

1080
00:57:28,020 --> 00:57:29,900
The biggest challenge
 for deep learning

1081
00:57:29,900 --> 00:57:30,960
Is to generalize

1082
00:57:31,100 --> 00:57:32,660
Generalize across domains.

1083
00:57:33,480 --> 00:57:35,700
It lacks the ability to reason,

1084
00:57:35,840 --> 00:57:38,520
In the way that we've defined
 understanding previously

1085
00:57:38,580 --> 00:57:41,530
Which is the ability to turn
 complex information

1086
00:57:41,530 --> 00:57:43,060
Into simple useful information.

1087
00:57:44,900 --> 00:57:47,750
Convert domain specific,

1088
00:57:48,120 --> 00:57:50,420
Complicated sensory information.

1089
00:57:50,770 --> 00:57:53,380
That doesn't relate to 
the initial training set.

1090
00:57:54,060 --> 00:57:56,180
That's the open challenge
 for deep learning

1091
00:57:56,620 --> 00:57:59,280
Train on very little data,
and then go and reason,

1092
00:57:59,280 --> 00:58:00,750
And operate in the real world.

1093
00:58:01,690 --> 00:58:03,960
Right now, you'll know,
 it's very inefficient

1094
00:58:04,130 --> 00:58:05,540
They require big data

1095
00:58:06,730 --> 00:58:08,380
They require supervised data

1096
00:58:08,380 --> 00:58:09,580
Which means they need human.

1097
00:58:09,580 --> 00:58:11,100
Cost a human input

1098
00:58:12,500 --> 00:58:14,020
They're not fully automated,

1099
00:58:14,100 --> 00:58:16,160
Despite the fact that
 the feature learning

1100
00:58:16,250 --> 00:58:17,980
Incredibly the big breakthrough

1101
00:58:17,980 --> 00:58:20,550
Feature learning is performed 
automatically,

1102
00:58:20,640 --> 00:58:22,640
You still have to do a lot of design,

1103
00:58:22,640 --> 00:58:24,280
Of the actual architecture
 of the network

1104
00:58:24,380 --> 00:58:26,700
And all the different 
hyper parameter tuning

1105
00:58:26,700 --> 00:58:27,790
needs to be performed.

1106
00:58:28,150 --> 00:58:29,220
Human input

1107
00:58:29,750 --> 00:58:32,280
Perhaps a little bit more educated
 human input,

1108
00:58:32,460 --> 00:58:35,350
A former PhD students,
postdocs faculty

1109
00:58:35,850 --> 00:58:39,150
Is required to tune 
these hyper parameters.

1110
00:58:39,250 --> 00:58:41,420
But nevertheless, human input
is still necessary.

1111
00:58:41,850 --> 00:58:43,440
They cannot be left alone.

1112
00:58:44,650 --> 00:58:45,900
For the most part...

1113
00:58:47,090 --> 00:58:49,550
The reward. Defining the reward
As we saw with coast run

1114
00:58:49,550 --> 00:58:50,980
Is extremely difficult

1115
00:58:51,690 --> 00:58:54,120
For systems that operate 
in the real world

1116
00:58:54,120 --> 00:58:55,450
Transparency

1117
00:58:56,420 --> 00:58:58,790
Quite possibly it's not 
an important one

1118
00:58:58,930 --> 00:59:01,200
But neural networks, 
currently, are a black box.

1119
00:59:01,200 --> 00:59:02,140
For the most part.

1120
00:59:02,240 --> 00:59:03,740
They're not able to accept

1121
00:59:03,740 --> 00:59:06,280
Through a few successful 
visualization methods

1122
00:59:06,380 --> 00:59:09,240
That visualize different aspects
 of the activations

1123
00:59:09,340 --> 00:59:13,550
They're not able to reveal, 
to us humans

1124
00:59:13,600 --> 00:59:15,550
Why they work,
 or where they fail

1125
00:59:17,300 --> 00:59:19,590
And this is a philosophical question,

1126
00:59:19,590 --> 00:59:21,010
For autonomous vehicles,

1127
00:59:21,120 --> 00:59:22,950
That we may not care 
as human beings

1128
00:59:22,950 --> 00:59:24,550
If a system works well enough.

1129
00:59:25,500 --> 00:59:29,090
But I would argue that,
it will be a long time,

1130
00:59:29,150 --> 00:59:31,500
Before systems work well enough,

1131
00:59:31,500 --> 00:59:32,700
Or we don't care.

1132
00:59:33,400 --> 00:59:34,400
We'll care,

1133
00:59:34,680 --> 00:59:36,660
And we'll have to work together
 with these systems

1134
00:59:36,660 --> 00:59:38,730
And that's where transparency,
communication,

1135
00:59:38,730 --> 00:59:40,400
...collaboration is critical.

1136
00:59:40,700 --> 00:59:43,240
Edge cases.
It's all about edge cases.

1137
00:59:43,850 --> 00:59:46,740
In robotics, in autonomous vehicles...

1138
00:59:47,440 --> 00:59:50,780
The 99.9 percent of driving
is really boring,

1139
00:59:50,780 --> 00:59:53,530
It's the same.
Especially highway driving.

1140
00:59:53,530 --> 00:59:56,270
Traffic driving. It's the same.

1141
00:59:56,460 --> 00:59:59,130
The obstacle avoidance,
the car following the lanes...

1142
00:59:59,130 --> 01:00:01,360
...centering.
All these problems are trivial.

1143
01:00:01,520 --> 01:00:03,760
It's the edge cases.

1144
01:00:04,150 --> 01:00:06,020
Trillions of edge cases,

1145
01:00:06,160 --> 01:00:07,790
They need to be generalised over,

1146
01:00:07,920 --> 01:00:09,830
On a very small amount 
of training data.

1147
01:00:15,600 --> 01:00:18,390
So again I return to: 
Why deep learning?

1148
01:00:21,900 --> 01:00:23,800
I mentioned a bunch of challenges,

1149
01:00:24,780 --> 01:00:26,160
And this is an opportunity!

1150
01:00:26,720 --> 01:00:32,100
It's an opportunity,
 to come up with techniques,

1151
01:00:33,300 --> 01:00:35,820
that operate successfully in this world.

1152
01:00:36,240 --> 01:00:39,110
So I hope the competitions 
we present in this class,

1153
01:00:39,140 --> 01:00:40,890
And the autonomous vehicle domain,

1154
01:00:40,920 --> 01:00:44,150
Will give you some insight,
 and an opportunity to apply...

1155
01:00:44,480 --> 01:00:47,140
In some of these cases are 
open research problems,

1156
01:00:47,720 --> 01:00:50,500
Wth semantic segmentation
 of external perception,

1157
01:00:50,830 --> 01:00:53,460
With control of the vehicle,
 and deep traffic

1158
01:00:54,750 --> 01:00:57,480
And, with deep crash,

1159
01:00:57,890 --> 01:01:01,120
Of control of the vehicle,
 and under actuated

1160
01:01:01,480 --> 01:01:06,280
High speed conditions, 
and the driver state perception.

1161
01:01:10,990 --> 01:01:13,920
So with that, I wanted to introduce
 deep learning to you today,

1162
01:01:13,990 --> 01:01:16,700
Before we get to the fun tomorrow 
of autonomous vehicles.

1163
01:01:17,250 --> 01:01:21,700
So, I would like to thank:
Nvidia, Google, Autoliv,

1164
01:01:22,240 --> 01:01:27,300
Toyota. And, at the risk of 
setting off people's phones:

1165
01:01:27,400 --> 01:01:29,040
Amazon Alexa, Auto...

1166
01:01:31,540 --> 01:01:38,130
But, truly, I would like to say,
 that I've been humbled

1167
01:01:38,130 --> 01:01:41,120
Over the past year, by the

1168
01:01:41,120 --> 01:01:42,990
thousands of messages 
were received

1169
01:01:43,000 --> 01:01:47,600
By the attention.
 By the 18,000 competition entries.

1170
01:01:47,790 --> 01:01:51,510
By the many people across the world,
 not just here at MIT,

1171
01:01:51,890 --> 01:01:55,350
That are brilliant,
 that I got a chance to interact with.

1172
01:01:55,450 --> 01:01:57,120
And I hope we go bigger,

1173
01:01:57,330 --> 01:01:59,700
And do some impressive stuff in 2018.

1174
01:02:00,450 --> 01:02:02,880
Thank you very much, 
and tomorrow is self-driving!

