1
00:00:00,290 --> 00:00:09,599
谢谢大家冒着寒冷 

2
00:00:03,659 --> 00:00:11,219
这里的雪 是六点钟 

3
00:00:09,599 --> 00:00:15,990
零九为深度学习 

4
00:00:11,219 --> 00:00:18,029
自动驾驶汽车 ，这是一个课程 

5
00:00:15,990 --> 00:00:21,330
我们在哪里讨论深刻 的 话题 

6
00:00:18,029 --> 00:00:23,460
学习这是 一套技术 

7
00:00:21,330 --> 00:00:27,539
这在过去采取的一个飞跃 

8
00:00:23,460 --> 00:00:29,010
我们了解什么十年

9
00:00:27,539 --> 00:00:31,949
人工智能系统 

10
00:00:29,010 --> 00:00:35,910
能够做的和自动驾驶汽车 的 

11
00:00:31,949 --> 00:00:39,090
这是可以采取这些的系统 

12
00:00:35,910 --> 00:00:42,390
技术并将它们整合到一个 

13
00:00:39,090 --> 00:00:46,020
内部日常有意义的深刻方式 

14
00:00:42,390 --> 00:00:48,110
住在改变社会 这样的方式

15
00:00:46,020 --> 00:00:50,250
这就是为什么这两个 主题 都是 

16
00:00:48,110 --> 00:00:55,079
非常重要而且非常 

17
00:00:50,250 --> 00:00:56,940
令我兴奋的是莱克斯弗里德曼和我

18
00:00:55,079 --> 00:01:00,840
由一群令人惊叹的 工程师加入

19
00:00:56,940 --> 00:01:04,670
在Jack terwilliger Jude Julia Kendall的 

20
00:01:00,840 --> 00:01:08,479
汉堡丹·布朗 迈克尔·格拉泽 李鼎 

21
00:01:04,670 --> 00:01:12,570
斯宾塞多德和本尼迪克特 之间 

22
00:01:08,479 --> 00:01:16,409
我们建造了自动驾驶汽车 

23
00:01:12,570 --> 00:01:20,310
在麻省理工学院这里不仅仅是那些感知到的人 

24
00:01:16,409 --> 00:01:23,310
并转移环境，但一些 

25
00:01:20,310 --> 00:01:26,850
互动沟通 和赚钱 

26
00:01:23,310 --> 00:01:28,770
对人类的信任和理解

27
00:01:26,850 --> 00:01:31,229
在车内司机和 

28
00:01:28,770 --> 00:01:34,320
乘客 和 外面 的人 

29
00:01:31,229 --> 00:01:40,079
汽车 行人和其他人 

30
00:01:34,320 --> 00:01:41,790
司机和骑自行车者的网站 

31
00:01:40,079 --> 00:01:42,960
这个课程自驾车那个 

32
00:01:41,790 --> 00:01:46,259
mit.edu 

33
00:01:42,960 --> 00:01:51,960
如果您有问题，请发送电子邮 

34
00:01:46,259 --> 00:01:54,299
麻省理工学院整理你整理懒散 - 麻省理工学院 

35
00:01:51,960 --> 00:01:58,829
你必须注册麻省理工学院的学生

36
00:01:54,299 --> 00:02:03,180
在网站上注册并在午夜之前注册

37
00:01:58,829 --> 00:02:04,829
1月19日星期五构建 神经 

38
00:02:03,180 --> 00:02:07,799
网络并提交给竞争对手 

39
00:02:04,829 --> 00:02:11,760
达到每英里65英里的速度 

40
00:02:07,799 --> 00:02:14,260
小时候 新的深度交通2.0就是这样 

41
00:02:11,760 --> 00:02:15,819
更难， 更 有趣 

42
00:02:14,260 --> 00:02:18,940
去年是那些你的人 

43
00:02:15,819 --> 00:02:23,170
参加了三场比赛 

44
00:02:18,940 --> 00:02:26,920
在这个类深层交通seg融合深 

45
00:02:23,170 --> 00:02:33,040
碰到有来宾的演讲嘉宾 

46
00:02:26,920 --> 00:02:35,530
从方式 更多谷歌特斯拉，而这些都是 

47
00:02:33,040 --> 00:02:43,989
启动新的自动驾驶汽车创业公司 

48
00:02:35,530 --> 00:02:49,420
在航行自治和Aurora然后 

49
00:02:43,989 --> 00:02:52,329
今天从CES使用了很多， 我们有 

50
00:02:49,420 --> 00:02:55,090
适合那些勇敢的人的衬衫

51
00:02:52,329 --> 00:02:56,769
下雪并继续这样做 

52
00:02:55,090 --> 00:02:59,470
课程结束 时会有免费的 

53
00:02:56,769 --> 00:03:03,430
衬衫是我说免费和衬衫 

54
00:02:59,470 --> 00:03:07,079
同样的句子你 应该在这里好吗 

55
00:03:03,430 --> 00:03:09,519
首先是深度交通竞争 

56
00:03:07,079 --> 00:03:11,709
有很多更新，我们将介绍 

57
00:03:09,519 --> 00:03:14,049
周三那些人很深 

58
00:03:11,709 --> 00:03:17,489
强化学习比赛最后

59
00:03:14,049 --> 00:03:23,380
那年我们收到了18,000多份意见书 

60
00:03:17,489 --> 00:03:25,450
今年我们不会变大 

61
00:03:23,380 --> 00:03:27,190
那么你只能控好一辆车 

62
00:03:25,450 --> 00:03:29,799
你可以在网络上控制多达十个 

63
00:03:27,190 --> 00:03:33,569
这是 多代理更深层次的执法 

64
00:03:29,799 --> 00:03:33,569
学习这是超级酷

65
00:03:33,750 --> 00:03:40,359
第二个心理融合动态驾驶场景 

66
00:03:37,150 --> 00:03:47,109
细分竞争你在哪里

67
00:03:40,359 --> 00:03:48,400
给出原始视频的运动学

68
00:03:47,109 --> 00:03:50,560
在运动中的车辆

69
00:03:48,400 --> 00:03:53,440
车辆是最先进的 

70
00:03:50,560 --> 00:03:56,260
你是训练集的细分

71
00:03:53,440 --> 00:03:59,709
给出地面实况标签像素级别

72
00:03:56,260 --> 00:04:02,829
标签场景分割和光学

73
00:03:59,709 --> 00:04:05,470
流动和你的那些数据 

74
00:04:02,829 --> 00:04:08,230
任务会尝试进行比好 

75
00:04:05,470 --> 00:04:12,959
基于图像的现有技术 

76
00:04:08,230 --> 00:04:16,410
细分这是为什么重要 ， 

77
00:04:12,959 --> 00:04:21,669
在一个开放的研究问题中引人入胜

78
00:04:16,410 --> 00:04:23,830
因为在这个世界上行动的机器人

79
00:04:21,669 --> 00:04:25,659
在物理空间 不仅必须 

80
00:04:23,830 --> 00:04:27,730
解释使用这些深度学习 

81
00:04:25,659 --> 00:04:29,680
解释空间视觉的方法 

82
00:04:27,730 --> 00:04:32,410
他们必须要有的场景特征

83
00:04:29,680 --> 00:04:34,240
也解释理解和跟踪 

84
00:04:32,410 --> 00:04:35,890
现场这个时间动态

85
00:04:34,240 --> 00:04:38,440
竞争是暂时的 

86
00:04:35,890 --> 00:04:41,380
信息的传播不仅仅是 

87
00:04:38,440 --> 00:04:48,130
看到细分你必须明白 

88
00:04:41,380 --> 00:04:50,170
在空间和时间，最后深陷 

89
00:04:48,130 --> 00:04:55,000
我们在哪里使用深度强化学习 

90
00:04:50,170 --> 00:04:59,100
在这里鞭打汽车数千次 

91
00:04:55,000 --> 00:05:03,070
在麻省理工学院的健身房，你得到的数据 

92
00:04:59,100 --> 00:05:05,110
一千个跑步或汽车或汽车知道 

93
00:05:03,070 --> 00:05:07,630
什么都没有使用单目 相机作为 

94
00:05:05,110 --> 00:05:10,090
单输入行驶超过30英里 

95
00:05:07,630 --> 00:05:12,190
小时通过一个场景它很少 

96
00:05:10,090 --> 00:05:14,170
通过很少的能力来控制

97
00:05:12,190 --> 00:05:16,690
为了本地化它必须采取行动 

98
00:05:14,170 --> 00:05:21,670
很快在那个场景中，你得到了一个 

99
00:05:16,690 --> 00:05:24,760
一千次跑来学习我们的任何东西

100
00:05:21,670 --> 00:05:27,790
在接下来的几周内讨论这一点 

101
00:05:24,760 --> 00:05:31,300
比赛将导致四场比赛

102
00:05:27,790 --> 00:05:33,460
我们评估每个人的提交

103
00:05:31,300 --> 00:05:35,530
在模拟但前四名 

104
00:05:33,460 --> 00:05:38,860
提交的内容我们正面对面

105
00:05:35,530 --> 00:05:42,310
健身房，直到有一个胜利者宣布 

106
00:05:38,860 --> 00:05:43,260
我们一直砸车30英里 

107
00:05:42,310 --> 00:05:46,690
小时

108
00:05:43,260 --> 00:05:49,360
深度崩溃，也在网站上 

109
00:05:46,690 --> 00:05:51,910
从去年开始，在github上有 

110
00:05:49,360 --> 00:05:53,710
特斯拉正在使用的 

111
00:05:51,910 --> 00:05:56,290
大规模的 自然驾驶数据 

112
00:05:53,710 --> 00:05:58,570
设置我们必须训练神经网络 

113
00:05:56,290 --> 00:06:00,370
进入和转向接受 

114
00:05:58,570 --> 00:06:03,430
来自前方道路的单眼视频

115
00:06:00,370 --> 00:06:07,630
并产生转向命令 该 

116
00:06:03,430 --> 00:06:09,550
汽车讲座的转向命令

117
00:06:07,630 --> 00:06:11,650
今天我们将谈论深度学习 

118
00:06:09,550 --> 00:06:16,270
明天我们会谈论自治 

119
00:06:11,650 --> 00:06:19,170
车辆深 RLS周三开车 

120
00:06:16,270 --> 00:06:23,650
场景理解如此分割

121
00:06:19,170 --> 00:06:26,440
星期四星期五我们有sasha 

122
00:06:23,650 --> 00:06:29,350
或者知道 工程 总监 

123
00:06:26,440 --> 00:06:31,780
mo mo way mo是其中一家公司 

124
00:06:29,350 --> 00:06:34,120
这确实取得了巨大的进步 

125
00:06:31,780 --> 00:06:36,700
他们正在采取完全自动驾驶的车辆

126
00:06:34,120 --> 00:06:38,590
完全ll l5自动驾驶汽车

127
00:06:36,700 --> 00:06:40,900
学习方法很有趣 

128
00:06:38,590 --> 00:06:41,320
他也是 感知 的头脑 

129
00:06:40,900 --> 00:06:44,980
他们

130
00:06:41,320 --> 00:06:46,510
向他学习什么样 的问题 

131
00:06:44,980 --> 00:06:48,610
他们正面临着 什么样 的 方法 

132
00:06:46,510 --> 00:06:50,920
他们正在接受我们有ameliafe 

133
00:06:48,610 --> 00:06:54,190
里佐利谁 去年的演讲者 之一 

134
00:06:50,920 --> 00:06:56,770
先生 - 卡门说阿米莉亚是最聪明的 

135
00:06:54,190 --> 00:06:59,850
他知道的人是阿米莉亚为佐利的 

136
00:06:56,770 --> 00:07:02,110
转喻的CTO是一种自动驾驶汽车

137
00:06:59,850 --> 00:07:05,320
刚被德尔福收购的公司 

138
00:07:02,110 --> 00:07:06,730
对于一大笔钱 ，他们是 

139
00:07:05,320 --> 00:07:10,570
做了很多令人难以置信的工作 

140
00:07:06,730 --> 00:07:14,230
新加坡和波士顿接下来

141
00:07:10,570 --> 00:07:16,600
星期三 我们要谈谈 

142
00:07:14,230 --> 00:07:19,690
我们研究的主题或我个人的 

143
00:07:16,600 --> 00:07:21,550
迷恋是 对司机的 深刻 学习 

144
00:07:19,690 --> 00:07:23,380
状态感知理解人类

145
00:07:21,550 --> 00:07:26,220
感知 人类的 一切 

146
00:07:23,380 --> 00:07:29,250
在车内和车外

147
00:07:26,220 --> 00:07:33,730
我真的很兴奋

148
00:07:29,250 --> 00:07:36,790
奥利弗卡梅隆周四他现在是 

149
00:07:33,730 --> 00:07:39,190
自动驾驶汽车启动航行首席执行官

150
00:07:36,790 --> 00:07:41,890
以前是导演 

151
00:07:39,190 --> 00:07:44,440
自驾车 方案， 他 大胆 

152
00:07:41,890 --> 00:07:47,530
将谈论如何开始 

153
00:07:44,440 --> 00:07:50,740
那些 他自驾车的公司

154
00:07:47,530 --> 00:07:52,240
说麻省理工学院的乡亲和企业家如果 

155
00:07:50,740 --> 00:07:54,640
你想自己开始一个

156
00:07:52,240 --> 00:07:58,710
他会告诉你 它的超级性 

157
00:07:54,640 --> 00:08:02,320
很酷， 然后是Sterling Anderson 

158
00:07:58,710 --> 00:08:05,050
导演以前 是特斯拉 汽车 

159
00:08:02,320 --> 00:08:10,180
驾驶员队伍，现在是公司的创始人之一 

160
00:08:05,050 --> 00:08:12,100
极光 自驾车启动 

161
00:08:10,180 --> 00:08:14,710
我提到的那个现在已经合作了 

162
00:08:12,100 --> 00:08:17,350
与NVIDIA和 其他许多人一样，为什么呢 

163
00:08:14,710 --> 00:08:20,980
这类自驾车是关于 

164
00:08:17,350 --> 00:08:23,500
应用数据驱动的学习方法 

165
00:08:20,980 --> 00:08:26,650
自动驾驶汽车的问题为何 

166
00:08:23,500 --> 00:08:31,090
自动驾驶汽车很吸引人 

167
00:08:26,650 --> 00:08:35,050
有趣的问题空间很可能

168
00:08:31,090 --> 00:08:37,060
在我看来，这 是第一次 广泛 

169
00:08:35,050 --> 00:08:40,930
达到和深刻融合 

170
00:08:37,060 --> 00:08:42,789
社会中的个人机器人影响广泛 

171
00:08:40,930 --> 00:08:46,200
因为那里有10亿辆汽车

172
00:08:42,789 --> 00:08:48,880
道路甚至一 小部分 会 改变 

173
00:08:46,200 --> 00:08:53,320
面对交通运输我们如何 

174
00:08:48,880 --> 00:08:55,060
关于这个世界的深刻和这个 

175
00:08:53,320 --> 00:08:58,690
是一个重要的点 

176
00:08:55,060 --> 00:09:02,260
并不总是被理解是 有 一个 

177
00:08:58,690 --> 00:09:06,130
人与人之间的亲密联系

178
00:09:02,260 --> 00:09:08,770
当有直接转移时的车辆 

179
00:09:06,130 --> 00:09:12,580
控制它是直接转移 

180
00:09:08,770 --> 00:09:14,260
掌控 他或 她的生命的控制 

181
00:09:12,580 --> 00:09:17,220
进入人工手中

182
00:09:14,260 --> 00:09:21,040
智能系统我展示了几下 

183
00:09:17,220 --> 00:09:23,020
退出快速 剪辑， 你可以 谷歌 

184
00:09:21,040 --> 00:09:26,200
第一次与特斯拉自动驾驶仪上 

185
00:09:23,020 --> 00:09:28,390
YouTube并观看人们执行 此操作 

186
00:09:26,200 --> 00:09:31,120
转移控制有一些东西 

187
00:09:28,390 --> 00:09:34,930
关于 人类和机器人的神奇

188
00:09:31,120 --> 00:09:37,300
共同努力将改变 

189
00:09:34,930 --> 00:09:39,940
什么人工智能是在 

190
00:09:37,300 --> 00:09:43,180
21世纪 和这个特别 

191
00:09:39,940 --> 00:09:47,529
自动系统AI系统自动驾驶

192
00:09:43,180 --> 00:09:49,210
汽车是规模和深刻的 

193
00:09:47,529 --> 00:09:51,550
它的生命的关键特性 是 

194
00:09:49,210 --> 00:09:56,529
在某种程度上深刻的，它会真正 

195
00:09:51,550 --> 00:09:58,720
测试AI的功能 有一个 

196
00:09:56,529 --> 00:10:01,120
个人联系会争辩 

197
00:09:58,720 --> 00:10:03,850
在这些讲座中我们做不到 

198
00:10:01,120 --> 00:10:05,650
逃避考虑人 说 

199
00:10:03,850 --> 00:10:07,510
自动驾驶汽车不仅必须 

200
00:10:05,650 --> 00:10:09,339
感知并控制其运动

201
00:10:07,510 --> 00:10:10,870
通过环境你 也 必须 

202
00:10:09,339 --> 00:10:13,000
感知关于人类的一切 

203
00:10:10,870 --> 00:10:14,770
司机和乘客互动

204
00:10:13,000 --> 00:10:25,120
通信，以及 与建立信任 

205
00:10:14,770 --> 00:10:26,920
司机，因为在我看来，我会 

206
00:10:25,120 --> 00:10:29,710
在整个课程中争论一下 

207
00:10:26,920 --> 00:10:33,100
自动驾驶汽车更像 是个人 

208
00:10:29,710 --> 00:10:35,910
机器人比它是完美的感知

209
00:10:33,100 --> 00:10:38,770
控制系统因为完美

210
00:10:35,910 --> 00:10:42,670
感知和控制 所以这个世界 

211
00:10:38,770 --> 00:10:46,230
充满 了人类是非常困难的 

212
00:10:42,670 --> 00:10:50,560
可能是两三四十年之后 

213
00:10:46,230 --> 00:10:53,680
完全自治的自动驾驶汽车 

214
00:10:50,560 --> 00:10:57,010
他们将会 有 瑕疵 

215
00:10:53,680 --> 00:10:59,650
缺陷和我们来设计系统， 其 

216
00:10:57,010 --> 00:11:02,410
有效地抓住了这个

217
00:10:59,650 --> 00:11:04,450
把控制转移到人类的时候 

218
00:11:02,410 --> 00:11:07,690
他们无法处理这种情况 

219
00:11:04,450 --> 00:11:08,920
转移控制不是一个 

220
00:11:07,690 --> 00:11:16,410
迷人

221
00:11:08,920 --> 00:11:20,200
因为AI 避免了障碍 

222
00:11:16,410 --> 00:11:24,310
障碍和障碍的 感知 

223
00:11:20,200 --> 00:11:26,139
避免是一个容易出问题的问题

224
00:11:24,310 --> 00:11:28,860
安全问题每小时30英里 

225
00:11:26,139 --> 00:11:33,160
在波士顿的街道上航行是 

226
00:11:28,860 --> 00:11:36,310
当你必须 去上班时很容易

227
00:11:33,160 --> 00:11:37,899
在 你迟到或你厌倦了 

228
00:11:36,310 --> 00:11:40,480
人在你面前， 你要 

229
00:11:37,899 --> 00:11:43,360
进入 对面的 车道和速度 

230
00:11:40,480 --> 00:11:46,570
这是人性 ， 我们做不到 

231
00:11:43,360 --> 00:11:49,389
逃吧我们的人工智能 

232
00:11:46,570 --> 00:11:52,120
系统无法逃脱人性 他们 

233
00:11:49,389 --> 00:11:53,829
必须与它合作这里显示的是什么 

234
00:11:52,120 --> 00:11:57,010
我们将谈论的算法之一

235
00:11:53,829 --> 00:12:00,310
下周的认知负荷或我们采取 

236
00:11:57,010 --> 00:12:03,399
原始的3d卷积神经网络 

237
00:12:00,310 --> 00:12:05,230
在眼睛区域眨眼和眨眼 

238
00:12:03,399 --> 00:12:07,480
瞳孔运动来确定 

239
00:12:05,230 --> 00:12:09,279
我们将看到的驾驶员的认知负荷

240
00:12:07,480 --> 00:12:12,060
我们如何能够发现 有关的 一切 

241
00:12:09,279 --> 00:12:15,899
司机，他们看起来 情绪化 

242
00:12:12,060 --> 00:12:21,519
认知负荷体姿态估计 

243
00:12:15,899 --> 00:12:24,790
瞌睡运动朝向充分 

244
00:12:21,519 --> 00:12:28,029
我认为，自治是如此困难 

245
00:12:24,790 --> 00:12:32,350
这几乎需要人的水平 

246
00:12:28,029 --> 00:12:35,170
正如我所说的 两个情报

247
00:12:32,350 --> 00:12:37,600
三十四年的旅程 

248
00:12:35,170 --> 00:12:39,640
人工智能研究人员

249
00:12:37,600 --> 00:12:41,890
实现完全自治需要 

250
00:12:39,640 --> 00:12:44,230
实现解决一些问题 

251
00:12:41,890 --> 00:12:48,760
创造的根本问题 

252
00:12:44,230 --> 00:12:51,519
智力，这是我们的事情

253
00:12:48,760 --> 00:12:53,860
在更广泛的范围内进行更深入的讨论

254
00:12:51,519 --> 00:12:56,440
在两周内查看人工 

255
00:12:53,860 --> 00:12:58,329
一般情报课程我们在哪里 

256
00:12:56,440 --> 00:13:01,480
特斯拉雷有安德烈 卡帕提亚 

257
00:12:58,329 --> 00:13:04,660
来自波士顿的 Kurzweil Mark Ryberg 

258
00:13:01,480 --> 00:13:07,889
要求尺寸的动力学

259
00:13:04,660 --> 00:13:11,889
这个房间因为他带着机器人

260
00:13:07,889 --> 00:13:14,310
没有别的告诉我， 这将 是一个 

261
00:13:11,889 --> 00:13:14,310
惊 

262
00:13:15,530 --> 00:13:18,890
所以这就是我为人类争论的原因

263
00:13:17,420 --> 00:13:21,770
中心人工智能 

264
00:13:18,890 --> 00:13:26,840
在 设计的 每个 算法中的方法

265
00:13:21,770 --> 00:13:29,990
认为人是自主的 

266
00:13:26,840 --> 00:13:32,810
车辆在左侧的感知场景 

267
00:13:29,990 --> 00:13:34,610
了解和控制问题， 

268
00:13:32,810 --> 00:13:37,190
我们将通过比赛进行探索

269
00:13:34,610 --> 00:13:41,330
在本课程 的作业 中可以 

270
00:13:37,190 --> 00:13:45,680
处理90并增加 百分比 

271
00:13:41,330 --> 00:13:48,500
案件，但它是10％的1.1％ 

272
00:13:45,680 --> 00:13:51,200
案件我们越来越好 那 

273
00:13:48,500 --> 00:13:53,060
我们不得不处理 

274
00:13:51,200 --> 00:13:54,980
通过这些方法，那就是在哪里 

275
00:13:53,060 --> 00:13:57,020
人类真正感知到人类 

276
00:13:54,980 --> 00:14:00,140
这是 最后 一段视频 

277
00:13:57,020 --> 00:14:03,020
凯旋门的一年谢谢你 

278
00:14:00,140 --> 00:14:07,790
去年我不知道我现在知道 了 

279
00:14:03,020 --> 00:14:10,580
是 人类 数以百万计 的案例 之一 

280
00:14:07,790 --> 00:14:14,840
对人类的互动是他们的 

281
00:14:10,580 --> 00:14:21,200
主导驾驶员不是基本感知 

282
00:14:14,840 --> 00:14:25,640
控制问题所以为什么要深入学习 

283
00:14:21,200 --> 00:14:29,930
这个空间因为 深度学习是一个 

284
00:14:25,640 --> 00:14:32,870
从很多方面 做得很好的一套方法 

285
00:14:29,930 --> 00:14:36,560
数据并 解决这些问题 

286
00:14:32,870 --> 00:14:38,960
人类 生命受到威胁的地方我们必须这样做 

287
00:14:36,560 --> 00:14:41,270
能够学习的技巧 

288
00:14:38,960 --> 00:14:44,150
从数据中学习现实世界的数据 

289
00:14:41,270 --> 00:14:45,680
这是 基本 的现实 

290
00:14:44,150 --> 00:14:47,420
人工智能系统 

291
00:14:45,680 --> 00:14:50,000
他们必须在现实世界中运作

292
00:14:47,420 --> 00:14:51,920
从现实世界数据中学习是否 

293
00:14:50,000 --> 00:14:56,360
这是感觉的左边 

294
00:14:51,920 --> 00:14:58,250
控制侧或 右侧的 

295
00:14:56,360 --> 00:15:00,040
人类的感知和 

296
00:14:58,250 --> 00:15:03,200
沟通互动

297
00:15:00,040 --> 00:15:08,839
与 人类和协作

298
00:15:03,200 --> 00:15:14,240
人体机器人互动确定是什么 

299
00:15:08,839 --> 00:15:16,850
深入学习它是一套技术

300
00:15:14,240 --> 00:15:18,890
如果你允许我的 定义 

301
00:15:16,850 --> 00:15:21,830
智力是 能力 

302
00:15:18,890 --> 00:15:24,470
我会完成复杂的目标

303
00:15:21,830 --> 00:15:28,100
认为理解的 定义 

304
00:15:24,470 --> 00:15:30,170
也许是推理 

305
00:15:28,100 --> 00:15:33,110
能够转变复杂的信息 

306
00:15:30,170 --> 00:15:35,540
变成简单有用的可操作的 

307
00:15:33,110 --> 00:15:38,480
信息，这是深刻的 

308
00:15:35,540 --> 00:15:41,149
学习深度学习是 

309
00:15:38,480 --> 00:15:44,209
表示学习或特征 

310
00:15:41,149 --> 00:15:47,240
学习，如果 你 将 其能够 采取 

311
00:15:44,209 --> 00:15:48,860
原始信息原始复杂 

312
00:15:47,240 --> 00:15:51,649
信息很难 做任何事情 

313
00:15:48,860 --> 00:15:53,959
这里有和构造是分层的 

314
00:15:51,649 --> 00:15:55,550
这些信息交涉 

315
00:15:53,959 --> 00:15:58,250
能够 做一些 有趣的 事情 

316
00:15:55,550 --> 00:16:01,069
它是人工的分支 

317
00:15:58,250 --> 00:16:04,550
最有能力的 智力 

318
00:16:01,069 --> 00:16:06,769
专注于这项任务的形成 

319
00:16:04,550 --> 00:16:08,779
来自数据的表示是否是 

320
00:16:06,769 --> 00:16:11,240
监督 或无人监督是否是 

321
00:16:08,779 --> 00:16:15,529
在人类的帮助下，它是否能够 

322
00:16:11,240 --> 00:16:18,560
构建结构 查找结构 

323
00:16:15,529 --> 00:16:20,920
您可以提取的数据

324
00:16:18,560 --> 00:16:26,860
简单实用可操作的信息

325
00:16:20,920 --> 00:16:29,149
Ian Goodfellows书的左边是 

326
00:16:26,860 --> 00:16:34,189
误 的基本示例

327
00:16:29,149 --> 00:16:36,980
分类图像的输入

328
00:16:34,189 --> 00:16:39,410
底部 带有 原始 像素和我们一样 

329
00:16:36,980 --> 00:16:41,720
当我们上层时， 上升 堆栈 

330
00:16:39,410 --> 00:16:44,569
雇用更高阶的代表是 

331
00:16:41,720 --> 00:16:47,149
由边缘形成的轮廓

332
00:16:44,569 --> 00:16:49,519
角落到对象部分然后最后

333
00:16:47,149 --> 00:16:51,980
完整对象语义分类 

334
00:16:49,519 --> 00:16:54,740
这是什么在图像 中 

335
00:16:51,980 --> 00:16:59,720
表达学习 的 最爱 

336
00:16:54,740 --> 00:17:03,410
我的例子是四分之一 

337
00:16:59,720 --> 00:17:06,559
几个世纪前我们在 宇宙中的位置 

338
00:17:03,410 --> 00:17:08,839
并代表那个地方 

339
00:17:06,559 --> 00:17:14,089
宇宙是否与地球有关 

340
00:17:08,839 --> 00:17:17,990
或相对于太阳左侧 为 

341
00:17:14,089 --> 00:17:21,140
我们目前对 这个权利的看法是 

342
00:17:17,990 --> 00:17:25,100
一个已经持续了几个世纪的人 

343
00:17:21,140 --> 00:17:27,289
代表性很重要，因为 

344
00:17:25,100 --> 00:17:30,880
右边的是更多 

345
00:17:27,289 --> 00:17:30,880
比左边的更复杂

346
00:17:33,760 --> 00:17:38,740
你可以在这里看一个简单的例子 

347
00:17:36,670 --> 00:17:40,210
当任务是绘制一条线 

348
00:17:38,740 --> 00:17:42,280
分隔绿色三角形和蓝色

349
00:17:40,210 --> 00:17:44,980
笛卡尔坐标系中的圆圈

350
00:17:42,280 --> 00:17:47,920
左边的空间任务更多 

351
00:17:44,980 --> 00:17:50,580
困难不可能在做好 

352
00:17:47,920 --> 00:17:54,100
在极坐标中右边是微不足道的

353
00:17:50,580 --> 00:17:55,600
这种转变正是如此

354
00:17:54,100 --> 00:17:58,240
我们需要了解这 一点 

355
00:17:55,600 --> 00:18:00,070
代表性学习，所以你可以采取 

356
00:17:58,240 --> 00:18:01,810
必须绘制一条线的同样任务

357
00:18:00,070 --> 00:18:04,480
分隔 蓝色曲线和 

358
00:18:01,810 --> 00:18:07,480
如果我们绘制一个左边的红色曲线

359
00:18:04,480 --> 00:18:10,570
直线它 会很高 

360
00:18:07,480 --> 00:18:14,800
零错误无法做到这一点 

361
00:18:10,570 --> 00:18:19,450
右侧显示的 100％精度是 

362
00:18:14,800 --> 00:18:21,220
我们最好的尝试，但我们可以做什么

363
00:18:19,450 --> 00:18:25,390
使用单个隐藏层进行深度学习

364
00:18:21,220 --> 00:18:28,090
这里完成的网络 是 形成的 

365
00:18:25,390 --> 00:18:30,910
拓扑空间中 的 映射 

366
00:18:28,090 --> 00:18:32,080
在允许中间这样的方式

367
00:18:30,910 --> 00:18:33,610
画一条直线

368
00:18:32,080 --> 00:18:37,120
将蓝色曲线和红色分开

369
00:18:33,610 --> 00:18:39,310
曲线学习中的功能 

370
00:18:37,120 --> 00:18:43,470
中间是我们能够实现的 

371
00:18:39,310 --> 00:18:46,630
深入学习它是生的 

372
00:18:43,470 --> 00:18:52,330
复杂的信息和制作 

373
00:18:46,630 --> 00:18:56,140
简单可行的有用和重点 

374
00:18:52,330 --> 00:18:58,900
就是这种学习的能力 

375
00:18:56,140 --> 00:19:01,150
从原始的 感官信息意味着 

376
00:18:58,900 --> 00:19:05,440
我们可以做更多的事情 

377
00:19:01,150 --> 00:19:11,020
数据如此深入的学习变得更好 

378
00:19:05,440 --> 00:19:15,520
更多数据，这对 真实而言 非常重要 

379
00:19:11,020 --> 00:19:19,780
边缘 情况的 世界应用 

380
00:19:15,520 --> 00:19:22,060
这一切都是我们驾驶的 两个 

381
00:19:19,780 --> 00:19:24,630
感知控制系统中的一个是在 

382
00:19:22,060 --> 00:19:27,010
特斯拉车辆与自动驾驶仪 

383
00:19:24,630 --> 00:19:28,360
使用a的第一版系统 

384
00:19:27,010 --> 00:19:30,580
单眼相机感知 

385
00:19:28,360 --> 00:19:33,580
外部环境 和生产控制 

386
00:19:30,580 --> 00:19:36,190
决定和我们自己的神经网络 

387
00:19:33,580 --> 00:19:38,110
在 邻近的ex2上运行

388
00:19:36,190 --> 00:19:41,650
与单目相机相同

389
00:19:38,110 --> 00:19:43,720
制定控制 决策和两者 

390
00:19:41,650 --> 00:19:46,720
系统争论，当他们不同意时

391
00:19:43,720 --> 00:19:47,710
他们举起一面旗帜 说这是 

392
00:19:46,720 --> 00:19:51,090
一个边缘案例东 

393
00:19:47,710 --> 00:19:53,860
这需要人为干预 

394
00:19:51,090 --> 00:19:57,250
使用机器覆盖这种边缘情况

395
00:19:53,860 --> 00:19:59,950
学习是 艺术 的主要问题 

396
00:19:57,250 --> 00:20:02,169
人工智能和应用时 

397
00:19:59,950 --> 00:20:07,029
对于现实世界来说，这是主要问题 

398
00:20:02,169 --> 00:20:11,289
解决好吧所以我们的神经 

399
00:20:07,029 --> 00:20:13,539
网络的灵感非常松散，我会 

400
00:20:11,289 --> 00:20:16,529
讨论关键区别

401
00:20:13,539 --> 00:20:18,820
我们自己的大脑和人工大脑

402
00:20:16,529 --> 00:20:22,210
因为有很多见解 

403
00:20:18,820 --> 00:20:24,490
这种差异， 但灵感来自于 

404
00:20:22,210 --> 00:20:27,789
生物神经网络在这里 作为 

405
00:20:24,490 --> 00:20:31,169
模拟 丘脑皮层的大脑 

406
00:20:27,789 --> 00:20:34,029
网络只有300万个 神经元 

407
00:20:31,169 --> 00:20:36,490
4.76 亿突触 满 人 

408
00:20:34,029 --> 00:20:42,299
大脑比一百多很多

409
00:20:36,490 --> 00:20:42,299
十亿个神经元 1000万亿个突触 

410
00:20:45,470 --> 00:20:51,090
有一个鼓舞人心的音乐与 此 

411
00:20:47,909 --> 00:20:54,059
一个我没有意识到的是在这里 

412
00:20:51,090 --> 00:21:00,090
应该让你认为人工 神经 

413
00:20:54,059 --> 00:21:02,880
网络是的 ，让我们让它发挥 

414
00:21:00,090 --> 00:21:05,130
人类神经网络是一百个 

415
00:21:02,880 --> 00:21:07,890
亿亿神经元正好 1000万亿 

416
00:21:05,130 --> 00:21:10,500
突触其中一个陈述 的 

417
00:21:07,890 --> 00:21:13,890
状态的最先进的 神经网络 作为 

418
00:21:10,500 --> 00:21:20,220
树脂那152有 1600万 

419
00:21:13,890 --> 00:21:22,500
突触，这是一个约的差异 

420
00:21:20,220 --> 00:21:25,950
七阶幅度差的 

421
00:21:22,500 --> 00:21:28,340
人类的大脑有一千万倍以上 

422
00:21:25,950 --> 00:21:30,470
突触比人工神经网络 

423
00:21:28,340 --> 00:21:34,590
加或减一个数量级 

424
00:21:30,470 --> 00:21:37,590
取决于网络，所以是什么 

425
00:21:34,590 --> 00:21:40,950
生物神经元之间的差异

426
00:21:37,590 --> 00:21:43,110
和人工神经 的 拓扑 

427
00:21:40,950 --> 00:21:46,110
人脑没有 神经 层 

428
00:21:43,110 --> 00:21:50,639
网络分层堆叠 他们 

429
00:21:46,110 --> 00:21:53,309
在大多数情况下固定有混乱a 

430
00:21:50,639 --> 00:21:55,409
人类大脑中的结构很少

431
00:21:53,309 --> 00:21:58,769
就神经元如何连接而言 

432
00:21:55,409 --> 00:22:01,169
它们 通常 连接 到10,000多个 

433
00:21:58,769 --> 00:22:03,720
其他神经元的突触数量 

434
00:22:01,169 --> 00:22:06,710
来自个体 神经元 

435
00:22:03,720 --> 00:22:09,090
输入神经元 是巨大的 

436
00:22:06,710 --> 00:22:11,789
他们与人类大脑异步

437
00:22:09,090 --> 00:22:15,570
大脑以异步人工方式工作 

438
00:22:11,789 --> 00:22:17,669
神经网络同步工作 

439
00:22:15,570 --> 00:22:22,309
学习算法 人工 神经 

440
00:22:17,669 --> 00:22:27,809
网络是唯一最好的网络

441
00:22:22,309 --> 00:22:35,820
反向传播，我们不知道如何 

442
00:22:27,809 --> 00:22:39,510
人脑学习处理速度这个

443
00:22:35,820 --> 00:22:41,750
是 我们唯一的好处 之一 

444
00:22:39,510 --> 00:22:45,600
用人工 神经网络 

445
00:22:41,750 --> 00:22:47,639
人工神经元更快但是

446
00:22:45,600 --> 00:22:53,549
他们也非常强大 

447
00:22:47,639 --> 00:22:55,350
效率很高，有两个部门 

448
00:22:53,549 --> 00:22:57,960
培训和测试阶段

449
00:22:55,350 --> 00:22:59,730
神经网络与 

450
00:22:57,960 --> 00:23:01,320
逻辑神经网络 就像 你一样 

451
00:22:59,730 --> 00:23:02,360
今天坐在这里，他们总是 

452
00:23:01,320 --> 00:23:05,940
学习

453
00:23:02,360 --> 00:23:09,059
唯一的深刻相似之处

454
00:23:05,940 --> 00:23:12,779
激励一个迷人的人 

455
00:23:09,059 --> 00:23:17,940
两者都是分布式计算

456
00:23:12,779 --> 00:23:21,179
规模有一个突现的方面 

457
00:23:17,940 --> 00:23:25,279
神经网络所在的基本要素 

458
00:23:21,179 --> 00:23:27,899
计算 神经元很简单 

459
00:23:25,279 --> 00:23:32,490
非常简单但连接时 

460
00:23:27,899 --> 00:23:35,909
一起 美丽惊人的强大 

461
00:23:32,490 --> 00:23:37,080
近似z'可以形成神经 

462
00:23:35,909 --> 00:23:38,970
网络是 用 这些 建立 起来的 

463
00:23:37,080 --> 00:23:41,940
输入的计算单位

464
00:23:38,970 --> 00:23:44,880
有一组带有重量的边 

465
00:23:41,940 --> 00:23:48,240
它们的边缘是重量 

466
00:23:44,880 --> 00:23:52,380
乘以该输入信号偏差 

467
00:23:48,240 --> 00:23:53,880
添加了非线性函数

468
00:23:52,380 --> 00:23:55,890
确定网络是否获得 

469
00:23:53,880 --> 00:23:58,640
激活或 不充分的神经元 得到 

470
00:23:55,890 --> 00:24:01,559
激活或不在这里 和 可视化 

471
00:23:58,640 --> 00:24:03,870
这些神经元可以在商场中组合 

472
00:24:01,559 --> 00:24:06,200
在许多 方式 ，他们 可以形成 

473
00:24:03,870 --> 00:24:10,950
前馈神经网络或他们可以 

474
00:24:06,200 --> 00:24:14,309
反馈到自己形成有 

475
00:24:10,950 --> 00:24:17,730
复发神经系统的状态记忆 

476
00:24:14,309 --> 00:24:20,549
网络左边的那些是 

477
00:24:17,730 --> 00:24:24,360
对大多数 人来说 最 成功的 

478
00:24:20,549 --> 00:24:27,029
在 计算机视觉中应用的那些 

479
00:24:24,360 --> 00:24:29,130
右边很受欢迎 ， 

480
00:24:27,029 --> 00:24:31,080
特定的一个时间动态或

481
00:24:29,130 --> 00:24:33,870
动态时间序列是任何一种

482
00:24:31,080 --> 00:24:37,049
事实上， 右边的那些是 

483
00:24:33,870 --> 00:24:40,500
更接近我们 人类的大脑 

484
00:24:37,049 --> 00:24:45,270
是和那些左边但那是 

485
00:24:40,500 --> 00:24:48,630
为什么他们真的很难训练一个 

486
00:24:45,270 --> 00:24:50,700
这种新兴力量的美丽方面 

487
00:24:48,630 --> 00:24:53,490
连接 多个神经元 

488
00:24:50,700 --> 00:24:55,620
一起是普遍的财产 

489
00:24:53,490 --> 00:24:58,950
这些 只有一个 隐藏层 

490
00:24:55,620 --> 00:25:01,260
网络可以学习任何学习的功能 

491
00:24:58,950 --> 00:25:03,440
近似任何函数

492
00:25:01,260 --> 00:25:09,480
要注意的重要财产

493
00:25:03,440 --> 00:25:12,180
因为这里的限制不在 

494
00:25:09,480 --> 00:25:15,060
网络的 力量是 极限 

495
00:25:12,180 --> 00:25:22,470
在是在方法，使 我们 

496
00:25:15,060 --> 00:25:25,320
构建它们并训练它们是什么类型

497
00:25:22,470 --> 00:25:29,460
机器学习深度学习

498
00:25:25,320 --> 00:25:36,030
我们可以分成两个 

499
00:25:29,460 --> 00:25:37,890
类别存储器现在的方法 

500
00:25:36,030 --> 00:25:40,830
基本上记住了模式 

501
00:25:37,890 --> 00:25:45,180
我们可以提供的数据和方法 

502
00:25:40,830 --> 00:25:46,980
松散地说，开始有理由 

503
00:25:45,180 --> 00:25:49,710
用最小化来概括数据

504
00:25:46,980 --> 00:25:52,200
左边 顶部的人为输入 是 

505
00:25:49,710 --> 00:25:54,540
引用unquote老师是 多少人 

506
00:25:52,200 --> 00:25:56,460
输入和蓝色是需要的 

507
00:25:54,540 --> 00:25:58,530
监督成功的方法

508
00:25:56,460 --> 00:26:00,960
学习哪个是 最 深刻的 

509
00:25:58,530 --> 00:26:02,810
学习成功来自或大部分 

510
00:26:00,960 --> 00:26:07,110
该数据是由人类注释 

511
00:26:02,810 --> 00:26:09,180
人是 成功 的核心 

512
00:26:07,110 --> 00:26:10,860
大多数数据都是其中的一部分 

513
00:26:09,180 --> 00:26:14,130
培训需要 人类 注释 

514
00:26:10,860 --> 00:26:16,290
有一些额外成功的人 

515
00:26:14,130 --> 00:26:20,400
来自增强方法 

516
00:26:16,290 --> 00:26:26,880
扩展基于扩展数据 

517
00:26:20,400 --> 00:26:29,010
这些网络是训练有素的 

518
00:26:26,880 --> 00:26:31,050
半监督强化学习 

519
00:26:29,010 --> 00:26:33,480
我们将谈论的无监督方法

520
00:26:31,050 --> 00:26:36,960
关于 后来的课程 就在那里 

521
00:26:33,480 --> 00:26:38,520
我们希望的近期 成功和 

522
00:26:36,960 --> 00:26:40,980
无监督学习

523
00:26:38,520 --> 00:26:42,690
接近真实的地方

524
00:26:40,980 --> 00:26:45,090
关于可能性的兴奋

525
00:26:42,690 --> 00:26:48,270
人工智能的谎言 能 

526
00:26:45,090 --> 00:26:54,360
以最小的方式 理解我们的 世界 

527
00:26:48,270 --> 00:27:00,330
来自人类的输入，所以我们可以想到两个 

528
00:26:54,360 --> 00:27:02,810
各种深度学习影响空间 之一 

529
00:27:00,330 --> 00:27:05,700
是一种特殊 目的的 情报 是 

530
00:27:02,810 --> 00:27:08,070
把问题正式化 

531
00:27:05,700 --> 00:27:13,680
收集足够的数据并存在 

532
00:27:08,070 --> 00:27:16,860
能够解决，这是一个特殊情况

533
00:27:13,680 --> 00:27:18,750
这提供了特别的价值 

534
00:27:16,860 --> 00:27:20,730
这里的兴趣是一个网络 

535
00:27:18,750 --> 00:27:22,680
估计 波士顿的 公寓费用 

536
00:27:20,730 --> 00:27:24,390
区域， 所以你可以采取的数量 

537
00:27:22,680 --> 00:27:25,620
卧室的平方英尺和 

538
00:27:24,390 --> 00:27:28,860
邻里和

539
00:27:25,620 --> 00:27:32,210
提供估计成本作为输出 

540
00:27:28,860 --> 00:27:34,890
右边是实际数据

541
00:27:32,210 --> 00:27:39,420
公寓成本我们实际上是站着的 

542
00:27:34,890 --> 00:27:42,800
在一个超过三个的区域

543
00:27:39,420 --> 00:27:42,800
一 室公寓一千美元

544
00:27:43,490 --> 00:27:49,020
你们中的一些人可能会感到 疼痛 

545
00:27:47,180 --> 00:27:52,950
然后是通用的 

546
00:27:49,020 --> 00:27:55,080
情报或感觉到的东西 

547
00:27:52,950 --> 00:27:57,750
喜欢 接近通用目的 

548
00:27:55,080 --> 00:28:00,660
智力是强化和

549
00:27:57,750 --> 00:28:03,059
与 Audra一起 在这里进行无人监督的学习

550
00:28:00,660 --> 00:28:05,490
对于神奇的派对来说 像素a 

551
00:28:03,059 --> 00:28:07,860
采用80 x 80像素的系统 

552
00:28:05,490 --> 00:28:10,080
图像，没有 其他信息 

553
00:28:07,860 --> 00:28:12,720
能够击败能够赢得这场比赛 

554
00:28:10,080 --> 00:28:15,570
除了序列之外 没有任何 信息 

555
00:28:12,720 --> 00:28:17,190
图像原始感官信息相同 

556
00:28:15,570 --> 00:28:19,590
方式同样 的信息 

557
00:28:17,190 --> 00:28:23,970
人类从视觉中吸收 

558
00:28:19,590 --> 00:28:26,220
音频触摸感官数据非常 

559
00:28:23,970 --> 00:28:28,559
低级数据并且能够 学习 

560
00:28:26,220 --> 00:28:31,530
赢了，它非常简单，而且是 

561
00:28:28,559 --> 00:28:33,900
非常人工建造的世界但是 

562
00:28:31,530 --> 00:28:36,660
然而，这是一个没有特色的世界 

563
00:28:33,900 --> 00:28:39,300
学习只进行原始感官 

564
00:28:36,660 --> 00:28:42,870
信息用于赢得非常

565
00:28:39,300 --> 00:28:47,309
稀疏的最小人类输入我们会谈 

566
00:28:42,870 --> 00:28:51,210
周三的情况很深 

567
00:28:47,309 --> 00:28:54,150
强化学习，但现在

568
00:28:51,210 --> 00:28:57,270
我们将专注 于监督学习的地方 

569
00:28:54,150 --> 00:29:00,210
有输入数据有一个网络 

570
00:28:57,270 --> 00:29:01,890
我们正在努力培养学习系统 

571
00:29:00,210 --> 00:29:04,770
并且 有正确的输出 

572
00:29:01,890 --> 00:29:06,720
被人类标记的是 

573
00:29:04,770 --> 00:29:10,200
对于神经一般培训过程 

574
00:29:06,720 --> 00:29:13,500
网络输入数据标签和 

575
00:29:10,200 --> 00:29:16,440
该网络的培训，以 使 模型 

576
00:29:13,500 --> 00:29:19,110
在测试阶段， 新的输入数据 

577
00:29:16,440 --> 00:29:21,840
从未见过 它的任务 

578
00:29:19,110 --> 00:29:24,210
产生猜测并基于评估 

579
00:29:21,840 --> 00:29:26,250
对于自动驾驶汽车而言

580
00:29:24,210 --> 00:29:28,140
装置被释放或者在 

581
00:29:26,250 --> 00:29:34,140
模拟或在现实世界中 

582
00:29:28,140 --> 00:29:37,260
操作以及他们如何学习神经 

583
00:29:34,140 --> 00:29:39,480
网络学习是前进传递

584
00:29:37,260 --> 00:29:42,870
获取输入 数据 

585
00:29:39,480 --> 00:29:44,789
从培训阶段开始 

586
00:29:42,870 --> 00:29:47,010
获取输入数据的阶段

587
00:29:44,789 --> 00:29:48,240
产生预测，然后给出 

588
00:29:47,010 --> 00:29:50,549
这是有根本的事实 

589
00:29:48,240 --> 00:29:52,350
培训阶段我们可以有一个 

590
00:29:50,549 --> 00:29:56,309
基于损失的误差测量

591
00:29:52,350 --> 00:29:58,710
然后惩罚的 功能 

592
00:29:56,309 --> 00:30:03,870
突触连接参数

593
00:29:58,710 --> 00:30:08,340
与此相关的 那些 

594
00:30:03,870 --> 00:30:11,399
错误的预测，它回传播

595
00:30:08,340 --> 00:30:13,019
我们将通过这些权重的错误

596
00:30:11,399 --> 00:30:15,600
讨论，在一个 多一点细节 

597
00:30:13,019 --> 00:30:17,460
在这里，我们可以 做些 什么 

598
00:30:15,600 --> 00:30:20,370
深入学习， 你可以一对一 

599
00:30:17,460 --> 00:30:22,289
映射真的你可以把输入视为 

600
00:30:20,370 --> 00:30:24,000
什么都可以，它可以是一些 

601
00:30:22,289 --> 00:30:26,639
矢量数字序列的数字a 

602
00:30:24,000 --> 00:30:28,380
数字矢量序列任何东西 

603
00:30:26,639 --> 00:30:30,360
你可以想到从图像到视频 

604
00:30:28,380 --> 00:30:33,630
音频到文本可以 在 此 表示 

605
00:30:30,360 --> 00:30:36,000
方式和输出可以在相同的 是 

606
00:30:33,630 --> 00:30:40,019
单个号码或它可以是图像视频 

607
00:30:36,000 --> 00:30:42,809
文本音频一对一映射

608
00:30:40,019 --> 00:30:46,799
下一个一对多多到一个很多人 

609
00:30:42,809 --> 00:30:48,919
许多人和许多人不同 

610
00:30:46,799 --> 00:30:54,570
数据的起点

611
00:30:48,919 --> 00:30:57,389
异步一些快速的术语 

612
00:30:54,570 --> 00:31:00,659
深入学习就像新的一样 

613
00:30:57,389 --> 00:31:04,169
网络它真的很神经 

614
00:31:00,659 --> 00:31:06,110
网络大型神经网络是一个 

615
00:31:04,169 --> 00:31:10,010
机器学习的子集

616
00:31:06,110 --> 00:31:12,389
在 过去十年中 非常成功 

617
00:31:10,010 --> 00:31:14,970
多层感知器深度神经网络

618
00:31:12,389 --> 00:31:17,149
网络递归神经网络 

619
00:31:14,970 --> 00:31:19,649
短期记忆网络 lsdm 

620
00:31:17,149 --> 00:31:21,240
卷积神经网络和深层次 

621
00:31:19,649 --> 00:31:25,980
信仰网络所有这些都将来临 

622
00:31:21,240 --> 00:31:28,440
直到幻灯片，并有具体的 

623
00:31:25,980 --> 00:31:30,690
这些网络中的 操作层 

624
00:31:28,440 --> 00:31:32,880
卷积池激活和 

625
00:31:30,690 --> 00:31:36,440
我们将反传这个概念 

626
00:31:32,880 --> 00:31:38,700
在这堂课上讨论

627
00:31:36,440 --> 00:31:42,600
激活功能有很多 

628
00:31:38,700 --> 00:31:44,850
左边的变体是激活 

629
00:31:42,600 --> 00:31:48,590
用于左列 和x轴 

630
00:31:44,850 --> 00:31:51,920
是 y轴上 的输入 是 输出 

631
00:31:48,590 --> 00:31:54,190
sigmoid函数 输出 

632
00:31:51,920 --> 00:31:59,420
如果字体太小，则输出为 

633
00:31:54,190 --> 00:32:02,390
在 10小时内没有居中于零

634
00:31:59,420 --> 00:32:04,180
它的 功能 是以 零 为中心 

635
00:32:02,390 --> 00:32:07,520
从 消失的成分仍然遭受 

636
00:32:04,180 --> 00:32:13,550
消失的 成分是 1的 价值 

637
00:32:07,520 --> 00:32:15,140
输入 低 或高输出 

638
00:32:13,550 --> 00:32:16,730
你在右边看到的网络

639
00:32:15,140 --> 00:32:19,520
列那里的衍生物 

640
00:32:16,730 --> 00:32:26,300
功能很低所以学习 

641
00:32:19,520 --> 00:32:29,150
对于真实的你来说， 率非常低 

642
00:32:26,300 --> 00:32:32,600
也不是零中心，但事实并非如此 

643
00:32:29,150 --> 00:32:34,280
遭受消失的成分 回来 

644
00:32:32,600 --> 00:32:36,950
传播是学习的过程 

645
00:32:34,280 --> 00:32:39,080
这是我们从 错误中 解脱出来的方式 

646
00:32:36,950 --> 00:32:41,180
计算作为损失函数 和 

647
00:32:39,080 --> 00:32:43,610
幻灯片的右下角

648
00:32:41,180 --> 00:32:46,700
一个网络的实际输出

649
00:32:43,610 --> 00:32:49,430
直传从减去 

650
00:32:46,700 --> 00:32:52,460
地面实况平方除以 2 

651
00:32:49,430 --> 00:32:54,800
并使用那个返回的损失函数 

652
00:32:52,460 --> 00:32:57,350
传播通过构建一个

653
00:32:54,800 --> 00:32:58,970
渐变回传播错误 

654
00:32:57,350 --> 00:33:00,770
负责的权重 

655
00:32:58,970 --> 00:33:04,100
做出正确 或不正确的 

656
00:33:00,770 --> 00:33:06,580
决定所以 子办公桌上有一个 

657
00:33:04,100 --> 00:33:09,290
向前传球有一个向后传球和 

658
00:33:06,580 --> 00:33:11,240
一小部分权重梯度 

659
00:33:09,290 --> 00:33:15,650
减去它的重量

660
00:33:11,240 --> 00:33:17,780
这个过程是模块化的，所以它是本地 的 

661
00:33:15,650 --> 00:33:19,940
每个神经元都是这个原因 

662
00:33:17,780 --> 00:33:25,790
非常只是我们能够做到的 

663
00:33:19,940 --> 00:33:31,660
跨越多个分发它 

664
00:33:25,790 --> 00:33:34,940
GPU 在 GPU上并行化 

665
00:33:31,660 --> 00:33:36,860
学习神经网络这些 

666
00:33:34,940 --> 00:33:39,800
比赛单位非常简单 

667
00:33:36,860 --> 00:33:41,060
他们非常简单 ，然后纠正 

668
00:33:39,800 --> 00:33:42,620
当他们犯错的时候

669
00:33:41,060 --> 00:33:45,380
一个更大的网络的一部分，使一个 

670
00:33:42,620 --> 00:33:46,580
错误和所有归结为 

671
00:33:45,380 --> 00:33:49,850
本质上是一个优化问题

672
00:33:46,580 --> 00:33:52,400
目标效用函数在哪里 

673
00:33:49,850 --> 00:33:54,380
损失函数和目标是 

674
00:33:52,400 --> 00:33:56,210
最小化它 ，我们必须更新 

675
00:33:54,380 --> 00:33:58,580
参数权重 和突触 

676
00:33:56,210 --> 00:34:02,930
以及减少损失的偏见 

677
00:33:58,580 --> 00:34:05,860
功能和损失功能是 

678
00:34:02,930 --> 00:34:05,860
高度非线性

679
00:34:05,960 --> 00:34:09,510
取决于激活功能 

680
00:34:08,070 --> 00:34:13,080
不同属性的不同问题 

681
00:34:09,510 --> 00:34:17,419
他们的消失成分 

682
00:34:13,080 --> 00:34:21,900
sigmoid在哪里学习可能很慢 

683
00:34:17,419 --> 00:34:25,290
Raley d 死 了 

684
00:34:21,900 --> 00:34:29,250
对于输入，导数恰好 为零 

685
00:34:25,290 --> 00:34:31,500
小于零有解决方案 

686
00:34:29,250 --> 00:34:33,840
这就像 泄漏的 Raley和 一堆 

687
00:34:31,500 --> 00:34:37,169
细节，你 尝试 你 会发现 

688
00:34:33,840 --> 00:34:38,400
赢得了深度交通竞争但是为了 

689
00:34:37,169 --> 00:34:41,159
这些都是主要的 

690
00:34:38,400 --> 00:34:45,750
激活功能，这是选择 

691
00:34:41,159 --> 00:34:47,179
神经网络设计师哪一个 

692
00:34:45,750 --> 00:34:49,890
效果最好

693
00:34:47,179 --> 00:34:51,659
所有的问题 都有马鞍点 

694
00:34:49,890 --> 00:34:55,610
从你的奇迹非线性 

695
00:34:51,659 --> 00:34:59,240
出现的优化问题出现在这里 

696
00:34:55,610 --> 00:35:02,610
它很难打破对称性 

697
00:34:59,240 --> 00:35:05,700
随机梯度下降没有任何 

698
00:35:02,610 --> 00:35:09,660
一种技巧- 可能需要很长时间 

699
00:35:05,700 --> 00:35:12,090
时间 到达最小的一个 

700
00:35:09,660 --> 00:35:14,100
所有机器中最大的问题

701
00:35:12,090 --> 00:35:16,500
学习，当然深度学习 

702
00:35:14,100 --> 00:35:19,290
过度拟合你可以想到蓝色 

703
00:35:16,500 --> 00:35:23,160
点和这里的图作为数据

704
00:35:19,290 --> 00:35:24,620
我们想要符合我们想要的曲线 

705
00:35:23,160 --> 00:35:27,780
设计一个学习系统 

706
00:35:24,620 --> 00:35:32,490
近似于的回归 

707
00:35:27,780 --> 00:35:36,000
这个绿色的数据是正弦曲线 

708
00:35:32,490 --> 00:35:38,670
简单适合 然后有一个 

709
00:35:36,000 --> 00:35:41,160
这符合甚至 第九 多项式 

710
00:35:38,670 --> 00:35:44,400
在错误方面更好，但它

711
00:35:41,160 --> 00:35:48,060
如果有的话，显然超过了这些 数据 

712
00:35:44,400 --> 00:35:50,640
它还未 上 见过 数据 

713
00:35:48,060 --> 00:35:52,380
它必须适合它可能 产生一个 

714
00:35:50,640 --> 00:35:55,290
高的错误，所以它在 拟合 

715
00:35:52,380 --> 00:35:58,740
训练集这是一个很大的问题 

716
00:35:55,290 --> 00:36:01,230
小 数据集，所以我们必须解决 

717
00:35:58,740 --> 00:36:03,720
正规化 正规化 

718
00:36:01,230 --> 00:36:07,350
是一套阻止的方法论 

719
00:36:03,720 --> 00:36:09,630
过度拟合学习培训 过 

720
00:36:07,350 --> 00:36:14,210
好了，然后不能 

721
00:36:09,630 --> 00:36:15,360
概括到测试阶段和 

722
00:36:14,210 --> 00:36:17,910
过度拟合

723
00:36:15,360 --> 00:36:19,770
主要症状是空气 

724
00:36:17,910 --> 00:36:23,880
和训练集 但增加了 

725
00:36:19,770 --> 00:36:25,170
测试集所以有很多 技巧 

726
00:36:23,880 --> 00:36:26,850
与传统机器学习 是 

727
00:36:25,170 --> 00:36:28,620
处理这个和交叉验证和 

728
00:36:26,850 --> 00:36:31,290
所以，但由于成本 

729
00:36:28,620 --> 00:36:34,050
神经 网络训练

730
00:36:31,290 --> 00:36:36,810
传统 的使用 所谓的a 

731
00:36:34,050 --> 00:36:40,110
验证集，以便您创建一个子集 

732
00:36:36,810 --> 00:36:42,240
你 为之 奋斗的训练 

733
00:36:40,110 --> 00:36:45,120
你有基本的真相和用法 

734
00:36:42,240 --> 00:36:48,990
作为测试的代表 

735
00:36:45,120 --> 00:36:50,670
设置，以便您提前停止或 

736
00:36:48,990 --> 00:36:55,170
更现实地保存一个 

737
00:36:50,670 --> 00:36:59,430
检查站经常看到如何 

738
00:36:55,170 --> 00:37:02,190
培训可以改变绩效变化 

739
00:36:59,430 --> 00:37:03,720
在验证集上 ，所以你可以 

740
00:37:02,190 --> 00:37:05,610
当停止在性能

741
00:37:03,720 --> 00:37:07,440
验证集越来越 糟糕了 

742
00:37:05,610 --> 00:37:13,500
意味着你在过度训练 

743
00:37:07,440 --> 00:37:16,020
培训当然是我们的实践 

744
00:37:13,500 --> 00:37:20,160
进行更长时间的训练，看看何时 

745
00:37:16,020 --> 00:37:22,380
什么是最好的表现是什么 

746
00:37:20,160 --> 00:37:26,460
性能最佳的快照检查点 

747
00:37:22,380 --> 00:37:28,620
网络辍学是另一个非常 

748
00:37:26,460 --> 00:37:30,680
强大的正则化技术在哪里 

749
00:37:28,620 --> 00:37:33,360
我们随机 删除部分网络 

750
00:37:30,680 --> 00:37:36,900
随机删除中的一些 节点 

751
00:37:33,360 --> 00:37:39,450
网络及其 传入和 

752
00:37:36,900 --> 00:37:41,610
外向的边缘， 所以 看起来 真的 

753
00:37:39,450 --> 00:37:44,190
喜欢是保持节点的概率

754
00:37:41,610 --> 00:37:47,670
在许多深度学习框架中 

755
00:37:44,190 --> 00:37:49,560
今天它带有一个 辍学 层 

756
00:37:47,670 --> 00:37:52,380
它本质上是一个概率的 

757
00:37:49,560 --> 00:37:55,710
通常大于0.5 然后 a 

758
00:37:52,380 --> 00:37:58,530
节点将保留为输入层 

759
00:37:55,710 --> 00:38:01,050
概率应该高 得多 

760
00:37:58,530 --> 00:38:03,960
更有效的是，效果如何

761
00:38:01,050 --> 00:38:07,050
添加噪音这里有什么意义 

762
00:38:03,960 --> 00:38:09,240
想要创造足够的多样性 

763
00:38:07,050 --> 00:38:13,920
训练数据 ，使得 它 

764
00:38:09,240 --> 00:38:15,600
可以推广到 测试和 

765
00:38:13,920 --> 00:38:18,750
你会看到 深度交通竞争 

766
00:38:15,600 --> 00:38:22,080
有l2和a1罚分减重 

767
00:38:18,750 --> 00:38:24,240
重量惩罚哪里有一个

768
00:38:22,080 --> 00:38:26,610
penalisation 对 太权

769
00:38:24,240 --> 00:38:29,660
大的l2惩罚保持了它的方式 

770
00:38:26,610 --> 00:38:31,470
除非空气导数很大 

771
00:38:29,660 --> 00:38:35,280
并生产

772
00:38:31,470 --> 00:38:37,680
模型并且更喜欢分发时 

773
00:38:35,280 --> 00:38:39,440
在 两个它更类似于输入 

774
00:38:37,680 --> 00:38:41,819
把 每个重量 减半 

775
00:38:39,440 --> 00:38:44,510
分配的权重，而不是 

776
00:38:41,819 --> 00:38:48,240
将重量放在其中一个 边缘上 

777
00:38:44,510 --> 00:38:50,130
使我们的网络更健壮 

778
00:38:48,240 --> 00:38:52,650
处罚有一个好处 ，对于 

779
00:38:50,130 --> 00:38:55,500
他们被允许的权重非常大 

780
00:38:52,650 --> 00:38:58,050
要保持这样，它允许 一些 

781
00:38:55,500 --> 00:39:00,060
权重仍然非常大，这些 都 

782
00:38:58,050 --> 00:39:01,380
正规化技术和我 

783
00:39:00,060 --> 00:39:03,089
我想提及它们，因为 它们是 

784
00:39:01,380 --> 00:39:05,760
对这里的一些比赛很有用

785
00:39:03,089 --> 00:39:07,470
在课程中，我建议去 

786
00:39:05,760 --> 00:39:09,690
操场帐篷 寺庙 地板 

787
00:39:07,470 --> 00:39:12,690
操场上玩的一些 

788
00:39:09,690 --> 00:39:14,880
您可以在线访问这些参数 

789
00:39:12,690 --> 00:39:16,650
在浏览器中玩弄 

790
00:39:14,880 --> 00:39:18,119
不同的输入不同功能

791
00:39:16,650 --> 00:39:21,089
不同数目的 层和 

792
00:39:18,119 --> 00:39:22,530
正规化技术和建设

793
00:39:21,089 --> 00:39:24,869
你对分类的直觉 

794
00:39:22,530 --> 00:39:31,589
给出不同的回归问题 

795
00:39:24,869 --> 00:39:34,950
输入数据集，所以改变了 原因 

796
00:39:31,589 --> 00:39:37,290
过去 几十年的 神经 网络 

797
00:39:34,950 --> 00:39:40,140
经历了 两个冬天的是 

798
00:39:37,290 --> 00:39:45,450
现在又占据 了 人工 

799
00:39:40,140 --> 00:39:47,550
智能社区CPUs GPU Asics 

800
00:39:45,450 --> 00:39:53,940
所以计算能力飙升 

801
00:39:47,550 --> 00:39:57,920
从摩尔定律到GPU， 存在巨大的问题 

802
00:39:53,940 --> 00:40:02,130
数据集包括图像网 和其他 

803
00:39:57,920 --> 00:40:07,560
有研究反向传播 

804
00:40:02,130 --> 00:40:10,430
80年代的卷积神经 

805
00:40:07,560 --> 00:40:12,810
网络LSDM那里已经有很多 

806
00:40:10,430 --> 00:40:14,970
关于如何有趣的突破

807
00:40:12,810 --> 00:40:16,319
设计这些架构 如何构建 

808
00:40:14,970 --> 00:40:21,000
他们是可以训练的 

809
00:40:16,319 --> 00:40:22,770
有效地使用GPU有

810
00:40:21,000 --> 00:40:25,500
软件基础设施能够 

811
00:40:22,770 --> 00:40:28,319
共享 数据或得到能够 

812
00:40:25,500 --> 00:40:31,020
培训网络和共享 代码和 

813
00:40:28,319 --> 00:40:33,960
有效地将网络作为一个网络 

814
00:40:31,020 --> 00:40:35,579
层叠而不是必须 

815
00:40:33,960 --> 00:40:37,140
从头开始实现的东西与 

816
00:40:35,579 --> 00:40:39,180
tensorflow pi火炬和其他 

817
00:40:37,140 --> 00:40:41,160
和其他深度 学习框架和 

818
00:40:39,180 --> 00:40:44,510
有巨大的财政支持 

819
00:40:41,160 --> 00:40:44,510
谷歌Facebook 等 

820
00:40:45,230 --> 00:40:56,940
深度学习是为了理解 

821
00:40:52,830 --> 00:40:58,950
为什么这么好 ，它的地方 

822
00:40:56,940 --> 00:41:00,840
我们需要了解的局限性

823
00:40:58,950 --> 00:41:03,300
我们自己的直觉来自何处

824
00:41:00,840 --> 00:41:04,590
什么是困难，什么是容易的 

825
00:41:03,300 --> 00:41:06,180
关于计算机视觉的重要事

826
00:41:04,590 --> 00:41:08,280
这是很多的这个课程 是 什么 

827
00:41:06,180 --> 00:41:11,100
约 什 它在深层加固 

828
00:41:08,280 --> 00:41:13,860
学习的表述就是视觉 

829
00:41:11,100 --> 00:41:17,100
对我们人类的看法是 

830
00:41:13,860 --> 00:41:21,180
形成5.4亿 年前 

831
00:41:17,100 --> 00:41:25,140
那是5.4 亿年的价值 

832
00:41:21,180 --> 00:41:26,820
数据只是抽象思维 

833
00:41:25,140 --> 00:41:29,850
形成了大约十万年 

834
00:41:26,820 --> 00:41:33,930
那是几个 数量级 

835
00:41:29,850 --> 00:41:39,740
更少的数据， 所以我们可以用神经 

836
00:41:33,930 --> 00:41:43,980
网络预测似乎微不足道 

837
00:41:39,740 --> 00:41:47,610
这对我们人类来说是微不足道的

838
00:41:43,980 --> 00:41:50,280
完全充满挑战和错误的 

839
00:41:47,610 --> 00:41:52,620
左边的神经网络显示 

840
00:41:50,280 --> 00:41:54,240
一点点预测一只狗 

841
00:41:52,620 --> 00:41:55,950
失真和噪音添加到 

842
00:41:54,240 --> 00:41:59,400
图像生成 右侧图像 

843
00:41:55,950 --> 00:42:01,770
并且您的网络充满信心 99 

844
00:41:59,400 --> 00:42:06,750
％加上准确预测 ， 

845
00:42:01,770 --> 00:42:08,460
这是一只鸵鸟 ，还有所有这些 

846
00:42:06,750 --> 00:42:10,560
问题是 要处理 它是否存在 

847
00:42:08,460 --> 00:42:13,580
计算机视觉数据是否存在

848
00:42:10,560 --> 00:42:16,800
所有这些变化的文本数据音频 

849
00:42:13,580 --> 00:42:19,770
在视觉中产生它的照明 

850
00:42:16,800 --> 00:42:21,090
可变性像素集和 

851
00:42:19,770 --> 00:42:22,800
数字看起来完全不同 

852
00:42:21,090 --> 00:42:24,830
根据照明 条件 

853
00:42:22,800 --> 00:42:27,660
这是驾驶中最大的问题

854
00:42:24,830 --> 00:42:31,020
照明条件照明可变性 

855
00:42:27,660 --> 00:42:33,120
姿势变化的对象必须 

856
00:42:31,020 --> 00:42:35,280
从各个不同的角度学习

857
00:42:33,120 --> 00:42:38,460
我将在感知时进行讨论

858
00:42:35,280 --> 00:42:40,020
驱动程序大部分是大多数 深层次的 

859
00:42:38,460 --> 00:42:43,290
这是一个在 脸上 做 了学习工作 

860
00:42:40,020 --> 00:42:45,870
人类是在正面或 

861
00:42:43,290 --> 00:42:49,820
半正面很少

862
00:42:45,870 --> 00:42:51,690
在 360 姿势完成的工作

863
00:42:49,820 --> 00:42:54,110
人类 可以 变化的可变性 

864
00:42:51,690 --> 00:42:54,110
接受

865
00:42:55,310 --> 00:42:58,850
对 组内的变异 

866
00:42:57,170 --> 00:43:01,130
检测的 分类问题 

867
00:42:58,850 --> 00:43:03,530
问题有很多 不同 

868
00:43:01,130 --> 00:43:07,850
猫狗车的各种物品

869
00:43:03,530 --> 00:43:10,190
骑自行车的行人带来了我们

870
00:43:07,850 --> 00:43:13,880
为对象的分类和我想 

871
00:43:10,190 --> 00:43:16,310
带你了解深度 学习的 地方 

872
00:43:13,880 --> 00:43:20,990
过去几次取得了重大进展

873
00:43:16,310 --> 00:43:24,200
到今年 到2018年这么多年

874
00:43:20,990 --> 00:43:26,990
让我们开始在对象分类 

875
00:43:24,200 --> 00:43:30,920
当你拍摄单张照片时 

876
00:43:26,990 --> 00:43:33,730
不得不说一个最有可能的课程 

877
00:43:30,920 --> 00:43:35,750
属于那个最着名的形象 

878
00:43:33,730 --> 00:43:37,850
其变体 是 图像网 

879
00:43:35,750 --> 00:43:39,860
竞争形象网挑战形象 

880
00:43:37,850 --> 00:43:44,150
现在数据集是一个1400万的数据集

881
00:43:39,860 --> 00:43:46,550
21个000类别和图像

882
00:43:44,150 --> 00:43:50,630
说水果 的类别 有一个 

883
00:43:46,550 --> 00:43:53,660
总的 果实的180倍8000的图像和 

884
00:43:50,630 --> 00:43:55,730
有1200张奶奶史密斯的照片 

885
00:43:53,660 --> 00:43:58,790
苹果它让你感觉到什么 

886
00:43:55,730 --> 00:44:02,420
我们在这里讨论的 所以这 

887
00:43:58,790 --> 00:44:04,310
一直是很多 有趣 的来源 

888
00:44:02,420 --> 00:44:06,820
深度学习的突破和很多

889
00:44:04,310 --> 00:44:10,370
深度学习 中的兴奋 是 

890
00:44:06,820 --> 00:44:14,240
首先在大圆满 网络 

891
00:44:10,370 --> 00:44:17,510
至少一个成名和深刻的人 

892
00:44:14,240 --> 00:44:20,870
学习是 Alex网络在2012年 花了一个 

893
00:44:17,510 --> 00:44:22,960
飞跃的重大飞跃 

894
00:44:20,870 --> 00:44:25,160
对图像网络挑战的表现

895
00:44:22,960 --> 00:44:27,140
所以它是第一个神经元之一 

896
00:44:25,160 --> 00:44:29,690
网络虽然成功接受了培训 

897
00:44:27,140 --> 00:44:31,700
GPU 并取得了不可思议的成就 

898
00:44:29,690 --> 00:44:34,400
性能比上一年有所提升

899
00:44:31,700 --> 00:44:36,410
在图像网上挑战挑战 

900
00:44:34,400 --> 00:44:38,750
是，我会谈谈 其中的一些 

901
00:44:36,410 --> 00:44:42,080
网络给予一个单一的 图像 

902
00:44:38,750 --> 00:44:44,330
给出五个猜测，你有五个 

903
00:44:42,080 --> 00:44:47,660
猜猜他们中的一个是 

904
00:44:44,330 --> 00:44:49,340
纠正人类注释是一个 

905
00:44:47,660 --> 00:44:51,680
问题经常出现，你怎么样 

906
00:44:49,340 --> 00:44:54,830
了解人类的基本事实

907
00:44:51,680 --> 00:44:59,810
性能是5.1 ％的准确度 

908
00:44:54,830 --> 00:45:02,150
这个任务，但标注了道路

909
00:44:59,810 --> 00:45:04,880
图像网执行是有一个 

910
00:45:02,150 --> 00:45:07,130
Google 搜索您提取图片的位置 

911
00:45:04,880 --> 00:45:08,630
已经贴上了你的标签，然后是 

912
00:45:07,130 --> 00:45:10,700
注解 

913
00:45:08,630 --> 00:45:12,770
机械土耳其人其他人的表演是 

914
00:45:10,700 --> 00:45:14,930
只是二元是这只猫还是不是猫 

915
00:45:12,770 --> 00:45:18,200
所以他们不负责表演 

916
00:45:14,930 --> 00:45:21,160
非常高分辨率的语义 

917
00:45:18,200 --> 00:45:25,040
图像的标记

918
00:45:21,160 --> 00:45:29,780
好的，所以从2012年到亚历克斯网 

919
00:45:25,040 --> 00:45:31,760
到今天和2018年的大转型 

920
00:45:29,780 --> 00:45:35,630
图像网络挑战离开 

921
00:45:31,760 --> 00:45:38,630
斯坦福和 凯格尔就是这样的 

922
00:45:35,630 --> 00:45:41,150
这是一个巨大的举措，因为在2015年 

923
00:45:38,630 --> 00:45:43,070
谐振 网络是 第一次 

924
00:45:41,150 --> 00:45:48,260
人的水平表现 

925
00:45:43,070 --> 00:45:53,300
超出了，我认为这是非常的 

926
00:45:48,260 --> 00:45:55,550
深度学习的重要地图

927
00:45:53,300 --> 00:45:57,950
特别是我认为是一个 

928
00:45:55,550 --> 00:46:00,530
尽管 它的玩具例子

929
00:45:57,950 --> 00:46:03,170
我们正在开发1400万张图像

930
00:46:00,530 --> 00:46:05,750
这里和最 先进的 技术 

931
00:46:03,170 --> 00:46:08,000
我们现在超越人类的下一阶段

932
00:46:05,750 --> 00:46:09,890
在 这个任务级别的性能如何 

933
00:46:08,000 --> 00:46:13,490
把这些方法带入现实世界 

934
00:46:09,890 --> 00:46:21,370
执行场景 感知 

935
00:46:13,490 --> 00:46:24,350
2016年和2017年的驾驶员状态感知 

936
00:46:21,370 --> 00:46:26,930
看到你的形象和se net有一个非常 

937
00:46:24,350 --> 00:46:28,790
独一无二的新增功能 

938
00:46:26,930 --> 00:46:33,740
已达到的配方

939
00:46:28,790 --> 00:46:35,150
2.2％误差的准确度2.25 

940
00:46:33,740 --> 00:46:36,830
图像网上的百分比误差 

941
00:46:35,150 --> 00:46:39,290
分类挑战它是一个

942
00:46:36,830 --> 00:46:42,200
令人难以置信的结果 好，所以你 有这个 

943
00:46:39,290 --> 00:46:44,900
图像分类架构 

944
00:46:42,200 --> 00:46:47,300
拍摄单个图像并生成 

945
00:46:44,900 --> 00:46:49,700
卷积并通过汇集来实现 

946
00:46:47,300 --> 00:46:51,230
卷积，最后完全 

947
00:46:49,700 --> 00:46:53,090
连接层并执行

948
00:46:51,230 --> 00:46:55,040
分类 任务或回归任务 

949
00:46:53,090 --> 00:46:58,810
你 可以换 出 那层 

950
00:46:55,040 --> 00:47:00,980
执行任何其他任务 

951
00:46:58,810 --> 00:47:03,500
包括复发神经网络

952
00:47:00,980 --> 00:47:06,770
图像字幕等等

953
00:47:03,500 --> 00:47:09,410
边界框或您的本地化

954
00:47:06,770 --> 00:47:13,250
可以做完全卷积网络

955
00:47:09,410 --> 00:47:16,610
我们将在周四讨论哪个 

956
00:47:13,250 --> 00:47:18,860
是当你把图像作为输入和 

957
00:47:16,610 --> 00:47:20,600
产生一个图像 作为输出，但 在哪里 

958
00:47:18,860 --> 00:47:21,860
在 这种情况下的输出图像是 

959
00:47:20,600 --> 00:47:25,460
分割 

960
00:47:21,860 --> 00:47:28,040
是一个颜色表明什么的

961
00:47:25,460 --> 00:47:30,140
object是the的类别 

962
00:47:28,040 --> 00:47:31,580
对象所以 它是像素级别的分割 

963
00:47:30,140 --> 00:47:35,090
图像中的每个像素都是 

964
00:47:31,580 --> 00:47:39,200
为一个类分配了一个类别 

965
00:47:35,090 --> 00:47:43,640
像素属于这种类型

966
00:47:39,200 --> 00:47:45,680
任务覆盖在其他任务之上 

967
00:47:43,640 --> 00:47:48,890
汽车的感官信息

968
00:47:45,680 --> 00:47:51,770
为了感知外在的 

969
00:47:48,890 --> 00:47:54,230
环境你可以继续 提取 

970
00:47:51,770 --> 00:47:56,150
以这种方式来自图像的信息

971
00:47:54,230 --> 00:47:58,730
生成图像到图像的映射 

972
00:47:56,150 --> 00:48:04,220
将图像着色并从中获取的示例

973
00:47:58,730 --> 00:48:05,900
灰度图像彩色图像或你

974
00:48:04,220 --> 00:48:08,120
可以使用那种热图 

975
00:48:05,900 --> 00:48:10,400
用于本地化对象的信息 

976
00:48:08,120 --> 00:48:13,820
图像，而不是仅仅分类 

977
00:48:10,400 --> 00:48:16,970
这是我们CNN的一头牛的形象 

978
00:48:13,820 --> 00:48:19,880
我们的CNN 和很多都 快速而 快速 

979
00:48:16,970 --> 00:48:22,490
其他本地化网络允许您

980
00:48:19,880 --> 00:48:24,590
提出不同的候选人在哪里 

981
00:48:22,490 --> 00:48:26,990
确切地说，牛位于此图像中 

982
00:48:24,590 --> 00:48:30,730
从而能够执行对象 

983
00:48:26,990 --> 00:48:30,730
检测不仅仅是对象分类 

984
00:48:31,510 --> 00:48:37,790
在2017年已经 很酷了 

985
00:48:34,580 --> 00:48:40,400
这些架构的应用之一

986
00:48:37,790 --> 00:48:42,980
其中再次删除背景 

987
00:48:40,400 --> 00:48:46,150
从图像映射到图像的能力 

988
00:48:42,980 --> 00:48:53,170
删除自拍的背景和背景

989
00:48:46,150 --> 00:48:57,080
人类或类似人类的 面孔 照片 

990
00:48:53,170 --> 00:48:59,090
参考是一些令人难以置信的

991
00:48:57,080 --> 00:49:01,130
动画在底部 

992
00:48:59,090 --> 00:49:08,810
幻灯片和幻灯片现在可用 

993
00:49:01,130 --> 00:49:12,290
在线pix描述HD有很多 

994
00:49:08,810 --> 00:49:16,480
工作和Ganz 在生成技巧 

995
00:49:12,290 --> 00:49:19,910
特别是 在驾驶中的空中网络

996
00:49:16,480 --> 00:49:24,140
Ganz已被用于 生成示例 

997
00:49:19,910 --> 00:49:26,420
从源数据生成示例

998
00:49:24,140 --> 00:49:29,110
无论是原始数据 还是 原始数据 

999
00:49:26,420 --> 00:49:32,810
案例与pix HD pics 正在拍摄 

1000
00:49:29,110 --> 00:49:35,750
当然，图像的 语义标签 

1001
00:49:32,810 --> 00:49:39,590
像素 级别和生产 

1002
00:49:35,750 --> 00:49:42,340
真实感的高清图像 

1003
00:49:39,590 --> 00:49:45,740
前进的道路这是 令人兴奋的 

1004
00:49:42,340 --> 00:49:48,080
能够 生成的可能性

1005
00:49:45,740 --> 00:49:49,910
各种 自动驾驶汽车 的案例 

1006
00:49:48,080 --> 00:49:51,980
自动驾驶汽车能够 

1007
00:49:49,910 --> 00:49:54,470
学会生成以增加数据 

1008
00:49:51,980 --> 00:49:56,600
并 能够 改变不同的方式 

1009
00:49:54,470 --> 00:49:59,650
道路看路况改变了 

1010
00:49:56,600 --> 00:50:02,000
车辆看起来像骑自行车的人行人

1011
00:49:59,650 --> 00:50:03,560
然后我们可以继续进行反复神经 

1012
00:50:02,000 --> 00:50:06,590
网络我所谈论的一切

1013
00:50:03,560 --> 00:50:08,990
是从图像到图像 的一对一 映射 

1014
00:50:06,590 --> 00:50:11,690
图像或图像编号，但内核 

1015
00:50:08,990 --> 00:50:19,090
我们可以使用序列工作的网络

1016
00:50:11,690 --> 00:50:22,480
使用序列生成手写

1017
00:50:19,090 --> 00:50:24,920
从图像生成文本标题 

1018
00:50:22,480 --> 00:50:29,870
基于本地化作为各种 

1019
00:50:24,920 --> 00:50:32,900
我们可以提供的图像中的检测

1020
00:50:29,870 --> 00:50:35,450
视频描述生成所以采取

1021
00:50:32,900 --> 00:50:37,520
视频和组合卷积神经 

1022
00:50:35,450 --> 00:50:39,500
具有 递归神经网络的网络 

1023
00:50:37,520 --> 00:50:41,540
使用卷积神经网络

1024
00:50:39,500 --> 00:50:44,540
提取框架到框架和 

1025
00:50:41,540 --> 00:50:48,550
使用那些提取的特征 来输入 

1026
00:50:44,540 --> 00:50:51,650
进入我们的 TRN 结束然后生成一个 

1027
00:50:48,550 --> 00:50:55,610
标记对正在发生的事情 的描述 

1028
00:50:51,650 --> 00:50:57,380
视频中的 许多 令人兴奋 

1029
00:50:55,610 --> 00:51:01,070
自治系统的方法

1030
00:50:57,380 --> 00:51:05,240
特别是在无人机所在的时间 

1031
00:51:01,070 --> 00:51:07,330
做出决定与之相同 

1032
00:51:05,240 --> 00:51:09,980
遥控车每小时行驶30英里

1033
00:51:07,330 --> 00:51:11,870
转向的注意机制

1034
00:51:09,980 --> 00:51:15,080
网络的关注度非常高 

1035
00:51:11,870 --> 00:51:17,750
流行的 本地化 任务， 

1036
00:51:15,080 --> 00:51:19,550
只是为了节省多少解释

1037
00:51:17,750 --> 00:51:22,970
图像需要多少像素 

1038
00:51:19,550 --> 00:51:25,850
在 分类任务这么认为

1039
00:51:22,970 --> 00:51:28,010
我们可以操纵 我们可以模仿的方式 

1040
00:51:25,850 --> 00:51:29,570
人类围绕图像来寻找 

1041
00:51:28,010 --> 00:51:31,970
解释它并使用 网络来做 

1042
00:51:29,570 --> 00:51:41,810
同样，我们可以使用 那种 

1043
00:51:31,970 --> 00:51:45,370
转向最终绘制图像

1044
00:51:41,810 --> 00:51:49,400
2017年的重大突破来自于 

1045
00:51:45,370 --> 00:51:49,670
这个pong像素 加固 

1046
00:51:49,400 --> 00:51:52,760
学习

1047
00:51:49,670 --> 00:51:54,890
使用感觉数据原始感觉数据和 

1048
00:51:52,760 --> 00:51:56,210
深入使用强化学习方法 

1049
00:51:54,890 --> 00:51:58,339
你将谈论的所有方法 

1050
00:51:56,210 --> 00:52:01,190
大约和周三 我真的很兴奋 

1051
00:51:58,339 --> 00:52:05,839
关于 深层次 的 基本方法论 

1052
00:52:01,190 --> 00:52:09,730
交通和深度崩溃正在使用神经 

1053
00:52:05,839 --> 00:52:12,109
网络作为内部的近似错误 

1054
00:52:09,730 --> 00:52:14,630
强化学习方法如此

1055
00:52:12,109 --> 00:52:17,630
alphago在2016年取得了成功 

1056
00:52:14,630 --> 00:52:19,069
我第一次做的巨大任务

1057
00:52:17,630 --> 00:52:21,559
开始在人工智能 是 

1058
00:52:19,069 --> 00:52:24,500
告诉我一个系统是不可能的 

1059
00:52:21,559 --> 00:52:26,660
完成哪个是赢得比赛 

1060
00:52:24,500 --> 00:52:30,589
与... 中的顶级人类玩家对抗 

1061
00:52:26,660 --> 00:52:34,099
然而，这个方法是世界

1062
00:52:30,589 --> 00:52:37,130
接受过人类专家培训 

1063
00:52:34,099 --> 00:52:40,309
alphago系统在之前接受过培训 

1064
00:52:37,130 --> 00:52:42,400
人类专家和一个人玩的游戏

1065
00:52:40,309 --> 00:52:47,950
不可思议的成就

1066
00:52:42,400 --> 00:52:52,730
2017 年的 alphago零能够击败 

1067
00:52:47,950 --> 00:52:58,369
alphago 及其许多变种 

1068
00:52:52,730 --> 00:53:02,599
从零信息中发挥作用

1069
00:52:58,369 --> 00:53:06,740
没有人类专家的 知识 没有游戏 

1070
00:53:02,599 --> 00:53:10,210
没有训练数据很少人为输入 

1071
00:53:06,740 --> 00:53:13,130
它还能产生什么呢

1072
00:53:10,210 --> 00:53:17,450
举动，是令人惊讶的人类 

1073
00:53:13,130 --> 00:53:21,049
专家我认为这是爱因斯坦说的 

1074
00:53:17,450 --> 00:53:24,530
那种智慧是关键的标志 

1075
00:53:21,049 --> 00:53:25,910
智力是我想象的想象力 

1076
00:53:24,530 --> 00:53:27,740
美女看人工 

1077
00:53:25,910 --> 00:53:31,030
智能系统想出来 了 

1078
00:53:27,740 --> 00:53:37,160
令人类专家惊喜的东西

1079
00:53:31,030 --> 00:53:41,059
赌博迷真的很惊喜

1080
00:53:37,160 --> 00:53:44,059
深堆栈和其他一些变种 

1081
00:53:41,059 --> 00:53:47,119
在2017年用于赢得单挑局 

1082
00:53:44,059 --> 00:53:48,650
扑克又一次令人难以置信的结果 我 

1083
00:53:47,119 --> 00:53:50,510
人工总是被告知

1084
00:53:48,650 --> 00:53:53,240
情报是不可能 的 

1085
00:53:50,510 --> 00:53:55,339
深入了解任何机器学习方法

1086
00:53:53,240 --> 00:53:57,079
实现并且能够击败一个 

1087
00:53:55,339 --> 00:54:00,890
职业球员和几个 

1088
00:53:57,079 --> 00:54:03,470
竞争对手从我们这里开始 

1089
00:54:00,890 --> 00:54:05,359
但是能够 击败赢得比赛 

1090
00:54:03,470 --> 00:54:06,619
设置多个玩家 

1091
00:54:05,359 --> 00:54:08,960
你熟悉的单挑扑克是

1092
00:54:06,619 --> 00:54:13,310
一对一， 它要小得多 

1093
00:54:08,960 --> 00:54:15,619
更容易解决的空间还有很多 

1094
00:54:13,310 --> 00:54:17,630
人类的人类动态从何时开始 

1095
00:54:15,619 --> 00:54:23,900
有多个球员，但那是 

1096
00:54:17,630 --> 00:54:26,660
2018年的任务和 缺点是一个 

1097
00:54:23,900 --> 00:54:30,109
他最喜欢的视频经常出现 

1098
00:54:26,660 --> 00:54:33,070
对于这些深海的海岸跑步者 

1099
00:54:30,109 --> 00:54:35,960
强化学习接近

1100
00:54:33,070 --> 00:54:37,670
奖励功能的学习

1101
00:54:35,960 --> 00:54:42,140
功能链这个词的定义

1102
00:54:37,670 --> 00:54:45,200
控制实际系统的行为方式 

1103
00:54:42,140 --> 00:54:46,430
这会是这样的 

1104
00:54:45,200 --> 00:54:49,970
对我们来说 极为重要 与 

1105
00:54:46,430 --> 00:54:52,280
这里的自动驾驶汽车是 

1106
00:54:49,970 --> 00:54:54,800
任务胜过最高 

1107
00:54:52,280 --> 00:54:56,900
点的数量和它的数字指出 ， 

1108
00:54:54,800 --> 00:54:58,880
它不需要比赛 

1109
00:54:56,900 --> 00:55:02,300
游戏的整点 ， 以获得 

1110
00:54:58,880 --> 00:55:05,080
点而 不是拿起绿色圆圈 

1111
00:55:02,300 --> 00:55:09,220
一遍 又一遍地重生

1112
00:55:05,080 --> 00:55:14,450
这是违反直觉的 

1113
00:55:09,220 --> 00:55:15,920
系统的 行为 不会 

1114
00:55:14,450 --> 00:55:17,810
预计当你第一次设计时 

1115
00:55:15,920 --> 00:55:20,710
奖励功能，这 是非常的 

1116
00:55:17,810 --> 00:55:23,150
然而，正式的简单系统是 

1117
00:55:20,710 --> 00:55:25,790
非常难以想出 一个 

1118
00:55:23,150 --> 00:55:27,580
使其运作的 奖励 功能 

1119
00:55:25,790 --> 00:55:30,980
你希望它 非常的运作方式

1120
00:55:27,580 --> 00:55:33,680
适用于自动驾驶汽车和 

1121
00:55:30,980 --> 00:55:35,480
当然在我的感知方面 

1122
00:55:33,680 --> 00:55:38,599
与鸵鸟 和狗一起提到的 

1123
00:55:35,480 --> 00:55:40,520
九十九点有点噪音 

1124
00:55:38,599 --> 00:55:42,770
我们可以有6％的信心 

1125
00:55:40,520 --> 00:55:45,650
预测顶部的噪音是一个 

1126
00:55:42,770 --> 00:55:47,380
抢劫猎豹 犰狳小熊猫 

1127
00:55:45,650 --> 00:55:52,010
这些是实际的输出 

1128
00:55:47,380 --> 00:55:54,020
最先进的神经网络 

1129
00:55:52,010 --> 00:55:57,260
在噪音和产生自信

1130
00:55:54,020 --> 00:55:59,359
预测它应该建立我们的直觉 

1131
00:55:57,260 --> 00:56:02,240
明白我们不是那个 

1132
00:55:59,359 --> 00:56:04,369
视觉特征视觉 

1133
00:56:02,240 --> 00:56:06,770
图像的空间特征确实如此 

1134
00:56:04,369 --> 00:56:08,960
不一定传达的水平

1135
00:56:06,770 --> 00:56:14,240
在这里运作所必需的等级

1136
00:56:08,960 --> 00:56:17,270
世界以类似的方式与一只狗在一起 

1137
00:56:14,240 --> 00:56:19,730
鸵鸟和鸵鸟和鸵鸟的一切

1138
00:56:17,270 --> 00:56:21,850
有点自信地工作

1139
00:56:19,730 --> 00:56:24,530
噪音可以做出错误的预测 

1140
00:56:21,850 --> 00:56:29,210
把校车 当成鸵鸟 

1141
00:56:24,530 --> 00:56:33,740
他们是一个鸵鸟的演讲者 

1142
00:56:29,210 --> 00:56:35,210
很容易被愚弄，但 不是因为 

1143
00:56:33,740 --> 00:56:40,100
他们的表现 ，他们 的任务 

1144
00:56:35,210 --> 00:56:45,500
训练有素， 所以我们必须做 

1145
00:56:40,100 --> 00:56:47,630
我们确保我们的直觉得到优化 

1146
00:56:45,500 --> 00:56:50,780
机器学习 的方式 不是 这样的 

1147
00:56:47,630 --> 00:56:53,510
人类已经学到了超过 5.4亿 

1148
00:56:50,780 --> 00:56:56,600
多年来我们获得的数据 

1149
00:56:53,510 --> 00:56:58,910
通过进化来发展人工智能 

1150
00:56:56,600 --> 00:57:01,670
目前的挑战首先出现

1151
00:56:58,910 --> 00:57:03,860
转学习有很多 

1152
00:57:01,670 --> 00:57:05,480
转学中的成功

1153
00:57:03,860 --> 00:57:07,880
域名非常接近每个 

1154
00:57:05,480 --> 00:57:11,240
其他如此图像分类 

1155
00:57:07,880 --> 00:57:12,980
领域到下一个有很多 

1156
00:57:11,240 --> 00:57:15,890
形成表征的价值

1157
00:57:12,980 --> 00:57:18,620
方式场景看起来以显示场景 

1158
00:57:15,890 --> 00:57:20,630
看看是为了做场景分割 

1159
00:57:18,620 --> 00:57:25,130
例如驾驶案例， 但我们是 

1160
00:57:20,630 --> 00:57:26,690
无法做任何更大的飞跃 

1161
00:57:25,130 --> 00:57:29,090
它会执行传输 方式 

1162
00:57:26,690 --> 00:57:31,520
学习深刻的最大挑战 

1163
00:57:29,090 --> 00:57:34,850
学习是概括推广

1164
00:57:31,520 --> 00:57:37,040
跨域， 它缺乏能力 

1165
00:57:34,850 --> 00:57:39,560
我们 定义 的方式的原因

1166
00:57:37,040 --> 00:57:41,630
以前了解哪个是

1167
00:57:39,560 --> 00:57:46,460
将复杂信息转化为的能力 

1168
00:57:41,630 --> 00:57:49,900
简单有用的信息转换域 

1169
00:57:46,460 --> 00:57:52,460
具体复杂的感官信息 

1170
00:57:49,900 --> 00:57:55,190
与 初始 无关 

1171
00:57:52,460 --> 00:57:57,530
培训设定这是一个开放的挑战 

1172
00:57:55,190 --> 00:57:59,870
深度学习很少受到训练 

1173
00:57:57,530 --> 00:58:02,690
数据，然后去理由 和操作 

1174
00:57:59,870 --> 00:58:04,580
在现实世界中你 现在 知道了 

1175
00:58:02,690 --> 00:58:08,120
他们需要什么是非常低效的 

1176
00:58:04,580 --> 00:58:10,040
大数据需要监督数据 

1177
00:58:08,120 --> 00:58:13,510
这意味着他们 需要 的 人力 成本 

1178
00:58:10,040 --> 00:58:15,350
人类输入他们没有完全自动化 

1179
00:58:13,510 --> 00:58:17,600
尽管该功能的事实

1180
00:58:15,350 --> 00:58:19,160
学习难以置信的重大突破 

1181
00:58:17,600 --> 00:58:22,040
进行特征学习 

1182
00:58:19,160 --> 00:58:23,690
自动你还需要做很多事情 

1183
00:58:22,040 --> 00:58:25,670
设计 的 实际 架构 

1184
00:58:23,690 --> 00:58:27,460
网络和所有不同的超级 

1185
00:58:25,670 --> 00:58:30,770
需要执行参数调整

1186
00:58:27,460 --> 00:58:31,140
人的输入可能还要多一点 

1187
00:58:30,770 --> 00:58:33,750
前卫

1188
00:58:31,140 --> 00:58:37,050
kthuman 输入和前博士生 

1189
00:58:33,750 --> 00:58:39,000
博士后教员必须参加

1190
00:58:37,050 --> 00:58:40,590
超级女孩做这些超级参数 

1191
00:58:39,000 --> 00:58:44,730
但人类的投入仍然存在 

1192
00:58:40,590 --> 00:58:48,270
必要的， 他们不能单独留下 来 

1193
00:58:44,730 --> 00:58:49,710
大部分奖励定义了 

1194
00:58:48,270 --> 00:58:52,290
我们看到沿海跑的奖励是 

1195
00:58:49,710 --> 00:58:54,020
系统极其困难

1196
00:58:52,290 --> 00:58:57,960
在 现实世界中 运作 

1197
00:58:54,020 --> 00:58:59,640
透明度很可能不是一个

1198
00:58:57,960 --> 00:59:01,530
重要的是神经网络 

1199
00:58:59,640 --> 00:59:04,020
目前是 最 黑的盒子 

1200
00:59:01,530 --> 00:59:05,970
部分他们无法接受 

1201
00:59:04,020 --> 00:59:07,980
一些成功的可视化方法 

1202
00:59:05,970 --> 00:59:11,400
可视化的不同方面 

1203
00:59:07,980 --> 00:59:14,820
激活， 他们无法 透露 

1204
00:59:11,400 --> 00:59:18,420
给我们人类他们为什么工作或他们在哪里 

1205
00:59:14,820 --> 00:59:21,390
失败，这是一个哲学 

1206
00:59:18,420 --> 00:59:23,550
对于我们自动驾驶汽车的问题 

1207
00:59:21,390 --> 00:59:26,550
如果一个系统可能不关心人类

1208
00:59:23,550 --> 00:59:30,690
作品不够好，但我认为 ， 

1209
00:59:26,550 --> 00:59:33,540
系统之前需要很长时间 

1210
00:59:30,690 --> 00:59:35,430
工作不够好，或者我们不关心，我们将 

1211
00:59:33,540 --> 00:59:37,140
我们必须共同努力

1212
00:59:35,430 --> 00:59:38,910
有了这些系统 ，就在 那里 

1213
00:59:37,140 --> 00:59:42,270
透明度沟通协作

1214
00:59:38,910 --> 00:59:46,700
是至关重要的边缘情况下， 它是所有关于 

1215
00:59:42,270 --> 00:59:50,580
Thomas车辆中的机器人教育工作者

1216
00:59:46,700 --> 00:59:53,190
99.9％的驾驶真的很无聊 

1217
00:59:50,580 --> 00:59:56,550
特别是高速公路驾驶也是如此 

1218
00:59:53,190 --> 00:59:58,650
交通驾驶它是一样的 

1219
00:59:56,550 --> 01:00:00,690
避障继汽车

1220
00:59:58,650 --> 01:00:03,740
车道所有这些问题 

1221
01:00:00,690 --> 01:00:06,630
琐碎它的边缘案件 

1222
01:00:03,740 --> 01:00:08,850
需要是边缘案件万亿

1223
01:00:06,630 --> 01:00:16,830
在很小的数量上推广 

1224
01:00:08,850 --> 01:00:22,830
培训 数据，所以我再次 回到 

1225
01:00:16,830 --> 01:00:25,820
为什么深入学习我提到了 一堆 

1226
01:00:22,830 --> 01:00:30,350
挑战，这是一个机会 

1227
01:00:25,820 --> 01:00:35,130
这是一个机会 来了 

1228
01:00:30,350 --> 01:00:37,560
成功运作的技术

1229
01:00:35,130 --> 01:00:39,300
这个世界所以我希望比赛 

1230
01:00:37,560 --> 01:00:41,280
会出现在这个班级和 

1231
01:00:39,300 --> 01:00:44,520
自动驾驶汽车领域将给你 

1232
01:00:41,280 --> 01:00:46,350
一些见解和申请的机会

1233
01:00:44,520 --> 01:00:49,230
其中一些案例是公开研究 

1234
01:00:46,350 --> 01:00:51,840
语义分割的问题

1235
01:00:49,230 --> 01:00:56,640
外部感知与控制 

1236
01:00:51,840 --> 01:00:59,700
车辆 和深交通，深入 

1237
01:00:56,640 --> 01:01:03,950
车辆控制崩溃

1238
01:00:59,700 --> 01:01:11,490
在致动的高速条件下 和 

1239
01:01:03,950 --> 01:01:13,260
驾驶员国家的感知如此

1240
01:01:11,490 --> 01:01:14,880
我想介绍一下深度学习 

1241
01:01:13,260 --> 01:01:17,520
在 我们获得乐趣 之前，你今天

1242
01:01:14,880 --> 01:01:21,680
明天的自动 驾驶汽车，所以我们 

1243
01:01:17,520 --> 01:01:25,800
喜欢 住 谢谢 Nvidia的谷歌 汽车 

1244
01:01:21,680 --> 01:01:32,600
丰田并冒着出发的风险 

1245
01:01:25,800 --> 01:01:36,920
人们的手机亚马逊Alexa Auto但是 

1246
01:01:32,600 --> 01:01:40,830
我真的想说我去过 

1247
01:01:36,920 --> 01:01:42,990
在过去的一年中，这一点 令人沮丧 

1248
01:01:40,830 --> 01:01:46,860
收到了成千上万的消息 

1249
01:01:42,990 --> 01:01:49,800
受到18,000名比赛的关注 

1250
01:01:46,860 --> 01:01:52,350
全国各地的人们参赛作品

1251
01:01:49,800 --> 01:01:54,540
世界不只是 在麻省理工学院那里 

1252
01:01:52,350 --> 01:01:56,670
很高兴，我有机会 

1253
01:01:54,540 --> 01:01:59,600
互动，我希望我们变得更大 

1254
01:01:56,670 --> 01:02:01,980
并在2018年做一些令人印象深刻的事情 

1255
01:01:59,600 --> 01:02:03,400
非常 感谢你 ，明天也是 

1256
01:02:01,980 --> 01:02:08,010
自驾车

1257
01:02:03,400 --> 01:02:08,010
[掌声] 

