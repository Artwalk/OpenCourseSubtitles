1
00:00:00,030 --> 00:00:05,660
今天我们将讨论如何申请 

2
00:00:02,240 --> 00:00:07,560
深度学习的方法 

3
00:00:05,660 --> 00:00:09,809
理解人的意识 

4
00:00:07,560 --> 00:00:11,969
重点将放在计算机上 

5
00:00:09,809 --> 00:00:12,360
视觉是人类的视觉方面 

6
00:00:11,969 --> 00:00:15,109
存在

7
00:00:12,360 --> 00:00:18,449
当然，我们人类表达自己 

8
00:00:15,109 --> 00:00:21,750
视觉上也通过音频语音 

9
00:00:18,449 --> 00:00:23,760
并通过文本美丽的诗歌和 

10
00:00:21,750 --> 00:00:25,230
小说等我们不会去 

11
00:00:23,760 --> 00:00:27,900
触摸今天我们要去的那些 

12
00:00:25,230 --> 00:00:30,960
专注于计算机视觉我们如何 使用 

13
00:00:27,900 --> 00:00:35,070
计算机视觉提取有用

14
00:00:30,960 --> 00:00:38,160
来自视频图像的可操作信息 

15
00:00:35,070 --> 00:00:44,640
特别是人类的视频

16
00:00:38,160 --> 00:00:47,010
汽车的背景是什么的

17
00:00:44,640 --> 00:00:49,280
成功申请的要求

18
00:00:47,010 --> 00:00:51,930
现实世界中的深度学习方法 

19
00:00:49,280 --> 00:00:55,170
所以当我们谈论人类的时候 

20
00:00:51,930 --> 00:00:57,960
感觉我们不是在谈论一个基本的 

21
00:00:55,170 --> 00:01:00,870
面对 名人形象的 认可 

22
00:00:57,960 --> 00:01:04,500
我们在谈论使用电脑 

23
00:01:00,870 --> 00:01:06,240
愿景深度学习方法创造 

24
00:01:04,500 --> 00:01:08,729
在 现实世界 中 运作的系统

25
00:01:06,240 --> 00:01:10,950
而为了 让他们 在 工作 

26
00:01:08,729 --> 00:01:13,590
现实世界中有 几件事 

27
00:01:10,950 --> 00:01:16,439
听起来简单有些比硬得多 

28
00:01:13,590 --> 00:01:19,500
他们听起来是第一位也是最重要的 

29
00:01:16,439 --> 00:01:22,860
这里的大多数 要少到更少 

30
00:01:19,500 --> 00:01:26,159
关键排序是数据数据 

31
00:01:22,860 --> 00:01:29,670
我们需要的一切真实世界数据 

32
00:01:26,159 --> 00:01:31,590
用于形成数据集 的现实世界 数据 

33
00:01:29,670 --> 00:01:35,250
这些监督学习 

34
00:01:31,590 --> 00:01:36,930
方法可以训练 我会说这个 

35
00:01:35,250 --> 00:01:39,119
一整天都在 一遍 又一遍 

36
00:01:36,930 --> 00:01:41,640
数据是 指数据的 一切 

37
00:01:39,119 --> 00:01:44,070
收藏是最难的部分和 

38
00:01:41,640 --> 00:01:46,470
最重要的部分 我们将谈论如何 

39
00:01:44,070 --> 00:01:49,500
数据收集 在 这里进行 

40
00:01:46,470 --> 00:01:51,450
我们在麻省理工学院的小组 都有所不同 

41
00:01:49,500 --> 00:01:54,360
捕捉人类的方法 

42
00:01:51,450 --> 00:02:00,810
在道路用户环境中驾驶环境 

43
00:01:54,360 --> 00:02:04,829
行人骑自行车但是数据呢

44
00:02:00,810 --> 00:02:07,710
有趣的东西 是 数据的开始和结束 

45
00:02:04,829 --> 00:02:12,100
算法但数据是 什么 

46
00:02:07,710 --> 00:02:14,140
使所有工作 真实的 世界数据 没关系 

47
00:02:12,100 --> 00:02:17,110
一旦你有数据好的数据 

48
00:02:14,140 --> 00:02:18,850
不是我撒谎的 一切， 因为 你有 

49
00:02:17,110 --> 00:02:22,720
实际上注释它所以我们做 什么 

50
00:02:18,850 --> 00:02:27,250
数据是指原始数据视频 

51
00:02:22,720 --> 00:02:32,230
音响激光雷达所有类型的传感器 

52
00:02:27,250 --> 00:02:35,740
我们将谈论捕捉 现实世界 

53
00:02:32,230 --> 00:02:38,220
你写了你必须的用户互动 

54
00:02:35,740 --> 00:02:41,500
将其减少为有意义的 

55
00:02:38,220 --> 00:02:44,290
发生了什么事的代表性案例

56
00:02:41,500 --> 00:02:45,970
真正的世界 在驾驶99％的 

57
00:02:44,290 --> 00:02:48,610
时间驾驶看起来是一样的

58
00:02:45,970 --> 00:02:51,220
这是有趣案例的1％ 

59
00:02:48,610 --> 00:02:53,770
我们感兴趣并且想要的是什么 

60
00:02:51,220 --> 00:02:58,510
训练学习算法的算法 

61
00:02:53,770 --> 00:02:59,920
在那1％所以我们必须收集 100 

62
00:02:58,510 --> 00:03:02,200
百分之我们 要 收集所有 数据 

63
00:02:59,920 --> 00:03:05,950
然后弄清楚 并自动化 

64
00:03:02,200 --> 00:03:07,870
找到碎片的半自动方式 

65
00:03:05,950 --> 00:03:09,730
那些可用于训练的数据 

66
00:03:07,870 --> 00:03:12,310
自己的网络 和 一个 

67
00:03:09,730 --> 00:03:14,020
代表性的一般事物 

68
00:03:12,310 --> 00:03:19,480
发生在 这里的各种事情

69
00:03:14,020 --> 00:03:23,020
世界有效的注释注释 

70
00:03:19,480 --> 00:03:27,550
不只是绘制边界框

71
00:03:23,020 --> 00:03:33,150
关于猫注释工具的图像是 

72
00:03:27,550 --> 00:03:37,330
解锁现实世界表现的关键

73
00:03:33,150 --> 00:03:39,310
成功解决一些问题的系统 

74
00:03:37,330 --> 00:03:41,170
问题在实际中完成了一些目标

75
00:03:39,310 --> 00:03:44,160
世界数据意味着设计 

76
00:03:41,170 --> 00:03:46,690
特定任务的注释工具

77
00:03:44,160 --> 00:03:48,400
用于的注释工具 

78
00:03:46,690 --> 00:03:49,990
扫视分类确定 

79
00:03:48,400 --> 00:03:51,820
司机们 正在寻找它 

80
00:03:49,990 --> 00:03:54,370
比用于注释工具不同

81
00:03:51,820 --> 00:03:57,130
身体姿势估计是非常不同的 

82
00:03:54,370 --> 00:03:59,140
而不是我们使用的工具用途 

83
00:03:57,130 --> 00:04:01,150
投资数千心理意见 

84
00:03:59,140 --> 00:04:04,060
为此竞争的美元

85
00:04:01,150 --> 00:04:05,590
用于注释完整 场景的类

86
00:04:04,060 --> 00:04:08,500
每个像素所在的分割

87
00:04:05,590 --> 00:04:09,760
颜色有需要为工具

88
00:04:08,500 --> 00:04:13,000
这些元素中的每一个都是 

89
00:04:09,760 --> 00:04:15,310
关键是HCI问题是一个设计 

90
00:04:13,000 --> 00:04:18,790
问题没有深刻的学习 

91
00:04:15,310 --> 00:04:21,270
那个问题没有机器人技术

92
00:04:18,790 --> 00:04:25,670
这是我们如何利用人类 

93
00:04:21,270 --> 00:04:27,770
计算人类人类大脑要 割草 

94
00:04:25,670 --> 00:04:29,980
有效地标记图像，使我们 

95
00:04:27,770 --> 00:04:35,270
可以训练你们所有的网络 

96
00:04:29,980 --> 00:04:39,080
硬件， 以培训这些 

97
00:04:35,270 --> 00:04:40,820
网络，以解析 我们 的 数据 

98
00:04:39,080 --> 00:04:44,900
收集， 我们现在谈论我们 

99
00:04:40,820 --> 00:04:47,300
超过50亿 的数据图像 

100
00:04:44,900 --> 00:04:50,540
驱动数据以便解析你 

101
00:04:47,300 --> 00:04:52,790
你不能在一台 机器上做到这一点 

102
00:04:50,540 --> 00:04:56,650
做大规模的分布式计算 

103
00:04:52,790 --> 00:05:00,350
和大规模的分布式存储和 

104
00:04:56,650 --> 00:05:04,280
最后的东西是最多的 

105
00:05:00,350 --> 00:05:06,800
令人兴奋的是，那就是这个 

106
00:05:04,280 --> 00:05:08,180
类和多类而远 之 

107
00:05:06,800 --> 00:05:10,490
文学的重点是 

108
00:05:08,180 --> 00:05:12,050
算法深度学习算法 

109
00:05:10,490 --> 00:05:13,880
机器学习算法 

110
00:05:12,050 --> 00:05:15,950
从数据中学习的算法

111
00:05:13,880 --> 00:05:18,710
当然这真的很令人兴奋 

112
00:05:15,950 --> 00:05:21,470
重要但我们找时间和时间 

113
00:05:18,710 --> 00:05:24,050
在现实世界系统中再次如此 

114
00:05:21,470 --> 00:05:26,960
只要 这些算法从数据中学习 

115
00:05:24,050 --> 00:05:29,210
所以只要 深入学习就可以 了 

116
00:05:26,960 --> 00:05:31,190
数据是更重要的 

117
00:05:29,210 --> 00:05:34,550
当然这 对算法 来说 很好 

118
00:05:31,190 --> 00:05:36,950
无校准意味着他们学习 

119
00:05:34,550 --> 00:05:38,690
校准自校准我们没有

120
00:05:36,950 --> 00:05:40,760
需要准确的传感器

121
00:05:38,690 --> 00:05:42,550
同样的岗位上 ，这是一个很 长的时间 

122
00:05:40,760 --> 00:05:45,710
不错的 功能 的 稳健性 

123
00:05:42,550 --> 00:05:49,640
系统然后 在 普及 

124
00:05:45,710 --> 00:05:53,510
多个多车辆和多个 

125
00:05:49,640 --> 00:05:55,550
方案和 关键事情之一 

126
00:05:53,510 --> 00:05:58,340
再次 出现的时间 一次又一次 

127
00:05:55,550 --> 00:06:00,320
我们今天要提的是很多 

128
00:05:58,340 --> 00:06:01,940
深度学习中开发的算法

129
00:06:00,320 --> 00:06:04,310
真正专注于计算机视觉 

130
00:06:01,940 --> 00:06:07,940
现在专注于单个图像 

131
00:06:04,310 --> 00:06:09,440
现实世界在空间 和 空间都有发生 

132
00:06:07,940 --> 00:06:12,260
时间，我们必须 有算法 

133
00:06:09,440 --> 00:06:14,140
两者都捕捉 视觉特征 

134
00:06:12,260 --> 00:06:15,680
还要看一下图像序列 

135
00:06:14,140 --> 00:06:17,330
那些 数字的 序列 

136
00:06:15,680 --> 00:06:19,640
形成时间的特征 

137
00:06:17,330 --> 00:06:21,860
动态这个 世界的物理学所以 

138
00:06:19,640 --> 00:06:25,690
当这些算法能够实现时，这很好

139
00:06:21,860 --> 00:06:29,390
捕捉 场景 的物理特征 

140
00:06:25,690 --> 00:06:31,800
如果 你 愿意，我想要的是一个很大的收获 

141
00:06:29,390 --> 00:06:34,650
今天什么都离开 

142
00:06:31,800 --> 00:06:37,720
不幸的是，这是痛苦的 

143
00:06:34,650 --> 00:06:40,270
无聊的收集数据 的东西

144
00:06:37,720 --> 00:06:43,180
清理那些 注释的 数据 

145
00:06:40,270 --> 00:06:45,130
数据才能创造 成功 

146
00:06:43,180 --> 00:06:47,710
系统比好的重要得多

147
00:06:45,130 --> 00:06:49,480
它的算法或优秀的算法

148
00:06:47,710 --> 00:06:52,030
拥有良好的算法非常重要

149
00:06:49,480 --> 00:06:55,480
只要你有神经网络 

150
00:06:52,030 --> 00:06:58,450
从这些数据中学习好，所以今天我会 

151
00:06:55,480 --> 00:07:03,490
谈我喜欢谈论 人 

152
00:06:58,450 --> 00:07:07,270
不完美 和各种检测 

153
00:07:03,490 --> 00:07:10,570
问题行人身体姿态一览 

154
00:07:07,270 --> 00:07:14,500
和运动认知负荷估计 

155
00:07:10,570 --> 00:07:18,330
我们可以用来帮助那些人类 

156
00:07:14,500 --> 00:07:25,720
他们在驾驶 背景 和操作

157
00:07:18,330 --> 00:07:27,970
终于尝试继续这个想法 了 

158
00:07:25,720 --> 00:07:29,290
完全自主的愿景

159
00:07:27,970 --> 00:07:31,240
作为我们的一些演讲嘉宾的车辆 

160
00:07:29,290 --> 00:07:33,940
已经谈到了， 并且 将会出现 英镑 

161
00:07:31,240 --> 00:07:36,730
谈及明天是真正远离 

162
00:07:33,940 --> 00:07:39,910
人类将成为不可或缺的一部分 

163
00:07:36,730 --> 00:07:43,840
与AI合作的运营 

164
00:07:39,910 --> 00:07:46,060
系统， 我将继续这样做 

165
00:07:43,840 --> 00:07:49,510
的思路 ，试图激发为什么 

166
00:07:46,060 --> 00:07:52,410
我们需要不断接近 

167
00:07:49,510 --> 00:08:00,670
自动驾驶 汽车 

168
00:07:52,410 --> 00:08:04,150
范式以人为中心的方式 好吧 

169
00:08:00,670 --> 00:08:06,130
在 我们谈论人类 之前 

170
00:08:04,150 --> 00:08:08,790
不完美让我们暂停一下 

171
00:08:06,130 --> 00:08:12,010
承认人类是惊人的 

172
00:08:08,790 --> 00:08:16,210
我们实际上是 在大量 的 真不错 

173
00:08:12,010 --> 00:08:18,340
有时候有趣的事情 

174
00:08:16,210 --> 00:08:20,140
谈论多少叫做可怕的 

175
00:08:18,340 --> 00:08:22,540
我们是多么分心的司机

176
00:08:20,140 --> 00:08:25,750
我们是多么不合理，但实际上我们是

177
00:08:22,540 --> 00:08:28,990
真的该死的擅长 驾驶这里是一个 

178
00:08:25,750 --> 00:08:30,760
视频的 体育场 我们的足球运动员 梅西 

179
00:08:28,990 --> 00:08:34,990
最好的足球运动员在世界 

180
00:08:30,760 --> 00:08:37,360
显然和最先进的 机器人 

181
00:08:34,990 --> 00:08:39,640
在同样的事情上 

182
00:08:37,360 --> 00:08:43,410
好吧，它不是在播放，但我

183
00:08:39,640 --> 00:08:43,410
向你保证美国忍者战士 

184
00:08:43,600 --> 00:08:52,520
凯西 是呃远远优于 

185
00:08:49,490 --> 00:09:00,470
显示DARPA人形机器人系统 

186
00:08:52,520 --> 00:09:02,840
正确的好 了，继续和 

187
00:09:00,470 --> 00:09:05,120
挑战的思路

188
00:09:02,840 --> 00:09:09,230
在这里挑战我们人类 

189
00:09:05,120 --> 00:09:12,650
太棒了，你 知道它有创纪录的高度 

190
00:09:09,230 --> 00:09:15,980
2016年在美国有 

191
00:09:12,650 --> 00:09:18,500
四万因为 呃多年 

192
00:09:15,980 --> 00:09:20,780
这是四万多 

193
00:09:18,500 --> 00:09:22,460
死亡人数 超过四万 

194
00:09:20,780 --> 00:09:25,790
人们在美国的车祸中丧生 

195
00:09:22,460 --> 00:09:28,190
国家， 但这是三点二 

196
00:09:25,790 --> 00:09:31,960
万亿英里旅行， 所以这是一个 

197
00:09:28,190 --> 00:09:38,420
每八千万英里的死亡率

198
00:09:31,960 --> 00:09:42,440
六分之一的机会死在车里 

199
00:09:38,420 --> 00:09:45,020
在你的一生有趣的一面崩溃

200
00:09:42,440 --> 00:09:48,260
对于美国的任何人来说都是如此

201
00:09:45,020 --> 00:09:51,280
住在 马萨诸塞州的 人是 

202
00:09:48,260 --> 00:09:56,720
最有可能在一场车祸中死亡 

203
00:09:51,280 --> 00:10:00,140
蒙大拿州是 最有可能因此对于每 

204
00:09:56,720 --> 00:10:02,900
一个想到波士顿驾驶的人是 

205
00:10:00,140 --> 00:10:05,210
可怕的可能会增加一些

206
00:10:02,900 --> 00:10:08,000
这里透视图的的可视化

207
00:10:05,210 --> 00:10:10,340
一天中的数据方式

208
00:10:08,000 --> 00:10:12,650
向您展示城市的丰富血液

209
00:10:10,340 --> 00:10:15,620
那个城市的交通流量

210
00:10:12,650 --> 00:10:19,880
人们 从A到B和 a 

211
00:10:15,620 --> 00:10:25,340
大规模的规模，让它 幸存下来 

212
00:10:19,880 --> 00:10:29,210
没关系，人类是惊人的，但他们是 

213
00:10:25,340 --> 00:10:31,340
也有缺陷的短信来源

214
00:10:29,210 --> 00:10:33,410
用智能手机分心吃 

215
00:10:31,340 --> 00:10:36,740
与他人交谈的次要任务 

216
00:10:33,410 --> 00:10:39,890
乘客梳理阅读使用 

217
00:10:36,740 --> 00:10:43,130
导航系统是有时候看 

218
00:10:39,890 --> 00:10:47,060
视频和手动调整或

219
00:10:43,130 --> 00:10:52,430
调整收音机和 3000人 

220
00:10:47,060 --> 00:10:54,650
他们 被杀，40万人受伤 

221
00:10:52,430 --> 00:10:55,930
机动车撞毁涉及的 

222
00:10:54,650 --> 00:11:00,310
娱乐

223
00:10:55,930 --> 00:11:05,050
在2014年分心是一个非常 

224
00:11:00,310 --> 00:11:06,610
安全短信的严重问题 

225
00:11:05,050 --> 00:11:08,110
一天越来越多的人发 短信 

226
00:11:06,610 --> 00:11:11,710
智能手机正在激增我们 

227
00:11:08,110 --> 00:11:13,390
社会170条十亿条短信 是 

228
00:11:11,710 --> 00:11:16,480
每月寄往美国 

229
00:11:13,390 --> 00:11:17,430
那是在2014年你 只能 想象什么 

230
00:11:16,480 --> 00:11:20,920
它是今天 

231
00:11:17,430 --> 00:11:22,330
眼睛越野五秒钟是 

232
00:11:20,920 --> 00:11:25,990
平均时间你的眼睛离开了 

233
00:11:22,330 --> 00:11:28,240
如果你 发短信 五秒钟的 话 

234
00:11:25,990 --> 00:11:30,370
这 五个人 每小时55英里 

235
00:11:28,240 --> 00:11:32,130
几秒钟就足够了 

236
00:11:30,370 --> 00:11:34,720
足球场的长度

237
00:11:32,130 --> 00:11:36,940
所以你被蒙上眼睛， 你不是在寻找 

238
00:11:34,720 --> 00:11:39,010
平均在五秒钟的路上

239
00:11:36,940 --> 00:11:41,800
你正在发短信的时间

240
00:11:39,010 --> 00:11:44,320
整个足球场 八个 这么多 

241
00:11:41,800 --> 00:11:51,070
事情可能发生在那个 时刻 

242
00:11:44,320 --> 00:11:52,900
这是分散醉酒驾驶的31％ 

243
00:11:51,070 --> 00:11:56,410
交通事故死亡人数 涉及醉酒 

244
00:11:52,900 --> 00:11:58,660
司机醉酒驾驶 23％ 的夜间 

245
00:11:56,410 --> 00:11:59,850
司机测试为 合法的 正面 

246
00:11:58,660 --> 00:12:03,310
处方药或非处方药

247
00:11:59,850 --> 00:12:05,890
正如我所说，药物分散了驾驶注意力

248
00:12:03,310 --> 00:12:08,589
是一个巨大的安全风险昏昏欲睡的驾驶 

249
00:12:05,890 --> 00:12:10,390
人们 开车累了差不多三个 

250
00:12:08,589 --> 00:12:15,270
所有交通事故死亡人数的百分比

251
00:12:10,390 --> 00:12:18,550
如果你是一个昏昏欲睡的司机 

252
00:12:15,270 --> 00:12:21,370
对涉及的视频感到不舒服 

253
00:12:18,550 --> 00:12:23,339
风险我劝你把 目光移开这些 都是 

254
00:12:21,370 --> 00:12:25,360
Triple A 收集的视频 

255
00:12:23,339 --> 00:12:27,520
青少年规模很大 

256
00:12:25,360 --> 00:12:29,290
自然驾驶数据集和它的 

257
00:12:27,520 --> 00:12:33,630
捕捉青少年的剪辑 

258
00:12:29,290 --> 00:12:33,630
在他们的智能手机上分心

259
00:12:35,120 --> 00:12:40,320
[音乐] 

260
00:13:24,170 --> 00:13:29,480
一旦你把它解决了我们 的 问题 

261
00:13:27,090 --> 00:13:29,480
反对

262
00:13:39,540 --> 00:13:44,750
所以在切割中 

263
00:13:41,390 --> 00:13:47,450
我们所拥有的人类不完美的背景

264
00:13:44,750 --> 00:13:49,670
要问自己是以人为本 

265
00:13:47,450 --> 00:13:51,860
系统中的自治方法

266
00:13:49,670 --> 00:13:53,690
正在使用的自动驾驶汽车

267
00:13:51,860 --> 00:13:56,330
人工智能 帮助 

268
00:13:53,690 --> 00:13:58,460
驾驶任务我们想要 像我一样去 

269
00:13:56,330 --> 00:14:01,130
提到几个 讲座 前 

270
00:13:58,460 --> 00:14:03,440
以人为本的方式 或完全 自治 

271
00:14:01,130 --> 00:14:05,960
诱人的道路朝向满满的方式

272
00:14:03,440 --> 00:14:08,420
自治，我们删除了这个不完美的 

273
00:14:05,960 --> 00:14:11,300
图片中完全有缺陷的人 

274
00:14:08,420 --> 00:14:13,750
并专注于机器人问题 

275
00:14:11,300 --> 00:14:18,500
感知 和控制与规划 

276
00:14:13,750 --> 00:14:21,560
推动政策或我们一起工作

277
00:14:18,500 --> 00:14:24,680
人和机器提高安全性 

278
00:14:21,560 --> 00:14:26,150
减轻分心带来的驱动力 

279
00:14:24,680 --> 00:14:28,340
我们的注意力回到了道路和使用上 

280
00:14:26,150 --> 00:14:31,190
人工智能增加 

281
00:14:28,340 --> 00:14:33,950
通过协作人机器人的安全 

282
00:14:31,190 --> 00:14:38,270
互动与消除人类 

283
00:14:33,950 --> 00:14:42,500
完全不是我的照片

284
00:14:38,270 --> 00:14:45,560
提到英镑肯定会 

285
00:14:42,500 --> 00:14:50,330
说说 明天是理所当然 

286
00:14:45,560 --> 00:14:53,230
所以，昨天或周二 埃米利奥 

287
00:14:50,330 --> 00:14:56,270
曾谈到精灵 四向 是 

288
00:14:53,230 --> 00:15:00,010
它 以文学 为基础，以此 为基础 

289
00:14:56,270 --> 00:15:03,160
从某种意义上讲，它是常识 

290
00:15:00,010 --> 00:15:06,860
你可以依靠人类的事实

291
00:15:03,160 --> 00:15:10,100
人类的自然缺陷 

292
00:15:06,860 --> 00:15:12,500
过分信任行为不当是非理性的 

293
00:15:10,100 --> 00:15:15,650
关于他们的风险估计将导致 

294
00:15:12,500 --> 00:15:19,250
在不正当使用的技术和 

295
00:15:15,650 --> 00:15:21,590
这导致 了 我之前展示的内容 

296
00:15:19,250 --> 00:15:23,510
公众对 司机做 什么的看法 

297
00:15:21,590 --> 00:15:25,580
他们开始和半自动驾驶汽车 

298
00:15:23,510 --> 00:15:27,920
过度信任系统的那一刻

299
00:15:25,580 --> 00:15:30,230
效果很好， 他们 开始过度信任他们 

300
00:15:27,920 --> 00:15:32,240
开始做他们不 应该做的事情

301
00:15:30,230 --> 00:15:35,120
在车里做它 

302
00:15:32,240 --> 00:15:38,450
有人 给 了最近的视频 

303
00:15:35,120 --> 00:15:41,260
发布这 是一种常见的更多 

304
00:15:38,450 --> 00:15:45,620
人们所 拥有的实际关注 点 

305
00:15:41,260 --> 00:15:48,560
而传统的方法，以确保 

306
00:15:45,620 --> 00:15:50,240
驾驶员的 身体参与 是通过 

307
00:15:48,560 --> 00:15:51,650
说他们应该触摸方向盘

308
00:15:50,240 --> 00:15:54,510
方向盘每隔一段时间 

309
00:15:51,650 --> 00:15:56,970
当然还有买的方法 

310
00:15:54,510 --> 00:16:00,360
需要触摸 方向盘 

311
00:15:56,970 --> 00:16:02,100
有些人像我一样可以挂掉物品

312
00:16:00,360 --> 00:16:06,329
在这种情况下 的 方向盘 

313
00:16:02,100 --> 00:16:11,130
我不得不说他们推了一个 

314
00:16:06,329 --> 00:16:13,230
橙色进入车轮制造

315
00:16:11,130 --> 00:16:15,860
触摸传感器起火，因此

316
00:16:13,230 --> 00:16:19,070
能够脱手了 

317
00:16:15,860 --> 00:16:21,570
自动驾驶仪 和那种想法 

318
00:16:19,070 --> 00:16:24,000
使我们相信 ，有 没有办法 

319
00:16:21,570 --> 00:16:27,180
你知道人类会找到一条路 

320
00:16:24,000 --> 00:16:31,230
然而，我 相信滥用这项技术 

321
00:16:27,180 --> 00:16:33,570
这不是技术 

322
00:16:31,230 --> 00:16:35,760
足够的信用人工智能 

323
00:16:33,570 --> 00:16:38,430
系统是否能够感知到 

324
00:16:35,760 --> 00:16:40,320
人类也能够工作 

325
00:16:38,430 --> 00:16:44,160
和人类在一起， 这就是我的意思 

326
00:16:40,320 --> 00:16:48,000
喜欢谈论 今天 教 车 

327
00:16:44,160 --> 00:16:51,480
感知人类和所有人

328
00:16:48,000 --> 00:16:53,430
从数据开始， 它都是关于数据的 

329
00:16:51,480 --> 00:16:55,980
我提到数据就是这些中的一切 

330
00:16:53,430 --> 00:16:58,740
与麻省理工学院的现实世界系统 

331
00:16:55,980 --> 00:17:01,290
自然驾驶数据集25 

332
00:16:58,740 --> 00:17:03,839
车辆有25 和 21并配备 

333
00:17:01,290 --> 00:17:05,280
我们用特斯拉自动驾驶仪测量它们 

334
00:17:03,839 --> 00:17:08,610
这就是我们做数据收集的方法 

335
00:17:05,280 --> 00:17:10,199
驾驶员 上 的 两个摄像头 将会看到 

336
00:17:08,610 --> 00:17:12,329
脸上捕捉的相机

337
00:17:10,199 --> 00:17:14,669
这是面对高清视频

338
00:17:12,329 --> 00:17:16,530
在哪里我们得到一瞥分类 

339
00:17:14,669 --> 00:17:18,480
情绪识别认知负荷

340
00:17:16,530 --> 00:17:20,490
一切都来自 我们 的脸 

341
00:17:18,480 --> 00:17:22,140
有另一个相机或 鱼眼 

342
00:17:20,490 --> 00:17:24,510
看着司机的身体和 

343
00:17:22,140 --> 00:17:27,150
那就是身体姿势 

344
00:17:24,510 --> 00:17:30,059
估计手轮活动 

345
00:17:27,150 --> 00:17:32,130
识别，然后一个视频看 

346
00:17:30,059 --> 00:17:33,809
为了完整的场景分割

347
00:17:32,130 --> 00:17:35,280
所有场景感知任务和 

348
00:17:33,809 --> 00:17:37,290
一切都在被记录下来 

349
00:17:35,280 --> 00:17:39,179
与GPS同步

350
00:17:37,290 --> 00:17:42,150
所有从覆盖可以将音频

351
00:17:39,179 --> 00:17:48,870
汽车在单个设备上同步 

352
00:17:42,150 --> 00:17:53,010
这些数据至关重要，因此只有一个

353
00:17:48,870 --> 00:17:55,559
数千人的公路旅行

354
00:17:53,010 --> 00:17:57,809
喜欢它旅行数百英里 

355
00:17:55,559 --> 00:18:02,760
有时数百英里以下 

356
00:17:57,809 --> 00:18:03,419
自动控制和自动驾驶仪 

357
00:18:02,760 --> 00:18:07,049
数据

358
00:18:03,419 --> 00:18:09,479
再次，因为我说数据是一切和 

359
00:18:07,049 --> 00:18:12,299
从这些数据中我们都可以获益 

360
00:18:09,479 --> 00:18:14,789
了解人们做了什么 

361
00:18:12,299 --> 00:18:17,190
了解如何非常重要 

362
00:18:14,789 --> 00:18:20,070
自治成功的自治可以

363
00:18:17,190 --> 00:18:23,820
部署在现实世界中并进行 设计 

364
00:18:20,070 --> 00:18:25,950
训练培训算法

365
00:18:23,820 --> 00:18:28,139
深入学习 深层神经 

366
00:18:25,950 --> 00:18:32,700
网络，以执行 

367
00:18:28,139 --> 00:18:39,389
感知任务更好 二十五 

368
00:18:32,700 --> 00:18:42,719
比格斯21 特斯拉的模型S模型X和 

369
00:18:39,389 --> 00:18:44,940
现在模型 三千里 

370
00:18:42,719 --> 00:18:46,499
收集了一天，每一天 ，我们 有 

371
00:18:44,940 --> 00:18:48,419
在波士顿数千英里 

372
00:18:46,499 --> 00:18:51,749
马萨诸塞州地区四处奔走 

373
00:18:48,419 --> 00:18:57,059
该 视频 目前 正在录制 过五 

374
00:18:51,749 --> 00:19:01,889
十亿个视频帧有几个

375
00:18:57,059 --> 00:19:07,739
方式 来看待 自主大的一个 

376
00:19:01,889 --> 00:19:09,089
每个人都是安全的 

377
00:19:07,739 --> 00:19:14,159
谈谈我们如何制作这些东西 

378
00:19:09,089 --> 00:19:17,909
安全，但另一个是享受 

379
00:19:14,159 --> 00:19:20,999
人们实际上想要尽我们所能 

380
00:19:17,909 --> 00:19:23,249
我们可以创造一个完全安全的系统 

381
00:19:20,999 --> 00:19:27,419
现在，我们已经 受 够 了 为创建

382
00:19:23,249 --> 00:19:29,579
甚至在汽车之前从未有过汽车 

383
00:19:27,419 --> 00:19:33,450
移动是一个非常安全的系统 

384
00:19:29,579 --> 00:19:35,549
虽然并不完美， 但差不多 

385
00:19:33,450 --> 00:19:37,709
不提供服务，是 

386
00:19:35,549 --> 00:19:40,529
有价值的， 它不提供愉快 

387
00:19:37,709 --> 00:19:42,779
驾驶体验那么好吧怎么样 

388
00:19:40,529 --> 00:19:45,809
缓慢移动的车辆 是开放的 

389
00:19:42,779 --> 00:19:48,359
质疑 这些 特斯拉 的现实 

390
00:19:45,809 --> 00:19:51,269
车辆和l2系统做自动化 

391
00:19:48,359 --> 00:19:54,479
驾驶人员驾驶33％的里程 

392
00:19:51,269 --> 00:19:57,209
使用特斯拉自动驾驶仪是什么做的 

393
00:19:54,479 --> 00:19:59,489
意味着这意味着 人们正在获得 

394
00:19:57,209 --> 00:20:02,239
它的价值很大一部分 

395
00:19:59,489 --> 00:20:08,260
他们的驾驶是以自动方式完成的 

396
00:20:02,239 --> 00:20:10,420
这是享受一瞥的价值

397
00:20:08,260 --> 00:20:14,530
我们将讨论窒息算法 

398
00:20:10,420 --> 00:20:16,900
今天 被用作 我们使用的 一个例子 

399
00:20:14,530 --> 00:20:18,610
了解所显示的数据中的内容 

400
00:20:16,900 --> 00:20:20,590
用条形图和红色

401
00:20:18,610 --> 00:20:22,570
手动时，蓝色红色 

402
00:20:20,590 --> 00:20:24,730
在自动驾驶仪驾驶期间驾驶蓝调 

403
00:20:22,570 --> 00:20:26,440
我们看一眼分类

404
00:20:24,730 --> 00:20:28,570
司机正在寻找的地区

405
00:20:26,440 --> 00:20:30,730
道路和越野，如果那样 

406
00:20:28,570 --> 00:20:34,360
分配随自动化而变化 

407
00:20:30,730 --> 00:20:36,310
驾驶或手动驾驶 

408
00:20:34,360 --> 00:20:37,930
这些玻璃分类方法我们

409
00:20:36,310 --> 00:20:40,420
可以确定没有多少 

410
00:20:37,930 --> 00:20:42,550
差异 至少直到你深入研究 

411
00:20:40,420 --> 00:20:44,830
我们还没有做过的细节 

412
00:20:42,550 --> 00:20:49,810
总计没有重要意义 

413
00:20:44,830 --> 00:20:52,950
区别这 意味着人们 越来越 

414
00:20:49,810 --> 00:20:56,860
使用这些技术享受的价值

415
00:20:52,950 --> 00:21:00,580
但他们仍然保持专注或在 

416
00:20:56,860 --> 00:21:03,010
至少不是细心而是身体上的 

417
00:21:00,580 --> 00:21:05,470
当你的眼睛 在 路上 时，你 会订婚

418
00:21:03,010 --> 00:21:08,080
你可能 不会注意但是你在 

419
00:21:05,470 --> 00:21:09,820
至少 在身体上是你的身体 

420
00:21:08,080 --> 00:21:11,500
以这样的方式定位你的头脑 

421
00:21:09,820 --> 00:21:13,840
看着前方的道路 

422
00:21:11,500 --> 00:21:16,920
你身体健康 

423
00:21:13,840 --> 00:21:22,600
提醒并接收前方道路 

424
00:21:16,920 --> 00:21:25,600
所以他们正在使用它并且它们没有结束 

425
00:21:22,600 --> 00:21:28,630
相信它，我觉得这很甜蜜 

426
00:21:25,600 --> 00:21:33,940
认为 人机交互需要 

427
00:21:28,630 --> 00:21:36,220
实现是人类获得通过 

428
00:21:33,940 --> 00:21:38,650
通过勘探经验， 通过 

429
00:21:36,220 --> 00:21:40,150
试错和探索 

430
00:21:38,650 --> 00:21:42,700
理解的局限性 

431
00:21:40,150 --> 00:21:44,800
系统达到 过度 信任 的程度 

432
00:21:42,700 --> 00:21:48,010
发生在这似乎正在发生 

433
00:21:44,800 --> 00:21:50,050
系统 和使用 计算机 视觉 

434
00:21:48,010 --> 00:21:52,390
方法我会谈到我们 可以继续 

435
00:21:50,050 --> 00:21:56,230
探讨如何能够 在实现 

436
00:21:52,390 --> 00:21:58,420
当其他系统何时何时出现 

437
00:21:56,230 --> 00:22:06,520
自动驾驶的比例增加

438
00:21:58,420 --> 00:22:07,120
从30％到40％到50％等等 

439
00:22:06,520 --> 00:22:09,160
所有

440
00:22:07,120 --> 00:22:11,470
关于数据，我会帮我 

441
00:22:09,160 --> 00:22:13,240
这又是算法

442
00:22:11,470 --> 00:22:15,700
有趣的你知道我会提到 的 

443
00:22:13,240 --> 00:22:18,580
当然它是相同的卷积神经 

444
00:22:15,700 --> 00:22:22,090
网络就是那个网络 

445
00:22:18,580 --> 00:22:25,210
获取原始像素并提取特征 

446
00:22:22,090 --> 00:22:27,190
感兴趣的是它的三维卷积神经 

447
00:22:25,210 --> 00:22:29,800
采取序列的网络

448
00:22:27,190 --> 00:22:31,780
图像并提取时间动态 

449
00:22:29,800 --> 00:22:34,120
沿着与视觉特性 

450
00:22:31,780 --> 00:22:36,970
个人 形象 是RN 和 

451
00:22:34,120 --> 00:22:39,100
使用卷积的动物园的TMS 

452
00:22:36,970 --> 00:22:42,040
神经网络提取 特征和 

453
00:22:39,100 --> 00:22:43,900
随着时间的推移看动态和 

454
00:22:42,040 --> 00:22:46,270
图像非常基本 

455
00:22:43,900 --> 00:22:49,540
建筑是同样的深刻 

456
00:22:46,270 --> 00:22:51,820
神经网络架构，但他们 

457
00:22:49,540 --> 00:22:57,610
从根本上深深依赖 

458
00:22:51,820 --> 00:23:00,040
关于真实世界数据的数据，让我们开始吧 

459
00:22:57,610 --> 00:23:01,840
也许在人类感知方面 

460
00:23:00,040 --> 00:23:09,539
一切都从行人开始了

461
00:23:01,840 --> 00:23:11,369
在几十年前检测到将它置于con 

462
00:23:09,539 --> 00:23:13,710
这里显示的texe行人检测 

463
00:23:11,369 --> 00:23:17,720
从左到右左边是绿色 

464
00:23:13,710 --> 00:23:20,399
显示更容易的人体感知任务

465
00:23:17,720 --> 00:23:22,529
向人类感知某些方面的任务

466
00:23:20,399 --> 00:23:25,769
但至于 你的检测是什么 

467
00:23:22,529 --> 00:23:29,190
检测人的全身 

468
00:23:25,769 --> 00:23:31,769
在图像或视频中是其中之一 

469
00:23:29,190 --> 00:23:34,950
更轻松的计算机视觉任务和

470
00:23:31,769 --> 00:23:36,840
在红色微电路的正下方 

471
00:23:34,950 --> 00:23:39,119
这些是眼睛或眼睛的震颤

472
00:23:36,840 --> 00:23:41,340
测量瞳孔直径或 

473
00:23:39,119 --> 00:23:44,729
测量认知负荷或罚款 

474
00:23:41,340 --> 00:23:48,479
眨眼动态的眼睛速度 

475
00:23:44,729 --> 00:23:50,279
眨眼间微微一瞥， 我摆出姿势 

476
00:23:48,479 --> 00:23:51,960
是更难的问题

477
00:23:50,279 --> 00:23:54,090
所以你认为身体姿势估计

478
00:23:51,960 --> 00:23:56,159
行人检测阶段

479
00:23:54,090 --> 00:23:58,169
分类检测识别

480
00:23:56,159 --> 00:24:00,269
头部姿势估计所有这些 

481
00:23:58,169 --> 00:24:02,960
任何开始的任务

482
00:24:00,269 --> 00:24:04,849
越来越小看着眼睛和 

483
00:24:02,960 --> 00:24:07,739
一切都开始得到 

484
00:24:04,849 --> 00:24:09,929
细粒度更难 

485
00:24:07,739 --> 00:24:13,830
所以我们从最简单的行人开始

486
00:24:09,929 --> 00:24:15,119
检测和作为通常的挑战 

487
00:24:13,830 --> 00:24:16,919
我们谈过的所有计算机视觉 

488
00:24:15,119 --> 00:24:20,369
关于各种风格 

489
00:24:16,919 --> 00:24:22,889
外观所以班级变异

490
00:24:20,369 --> 00:24:27,119
不同的可能的关节

491
00:24:22,889 --> 00:24:30,269
的把它放在 我们唯一的替代机构 

492
00:24:27,119 --> 00:24:32,399
可能是猫，但 人类很 漂亮 

493
00:24:30,269 --> 00:24:34,590
灵活以及存在

494
00:24:32,399 --> 00:24:36,720
闭塞我们的配件 

495
00:24:34,590 --> 00:24:39,599
穿戴以阻塞自闭塞和 

496
00:24:36,720 --> 00:24:41,940
包括彼此，但拥挤 

497
00:24:39,599 --> 00:24:44,429
场景中有很多人 

498
00:24:41,940 --> 00:24:46,529
他们包括彼此，因此 

499
00:24:44,429 --> 00:24:48,570
能够消除歧义以弄清楚 

500
00:24:46,529 --> 00:24:50,580
每个行人都是非常的

501
00:24:48,570 --> 00:24:53,789
挑战性的问题所以人们如何 

502
00:24:50,580 --> 00:24:59,840
解决这个问题 也有 我 

503
00:24:53,789 --> 00:25:03,989
需要从原始像素中提取特征 

504
00:24:59,840 --> 00:25:09,330
无论是 热 级联猪还是CNN 

505
00:25:03,989 --> 00:25:11,369
经过几十年的滑动 

506
00:25:09,330 --> 00:25:13,320
窗口方法被使用， 因为 

507
00:25:11,369 --> 00:25:15,330
行人在图像中可以很小或 

508
00:25:13,320 --> 00:25:17,849
大所以有规模的问题，以便 

509
00:25:15,330 --> 00:25:20,369
你 使用滑动窗口来检测在哪里 

510
00:25:17,849 --> 00:25:22,500
那个行人就是你有一个分类器

511
00:25:20,369 --> 00:25:24,570
这给了一个单一的形象，如 本 

512
00:25:22,500 --> 00:25:27,630
那是 你不是 你的分类 

513
00:25:24,570 --> 00:25:29,520
你在图像 上滑动以找到位置 

514
00:25:27,630 --> 00:25:32,430
现场的所有行人 都是如此 

515
00:25:29,520 --> 00:25:34,260
可以使用非神经网络方法或 

516
00:25:32,430 --> 00:25:36,870
你可以使用卷积神经网络

517
00:25:34,260 --> 00:25:40,260
对于那个分类器来说非常棒 

518
00:25:36,870 --> 00:25:42,930
效率低下然后我们快速地来到我们的CNN 

519
00:25:40,260 --> 00:25:46,200
我们的CNN快速我们的CNN 这些是网络 

520
00:25:42,930 --> 00:25:48,330
而不是做一个完整的 

521
00:25:46,200 --> 00:25:51,390
滑动窗口方法更多 

522
00:25:48,330 --> 00:25:53,760
智能聪明的生成 

523
00:25:51,390 --> 00:25:55,560
考生如此反对 

524
00:25:53,760 --> 00:25:57,300
考虑到的每一个可能的位置

525
00:25:55,560 --> 00:26:01,350
窗口不同尺度的窗口 

526
00:25:57,300 --> 00:26:03,800
他们生成了更多的一小部分 

527
00:26:01,350 --> 00:26:06,450
考生更有可能和 

528
00:26:03,800 --> 00:26:07,710
最后利用CNN归类为 那些 

529
00:26:06,450 --> 00:26:10,440
候选人是否有行人 

530
00:26:07,710 --> 00:26:14,130
或不是否有一个对象 

531
00:26:10,440 --> 00:26:15,810
是否有兴趣或不使用 

532
00:26:14,130 --> 00:26:18,120
最大限度的抑制，因为有 

533
00:26:15,810 --> 00:26:19,830
重叠边界框来弄清楚

534
00:26:18,120 --> 00:26:21,690
什么是最有可能的边界框 

535
00:26:19,830 --> 00:26:24,420
围绕着这个行人 

536
00:26:21,690 --> 00:26:26,910
对象是我们的CNN而且有很多 

537
00:26:24,420 --> 00:26:29,520
我们的CNN现在使用面具的变种 

538
00:26:26,910 --> 00:26:34,170
真正的最先进的 本地化 

539
00:26:29,520 --> 00:26:36,210
网络掩码 也增加了这一点 

540
00:26:34,170 --> 00:26:37,800
机身盒也 进行了分割 

541
00:26:36,210 --> 00:26:39,480
那里有体素网 

542
00:26:37,800 --> 00:26:42,540
三维和轻我们的数据 

543
00:26:39,480 --> 00:26:44,340
使用本地化和点云 

544
00:26:42,540 --> 00:26:47,580
它不只是用于图像 而是 

545
00:26:44,340 --> 00:26:51,750
在3d 但它就是它的全部 

546
00:26:47,580 --> 00:26:56,010
扎根于我们的CNN框架确定 

547
00:26:51,750 --> 00:26:58,650
数据因此我们有大规模的数据 

548
00:26:56,010 --> 00:27:00,420
如果在剑桥这里收集的话 

549
00:26:58,650 --> 00:27:03,030
你看过各种各样的激光雷达相机

550
00:27:00,420 --> 00:27:05,190
麻省理工学院的交叉点我们是其中的一部分 

551
00:27:03,030 --> 00:27:07,230
例如，这是其中之一 

552
00:27:05,190 --> 00:27:11,210
收集大约10个交叉点

553
00:27:07,230 --> 00:27:14,640
每天工作几小时 

554
00:27:11,210 --> 00:27:18,810
我会提到各种传感器， 但我们看到了 

555
00:27:14,640 --> 00:27:22,500
每天大约12,000名行人 

556
00:27:18,810 --> 00:27:27,660
使用4k的特定交叉点

557
00:27:22,500 --> 00:27:30,480
使用立体视觉相机的相机360 

558
00:27:27,660 --> 00:27:34,650
现在的insta 360 是一个8k 360 

559
00:27:30,480 --> 00:27:37,030
相机gopro激光雷达 各种尺寸的64 

560
00:27:34,650 --> 00:27:43,340
6的频道

561
00:27:37,030 --> 00:27:45,110
和记录这就是这是 

562
00:27:43,340 --> 00:27:49,340
这是数据的来源 

563
00:27:45,110 --> 00:27:52,730
是来自360的视频来自 

564
00:27:49,340 --> 00:27:56,570
这个相同交叉点的激光雷达数据

565
00:27:52,730 --> 00:28:00,220
适用于指向a的4k摄像机

566
00:27:56,570 --> 00:28:03,200
不同的交叉点和不同

567
00:28:00,220 --> 00:28:04,250
而不是 捕获整个 360 视图 

568
00:28:03,200 --> 00:28:07,929
车辆在接近

569
00:28:04,250 --> 00:28:10,700
行人做出交叉决定

570
00:28:07,929 --> 00:28:12,169
这是对谈判的理解 

571
00:28:10,700 --> 00:28:14,150
那个行人是非语言的 

572
00:28:12,169 --> 00:28:16,010
行人执行的谈判和

573
00:28:14,150 --> 00:28:17,870
选择交叉或不交时尤其是 

574
00:28:16,010 --> 00:28:22,490
他们是jaywalking和每个人 

575
00:28:17,870 --> 00:28:23,559
jaywalks特别是如果你熟悉的话 

576
00:28:22,490 --> 00:28:25,850
与这个 特殊的交集 

577
00:28:23,559 --> 00:28:28,820
还有更多 杰伊步行者比非 

578
00:28:25,850 --> 00:28:30,260
jaywalkers 它是一个迷人的 等等 

579
00:28:28,820 --> 00:28:33,850
我们记录有关司机的一切

580
00:28:30,260 --> 00:28:36,710
关于行人的一切 

581
00:28:33,850 --> 00:28:39,169
再次，我们的 CNN 就在这里 

582
00:28:36,710 --> 00:28:40,730
你做 Bonney盒检测了 吗？ 

583
00:28:39,169 --> 00:28:42,890
这里的行人是车辆 

584
00:28:40,730 --> 00:28:48,679
好吧， 并允许你转换这个原始 

585
00:28:42,890 --> 00:28:52,059
数据分为行人过路时间 

586
00:28:48,679 --> 00:28:55,190
决定并开始解释它 

587
00:28:52,059 --> 00:29:01,280
这是行人检测边界框 

588
00:28:55,190 --> 00:29:03,830
用于身体姿势估计 的更多 

589
00:29:01,280 --> 00:29:07,280
困难的任务 身体姿势估计是 

590
00:29:03,830 --> 00:29:10,750
也找到 了手的关节 

591
00:29:07,280 --> 00:29:14,539
肘部膝盖肘部弯曲 

592
00:29:10,750 --> 00:29:17,539
图像XY中的标志点

593
00:29:14,539 --> 00:29:20,809
标志着那些关节的位置 

594
00:29:17,539 --> 00:29:22,010
这是身体姿势估计所以为什么 

595
00:29:20,809 --> 00:29:24,380
这在驾驶中很重要

596
00:29:22,010 --> 00:29:26,120
确定这一点非常重要 

597
00:29:24,380 --> 00:29:29,179
垂直位置或对齐方式 

598
00:29:26,120 --> 00:29:32,030
安全带的司机和那种 

599
00:29:29,179 --> 00:29:33,440
安全气囊测试总是如此 

600
00:29:32,030 --> 00:29:35,240
进行 安全带测试 

601
00:29:33,440 --> 00:29:37,309
与 虚拟考虑进行

602
00:29:35,240 --> 00:29:41,270
标准假人的正面位置 

603
00:29:37,309 --> 00:29:44,419
定位越大的程度 

604
00:29:41,270 --> 00:29:46,000
自动化带来更多的能力和 

605
00:29:44,419 --> 00:29:48,269
灵活的 司机赶下车 

606
00:29:46,000 --> 00:29:51,599
与标准角落不对齐

607
00:29:48,269 --> 00:29:53,609
假位置和身体姿势或在

608
00:29:51,599 --> 00:29:55,679
最小上身姿势估计允许

609
00:29:53,609 --> 00:29:59,279
你确定 这些多久驱动程序 

610
00:29:55,679 --> 00:30:01,799
从标准中脱离出来

611
00:29:59,279 --> 00:30:03,739
定位一般运动然后 

612
00:30:01,799 --> 00:30:08,190
你可以看看手上的轮子 

613
00:30:03,739 --> 00:30:11,219
智能手机智能手机检测 

614
00:30:08,190 --> 00:30:14,330
并帮助添加上下文 一目了然 

615
00:30:11,219 --> 00:30:17,039
估算的是， 我们将谈论 

616
00:30:14,330 --> 00:30:20,519
所以一些比较传统的 方法 

617
00:30:17,039 --> 00:30:22,469
顺序是首先检测到 

618
00:30:20,519 --> 00:30:28,039
然后踩踏检测

619
00:30:22,469 --> 00:30:32,999
肩膀肘部 的手 

620
00:30:28,039 --> 00:30:36,559
仓库的整体观点 一直是 

621
00:30:32,999 --> 00:30:41,249
非常强大的 成功方式 

622
00:30:36,559 --> 00:30:45,570
人物姿势估计正在执行 

623
00:30:41,249 --> 00:30:48,659
检测身体部位的回归 

624
00:30:45,570 --> 00:30:50,729
整个图像不是顺序的 

625
00:30:48,659 --> 00:30:53,039
将身体缝合在一起它的检测 

626
00:30:50,729 --> 00:30:56,309
左手肘右手肘手 

627
00:30:53,039 --> 00:30:57,989
个别它正在表演 

628
00:30:56,309 --> 00:31:03,659
检测然后缝合一切 

629
00:30:57,989 --> 00:31:06,119
之后一起让你交易 

630
00:31:03,659 --> 00:31:08,669
随着 身体 的疯狂变形 

631
00:31:06,119 --> 00:31:11,190
那发生了遮挡 等等 

632
00:31:08,669 --> 00:31:16,919
因为你 不需要所有关节 

633
00:31:11,190 --> 00:31:19,259
是可见的和这个级联的姿势 

634
00:31:16,919 --> 00:31:20,820
回归量意味着这些 

635
00:31:19,259 --> 00:31:23,940
卷积神经网络已经采取 

636
00:31:20,820 --> 00:31:25,889
原始图像并生成 XY位置 

637
00:31:23,940 --> 00:31:29,009
他们对每个人的估计 

638
00:31:25,889 --> 00:31:33,139
联合输入作为图像输出是 

639
00:31:29,009 --> 00:31:36,479
估计 肘关节 的关节 

640
00:31:33,139 --> 00:31:40,129
几个标志性建筑中的任何一个 

641
00:31:36,479 --> 00:31:42,839
那么你就可以建立在每一个顶部

642
00:31:40,129 --> 00:31:46,559
估计放大了那个 特定的 

643
00:31:42,839 --> 00:31:48,719
区域，并执行更精细 

644
00:31:46,559 --> 00:31:52,139
谷物估计的确切 位置 

645
00:31:48,719 --> 00:31:55,139
Joye一遍又一 遍地 重复着它 

646
00:31:52,139 --> 00:31:58,129
通过这个过程，我们可以 

647
00:31:55,139 --> 00:32:00,179
部分检测和多人和 

648
00:31:58,129 --> 00:32:03,239
包含 多 个人的多人 场景 

649
00:32:00,179 --> 00:32:05,969
人们所以我们可以检测出头部了 

650
00:32:03,239 --> 00:32:08,399
脖子在这里肘部所示的手

651
00:32:05,969 --> 00:32:10,499
右边的各种图像是 

652
00:32:08,399 --> 00:32:12,899
不了解谁的头 

653
00:32:10,499 --> 00:32:16,019
手所属的肘部

654
00:32:12,899 --> 00:32:18,179
它只是在没有执行检测 

655
00:32:16,019 --> 00:32:25,259
试图做个人检测

656
00:32:18,179 --> 00:32:27,299
首先，然后最终连接或不连接

657
00:32:25,259 --> 00:32:30,559
最后但下一步 是与之相连 

658
00:32:27,299 --> 00:32:33,210
部分亲和力字段正在连接它们 

659
00:32:30,559 --> 00:32:34,559
部分在一起， 所以首先你发现 

660
00:32:33,210 --> 00:32:36,989
各个部分，然后你连接 它们 

661
00:32:34,559 --> 00:32:40,019
一起，然后通过双方 

662
00:32:36,989 --> 00:32:41,879
匹配你确定谁是谁

663
00:32:40,019 --> 00:32:43,589
每个人身体最重要的部分

664
00:32:41,879 --> 00:32:45,299
可能属于你所以

665
00:32:43,589 --> 00:32:46,410
把不同的人缝在一起 

666
00:32:45,299 --> 00:32:50,210
经过 现场 

667
00:32:46,410 --> 00:32:50,210
用CNN进行检测 

668
00:32:52,040 --> 00:32:57,720
我们使用这种方法来检测 

669
00:32:55,830 --> 00:33:02,480
上身特别是肩膀

670
00:32:57,720 --> 00:33:06,900
颈部和 头部的 眼睛是鼻子的耳朵 

671
00:33:02,480 --> 00:33:09,150
那是用来确定 的 

672
00:33:06,900 --> 00:33:11,400
司机的位置相对于 

673
00:33:09,150 --> 00:33:13,610
例如标准虚拟位置 

674
00:33:11,400 --> 00:33:17,190
在自动驾驶仪驾驶期间看

675
00:33:13,610 --> 00:33:19,170
30分钟的时间 我们可以看看 

676
00:33:17,190 --> 00:33:20,910
x轴是时间 ， y轴 是 

677
00:33:19,170 --> 00:33:23,130
我的颈部位置 

678
00:33:20,910 --> 00:33:27,420
在上一张幻灯片中指出了这一点 

679
00:33:23,130 --> 00:33:30,510
两者之间的 的 中点 

680
00:33:27,420 --> 00:33:32,940
肩膀的 脖子是 位置 

681
00:33:30,510 --> 00:33:36,980
相 对于它 开始的 时间 而言 

682
00:33:32,940 --> 00:33:38,820
懒散地沉入座位 

683
00:33:36,980 --> 00:33:41,160
让汽车知道这一点 

684
00:33:38,820 --> 00:33:42,900
信息并 允许我们或 

685
00:33:41,160 --> 00:33:46,350
安全系统的设计者和所有这些 

686
00:33:42,900 --> 00:33:48,750
信息对我们 来说 非常重要 

687
00:33:46,350 --> 00:33:50,820
使用相同的身体姿势算法来自 

688
00:33:48,750 --> 00:33:52,890
车外的视角

689
00:33:50,820 --> 00:33:54,990
车辆视角如此车辆 

690
00:33:52,890 --> 00:33:56,910
望着正在反对

691
00:33:54,990 --> 00:34:01,740
只是简单的行人检测 使用 

692
00:33:56,910 --> 00:34:05,420
身体姿势估计再次在这里

693
00:34:01,740 --> 00:34:07,740
肯德尔广场车辆穿越 

694
00:34:05,420 --> 00:34:10,169
观察行人过马路

695
00:34:07,740 --> 00:34:15,500
决定和表演身体姿势 

696
00:34:10,169 --> 00:34:15,500
估计哪个允许你呢 

697
00:34:16,250 --> 00:34:21,629
生成像这样的可视化

698
00:34:19,379 --> 00:34:26,040
在这上获得这样的理解

699
00:34:21,629 --> 00:34:28,409
x轴是y轴上 的时间 

700
00:34:26,040 --> 00:34:31,080
在蓝顶情节 的 速度 

701
00:34:28,409 --> 00:34:33,470
车辆的速度是自我 

702
00:34:31,080 --> 00:34:36,780
相机所在的车辆

703
00:34:33,470 --> 00:34:40,639
观察现场和底部 

704
00:34:36,780 --> 00:34:43,260
绿色上下 作为二进制 值 

705
00:34:40,639 --> 00:34:45,300
是否Podesta当行人 

706
00:34:43,260 --> 00:34:48,120
是不是在看车的时候 

707
00:34:45,300 --> 00:34:50,070
行人正在看车，所以我们 

708
00:34:48,120 --> 00:34:51,780
可以看看成千上万的剧集 

709
00:34:50,070 --> 00:34:53,909
这种交叉决定是非语言的

710
00:34:51,780 --> 00:34:58,350
沟通决定和决定

711
00:34:53,909 --> 00:34:59,980
使用身体姿势估计动力学 

712
00:34:58,350 --> 00:35:04,480
这种非语言的

713
00:34:59,980 --> 00:35:06,670
这附近就是媒体实验室 穿越 

714
00:35:04,480 --> 00:35:08,170
我们可以采用行人路 

715
00:35:06,670 --> 00:35:11,290
当行人看时， 绿色那里 

716
00:35:08,170 --> 00:35:14,170
眼镜看起来像汽车看起来的眼镜 

717
00:35:11,290 --> 00:35:17,770
远迷人的一瞥行为 

718
00:35:14,170 --> 00:35:24,460
大多数人看起来很有趣 

719
00:35:17,770 --> 00:35:26,740
在他们穿过同样的东西之前离开

720
00:35:24,460 --> 00:35:29,050
这只是我们的一个例子 

721
00:35:26,740 --> 00:35:31,950
成千上万的身体姿势估计 

722
00:35:29,050 --> 00:35:34,570
允许你获得这种细粒度 

723
00:35:31,950 --> 00:35:37,090
有关行人一瞥的信息 

724
00:35:34,570 --> 00:35:42,609
行为人体行为

725
00:35:37,090 --> 00:35:44,650
犹豫玻璃分类之一 

726
00:35:42,609 --> 00:35:48,400
驾驶中最重要的事情是

727
00:35:44,650 --> 00:35:53,800
确定司机在哪里看 

728
00:35:48,400 --> 00:35:57,280
如果有任何感觉， 我提倡 

729
00:35:53,800 --> 00:35:59,880
并且在影响最大

730
00:35:57,280 --> 00:36:03,190
驾驶环境是让汽车知道的 

731
00:35:59,880 --> 00:36:08,140
司机正在寻找的地方 

732
00:36:03,190 --> 00:36:10,240
非常原始的区域级信息 

733
00:36:08,140 --> 00:36:11,980
被司机看路面上或关闭 

734
00:36:10,240 --> 00:36:14,650
道路，这就是我们所说的一瞥 

735
00:36:11,980 --> 00:36:16,780
分类它不是标准 

736
00:36:14,650 --> 00:36:19,000
XYZ的注视估计问题 

737
00:36:16,780 --> 00:36:21,400
确定 眼睛的姿势和姿势 

738
00:36:19,000 --> 00:36:23,470
头部姿势结合起来确定 在哪里 

739
00:36:21,400 --> 00:36:27,010
司机看起来 不是这个 

740
00:36:23,470 --> 00:36:30,730
在越野公路上划分两个区域 

741
00:36:27,010 --> 00:36:33,100
或离开道路的六个地区

742
00:36:30,730 --> 00:36:36,750
右中心堆栈后视镜和

743
00:36:33,100 --> 00:36:41,080
仪表盘所以它是基于区域的 

744
00:36:36,750 --> 00:36:43,119
扫视分配不是几何凝视

745
00:36:41,080 --> 00:36:46,750
估计问题为什么那么重要 

746
00:36:43,119 --> 00:36:49,420
它允许您将 其作为一台机器 来 处理 

747
00:36:46,750 --> 00:36:51,730
学习问题这是一个微妙的但是 

748
00:36:49,420 --> 00:36:54,760
关键点我们尝试的每一个问题

749
00:36:51,730 --> 00:36:57,730
在驾驶员感知中解决人体感知问题

750
00:36:54,760 --> 00:37:02,160
必须从数据中 学习 

751
00:36:57,730 --> 00:37:04,930
否则它不适合 

752
00:37:02,160 --> 00:37:07,210
在现实世界中我们不能应用 

753
00:37:04,930 --> 00:37:09,490
设计系统是实验室

754
00:37:07,210 --> 00:37:13,080
部署而不学习 他们 

755
00:37:09,490 --> 00:37:16,650
涉及人类可以做大满贯 

756
00:37:13,080 --> 00:37:19,560
通过 非常好的 本地化 

757
00:37:16,650 --> 00:37:21,930
传感器和使用的本地化

758
00:37:19,560 --> 00:37:24,150
那些没有太多学习的传感器

759
00:37:21,930 --> 00:37:26,430
不可能设计 出处理的系统 

760
00:37:24,150 --> 00:37:29,460
用灯光变化和全 

761
00:37:26,430 --> 00:37:31,860
没有 人的行为的可变性

762
00:37:29,460 --> 00:37:34,560
能够学习如此凝视估计 

763
00:37:31,860 --> 00:37:36,300
寻找的几何方法

764
00:37:34,560 --> 00:37:39,150
面部和 那些地标

765
00:37:36,300 --> 00:37:41,100
确定Jeremie的地标

766
00:37:39,150 --> 00:37:43,020
头部和头部的方向 

767
00:37:41,100 --> 00:37:45,840
眼睛的方向没有 

768
00:37:43,020 --> 00:37:47,880
实际上在那里学习 

769
00:37:45,840 --> 00:37:50,940
训练系统 检测 

770
00:37:47,880 --> 00:37:52,890
如果我们转换 这个不同的地标

771
00:37:50,940 --> 00:37:57,960
进入所示的凝视分类问题

772
00:37:52,890 --> 00:38:01,800
这里玻璃分类是在服用时 

773
00:37:57,960 --> 00:38:04,290
在帖子中确定的原始视频流 

774
00:38:01,800 --> 00:38:06,480
所以人类正在诠释这个视频 

775
00:38:04,290 --> 00:38:11,160
司机是哪个区域的司机 

776
00:38:06,480 --> 00:38:12,780
看着我们能够做到的 

777
00:38:11,160 --> 00:38:15,780
将问题转化为简单的问题 

778
00:38:12,780 --> 00:38:18,210
公路分类的变种 

779
00:38:15,780 --> 00:38:22,080
越野左右同样可以做到 

780
00:38:18,210 --> 00:38:24,720
对于行人左前方吧 

781
00:38:22,080 --> 00:38:28,320
可以注释它们所在的区域

782
00:38:24,720 --> 00:38:30,300
寻找和使用那种 

783
00:38:28,320 --> 00:38:32,670
分类方法确定

784
00:38:30,300 --> 00:38:34,230
他们看着汽车与否 

785
00:38:32,670 --> 00:38:36,690
他们看着他们正在看着他们 

786
00:38:34,230 --> 00:38:39,420
智能手机没有做3d凝视 

787
00:38:36,690 --> 00:38:41,190
再次估计它是一个微妙的点， 但是 

788
00:38:39,420 --> 00:38:42,960
如果 你想 估计，请考虑一下

789
00:38:41,190 --> 00:38:46,410
他们正在寻找的确切位置 

790
00:38:42,960 --> 00:38:49,290
你需要那些你没有的基本事实 

791
00:38:46,410 --> 00:38:51,000
除非你在那里，否则有这个基本事实

792
00:38:49,290 --> 00:38:52,650
在现实世界中没有数据 

793
00:38:51,000 --> 00:38:54,330
没有办法获取信息 

794
00:38:52,650 --> 00:38:57,750
关于 人们在 哪里 看 

795
00:38:54,330 --> 00:38:59,070
你只是 推断，所以你必须 

796
00:38:57,750 --> 00:39:00,780
将其转换为基于区域 

797
00:38:59,070 --> 00:39:03,060
分类问题是为了 

798
00:39:00,780 --> 00:39:05,910
能够训练 你的网络 和 

799
00:39:03,060 --> 00:39:10,770
管道是 相同 的源 

800
00:39:05,910 --> 00:39:12,600
视频在这里面对30帧a 

801
00:39:10,770 --> 00:39:15,330
第二个视频进入了 司机 

802
00:39:12,600 --> 00:39:16,950
面对人脸有一些 

803
00:39:15,330 --> 00:39:19,020
需要的校准程度

804
00:39:16,950 --> 00:39:21,630
你必须大致确定 

805
00:39:19,020 --> 00:39:23,970
传感器正在 接收的地方 

806
00:39:21,630 --> 00:39:26,070
图像特别 是一目了然 

807
00:39:23,970 --> 00:39:26,789
分类任务因为它的 区域 

808
00:39:26,070 --> 00:39:29,519
基于 

809
00:39:26,789 --> 00:39:32,910
需要能够估计其中 

810
00:39:29,519 --> 00:39:36,630
前进道路是摄像机的所在 

811
00:39:32,910 --> 00:39:39,089
框架是相对世界框架的 

812
00:39:36,630 --> 00:39:40,859
视频稳定和 面对面 

813
00:39:39,089 --> 00:39:42,329
提升所有基本处理 

814
00:39:40,859 --> 00:39:45,209
他们已经删除 的振动 

815
00:39:42,329 --> 00:39:47,819
噪声 除去的 物理移动 

816
00:39:45,209 --> 00:39:50,219
头部 的 时候删掉的晃动 

817
00:39:47,819 --> 00:39:51,839
汽车以便 能够确定 

818
00:39:50,219 --> 00:39:55,079
眼睛运动 和眨眼的东西

819
00:39:51,839 --> 00:39:59,640
动力学，最后与神经 

820
00:39:55,079 --> 00:40:02,819
网络没有什么可以留下的 

821
00:39:59,640 --> 00:40:05,309
接受面部的原始视频 

822
00:40:02,819 --> 00:40:07,739
玻璃分类任务和 

823
00:40:05,309 --> 00:40:09,509
关注认知负荷任务原始 

824
00:40:07,739 --> 00:40:11,609
像素是这些的输入 

825
00:40:09,509 --> 00:40:15,299
网络和输出是什么 

826
00:40:11,609 --> 00:40:17,339
培训数据是，我们将提到每个 

827
00:40:15,299 --> 00:40:22,049
那么这是否是认知负荷 

828
00:40:17,339 --> 00:40:23,849
一瞥 情感困倦的输入是 

829
00:40:22,049 --> 00:40:26,099
原始像素 和 输出是 

830
00:40:23,849 --> 00:40:29,130
无论你有什么数据数据是 

831
00:40:26,099 --> 00:40:33,299
这里的一切都是面对面的 

832
00:40:29,130 --> 00:40:36,439
问题是传统的 几何问题 

833
00:40:33,299 --> 00:40:38,609
解决这个问题的方法是设计 

834
00:40:36,439 --> 00:40:40,799
能够 检测的 算法 

835
00:40:38,609 --> 00:40:42,630
准确地说明了各个地标

836
00:40:40,799 --> 00:40:48,900
面子和那个估计 的 

837
00:40:42,630 --> 00:40:49,359
班级头部姿势的几何形状

838
00:40:48,900 --> 00:40:52,089
的

839
00:40:49,359 --> 00:40:54,249
在版本中 我们执行相同的类型 

840
00:40:52,089 --> 00:40:55,839
对齐或与同一种脸型 

841
00:40:54,249 --> 00:40:58,509
检测对齐以确定 

842
00:40:55,839 --> 00:41:00,819
头部在哪里， 但一旦我们拥有它 

843
00:40:58,509 --> 00:41:03,809
我们只传入原始 像素 和 

844
00:41:00,819 --> 00:41:05,890
对其进行分类

845
00:41:03,809 --> 00:41:09,160
反对这样做估计 其 

846
00:41:05,890 --> 00:41:11,619
分类允许你 执行 

847
00:41:09,160 --> 00:41:15,400
什么是显示有在 底部是 

848
00:41:11,619 --> 00:41:18,130
实时 分类在哪里 

849
00:41:15,400 --> 00:41:20,859
司机正在寻找道路左右中心 

850
00:41:18,130 --> 00:41:26,950
堆栈仪表组和后视图 

851
00:41:20,859 --> 00:41:31,239
镜像和我提到的注释 

852
00:41:26,950 --> 00:41:33,819
工具是关键所以我们共有 5个 

853
00:41:31,239 --> 00:41:41,200
十亿个视频帧一个半 

854
00:41:33,819 --> 00:41:43,119
数十亿的面孔需要数十 

855
00:41:41,200 --> 00:41:46,569
只需数百万美元即可注释 

856
00:41:43,119 --> 00:41:49,630
对于玻璃分类完全如此我们

857
00:41:46,569 --> 00:41:50,950
必须弄清楚要注释的内容 

858
00:41:49,630 --> 00:41:53,440
交易，你会网络 

859
00:41:50,950 --> 00:41:55,959
执行此任务以及我们注释的内容 

860
00:41:53,440 --> 00:41:58,269
是 网络不是 的东西 

861
00:41:55,959 --> 00:42:00,430
对... 的时刻充满信心

862
00:41:58,269 --> 00:42:02,440
突出部分变化

863
00:42:00,430 --> 00:42:04,930
来自光明或自我的遮挡 

864
00:42:02,440 --> 00:42:08,049
遮挡和移出框架 

865
00:42:04,930 --> 00:42:10,420
所有的外框遮挡

866
00:42:08,049 --> 00:42:12,489
困难的案例从框架到 

867
00:42:10,420 --> 00:42:14,109
框架到这里框架和 不同 

868
00:42:12,489 --> 00:42:17,709
管道起点在餐桌上要 在 

869
00:42:14,109 --> 00:42:19,749
每当分类底部

870
00:42:17,709 --> 00:42:22,420
信心不足 我们把它传递给了 

871
00:42:19,749 --> 00:42:24,569
人类很简单， 我们依靠人类 

872
00:42:22,420 --> 00:42:29,319
只有当分类器不是时 

873
00:42:24,569 --> 00:42:32,799
自信和基本的权衡

874
00:42:29,319 --> 00:42:34,859
在所有这些系统中是什么 

875
00:42:32,799 --> 00:42:37,959
我们愿意 忍受的准确性

876
00:42:34,859 --> 00:42:41,259
这里红色 和蓝色 ，红色是人类 

877
00:42:37,959 --> 00:42:45,789
选择决定和蓝色 作为一台机器 

878
00:42:41,259 --> 00:42:51,819
红色的任务我们选择 我们想要 的视频 

879
00:42:45,789 --> 00:42:54,059
将神经分类为蓝色

880
00:42:51,819 --> 00:42:56,589
网络执行面部检测任务 

881
00:42:54,059 --> 00:42:58,500
选择什么是本地化相机 

882
00:42:56,589 --> 00:43:01,710
相机 的角度 

883
00:42:58,500 --> 00:43:05,520
并提供贸易机会和

884
00:43:01,710 --> 00:43:07,530
它可以注释的百分比帧数 

885
00:43:05,520 --> 00:43:09,780
当然，你会 在一个网络 

886
00:43:07,530 --> 00:43:12,180
浏览整个数据集 

887
00:43:09,780 --> 00:43:16,550
在这种情况下会达到准确性 

888
00:43:12,180 --> 00:43:18,810
玻璃分类九低 90％ 

889
00:43:16,550 --> 00:43:21,359
关于 第六次玻璃任务的分类

890
00:43:18,810 --> 00:43:23,040
现在，如果你想要更高的精确度 

891
00:43:21,359 --> 00:43:25,080
它只能 实现这一目标 

892
00:43:23,040 --> 00:43:26,340
我们用于 较小部分的帧 

893
00:43:25,080 --> 00:43:30,119
这是选择 

894
00:43:26,340 --> 00:43:34,590
然后一个人必须进去

895
00:43:30,119 --> 00:43:36,630
执行 框架 的注释 

896
00:43:34,590 --> 00:43:39,660
算法没有信心 

897
00:43:36,630 --> 00:43:41,640
关于 和它一遍又一遍地重复 

898
00:43:39,660 --> 00:43:43,670
然后在帧上训练算法

899
00:43:41,640 --> 00:43:45,900
这是由人和人注释的 

900
00:43:43,670 --> 00:43:47,400
一遍又一遍 的 重复这个过程 

901
00:43:45,900 --> 00:43:53,040
框架直到所有内容都被注释 

902
00:43:47,400 --> 00:43:55,650
是的，绝对是的 

903
00:43:53,040 --> 00:43:57,780
问题是你有没有观察过 

904
00:43:55,650 --> 00:44:03,450
分类器非常自信

905
00:43:57,780 --> 00:44:06,050
关于错误的类，是的 

906
00:44:03,450 --> 00:44:07,890
问题很热，那么你怎么样 

907
00:44:06,050 --> 00:44:10,320
你怎么处理 你怎么样 

908
00:44:07,890 --> 00:44:12,920
说明你如何解释 

909
00:44:10,320 --> 00:44:17,130
高度自信的事实

910
00:44:12,920 --> 00:44:20,310
预测可能是非常错误的 

911
00:44:17,130 --> 00:44:23,220
误报误报是 

912
00:44:20,310 --> 00:44:25,050
你真的对那里有信心 

913
00:44:23,220 --> 00:44:27,750
至少根据 我们的经验，没有 

914
00:44:25,050 --> 00:44:29,040
对此 更好的答案 除了更多 

915
00:44:27,750 --> 00:44:31,080
以及有关事物的更多培训数据 

916
00:44:29,040 --> 00:44:35,280
你通常对此没有信心 

917
00:44:31,080 --> 00:44:37,770
似乎对我们的案例进行了概括 

918
00:44:35,280 --> 00:44:42,570
不要遇到明显的大类 

919
00:44:37,770 --> 00:44:46,020
对你真正有信心的数据 

920
00:44:42,570 --> 00:44:48,510
关于错误的事情通常是一些 

921
00:44:46,020 --> 00:44:50,720
人类注释程度最大 

922
00:44:48,510 --> 00:44:53,630
问题

923
00:44:50,720 --> 00:44:57,140
贬低低信心 

924
00:44:53,630 --> 00:44:57,140
部分数据 

925
00:44:57,370 --> 00:45:04,510
解决所有不正确的问题但是 

926
00:45:02,260 --> 00:45:06,670
当然，这并不总是正确 的 

927
00:45:04,510 --> 00:45:11,980
一般情况下 你可以想象 很多 

928
00:45:06,670 --> 00:45:14,640
情况是否不 适用 

929
00:45:11,980 --> 00:45:19,240
例如，他们总是一件事 

930
00:45:14,640 --> 00:45:21,040
表演是针对我们每个人 

931
00:45:19,240 --> 00:45:23,860
通常会招待大量的 

932
00:45:21,040 --> 00:45:25,330
手动数据，无论我们有什么

933
00:45:23,860 --> 00:45:28,360
确保神经网络具有 

934
00:45:25,330 --> 00:45:30,460
看到那个人 在各种各样的 

935
00:45:28,360 --> 00:45:33,490
各种方式自己的脸看起来 像 

936
00:45:30,460 --> 00:45:37,000
不同头发的眼镜 

937
00:45:33,490 --> 00:45:38,560
不同的照明变化所以我们 

938
00:45:37,000 --> 00:45:40,120
想要手动注释它 

939
00:45:38,560 --> 00:45:41,370
超时我们允许机器 

940
00:45:40,120 --> 00:45:44,050
做越来越多 的工作 

941
00:45:41,370 --> 00:45:45,730
是什么导致了这一点

942
00:45:44,050 --> 00:45:47,290
你可以做一瞥分类案例 

943
00:45:45,730 --> 00:45:49,150
你可以给出的实时分类 

944
00:45:47,290 --> 00:45:50,740
关于是否的汽车信息 

945
00:45:49,150 --> 00:45:52,930
司机正在寻找 道路或越野 

946
00:45:50,740 --> 00:45:54,760
这是 汽车的关键信息 

947
00:45:52,930 --> 00:45:57,040
理解，你想暂停 

948
00:45:54,760 --> 00:45:59,320
一秒钟才意识到 你什么时候 

949
00:45:57,040 --> 00:46:01,060
为 我们的司机驾驶汽车 

950
00:45:59,320 --> 00:46:04,450
那些驾驶任何一种车的人 

951
00:46:01,060 --> 00:46:07,060
任何类型的自动化它都不知道 

952
00:46:04,450 --> 00:46:09,160
关于你所做的 一切 

953
00:46:07,060 --> 00:46:11,290
不，它没有任何 关于的 信息 

954
00:46:09,160 --> 00:46:13,360
司机， 除非他们正在接触 

955
00:46:11,290 --> 00:46:15,700
方向盘与否也越来越 多 

956
00:46:13,360 --> 00:46:18,010
现在与通用汽车超级车辆和 

957
00:46:15,700 --> 00:46:20,230
特斯拉现在增加了一个烘干机面 

958
00:46:18,010 --> 00:46:23,350
慢慢开始 思考的相机

959
00:46:20,230 --> 00:46:25,420
关于走向 感知 

960
00:46:23,350 --> 00:46:27,100
司机， 但大多数车辆在路上 

961
00:46:25,420 --> 00:46:29,980
今天不了解司机 

962
00:46:27,100 --> 00:46:33,610
这种知识几乎是常识

963
00:46:29,980 --> 00:46:35,050
并且让汽车拥有它的微不足道

964
00:46:33,610 --> 00:46:37,450
常识这有多重要

965
00:46:35,050 --> 00:46:39,400
信息是司机所在的位置 

966
00:46:37,450 --> 00:46:43,330
看那是一瞥分类 

967
00:46:39,400 --> 00:46:46,660
问题再次强调我们已经

968
00:46:43,330 --> 00:46:48,790
转换它已经三十年了 

969
00:46:46,660 --> 00:46:50,470
致力于凝视估计而凝视 

970
00:46:48,790 --> 00:46:53,080
估计是做头部姿势估计

971
00:46:50,470 --> 00:46:55,330
所以头部的几何方向 

972
00:46:53,080 --> 00:46:58,000
结合 眼睛 的方向 

973
00:46:55,330 --> 00:46:59,850
并使用该组合信息

974
00:46:58,000 --> 00:47:02,350
确定此 人的目的地 

975
00:46:59,850 --> 00:47:04,840
将其转换为分类 

976
00:47:02,350 --> 00:47:06,520
问题所以标准凝视估计

977
00:47:04,840 --> 00:47:08,730
定义不是机器学习 

978
00:47:06,520 --> 00:47:08,730
问题

979
00:47:08,970 --> 00:47:13,099
分类是机器学习 

980
00:47:10,349 --> 00:47:17,820
问题 这种 转变是关键 

981
00:47:13,099 --> 00:47:22,040
情感人类的情感是一种迷人的 

982
00:47:17,820 --> 00:47:24,599
东西所以同样 的管道 

983
00:47:22,040 --> 00:47:27,150
稳定清理数据原始 

984
00:47:24,599 --> 00:47:30,960
以像素为单位，然后将分类是 

985
00:47:27,150 --> 00:47:36,750
如果我，情绪问题

986
00:47:30,960 --> 00:47:38,220
可以作为专家说话而不是 

987
00:47:36,750 --> 00:47:41,490
情感专家就是专家 

988
00:47:38,220 --> 00:47:43,590
作为人类的是有很多 

989
00:47:41,490 --> 00:47:47,599
这种方式是 一种鸡奸情绪 

990
00:47:43,590 --> 00:47:50,550
将情绪分类以定义情绪

991
00:47:47,599 --> 00:47:52,410
是否是主要的 

992
00:47:50,550 --> 00:47:55,200
para scale的情感 会喜欢快乐 

993
00:47:52,410 --> 00:47:57,510
惊讶的愤怒悲伤恐惧有一个 

994
00:47:55,200 --> 00:47:59,130
很多方法可以将它们混合在一起 

995
00:47:57,510 --> 00:48:02,910
打破这些分裂成 层次 

996
00:47:59,130 --> 00:48:05,430
分类法以及我们 对它的思考 方式 

997
00:48:02,910 --> 00:48:09,090
在 驱动情况下至少 有 

998
00:48:05,430 --> 00:48:12,300
一般的情感识别任务 排序 

999
00:48:09,090 --> 00:48:14,160
我提到过我会提到它，但它是 

1000
00:48:12,300 --> 00:48:17,910
我们如何看待初级 

1001
00:48:14,160 --> 00:48:20,490
情绪正在发现

1002
00:48:17,910 --> 00:48:24,210
喜悦和愤怒的情感类别

1003
00:48:20,490 --> 00:48:26,820
令人厌恶和惊讶然后在那里 

1004
00:48:24,210 --> 00:48:29,099
是特定于应用的情感 

1005
00:48:26,820 --> 00:48:31,740
识别你正在使用的地方 

1006
00:48:29,099 --> 00:48:33,470
所有各种各样的面部表情 

1007
00:48:31,740 --> 00:48:38,780
我们可以改变面子的方式 

1008
00:48:33,470 --> 00:48:42,000
通信信息 来确定 

1009
00:48:38,780 --> 00:48:45,089
关于互动的 具体问题 

1010
00:48:42,000 --> 00:48:47,280
司机所以我先是为了 

1011
00:48:45,089 --> 00:48:49,680
一般情况下 这些是建筑物 

1012
00:48:47,280 --> 00:48:53,250
块我的意思是那里有 无数的 

1013
00:48:49,680 --> 00:48:54,990
使我们使用 的脸部变形的方法

1014
00:48:53,250 --> 00:48:59,710
互相 有交流

1015
00:48:54,990 --> 00:49:06,070
可以是 42个单独的面部肌肉

1016
00:48:59,710 --> 00:49:06,820
用来形成那些表达式之一 

1017
00:49:06,070 --> 00:49:09,490
我们的最爱 

1018
00:49:06,820 --> 00:49:11,410
与工作是有效的SDK，这是 

1019
00:49:09,490 --> 00:49:15,150
他们与将军的任务 

1020
00:49:11,410 --> 00:49:18,400
情绪识别任务 正在进行中 

1021
00:49:15,150 --> 00:49:20,860
原始像素和确定的类别 

1022
00:49:18,400 --> 00:49:23,320
情绪非常微妙的那种情绪 

1023
00:49:20,860 --> 00:49:25,870
在一般情况下生产一个 

1024
00:49:23,320 --> 00:49:30,550
愤怒的分类厌恶恐惧

1025
00:49:25,870 --> 00:49:31,900
如此惊喜然后映射我的意思 

1026
00:49:30,550 --> 00:49:33,490
基本上这些算法是什么

1027
00:49:31,900 --> 00:49:35,470
做是否 他们 使用深 

1028
00:49:33,490 --> 00:49:37,180
是否使用神经网络 

1029
00:49:35,470 --> 00:49:39,010
面对齐做地标

1030
00:49:37,180 --> 00:49:40,840
检测然后跟踪那些 

1031
00:49:39,010 --> 00:49:43,210
随着时间的推移做地标的地标

1032
00:49:40,840 --> 00:49:46,450
他们确定的行动是他们的 

1033
00:49:43,210 --> 00:49:47,860
映射组件的表达式

1034
00:49:46,450 --> 00:49:49,390
他们 可以做出 的各种表达 方式 

1035
00:49:47,860 --> 00:49:54,160
用他们的眉毛或他们的鼻子和 

1036
00:49:49,390 --> 00:49:56,230
嘴 和眼睛将它们映射到 

1037
00:49:54,160 --> 00:49:57,880
情绪，所以我想强调 一个 

1038
00:49:56,230 --> 00:50:02,280
因为我认为这是 一个 说明性的 

1039
00:49:57,880 --> 00:50:05,110
快乐的表达 正在微笑 

1040
00:50:02,280 --> 00:50:07,780
所以可能性增加了

1041
00:50:05,110 --> 00:50:10,450
你观察到一个微笑的表情 

1042
00:50:07,780 --> 00:50:12,190
当喜悦 经历或恶习时面对

1043
00:50:10,450 --> 00:50:15,520
反之亦然， 如果有增加 

1044
00:50:12,190 --> 00:50:17,290
微笑的可能性有一个

1045
00:50:15,520 --> 00:50:20,620
增加快乐情绪的可能性 

1046
00:50:17,290 --> 00:50:22,720
经历，然后快乐 

1047
00:50:20,620 --> 00:50:25,540
经验的可能性降低

1048
00:50:22,720 --> 00:50:30,190
眉毛抬起和眉毛的可能性

1049
00:50:25,540 --> 00:50:33,430
如果你看到微笑就是这样的话

1050
00:50:30,190 --> 00:50:34,510
如果你看到眉毛 ，这是一个加号

1051
00:50:33,430 --> 00:50:38,110
哦 募集 亮 

1052
00:50:34,510 --> 00:50:39,490
额头皱纹是欢乐减去这 

1053
00:50:38,110 --> 00:50:41,170
对于一般的情感认可 

1054
00:50:39,490 --> 00:50:42,730
这个任务得到了很好的 研究 

1055
00:50:41,170 --> 00:50:44,380
一种情感 计算的核心

1056
00:50:42,730 --> 00:50:45,640
来自视觉的运动

1057
00:50:44,380 --> 00:50:48,010
从计算机再次透视

1058
00:50:45,640 --> 00:50:50,770
从应用程序的 愿景角度 

1059
00:50:48,010 --> 00:50:53,110
具体的观点是什么 

1060
00:50:50,770 --> 00:50:55,150
真正专注于数据的是 

1061
00:50:53,110 --> 00:50:58,120
什么是你注释的一切

1062
00:50:55,150 --> 00:51:00,370
我们可以在这里采取大规模的 

1063
00:50:58,120 --> 00:51:03,340
与a交互的驱动程序数据集

1064
00:51:00,370 --> 00:51:05,890
基于语音的导航系统，所以他们 

1065
00:51:03,340 --> 00:51:09,040
在各种车辆 进入任务

1066
00:51:05,890 --> 00:51:11,620
导航，所以他们正在交谈 

1067
00:51:09,040 --> 00:51:13,060
他们的GPS使用他们的声音这是为了 

1068
00:51:11,620 --> 00:51:15,280
根据车辆 取决于 

1069
00:51:13,060 --> 00:51:17,470
在大多数情况下 ， 该系统 令人难以置信 

1070
00:51:15,280 --> 00:51:19,040
令人沮丧的经历让我们拥有它们 

1071
00:51:17,470 --> 00:51:22,430
执行此任务然后

1072
00:51:19,040 --> 00:51:24,820
注释是自我报告后 的 

1073
00:51:22,430 --> 00:51:27,740
他们说的任务规模是 1到10怎么样 

1074
00:51:24,820 --> 00:51:32,150
令人沮丧的是这种体验和时间 

1075
00:51:27,740 --> 00:51:35,360
你看到的是表达式

1076
00:51:32,150 --> 00:51:38,630
检测到并 与满意 相关联 

1077
00:51:35,360 --> 00:51:41,690
一个人谁说AA 10 对 

1078
00:51:38,630 --> 00:51:44,750
在无奈满意这样一个 1 

1079
00:51:41,690 --> 00:51:47,770
规模完全满足于 

1080
00:51:44,750 --> 00:51:51,950
底部 基于语音的交互 是 

1081
00:51:47,770 --> 00:51:56,360
作为失意的一个believin 9 

1082
00:51:51,950 --> 00:51:58,370
无奈规模因此该功能的 

1083
00:51:56,360 --> 00:52:01,820
那里表达最强的记忆 

1084
00:51:58,370 --> 00:52:03,920
欢乐的笑容是最强烈的指标 

1085
00:52:01,820 --> 00:52:06,080
我们所有科目都感到沮丧

1086
00:52:03,920 --> 00:52:08,260
微笑是最强烈的表达 

1087
00:52:06,080 --> 00:52:12,160
这是一直存在 的 东西 

1088
00:52:08,260 --> 00:52:14,540
沮丧还有其他各种各样的 

1089
00:52:12,160 --> 00:52:17,510
皱着眉头随后摇晃着

1090
00:52:14,540 --> 00:52:19,250
头等等，但微笑就在那里

1091
00:52:17,510 --> 00:52:21,650
显示你的那种干净 

1092
00:52:19,250 --> 00:52:23,030
一般情绪之间的差异

1093
00:52:21,650 --> 00:52:24,200
识别任务和 

1094
00:52:23,030 --> 00:52:27,700
专用 

1095
00:52:24,200 --> 00:52:31,010
也许他们喜欢荒唐 

1096
00:52:27,700 --> 00:52:32,270
欢乐的时刻在无奈地 说 ， 

1097
00:52:31,010 --> 00:52:33,920
正在体验你可以获得 

1098
00:52:32,270 --> 00:52:35,630
哲学，但实用 

1099
00:52:33,920 --> 00:52:38,210
自然是他们与沮丧

1100
00:52:35,630 --> 00:52:40,480
经验，我们使用最多的42 

1101
00:52:38,210 --> 00:52:44,050
面部表情要做 

1102
00:52:40,480 --> 00:52:46,460
分类沮丧或不 和 

1103
00:52:44,050 --> 00:52:49,910
他们的数据不是工作而是工作

1104
00:52:46,460 --> 00:52:53,360
算法它是一个快速的注释 

1105
00:52:49,910 --> 00:52:54,110
提到下周 的AGI课程 

1106
00:52:53,360 --> 00:52:56,810
人工智能 

1107
00:52:54,110 --> 00:53:01,900
一类比赛的我们 的 

1108
00:52:56,810 --> 00:53:05,210
做的是我们有一个 JavaScript 面孔 

1109
00:53:01,900 --> 00:53:10,060
这与神经网络来训练的

1110
00:53:05,210 --> 00:53:14,360
形成各种表达来沟通

1111
00:53:10,060 --> 00:53:18,290
与观察者一起， 所以我们感兴趣 

1112
00:53:14,360 --> 00:53:20,450
创造情感，这是一面很好的镜子 

1113
00:53:18,290 --> 00:53:23,980
情感认知的耦合

1114
00:53:20,450 --> 00:53:28,000
这个问题会非常 酷 

1115
00:53:23,980 --> 00:53:30,799
我们开始认识到的认知负荷

1116
00:53:28,000 --> 00:53:34,679
眼睛 

1117
00:53:30,799 --> 00:53:38,189
认知负荷是一种程度 

1118
00:53:34,679 --> 00:53:41,309
人类正在访问他们的记忆或 

1119
00:53:38,189 --> 00:53:43,979
劳森认为他们有多难 

1120
00:53:41,309 --> 00:53:46,499
在他们的脑海 里回想起来 

1121
00:53:43,979 --> 00:53:50,099
值得思考 的 东西 

1122
00:53:46,499 --> 00:53:53,189
认知负荷并快速暂停 

1123
00:53:50,099 --> 00:53:56,069
眼睛作为认知负荷的窗口 

1124
00:53:53,189 --> 00:53:58,019
眼睛窗口心中 有一个 

1125
00:53:56,069 --> 00:54:00,029
眼睛移动的方式不同，所以有

1126
00:53:58,019 --> 00:54:03,089
瞳孔是他们眼睛的黑色部分

1127
00:54:00,029 --> 00:54:05,369
可以扩大和合同，并根据 

1128
00:54:03,089 --> 00:54:07,529
各种因素， 包括 照明 

1129
00:54:05,369 --> 00:54:09,629
场景的变化， 但他们 也 

1130
00:54:07,529 --> 00:54:12,419
基于认知扩展和收缩 

1131
00:54:09,629 --> 00:54:14,039
加载这是一个强烈的信号 

1132
00:54:12,419 --> 00:54:16,139
他们也可以四处走动 

1133
00:54:14,039 --> 00:54:17,999
有弹道运动的时候会出现跳伞运动 

1134
00:54:16,139 --> 00:54:20,969
环顾周围的眼皮跳

1135
00:54:17,999 --> 00:54:23,789
场景他们也可以做一些 叫做的 事 

1136
00:54:20,969 --> 00:54:25,979
当你和连接时顺利追求

1137
00:54:23,789 --> 00:54:28,139
我们的动物 过去你可以看到一个 

1138
00:54:25,979 --> 00:54:31,739
美味的一餐 

1139
00:54:28,139 --> 00:54:33,479
通过你的眼睛飞行或奔跑

1140
00:54:31,739 --> 00:54:35,849
可以完全遵循它们，但它们不是 

1141
00:54:33,479 --> 00:54:38,759
当我们读一本书时 跳来跳去 

1142
00:54:35,849 --> 00:54:41,459
我们的眼睛正在使用扫视运动

1143
00:54:38,759 --> 00:54:43,049
他们在哪里跳来跳去的时候 

1144
00:54:41,459 --> 00:54:44,789
钱包muth追求眼睛在移动 

1145
00:54:43,049 --> 00:54:48,079
非常顺利的是那些种类 

1146
00:54:44,789 --> 00:54:50,869
必须与之合作的运动 

1147
00:54:48,079 --> 00:54:53,479
认知负荷可以通过检测 

1148
00:54:50,869 --> 00:54:56,639
看着 眼睛的各种因素 

1149
00:54:53,479 --> 00:55:01,139
眨眼动态的眼球运动和 

1150
00:54:56,639 --> 00:55:03,749
眼睛瞳孔直径问题 

1151
00:55:01,139 --> 00:55:06,269
是在现实世界和现实世界的数据 

1152
00:55:03,749 --> 00:55:07,859
随着照明变化一切顺利 

1153
00:55:06,269 --> 00:55:09,779
在使用瞳孔方面窗外 

1154
00:55:07,859 --> 00:55:12,059
直径这是 标准的方式 来 

1155
00:55:09,779 --> 00:55:13,679
衡量非接触式测量方法 

1156
00:55:12,059 --> 00:55:15,149
在实验室认知负荷时，你可以 

1157
00:55:13,679 --> 00:55:18,179
控制照明条件和使用 

1158
00:55:15,149 --> 00:55:19,799
红外摄像机，你不能那么多 

1159
00:55:18,179 --> 00:55:21,629
走出窗外，你拥有的只是 

1160
00:55:19,799 --> 00:55:24,319
眨眼动态和眼球运动

1161
00:55:21,629 --> 00:55:26,519
所以神经网络来救援 

1162
00:55:24,319 --> 00:55:28,529
在这个 3D卷积神经网络

1163
00:55:26,519 --> 00:55:32,249
情况下，我们采取的图像的序列， 即 

1164
00:55:28,529 --> 00:55:34,139
我通过时间和使用3D卷积 

1165
00:55:32,249 --> 00:55:36,049
而不是2d卷积

1166
00:55:34,139 --> 00:55:39,179
左边是我们无话不谈 

1167
00:55:36,049 --> 00:55:41,129
在此之前作为2d卷积时 

1168
00:55:39,179 --> 00:55:41,920
卷积滤波器正在运行

1169
00:55:41,129 --> 00:55:46,420
该 

1170
00:55:41,920 --> 00:55:49,930
操作 每个通道的 XY 2d图像 

1171
00:55:46,420 --> 00:55:54,310
由过滤器个体分别为3d 

1172
00:55:49,930 --> 00:55:57,010
卷积结合了那些卷积

1173
00:55:54,310 --> 00:56:01,210
跨越多个图像 

1174
00:55:57,010 --> 00:56:04,480
因此多个渠道能够 

1175
00:56:01,210 --> 00:56:07,680
学习 场景 的动态 

1176
00:56:04,480 --> 00:56:12,790
通过时间不仅仅是在空间上

1177
00:56:07,680 --> 00:56:16,690
时间和数据数据就是一切

1178
00:56:12,790 --> 00:56:20,200
我们 在这种情况下的认知负担92 

1179
00:56:16,690 --> 00:56:22,510
司机所以我们如何执行 

1180
00:56:20,200 --> 00:56:24,160
认知负荷分类任务我们 

1181
00:56:22,510 --> 00:56:26,260
让这些司机 开车 

1182
00:56:24,160 --> 00:56:28,450
公路和执行 什么 叫做 

1183
00:56:26,260 --> 00:56:32,080
n-back任务将一个回零 

1184
00:56:28,450 --> 00:56:34,030
回来，那个任务涉及听证会 

1185
00:56:32,080 --> 00:56:37,870
数字正在读给你然后

1186
00:56:34,030 --> 00:56:40,510
在一次回想起这些数字之一 ，所以 

1187
00:56:37,870 --> 00:56:42,640
一个零回系统 给你 一个 

1188
00:56:40,510 --> 00:56:45,880
七号，然后你必须 

1189
00:56:42,640 --> 00:56:47,440
说这个数字 回七，它保持 

1190
00:56:45,880 --> 00:56:49,930
重复这很容易它应该 

1191
00:56:47,440 --> 00:56:51,940
当 你 回来时， 这 是一件容易的事

1192
00:56:49,930 --> 00:56:55,060
听到号码你必须 记住它 

1193
00:56:51,940 --> 00:56:58,540
那么你有下一个号码 

1194
00:56:55,060 --> 00:56:59,950
说出之前的数字

1195
00:56:58,540 --> 00:57:01,750
你必须 保留一个号码 

1196
00:56:59,950 --> 00:57:04,420
你的记忆永远不会得到 

1197
00:57:01,750 --> 00:57:06,850
被 新 信息分散注意力

1198
00:57:04,420 --> 00:57:08,800
起来但要回来你必须做那 两个 

1199
00:57:06,850 --> 00:57:11,350
数字回来所以你必须使用记忆 

1200
00:57:08,800 --> 00:57:13,990
越来越多的 人回归认知 

1201
00:57:11,350 --> 00:57:17,620
什么是负载越高越好 

1202
00:57:13,990 --> 00:57:19,870
我们是否使用面部对齐面 

1203
00:57:17,620 --> 00:57:22,150
正面抬高并检测眼睛 

1204
00:57:19,870 --> 00:57:25,450
最接近相机并提取 

1205
00:57:22,150 --> 00:57:28,360
眼睛区域，现在我们有这个很好的原料 

1206
00:57:25,450 --> 00:57:31,960
六个眼睛区域的像素

1207
00:57:28,360 --> 00:57:33,610
几秒钟的视频，我们采取了 这个和 

1208
00:57:31,960 --> 00:57:37,270
把 它 作为一个三维卷积神经 

1209
00:57:33,610 --> 00:57:39,220
网络和分类只是三个中的一个

1210
00:57:37,270 --> 00:57:41,860
班级归零一回， 两回 

1211
00:57:39,220 --> 00:57:43,480
所以我们有 很多人 的数据 

1212
00:57:41,860 --> 00:57:45,430
高速公路执行这些任务和

1213
00:57:43,480 --> 00:57:47,650
后面的任务，形成了

1214
00:57:45,430 --> 00:57:52,450
分类监督学习

1215
00:57:47,650 --> 00:57:55,250
训练数据 输入是90 

1216
00:57:52,450 --> 00:57:59,680
它的图像是每秒15帧 

1217
00:57:55,250 --> 00:57:59,680
输出是三个类之一 

1218
00:58:01,180 --> 00:58:06,080
我应该提到的是面对额头化 

1219
00:58:03,920 --> 00:58:07,790
为面子开发的技术

1220
00:58:06,080 --> 00:58:10,250
因为大多数人都认可

1221
00:58:07,790 --> 00:58:12,619
识别任务需要正面 

1222
00:58:10,250 --> 00:58:14,599
方向也是 我们在这里使用的方式 

1223
00:58:12,619 --> 00:58:18,520
规范我们可以关注的一切 

1224
00:58:14,599 --> 00:58:20,900
在确切的眨眼之间它正在接受 

1225
00:58:18,520 --> 00:58:22,609
它正在采取 任何方向 

1226
00:58:20,900 --> 00:58:27,710
脸部和突出到正面 

1227
00:58:22,609 --> 00:58:30,320
采取原始像素的位置

1228
00:58:27,710 --> 00:58:37,160
脸部正在检测眼睛区域变焦 

1229
00:58:30,320 --> 00:58:39,550
在你找到的地方抓住眼睛 

1230
00:58:37,160 --> 00:58:45,680
这就是直觉的建立 

1231
00:58:39,550 --> 00:58:47,300
它是一个迷人的东西 

1232
00:58:45,680 --> 00:58:50,599
这里绘制的是相对运动

1233
00:58:47,300 --> 00:58:54,369
瞳孔的相对运动 

1234
00:58:50,599 --> 00:58:56,960
眼睛基于不同的认知负荷 

1235
00:58:54,369 --> 00:58:58,940
对于 零 左边的认知负荷 

1236
00:58:56,960 --> 00:59:01,790
所以当你的思想 不是那么迷失的时候 

1237
00:58:58,940 --> 00:59:03,770
两个人的思想和认知负担 

1238
00:59:01,790 --> 00:59:06,920
当它 在思想眼中迷失的 时候 

1239
00:59:03,770 --> 00:59:09,740
移动少了很多眼睛更侧重 于 

1240
00:59:06,920 --> 00:59:11,270
前进的道路是一个 

1241
00:59:09,740 --> 00:59:13,070
有趣的发现， 但它只是在 

1242
00:59:11,270 --> 00:59:15,580
聚合，这就是神经 

1243
00:59:13,070 --> 00:59:18,820
神经网络是任务会做到的 

1244
00:59:15,580 --> 00:59:22,089
提取 一帧接一帧的基础 

1245
00:59:18,820 --> 00:59:25,310
这是一个标准的3d卷积 

1246
00:59:22,089 --> 00:59:27,260
建筑再次采取图像 

1247
00:59:25,310 --> 00:59:29,140
序列是输入的认知 负荷 

1248
00:59:27,260 --> 00:59:33,950
分类是输出和 

1249
00:59:29,140 --> 00:59:37,339
在右边分类是准确性 

1250
00:59:33,950 --> 00:59:41,480
这是能够实现的 86％ 这 

1251
00:59:37,339 --> 00:59:42,770
来自真实世界的数据很酷的 

1252
00:59:41,480 --> 00:59:46,940
想法是你可以 只是一个人 

1253
00:59:42,770 --> 00:59:50,410
摄像头让视频 进入 

1254
00:59:46,940 --> 00:59:52,130
神经网络和 这种 预测 

1255
00:59:50,410 --> 00:59:56,030
它 继续 

1256
00:59:52,130 --> 01:00:00,890
从零到两个 认知 的流 

1257
00:59:56,030 --> 01:00:03,560
因为每一个零想要回来加载

1258
01:00:00,890 --> 01:00:05,060
一个背靠背的课程 有一个 

1259
01:00:03,560 --> 01:00:07,820
与他们相关的信心

1260
01:00:05,060 --> 01:00:09,800
所以你可以把它变成真正的价值 

1261
01:00:07,820 --> 01:00:13,400
在零 到 两之间，当你看到 

1262
01:00:09,800 --> 01:00:16,490
这是 三个人的情节

1263
01:00:13,400 --> 01:00:21,430
这里的车队开着车表演 

1264
01:00:16,490 --> 01:00:24,050
谈话和白色的任务

1265
01:00:21,430 --> 01:00:25,550
通过显示认知负荷 框架 

1266
01:00:24,050 --> 01:00:27,560
帧一个三十个帧 的第二 

1267
01:00:25,550 --> 01:00:30,650
估计每个人的认知负荷

1268
01:00:27,560 --> 01:00:33,560
驾驶员从0到2上 

1269
01:00:30,650 --> 01:00:37,480
y轴因此这些都是高认知负荷 

1270
01:00:33,560 --> 01:00:41,060
并显示在底部的红色和 

1271
01:00:37,480 --> 01:00:43,040
黄色的高中等认知负荷和 

1272
01:00:41,060 --> 01:00:45,470
当每个人都沉默 认知时 

1273
01:00:43,040 --> 01:00:47,660
负载下降所以我们现在可以执行 

1274
01:00:45,470 --> 01:00:49,550
用这个简单的神经网络 

1275
01:00:47,660 --> 01:00:51,890
训练我们形成的数据我们 可以 

1276
01:00:49,550 --> 01:00:55,550
将其扩展到 任意 新数据 

1277
01:00:51,890 --> 01:00:57,020
设置和概括确定那些是一些 

1278
01:00:55,550 --> 01:00:59,390
哈尼亚神经网络的例子可以 

1279
01:00:57,020 --> 01:01:03,620
应用，为什么这很重要 

1280
01:00:59,390 --> 01:01:06,230
再一次，我们专注于那种 

1281
01:01:03,620 --> 01:01:08,630
使用神经网络 的感知 任务 

1282
01:01:06,230 --> 01:01:10,970
使用传感器和信号的网络

1283
01:01:08,630 --> 01:01:12,260
处理以确定我们所处的位置 

1284
01:01:10,970 --> 01:01:13,940
世界上不同的障碍 

1285
01:01:12,260 --> 01:01:17,270
是围绕 这些的 通知轨迹 

1286
01:01:13,940 --> 01:01:21,200
阻碍 我们仍然远离 

1287
01:01:17,270 --> 01:01:24,380
我会完全解决这个问题

1288
01:01:21,200 --> 01:01:27,800
争论20多年 的人类 意志 

1289
01:01:24,380 --> 01:01:30,200
必须参与，所以当它是 

1290
01:01:27,800 --> 01:01:31,760
系统无法控制何时 

1291
01:01:30,200 --> 01:01:33,350
系统无法 察觉何时 

1292
01:01:31,760 --> 01:01:36,080
有一些缺陷方面有关 

1293
01:01:33,350 --> 01:01:37,910
感知或驾驶政策 

1294
01:01:36,080 --> 01:01:40,190
人类必须参与其中 

1295
01:01:37,910 --> 01:01:43,190
在那里我们必须知道 让汽车知道 

1296
01:01:40,190 --> 01:01:44,990
什么人在做这就是

1297
01:01:43,190 --> 01:01:49,550
人体机器人的基本要素 

1298
01:01:44,990 --> 01:01:52,790
互动中最流行的汽车

1299
01:01:49,550 --> 01:01:55,670
美国今天是福特f-150没有 

1300
01:01:52,790 --> 01:01:59,890
自动化那种东西

1301
01:01:55,670 --> 01:02:02,120
激励我们， 让我们 思考 

1302
01:01:59,890 --> 01:02:03,770
运输可以从根本上 

1303
01:02:02,120 --> 01:02:05,240
转型是谷歌自驾车

1304
01:02:03,770 --> 01:02:07,340
莫

1305
01:02:05,240 --> 01:02:08,450
我们的，虽然我们的演讲嘉宾 和 

1306
01:02:07,340 --> 01:02:12,410
所有人都在自治中工作 

1307
01:02:08,450 --> 01:02:14,210
车辆，但如果你看看它的 唯一 

1308
01:02:12,410 --> 01:02:17,300
大规模的人 或 

1309
01:02:14,210 --> 01:02:20,360
开始实际注射 

1310
01:02:17,300 --> 01:02:21,920
自动化进入我们的日常生活 是 

1311
01:02:20,360 --> 01:02:24,800
介于两者之间 

1312
01:02:21,920 --> 01:02:29,020
这是特斯拉的l2系统 

1313
01:02:24,800 --> 01:02:33,200
特斯拉系统 超级音响 

1314
01:02:29,020 --> 01:02:36,790
像90年代 那样 缓慢 的车辆 

1315
01:02:33,200 --> 01:02:38,990
增加一定程度的自动化和 

1316
01:02:36,790 --> 01:02:43,119
教人类如何互动 

1317
01:02:38,990 --> 01:02:51,080
随着自动化，这里又来了 

1318
01:02:43,119 --> 01:02:54,740
通向大规模的道路

1319
01:02:51,080 --> 01:02:57,380
自动化我们 的方向盘 去除 

1320
01:02:54,740 --> 01:03:01,660
考虑到人类移除了我 

1321
01:02:57,380 --> 01:03:05,450
相信是二十多年了 

1322
01:03:01,660 --> 01:03:07,730
我们必须了解的道路

1323
01:03:05,450 --> 01:03:11,350
并创造成功的 人类机器人 

1324
01:03:07,730 --> 01:03:14,030
互动方式自动驾驶汽车 

1325
01:03:11,350 --> 01:03:17,359
以人为本的自治系统

1326
01:03:14,030 --> 01:03:20,060
这些方式的大规模整合 

1327
01:03:17,359 --> 01:03:22,100
像 人类 中心系统的系统

1328
01:03:20,060 --> 01:03:24,440
测试特斯拉的车辆只是一个 

1329
01:03:22,100 --> 01:03:26,630
小公司现在 的那种 

1330
01:03:24,440 --> 01:03:28,880
l2技术还没有真正实现 

1331
01:03:26,630 --> 01:03:30,710
渗透市场还没有

1332
01:03:28,880 --> 01:03:32,119
我们的车辆 甚至 穿透 了 

1333
01:03:30,710 --> 01:03:34,070
Brittain新车被释放 

1334
01:03:32,119 --> 01:03:38,300
今天我相信这发生在 

1335
01:03:34,070 --> 01:03:41,450
20世纪20年代初 ，这将 形成 

1336
01:03:38,300 --> 01:03:43,970
将成为我们算法的核心

1337
01:03:41,450 --> 01:03:46,100
最终导致所有的完全自治 

1338
01:03:43,970 --> 01:03:49,310
我在特斯拉提到的那些数据 

1339
01:03:46,100 --> 01:03:50,930
全部驾驶 32％的 里程 

1340
01:03:49,310 --> 01:03:53,390
这是训练 算法的 数据 

1341
01:03:50,930 --> 01:03:55,940
边缘的情况下出现的还有这就是 

1342
01:03:53,390 --> 01:04:00,710
我们在数据集中获取所有这些数据 

1343
01:03:55,940 --> 01:04:03,560
麻省理工学院是400,000英里特斯拉有十亿 

1344
01:04:00,710 --> 01:04:07,010
英里所以这 是所有训练数据 

1345
01:04:03,560 --> 01:04:10,900
在 通往大规模 楼梯的路上 

1346
01:04:07,010 --> 01:04:14,380
自动化为什么会这样 

1347
01:04:10,900 --> 01:04:16,599
重要的美丽，从根本 上 

1348
01:04:14,380 --> 01:04:18,789
人工智能在社会中的作用我相信 

1349
01:04:16,599 --> 01:04:21,160
当他们在这里时，自动驾驶汽车

1350
01:04:18,789 --> 01:04:24,460
方式专注于人类机器人 

1351
01:04:21,160 --> 01:04:27,250
与我们的个人机器人互动 

1352
01:04:24,460 --> 01:04:30,220
不是感知控制系统工具 

1353
01:04:27,250 --> 01:04:33,880
就像Roomba表演一个 特别的 

1354
01:04:30,220 --> 01:04:35,289
当人类生活是牛排时的任务

1355
01:04:33,880 --> 01:04:39,460
两者之间有根本的转移

1356
01:04:35,289 --> 01:04:41,920
一个人的 生命给他们的 

1357
01:04:39,460 --> 01:04:46,480
直接生活到AI系统 之一 

1358
01:04:41,920 --> 01:04:50,380
在一个是转移，是一种 

1359
01:04:46,480 --> 01:04:54,880
关系是一个指示a的关系 

1360
01:04:50,380 --> 01:04:56,200
个人机器人这是它需要的一切 

1361
01:04:54,880 --> 01:05:00,029
理解的东西 

1362
01:04:56,200 --> 01:05:03,220
这些信任的沟通

1363
01:05:00,029 --> 01:05:05,799
了解一个 人是 多么迷人

1364
01:05:03,220 --> 01:05:10,210
和机器人可以形成足够的信任

1365
01:05:05,799 --> 01:05:12,700
创造一个真正的差不多 

1366
01:05:10,210 --> 01:05:15,510
彼此一对一的理解 

1367
01:05:12,700 --> 01:05:18,510
精神状态互相学习哦 

1368
01:05:15,510 --> 01:05:18,510
男孩

1369
01:05:19,800 --> 01:05:25,270
所以我 最喜欢的电影之一Good Will 

1370
01:05:23,410 --> 01:05:29,800
狩猎我们在波士顿剑桥有 

1371
01:05:25,270 --> 01:05:34,150
两者有两个还要遗憾 这一个 本 

1372
01:05:29,800 --> 01:05:36,160
是罗宾威廉姆斯谈论人类 

1373
01:05:34,150 --> 01:05:39,280
瑕疵所以我希望你 能接受 

1374
01:05:36,160 --> 01:05:44,320
这个引用并且每次都替换 

1375
01:05:39,280 --> 01:05:47,230
提到女孩与汽车人打电话 

1376
01:05:44,320 --> 01:05:48,790
那些不完美的事情罗宾

1377
01:05:47,230 --> 01:05:52,119
威廉姆斯正在谈论 他的妻子 

1378
01:05:48,790 --> 01:05:54,580
在电影里谈论 过世了 

1379
01:05:52,119 --> 01:05:56,770
她称之为瑕疵

1380
01:05:54,580 --> 01:05:59,560
不完美，但他们不是那样的 

1381
01:05:56,770 --> 01:06:02,430
好东西然后 我们会选择 

1382
01:05:59,560 --> 01:06:05,680
我们让谁进入我们奇怪的小世界 

1383
01:06:02,430 --> 01:06:08,170
你不是完美的运动，让我拯救 

1384
01:06:05,680 --> 01:06:09,400
你是这个女孩的悬念你遇到了她 

1385
01:06:08,170 --> 01:06:11,970
在那里，你知道 什么是不完美的

1386
01:06:09,400 --> 01:06:11,970
让我吧 

1387
01:06:19,289 --> 01:06:22,499
只有我知道 的视频序列 

1388
01:06:21,729 --> 01:06:26,170
关于 

1389
01:06:22,499 --> 01:06:29,130
这就是 她 做 我妻子的原因 

1390
01:06:26,170 --> 01:06:33,089
骗了我 - 她是我的宠物狗 

1391
01:06:29,130 --> 01:06:37,959
人们 将 这些东西 称为 时尚 

1392
01:06:33,089 --> 01:06:43,049
足以没有必要选择我们 学习 

1393
01:06:37,959 --> 01:06:46,709
避免 在我的 呼吸探索中 的话 

1394
01:06:43,049 --> 01:06:49,869
悬念中的事情 

1395
01:06:46,709 --> 01:06:53,609
他有空袭， 但问题是 

1396
01:06:49,869 --> 01:06:53,609
我对彼此的完美之处 

1397
01:06:54,070 --> 01:06:57,139
[音乐] 

1398
01:07:00,250 --> 01:07:03,420
[音乐] 

1399
01:07:07,680 --> 01:07:15,039
所以我们正在建设的方法

1400
01:07:12,910 --> 01:07:17,890
我们在这里的自动驾驶汽车

1401
01:07:15,039 --> 01:07:20,170
麻省理工学院在我们小组中以人为本 

1402
01:07:17,890 --> 01:07:22,839
他们接近自动驾驶汽车

1403
01:07:20,170 --> 01:07:29,680
将于2018年3月发布

1404
01:07:22,839 --> 01:07:35,920
在波士顿街头那些愿意的人

1405
01:07:29,680 --> 01:07:38,349
请 帮忙 ， 我会说话 跑 

1406
01:07:35,920 --> 01:07:40,390
当然深的学问

1407
01:07:38,349 --> 01:07:42,160
了解Chi 2018的人类 

1408
01:07:40,390 --> 01:07:45,849
将会进行教程 

1409
01:07:42,160 --> 01:07:47,770
卷积的远远超出了视觉 

1410
01:07:45,849 --> 01:07:50,920
基于神经网络的检测

1411
01:07:47,770 --> 01:07:53,710
面部和身体的各个方面 

1412
01:07:50,920 --> 01:07:58,420
会看 自然语言 

1413
01:07:53,710 --> 01:08:02,559
处理语音识别和 Gans 

1414
01:07:58,420 --> 01:08:07,150
如果你要去Chi，请加入下一个

1415
01:08:02,559 --> 01:08:12,210
一周，我们有一个令人难以置信的课程 

1416
01:08:07,150 --> 01:08:17,199
旨在了解开始探索 

1417
01:08:12,210 --> 01:08:20,589
智力 的本质和 自然 

1418
01:08:17,199 --> 01:08:26,170
人工我们有Josh Tenenbaum Ray 

1419
01:08:20,589 --> 01:08:27,370
Kurzweil Lisa Barret Nate Dubinsky 

1420
01:08:26,170 --> 01:08:30,429
看着认知建模 

1421
01:08:27,370 --> 01:08:33,040
架构安德烈· 卡尔帕蒂 斯蒂芬 

1422
01:08:30,429 --> 01:08:36,929
Wolfram Richard Moyes 在谈论 

1423
01:08:33,040 --> 01:08:41,140
自主武器系统和 人工智能安全 

1424
01:08:36,929 --> 01:08:44,910
来自波士顿动力公司的罗伯特 和 

1425
01:08:41,140 --> 01:08:51,480
令我惊讶的令人难以置信的机器人

1426
01:08:44,910 --> 01:08:55,540
来自开放AI和我自己的 Ilya sutskever 

1427
01:08:51,480 --> 01:08:59,910
所以接下来 的人们会 注册这个 

1428
01:08:55,540 --> 01:09:03,520
当然你 必须在 今晚 提交 一份 

1429
01:08:59,910 --> 01:09:07,540
实现速度的深度交通入口

1430
01:09:03,520 --> 01:09:10,179
每小时65英里，我希望你 

1431
01:09:07,540 --> 01:09:13,029
继续提交更多赢得的 

1432
01:09:10,179 --> 01:09:15,880
竞争高绩效奖 

1433
01:09:13,029 --> 01:09:19,120
将会给 极少数人 

1434
01:09:15,880 --> 01:09:23,290
每小时 达到 70英里的人们

1435
01:09:19,120 --> 01:09:28,089
我们将继续更快地推出seg 

1436
01:09:23,290 --> 01:09:31,299
保险丝遇到了一些障碍并投入了资金 

1437
01:09:28,089 --> 01:09:34,600
几千美元

1438
01:09:31,299 --> 01:09:37,989
注释的卫生过程

1439
01:09:34,600 --> 01:09:39,880
我们将为您提供大规模的数据集 

1440
01:09:37,989 --> 01:09:41,390
继续本次比赛将采取 

1441
01:09:39,880 --> 01:09:44,510
我们进入

1442
01:09:41,390 --> 01:09:46,130
在我们的地方 提交 到他的nips 

1443
01:09:44,510 --> 01:09:48,710
希望 为此提交结果 

1444
01:09:46,130 --> 01:09:50,600
竞争和深度崩溃 更深层次 

1445
01:09:48,710 --> 01:09:53,270
执法学习这些比赛 

1446
01:09:50,600 --> 01:09:55,000
将继续到2018年5月我希望 

1447
01:09:53,270 --> 01:09:59,090
你保持关注和参与

1448
01:09:55,000 --> 01:10:01,670
即将上课的 GI课程 

1449
01:09:59,090 --> 01:10:05,270
我鼓励 你们来 是要 

1450
01:10:01,670 --> 01:10:06,770
很有魅力， 而且 很酷 

1451
01:10:05,270 --> 01:10:08,450
那我们要有趣的想法

1452
01:10:06,770 --> 01:10:10,460
探索它会很棒 

1453
01:10:08,450 --> 01:10:13,040
有深度学习 的 介绍 

1454
01:10:10,460 --> 01:10:15,710
当然，我也会参与 其中 

1455
01:10:13,040 --> 01:10:18,190
更多应用并得到人们 

1456
01:10:15,710 --> 01:10:20,870
谁对 最基本的 感兴趣 

1457
01:10:18,190 --> 01:10:25,130
深度学习的算法如何 获得 

1458
01:10:20,870 --> 01:10:26,930
从那些动手开始，那就是 

1459
01:10:25,130 --> 01:10:28,970
去年参加的一个很棒的课程 

1460
01:10:26,930 --> 01:10:32,360
那些去年上课的人我们 

1461
01:10:28,970 --> 01:10:34,700
还在全球范围内谈到了它

1462
01:10:32,360 --> 01:10:36,440
人工智能和 机器人技术 的幻灯片 

1463
01:10:34,700 --> 01:10:38,300
在线我鼓励你点击 一个 

1464
01:10:36,440 --> 01:10:41,900
链接在那里并注册 它在 

1465
01:10:38,300 --> 01:10:43,130
它每周一次，它是真的

1466
01:10:41,900 --> 01:10:45,530
汇集了很多 

1467
01:10:43,130 --> 01:10:47,720
跨学科的人谈谈 

1468
01:10:45,530 --> 01:10:49,940
人工智能 和 想法 

1469
01:10:47,720 --> 01:10:53,740
人工智能和机器人技术以及社会的作用 

1470
01:10:49,940 --> 01:10:56,240
一个很棒的课程，如果你是 

1471
01:10:53,740 --> 01:10:58,640
有兴趣应用深度学习 

1472
01:10:56,240 --> 01:11:01,160
汽车领域的方法来了 

1473
01:10:58,640 --> 01:11:03,410
与我们合作我们有 很多 

1474
01:11:01,160 --> 01:11:07,910
有趣的问题 来 解决或 

1475
01:11:03,410 --> 01:11:11,020
与我合作，我想

1476
01:11:07,910 --> 01:11:13,730
谢谢 大家这里所有人 

1477
01:11:11,020 --> 01:11:16,040
一直在贡献的社区

1478
01:11:13,730 --> 01:11:18,320
我们有成千上万的提交 

1479
01:11:16,040 --> 01:11:20,300
对于深度交通，我只是真的 

1480
01:11:18,320 --> 01:11:22,100
受到我们支持的谦卑

1481
01:11:20,300 --> 01:11:24,410
获得和这个班级背后的团队

1482
01:11:22,100 --> 01:11:27,350
非常感谢Nvidia Google 

1483
01:11:24,410 --> 01:11:33,770
亚马逊Alexa 自动 生活在丰田和 

1484
01:11:27,350 --> 01:11:36,500
今天我们有额外的额外衬衫

1485
01:11:33,770 --> 01:11:39,350
超大的 媒介在那里小 和 

1486
01:11:36,500 --> 01:11:40,490
大大小小的那边

1487
01:11:39,350 --> 01:11:43,730
人们在这里然后 

1488
01:11:40,490 --> 01:11:46,940
这里只是中等规模的人 

1489
01:11:43,730 --> 01:11:47,480
抓住它抓住 一个，谢谢你 

1490
01:11:46,940 --> 01:11:51,660
非常

1491
01:11:47,480 --> 01:11:51,660
[掌声] 

