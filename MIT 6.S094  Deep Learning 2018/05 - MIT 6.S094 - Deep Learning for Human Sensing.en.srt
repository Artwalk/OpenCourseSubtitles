1
00:00:00,030 --> 00:00:02,230

today we will talk about how to apply

2
00:00:02,230 --> 00:00:02,240
today we will talk about how to apply
 

3
00:00:02,240 --> 00:00:05,650
today we will talk about how to apply
the methods of deep learning to

4
00:00:05,650 --> 00:00:05,660
the methods of deep learning to
 

5
00:00:05,660 --> 00:00:07,550
the methods of deep learning to
understanding the sense of the human

6
00:00:07,550 --> 00:00:07,560
understanding the sense of the human
 

7
00:00:07,560 --> 00:00:09,799
understanding the sense of the human
being the focus will be on computer

8
00:00:09,799 --> 00:00:09,809
being the focus will be on computer
 

9
00:00:09,809 --> 00:00:11,959
being the focus will be on computer
vision the visual aspects of a human

10
00:00:11,959 --> 00:00:11,969
vision the visual aspects of a human
 

11
00:00:11,969 --> 00:00:12,350
vision the visual aspects of a human
being

12
00:00:12,350 --> 00:00:12,360
being
 

13
00:00:12,360 --> 00:00:15,099
being
of course we humans express ourselves

14
00:00:15,099 --> 00:00:15,109
of course we humans express ourselves
 

15
00:00:15,109 --> 00:00:18,439
of course we humans express ourselves
visually but also through audio voice

16
00:00:18,439 --> 00:00:18,449
visually but also through audio voice
 

17
00:00:18,449 --> 00:00:21,740
visually but also through audio voice
and through text beautiful poetry and

18
00:00:21,740 --> 00:00:21,750
and through text beautiful poetry and
 

19
00:00:21,750 --> 00:00:23,750
and through text beautiful poetry and
novels and so on we're not going to

20
00:00:23,750 --> 00:00:23,760
novels and so on we're not going to
 

21
00:00:23,760 --> 00:00:25,220
novels and so on we're not going to
touch those today we're just going to

22
00:00:25,220 --> 00:00:25,230
touch those today we're just going to
 

23
00:00:25,230 --> 00:00:27,890
touch those today we're just going to
focus on computer vision how we can use

24
00:00:27,890 --> 00:00:27,900
focus on computer vision how we can use
 

25
00:00:27,900 --> 00:00:30,950
focus on computer vision how we can use
computer vision to extract useful

26
00:00:30,950 --> 00:00:30,960
computer vision to extract useful
 

27
00:00:30,960 --> 00:00:35,060
computer vision to extract useful
actionable information from video images

28
00:00:35,060 --> 00:00:35,070
actionable information from video images
 

29
00:00:35,070 --> 00:00:38,150
actionable information from video images
video of human beings in particular in

30
00:00:38,150 --> 00:00:38,160
video of human beings in particular in
 

31
00:00:38,160 --> 00:00:44,630
video of human beings in particular in
the context of the car so what are the

32
00:00:44,630 --> 00:00:44,640
the context of the car so what are the
 

33
00:00:44,640 --> 00:00:47,000
the context of the car so what are the
requirements for successfully applying

34
00:00:47,000 --> 00:00:47,010
requirements for successfully applying
 

35
00:00:47,010 --> 00:00:49,270
requirements for successfully applying
deep learning methods in the real world

36
00:00:49,270 --> 00:00:49,280
deep learning methods in the real world
 

37
00:00:49,280 --> 00:00:51,920
deep learning methods in the real world
so when we're talking about human

38
00:00:51,920 --> 00:00:51,930
so when we're talking about human
 

39
00:00:51,930 --> 00:00:55,160
so when we're talking about human
sensing we're not talking about a basic

40
00:00:55,160 --> 00:00:55,170
sensing we're not talking about a basic
 

41
00:00:55,170 --> 00:00:57,950
sensing we're not talking about a basic
face recognition of celebrity images

42
00:00:57,950 --> 00:00:57,960
face recognition of celebrity images
 

43
00:00:57,960 --> 00:01:00,860
face recognition of celebrity images
we're talking about using computer

44
00:01:00,860 --> 00:01:00,870
we're talking about using computer
 

45
00:01:00,870 --> 00:01:04,490
we're talking about using computer
vision deep learning methods to create

46
00:01:04,490 --> 00:01:04,500
vision deep learning methods to create
 

47
00:01:04,500 --> 00:01:06,230
vision deep learning methods to create
systems that operate in the real world

48
00:01:06,230 --> 00:01:06,240
systems that operate in the real world
 

49
00:01:06,240 --> 00:01:08,719
systems that operate in the real world
and in order for them to operate in the

50
00:01:08,719 --> 00:01:08,729
and in order for them to operate in the
 

51
00:01:08,729 --> 00:01:10,940
and in order for them to operate in the
real world there are several things they

52
00:01:10,940 --> 00:01:10,950
real world there are several things they
 

53
00:01:10,950 --> 00:01:13,580
real world there are several things they
sound simple some are much harder than

54
00:01:13,580 --> 00:01:13,590
sound simple some are much harder than
 

55
00:01:13,590 --> 00:01:16,429
sound simple some are much harder than
they sound first and the most important

56
00:01:16,429 --> 00:01:16,439
they sound first and the most important
 

57
00:01:16,439 --> 00:01:19,490
they sound first and the most important
here for most to less more to less

58
00:01:19,490 --> 00:01:19,500
here for most to less more to less
 

59
00:01:19,500 --> 00:01:22,850
here for most to less more to less
critical ordered is data data is

60
00:01:22,850 --> 00:01:22,860
critical ordered is data data is
 

61
00:01:22,860 --> 00:01:26,149
critical ordered is data data is
everything real world data we need a lot

62
00:01:26,149 --> 00:01:26,159
everything real world data we need a lot
 

63
00:01:26,159 --> 00:01:29,660
everything real world data we need a lot
of real world data to form the data set

64
00:01:29,660 --> 00:01:29,670
of real world data to form the data set
 

65
00:01:29,670 --> 00:01:31,580
of real world data to form the data set
on which these supervised learning

66
00:01:31,580 --> 00:01:31,590
on which these supervised learning
 

67
00:01:31,590 --> 00:01:35,240
on which these supervised learning
methods can be trained I'll say this

68
00:01:35,240 --> 00:01:35,250
methods can be trained I'll say this
 

69
00:01:35,250 --> 00:01:36,920
methods can be trained I'll say this
over and over throughout the day today

70
00:01:36,920 --> 00:01:36,930
over and over throughout the day today
 

71
00:01:36,930 --> 00:01:39,109
over and over throughout the day today
data is everything that means data

72
00:01:39,109 --> 00:01:39,119
data is everything that means data
 

73
00:01:39,119 --> 00:01:41,630
data is everything that means data
collection is the hardest part and the

74
00:01:41,630 --> 00:01:41,640
collection is the hardest part and the
 

75
00:01:41,640 --> 00:01:44,060
collection is the hardest part and the
most important part we'll talk about how

76
00:01:44,060 --> 00:01:44,070
most important part we'll talk about how
 

77
00:01:44,070 --> 00:01:46,460
most important part we'll talk about how
that data collection is carried out here

78
00:01:46,460 --> 00:01:46,470
that data collection is carried out here
 

79
00:01:46,470 --> 00:01:49,490
that data collection is carried out here
in our group at MIT all the different

80
00:01:49,490 --> 00:01:49,500
in our group at MIT all the different
 

81
00:01:49,500 --> 00:01:51,440
in our group at MIT all the different
ways to capture human beings in the

82
00:01:51,440 --> 00:01:51,450
ways to capture human beings in the
 

83
00:01:51,450 --> 00:01:54,350
ways to capture human beings in the
driving context in the road user context

84
00:01:54,350 --> 00:01:54,360
driving context in the road user context
 

85
00:01:54,360 --> 00:02:00,800
driving context in the road user context
pedestrians cyclists but the data it

86
00:02:00,800 --> 00:02:00,810
pedestrians cyclists but the data it
 

87
00:02:00,810 --> 00:02:04,819
pedestrians cyclists but the data it
starts and ends at data the fun stuff is

88
00:02:04,819 --> 00:02:04,829
starts and ends at data the fun stuff is
 

89
00:02:04,829 --> 00:02:07,700
starts and ends at data the fun stuff is
the algorithms but the data is what

90
00:02:07,700 --> 00:02:07,710
the algorithms but the data is what
 

91
00:02:07,710 --> 00:02:12,090
the algorithms but the data is what
makes it all work real world data okay

92
00:02:12,090 --> 00:02:12,100
makes it all work real world data okay
 

93
00:02:12,100 --> 00:02:14,130
makes it all work real world data okay
then once you have the data okay data

94
00:02:14,130 --> 00:02:14,140
then once you have the data okay data
 

95
00:02:14,140 --> 00:02:17,100
then once you have the data okay data
isn't everything I lied because you have

96
00:02:17,100 --> 00:02:17,110
isn't everything I lied because you have
 

97
00:02:17,110 --> 00:02:18,840
isn't everything I lied because you have
to actually annotate it so what do we

98
00:02:18,840 --> 00:02:18,850
to actually annotate it so what do we
 

99
00:02:18,850 --> 00:02:22,710
to actually annotate it so what do we
mean by data there's raw data video

100
00:02:22,710 --> 00:02:22,720
mean by data there's raw data video
 

101
00:02:22,720 --> 00:02:27,240
mean by data there's raw data video
audio lidar all the types of sensors

102
00:02:27,240 --> 00:02:27,250
audio lidar all the types of sensors
 

103
00:02:27,250 --> 00:02:32,220
audio lidar all the types of sensors
we'll talk about to capture real world

104
00:02:32,220 --> 00:02:32,230
we'll talk about to capture real world
 

105
00:02:32,230 --> 00:02:35,730
we'll talk about to capture real world
you wrote user interaction you have to

106
00:02:35,730 --> 00:02:35,740
you wrote user interaction you have to
 

107
00:02:35,740 --> 00:02:38,210
you wrote user interaction you have to
reduce that into meaningful

108
00:02:38,210 --> 00:02:38,220
reduce that into meaningful
 

109
00:02:38,220 --> 00:02:41,490
reduce that into meaningful
representative cases of what happens in

110
00:02:41,490 --> 00:02:41,500
representative cases of what happens in
 

111
00:02:41,500 --> 00:02:44,280
representative cases of what happens in
that real world in driving 99% of the

112
00:02:44,280 --> 00:02:44,290
that real world in driving 99% of the
 

113
00:02:44,290 --> 00:02:45,960
that real world in driving 99% of the
time driving looks the same it's the

114
00:02:45,960 --> 00:02:45,970
time driving looks the same it's the
 

115
00:02:45,970 --> 00:02:48,600
time driving looks the same it's the
it's the 1% the interesting cases that

116
00:02:48,600 --> 00:02:48,610
it's the 1% the interesting cases that
 

117
00:02:48,610 --> 00:02:51,210
it's the 1% the interesting cases that
we're interested in and what we want is

118
00:02:51,210 --> 00:02:51,220
we're interested in and what we want is
 

119
00:02:51,220 --> 00:02:53,760
we're interested in and what we want is
algorithm to train learning algorithms

120
00:02:53,760 --> 00:02:53,770
algorithm to train learning algorithms
 

121
00:02:53,770 --> 00:02:58,500
algorithm to train learning algorithms
on those 1% so we have to collect 100

122
00:02:58,500 --> 00:02:58,510
on those 1% so we have to collect 100
 

123
00:02:58,510 --> 00:02:59,910
on those 1% so we have to collect 100
percent we have to collect all the data

124
00:02:59,910 --> 00:02:59,920
percent we have to collect all the data
 

125
00:02:59,920 --> 00:03:02,190
percent we have to collect all the data
and then figure out and automated

126
00:03:02,190 --> 00:03:02,200
and then figure out and automated
 

127
00:03:02,200 --> 00:03:05,940
and then figure out and automated
semi-automated ways to find the pieces

128
00:03:05,940 --> 00:03:05,950
semi-automated ways to find the pieces
 

129
00:03:05,950 --> 00:03:07,860
semi-automated ways to find the pieces
of that data that could be used to train

130
00:03:07,860 --> 00:03:07,870
of that data that could be used to train
 

131
00:03:07,870 --> 00:03:09,720
of that data that could be used to train
your own networks and that a

132
00:03:09,720 --> 00:03:09,730
your own networks and that a
 

133
00:03:09,730 --> 00:03:12,300
your own networks and that a
representative of the general thing

134
00:03:12,300 --> 00:03:12,310
representative of the general thing
 

135
00:03:12,310 --> 00:03:14,010
representative of the general thing
kinds of things that happen in this

136
00:03:14,010 --> 00:03:14,020
kinds of things that happen in this
 

137
00:03:14,020 --> 00:03:19,470
kinds of things that happen in this
world efficient annotation annotation

138
00:03:19,470 --> 00:03:19,480
world efficient annotation annotation
 

139
00:03:19,480 --> 00:03:23,010
world efficient annotation annotation
isn't just about drawing bounding boxes

140
00:03:23,010 --> 00:03:23,020
isn't just about drawing bounding boxes
 

141
00:03:23,020 --> 00:03:27,540
isn't just about drawing bounding boxes
on images of cats annotation tooling is

142
00:03:27,540 --> 00:03:27,550
on images of cats annotation tooling is
 

143
00:03:27,550 --> 00:03:33,140
on images of cats annotation tooling is
key to unlocking real world performance

144
00:03:33,140 --> 00:03:33,150
key to unlocking real world performance
 

145
00:03:33,150 --> 00:03:37,320
key to unlocking real world performance
systems that successfully solve some

146
00:03:37,320 --> 00:03:37,330
systems that successfully solve some
 

147
00:03:37,330 --> 00:03:39,300
systems that successfully solve some
problem accomplish some goal in real

148
00:03:39,300 --> 00:03:39,310
problem accomplish some goal in real
 

149
00:03:39,310 --> 00:03:41,160
problem accomplish some goal in real
world data that means designing

150
00:03:41,160 --> 00:03:41,170
world data that means designing
 

151
00:03:41,170 --> 00:03:44,150
world data that means designing
annotation tools for a particular task

152
00:03:44,150 --> 00:03:44,160
annotation tools for a particular task
 

153
00:03:44,160 --> 00:03:46,680
annotation tools for a particular task
annotation tools that are used for

154
00:03:46,680 --> 00:03:46,690
annotation tools that are used for
 

155
00:03:46,690 --> 00:03:48,390
annotation tools that are used for
glance classification for determining

156
00:03:48,390 --> 00:03:48,400
glance classification for determining
 

157
00:03:48,400 --> 00:03:49,980
glance classification for determining
where drivers are looking it's very

158
00:03:49,980 --> 00:03:49,990
where drivers are looking it's very
 

159
00:03:49,990 --> 00:03:51,810
where drivers are looking it's very
different than annotation tools used for

160
00:03:51,810 --> 00:03:51,820
different than annotation tools used for
 

161
00:03:51,820 --> 00:03:54,360
different than annotation tools used for
body pose estimation is very different

162
00:03:54,360 --> 00:03:54,370
body pose estimation is very different
 

163
00:03:54,370 --> 00:03:57,120
body pose estimation is very different
than the tooling use that we use for

164
00:03:57,120 --> 00:03:57,130
than the tooling use that we use for
 

165
00:03:57,130 --> 00:03:59,130
than the tooling use that we use for
psyche views investing thousands of

166
00:03:59,130 --> 00:03:59,140
psyche views investing thousands of
 

167
00:03:59,140 --> 00:04:01,140
psyche views investing thousands of
dollars for the competition for this

168
00:04:01,140 --> 00:04:01,150
dollars for the competition for this
 

169
00:04:01,150 --> 00:04:04,050
dollars for the competition for this
class to annotate fully scene

170
00:04:04,050 --> 00:04:04,060
class to annotate fully scene
 

171
00:04:04,060 --> 00:04:05,580
class to annotate fully scene
segmentation where every pixel is

172
00:04:05,580 --> 00:04:05,590
segmentation where every pixel is
 

173
00:04:05,590 --> 00:04:08,490
segmentation where every pixel is
colored there's needs to be tooling for

174
00:04:08,490 --> 00:04:08,500
colored there's needs to be tooling for
 

175
00:04:08,500 --> 00:04:09,750
colored there's needs to be tooling for
each one of those elements and they're

176
00:04:09,750 --> 00:04:09,760
each one of those elements and they're
 

177
00:04:09,760 --> 00:04:12,990
each one of those elements and they're
key that's HCI question that's a design

178
00:04:12,990 --> 00:04:13,000
key that's HCI question that's a design
 

179
00:04:13,000 --> 00:04:15,300
key that's HCI question that's a design
question there's no deep learning

180
00:04:15,300 --> 00:04:15,310
question there's no deep learning
 

181
00:04:15,310 --> 00:04:18,780
question there's no deep learning
there's no robotics in that question

182
00:04:18,780 --> 00:04:18,790
there's no robotics in that question
 

183
00:04:18,790 --> 00:04:21,260
there's no robotics in that question
it's how do we leverage human

184
00:04:21,260 --> 00:04:21,270
it's how do we leverage human
 

185
00:04:21,270 --> 00:04:25,660
it's how do we leverage human
computation human the human brain to mow

186
00:04:25,660 --> 00:04:25,670
computation human the human brain to mow
 

187
00:04:25,670 --> 00:04:27,760
computation human the human brain to mow
effectively label images such that we

188
00:04:27,760 --> 00:04:27,770
effectively label images such that we
 

189
00:04:27,770 --> 00:04:29,970
effectively label images such that we
can train y'all networks on them

190
00:04:29,970 --> 00:04:29,980
can train y'all networks on them
 

191
00:04:29,980 --> 00:04:35,260
can train y'all networks on them
hardware in order to train these

192
00:04:35,260 --> 00:04:35,270
hardware in order to train these
 

193
00:04:35,270 --> 00:04:39,070
hardware in order to train these
networks in order to parse the data we

194
00:04:39,070 --> 00:04:39,080
networks in order to parse the data we
 

195
00:04:39,080 --> 00:04:40,810
networks in order to parse the data we
collect and we'll talk about we have now

196
00:04:40,810 --> 00:04:40,820
collect and we'll talk about we have now
 

197
00:04:40,820 --> 00:04:44,890
collect and we'll talk about we have now
over five billion images of data of

198
00:04:44,890 --> 00:04:44,900
over five billion images of data of
 

199
00:04:44,900 --> 00:04:47,290
over five billion images of data of
driving data in order to parse that you

200
00:04:47,290 --> 00:04:47,300
driving data in order to parse that you
 

201
00:04:47,300 --> 00:04:50,530
driving data in order to parse that you
can't do it on a single machine you have

202
00:04:50,530 --> 00:04:50,540
can't do it on a single machine you have
 

203
00:04:50,540 --> 00:04:52,780
can't do it on a single machine you have
to do large-scale distributed compute

204
00:04:52,780 --> 00:04:52,790
to do large-scale distributed compute
 

205
00:04:52,790 --> 00:04:56,640
to do large-scale distributed compute
and large-scale distributed storage and

206
00:04:56,640 --> 00:04:56,650
and large-scale distributed storage and
 

207
00:04:56,650 --> 00:05:00,340
and large-scale distributed storage and
finally the the stuff that's the most

208
00:05:00,340 --> 00:05:00,350
finally the the stuff that's the most
 

209
00:05:00,350 --> 00:05:04,270
finally the the stuff that's the most
exciting that people that there's this

210
00:05:04,270 --> 00:05:04,280
exciting that people that there's this
 

211
00:05:04,280 --> 00:05:06,790
exciting that people that there's this
class and many classes and much of the

212
00:05:06,790 --> 00:05:06,800
class and many classes and much of the
 

213
00:05:06,800 --> 00:05:08,170
class and many classes and much of the
literature is focused on is the

214
00:05:08,170 --> 00:05:08,180
literature is focused on is the
 

215
00:05:08,180 --> 00:05:10,480
literature is focused on is the
algorithms the deep learning algorithms

216
00:05:10,480 --> 00:05:10,490
algorithms the deep learning algorithms
 

217
00:05:10,490 --> 00:05:12,040
algorithms the deep learning algorithms
the machine learning algorithms the

218
00:05:12,040 --> 00:05:12,050
the machine learning algorithms the
 

219
00:05:12,050 --> 00:05:13,870
the machine learning algorithms the
algorithms that learn from data of

220
00:05:13,870 --> 00:05:13,880
algorithms that learn from data of
 

221
00:05:13,880 --> 00:05:15,940
algorithms that learn from data of
course that's really exciting and

222
00:05:15,940 --> 00:05:15,950
course that's really exciting and
 

223
00:05:15,950 --> 00:05:18,700
course that's really exciting and
important but what we find time and time

224
00:05:18,700 --> 00:05:18,710
important but what we find time and time
 

225
00:05:18,710 --> 00:05:21,460
important but what we find time and time
again in real world systems is that as

226
00:05:21,460 --> 00:05:21,470
again in real world systems is that as
 

227
00:05:21,470 --> 00:05:24,040
again in real world systems is that as
long as these algorithms learn from data

228
00:05:24,040 --> 00:05:24,050
long as these algorithms learn from data
 

229
00:05:24,050 --> 00:05:26,950
long as these algorithms learn from data
so as long as this deep learning the

230
00:05:26,950 --> 00:05:26,960
so as long as this deep learning the
 

231
00:05:26,960 --> 00:05:29,200
so as long as this deep learning the
data is what's much more important of

232
00:05:29,200 --> 00:05:29,210
data is what's much more important of
 

233
00:05:29,210 --> 00:05:31,180
data is what's much more important of
course it's nice for the algorithms to

234
00:05:31,180 --> 00:05:31,190
course it's nice for the algorithms to
 

235
00:05:31,190 --> 00:05:34,540
course it's nice for the algorithms to
be calibration free meaning they learn

236
00:05:34,540 --> 00:05:34,550
be calibration free meaning they learn
 

237
00:05:34,550 --> 00:05:36,940
be calibration free meaning they learn
to calibrate self calibrate we don't

238
00:05:36,940 --> 00:05:36,950
to calibrate self calibrate we don't
 

239
00:05:36,950 --> 00:05:38,680
to calibrate self calibrate we don't
need to have the sensors in an exact

240
00:05:38,680 --> 00:05:38,690
need to have the sensors in an exact
 

241
00:05:38,690 --> 00:05:40,750
need to have the sensors in an exact
same position every time that's a very

242
00:05:40,750 --> 00:05:40,760
same position every time that's a very
 

243
00:05:40,760 --> 00:05:42,540
same position every time that's a very
nice feature the robustness of the

244
00:05:42,540 --> 00:05:42,550
nice feature the robustness of the
 

245
00:05:42,550 --> 00:05:45,700
nice feature the robustness of the
system is then generalizable across

246
00:05:45,700 --> 00:05:45,710
system is then generalizable across
 

247
00:05:45,710 --> 00:05:49,630
system is then generalizable across
multiple multiple vehicles and multiple

248
00:05:49,630 --> 00:05:49,640
multiple multiple vehicles and multiple
 

249
00:05:49,640 --> 00:05:53,500
multiple multiple vehicles and multiple
scenarios and one of the key things that

250
00:05:53,500 --> 00:05:53,510
scenarios and one of the key things that
 

251
00:05:53,510 --> 00:05:55,540
scenarios and one of the key things that
comes up time again time and time again

252
00:05:55,540 --> 00:05:55,550
comes up time again time and time again
 

253
00:05:55,550 --> 00:05:58,330
comes up time again time and time again
and we'll mention today is a lot of the

254
00:05:58,330 --> 00:05:58,340
and we'll mention today is a lot of the
 

255
00:05:58,340 --> 00:06:00,310
and we'll mention today is a lot of the
algorithms developed in deep learning

256
00:06:00,310 --> 00:06:00,320
algorithms developed in deep learning
 

257
00:06:00,320 --> 00:06:01,930
algorithms developed in deep learning
are really focused for computer vision

258
00:06:01,930 --> 00:06:01,940
are really focused for computer vision
 

259
00:06:01,940 --> 00:06:04,300
are really focused for computer vision
are focused on single images now the

260
00:06:04,300 --> 00:06:04,310
are focused on single images now the
 

261
00:06:04,310 --> 00:06:07,930
are focused on single images now the
real world is happens in both space and

262
00:06:07,930 --> 00:06:07,940
real world is happens in both space and
 

263
00:06:07,940 --> 00:06:09,430
real world is happens in both space and
time and we have to have algorithms that

264
00:06:09,430 --> 00:06:09,440
time and we have to have algorithms that
 

265
00:06:09,440 --> 00:06:12,250
time and we have to have algorithms that
both capture the visual characteristics

266
00:06:12,250 --> 00:06:12,260
both capture the visual characteristics
 

267
00:06:12,260 --> 00:06:14,130
both capture the visual characteristics
but also look at the sequence of images

268
00:06:14,130 --> 00:06:14,140
but also look at the sequence of images
 

269
00:06:14,140 --> 00:06:15,670
but also look at the sequence of images
sequence of those digital

270
00:06:15,670 --> 00:06:15,680
sequence of those digital
 

271
00:06:15,680 --> 00:06:17,320
sequence of those digital
characteristics that form the temporal

272
00:06:17,320 --> 00:06:17,330
characteristics that form the temporal
 

273
00:06:17,330 --> 00:06:19,630
characteristics that form the temporal
dynamics the physics of this world so

274
00:06:19,630 --> 00:06:19,640
dynamics the physics of this world so
 

275
00:06:19,640 --> 00:06:21,850
dynamics the physics of this world so
it's nice when those algorithms are able

276
00:06:21,850 --> 00:06:21,860
it's nice when those algorithms are able
 

277
00:06:21,860 --> 00:06:25,680
it's nice when those algorithms are able
to capture the physics of the scene

278
00:06:25,680 --> 00:06:25,690
to capture the physics of the scene
 

279
00:06:25,690 --> 00:06:29,380
to capture the physics of the scene
the big takeaway I would like if you

280
00:06:29,380 --> 00:06:29,390
the big takeaway I would like if you
 

281
00:06:29,390 --> 00:06:31,790
the big takeaway I would like if you
leave with anything today

282
00:06:31,790 --> 00:06:31,800
leave with anything today
 

283
00:06:31,800 --> 00:06:34,640
leave with anything today
unfortunately it's that the painful

284
00:06:34,640 --> 00:06:34,650
unfortunately it's that the painful
 

285
00:06:34,650 --> 00:06:37,710
unfortunately it's that the painful
boring stuff of collecting data of

286
00:06:37,710 --> 00:06:37,720
boring stuff of collecting data of
 

287
00:06:37,720 --> 00:06:40,260
boring stuff of collecting data of
cleaning that data of annotating that

288
00:06:40,260 --> 00:06:40,270
cleaning that data of annotating that
 

289
00:06:40,270 --> 00:06:43,170
cleaning that data of annotating that
data in order to create successful

290
00:06:43,170 --> 00:06:43,180
data in order to create successful
 

291
00:06:43,180 --> 00:06:45,120
data in order to create successful
systems is much more important than good

292
00:06:45,120 --> 00:06:45,130
systems is much more important than good
 

293
00:06:45,130 --> 00:06:47,700
systems is much more important than good
algorithms or great algorithms it's

294
00:06:47,700 --> 00:06:47,710
algorithms or great algorithms it's
 

295
00:06:47,710 --> 00:06:49,470
algorithms or great algorithms it's
important to have good algorithms as

296
00:06:49,470 --> 00:06:49,480
important to have good algorithms as
 

297
00:06:49,480 --> 00:06:52,020
important to have good algorithms as
long as you have neural networks that

298
00:06:52,020 --> 00:06:52,030
long as you have neural networks that
 

299
00:06:52,030 --> 00:06:55,470
long as you have neural networks that
learn from that data okay so today I'll

300
00:06:55,470 --> 00:06:55,480
learn from that data okay so today I'll
 

301
00:06:55,480 --> 00:06:58,440
learn from that data okay so today I'll
talk I like to talk about human

302
00:06:58,440 --> 00:06:58,450
talk I like to talk about human
 

303
00:06:58,450 --> 00:07:03,480
talk I like to talk about human
imperfections and the various detection

304
00:07:03,480 --> 00:07:03,490
imperfections and the various detection
 

305
00:07:03,490 --> 00:07:07,260
imperfections and the various detection
problems the pedestrian body pose glance

306
00:07:07,260 --> 00:07:07,270
problems the pedestrian body pose glance
 

307
00:07:07,270 --> 00:07:10,560
problems the pedestrian body pose glance
and motion cognitive load estimation

308
00:07:10,560 --> 00:07:10,570
and motion cognitive load estimation
 

309
00:07:10,570 --> 00:07:14,490
and motion cognitive load estimation
that we can use to help those humans as

310
00:07:14,490 --> 00:07:14,500
that we can use to help those humans as
 

311
00:07:14,500 --> 00:07:18,320
that we can use to help those humans as
they operate in the driving context and

312
00:07:18,320 --> 00:07:18,330
they operate in the driving context and
 

313
00:07:18,330 --> 00:07:25,710
they operate in the driving context and
finally try to continue with the idea of

314
00:07:25,710 --> 00:07:25,720
finally try to continue with the idea of
 

315
00:07:25,720 --> 00:07:27,960
finally try to continue with the idea of
the vision that fully autonomous

316
00:07:27,960 --> 00:07:27,970
the vision that fully autonomous
 

317
00:07:27,970 --> 00:07:29,280
the vision that fully autonomous
vehicles as some of our guest speakers

318
00:07:29,280 --> 00:07:29,290
vehicles as some of our guest speakers
 

319
00:07:29,290 --> 00:07:31,230
vehicles as some of our guest speakers
have spoke about and sterling anis will

320
00:07:31,230 --> 00:07:31,240
have spoke about and sterling anis will
 

321
00:07:31,240 --> 00:07:33,930
have spoke about and sterling anis will
speak about tomorrow is really far away

322
00:07:33,930 --> 00:07:33,940
speak about tomorrow is really far away
 

323
00:07:33,940 --> 00:07:36,720
speak about tomorrow is really far away
that the humans will be an integral part

324
00:07:36,720 --> 00:07:36,730
that the humans will be an integral part
 

325
00:07:36,730 --> 00:07:39,900
that the humans will be an integral part
of the operating cooperating with the AI

326
00:07:39,900 --> 00:07:39,910
of the operating cooperating with the AI
 

327
00:07:39,910 --> 00:07:43,830
of the operating cooperating with the AI
systems and I will continue on on that

328
00:07:43,830 --> 00:07:43,840
systems and I will continue on on that
 

329
00:07:43,840 --> 00:07:46,050
systems and I will continue on on that
line of thought to try to motivate why

330
00:07:46,050 --> 00:07:46,060
line of thought to try to motivate why
 

331
00:07:46,060 --> 00:07:49,500
line of thought to try to motivate why
we need to continuously approach the

332
00:07:49,500 --> 00:07:49,510
we need to continuously approach the
 

333
00:07:49,510 --> 00:07:52,400
we need to continuously approach the
autonomous vehicle the self-driving car

334
00:07:52,400 --> 00:07:52,410
autonomous vehicle the self-driving car
 

335
00:07:52,410 --> 00:08:00,660
autonomous vehicle the self-driving car
paradigm in the human centered way okay

336
00:08:00,660 --> 00:08:00,670
paradigm in the human centered way okay
 

337
00:08:00,670 --> 00:08:04,140
paradigm in the human centered way okay
first before we talk about human

338
00:08:04,140 --> 00:08:04,150
first before we talk about human
 

339
00:08:04,150 --> 00:08:06,120
first before we talk about human
imperfections let's just pause and

340
00:08:06,120 --> 00:08:06,130
imperfections let's just pause and
 

341
00:08:06,130 --> 00:08:08,780
imperfections let's just pause and
acknowledge that humans are amazing

342
00:08:08,780 --> 00:08:08,790
acknowledge that humans are amazing
 

343
00:08:08,790 --> 00:08:12,000
acknowledge that humans are amazing
we're actually really good at a lot of

344
00:08:12,000 --> 00:08:12,010
we're actually really good at a lot of
 

345
00:08:12,010 --> 00:08:16,200
we're actually really good at a lot of
things that's sometimes sort of fun to

346
00:08:16,200 --> 00:08:16,210
things that's sometimes sort of fun to
 

347
00:08:16,210 --> 00:08:18,330
things that's sometimes sort of fun to
talk about how much called terrible of

348
00:08:18,330 --> 00:08:18,340
talk about how much called terrible of
 

349
00:08:18,340 --> 00:08:20,130
talk about how much called terrible of
drivers who are how distracted we are

350
00:08:20,130 --> 00:08:20,140
drivers who are how distracted we are
 

351
00:08:20,140 --> 00:08:22,530
drivers who are how distracted we are
how irrational we are but we're actually

352
00:08:22,530 --> 00:08:22,540
how irrational we are but we're actually
 

353
00:08:22,540 --> 00:08:25,740
how irrational we are but we're actually
really damn good at driving here's a

354
00:08:25,740 --> 00:08:25,750
really damn good at driving here's a
 

355
00:08:25,750 --> 00:08:28,980
really damn good at driving here's a
video of stadia our soccer player messi

356
00:08:28,980 --> 00:08:28,990
video of stadia our soccer player messi
 

357
00:08:28,990 --> 00:08:30,750
video of stadia our soccer player messi
the best soccer player in the world

358
00:08:30,750 --> 00:08:30,760
the best soccer player in the world
 

359
00:08:30,760 --> 00:08:34,980
the best soccer player in the world
obviously and the state-of-the-art robot

360
00:08:34,980 --> 00:08:34,990
obviously and the state-of-the-art robot
 

361
00:08:34,990 --> 00:08:37,350
obviously and the state-of-the-art robot
on the right same thing

362
00:08:37,350 --> 00:08:37,360
on the right same thing
 

363
00:08:37,360 --> 00:08:39,630
on the right same thing
well there's it's not playing but I

364
00:08:39,630 --> 00:08:39,640
well there's it's not playing but I
 

365
00:08:39,640 --> 00:08:43,590
well there's it's not playing but I
assure you the American Ninja Warrior

366
00:08:43,590 --> 00:08:43,600

 

367
00:08:43,600 --> 00:08:49,480

Casey is is uh is far superior to the

368
00:08:49,480 --> 00:08:49,490
Casey is is uh is far superior to the
 

369
00:08:49,490 --> 00:08:52,510
Casey is is uh is far superior to the
DARPA humanoid robotics systems shown on

370
00:08:52,510 --> 00:08:52,520
DARPA humanoid robotics systems shown on
 

371
00:08:52,520 --> 00:09:00,460
DARPA humanoid robotics systems shown on
the right okay so continuing and the

372
00:09:00,460 --> 00:09:00,470
the right okay so continuing and the
 

373
00:09:00,470 --> 00:09:02,830
the right okay so continuing and the
line of thought to challenge to

374
00:09:02,830 --> 00:09:02,840
line of thought to challenge to
 

375
00:09:02,840 --> 00:09:05,110
line of thought to challenge to
challenge us here that humans are

376
00:09:05,110 --> 00:09:05,120
challenge us here that humans are
 

377
00:09:05,120 --> 00:09:09,220
challenge us here that humans are
amazing is you know there's record high

378
00:09:09,220 --> 00:09:09,230
amazing is you know there's record high
 

379
00:09:09,230 --> 00:09:12,640
amazing is you know there's record high
in 2016 in the United States there was

380
00:09:12,640 --> 00:09:12,650
in 2016 in the United States there was
 

381
00:09:12,650 --> 00:09:15,970
in 2016 in the United States there was
over forty thousand since uh many years

382
00:09:15,970 --> 00:09:15,980
over forty thousand since uh many years
 

383
00:09:15,980 --> 00:09:18,490
over forty thousand since uh many years
it's across the forty thousand

384
00:09:18,490 --> 00:09:18,500
it's across the forty thousand
 

385
00:09:18,500 --> 00:09:20,770
it's across the forty thousand
fatalities mark more than forty thousand

386
00:09:20,770 --> 00:09:20,780
fatalities mark more than forty thousand
 

387
00:09:20,780 --> 00:09:22,450
fatalities mark more than forty thousand
people died in car crashes in the United

388
00:09:22,450 --> 00:09:22,460
people died in car crashes in the United
 

389
00:09:22,460 --> 00:09:25,780
people died in car crashes in the United
States but that's in three point two

390
00:09:25,780 --> 00:09:25,790
States but that's in three point two
 

391
00:09:25,790 --> 00:09:28,180
States but that's in three point two
trillion miles traveled so that's one

392
00:09:28,180 --> 00:09:28,190
trillion miles traveled so that's one
 

393
00:09:28,190 --> 00:09:31,950
trillion miles traveled so that's one
fatality per eighty million miles that's

394
00:09:31,950 --> 00:09:31,960
fatality per eighty million miles that's
 

395
00:09:31,960 --> 00:09:38,410
fatality per eighty million miles that's
one in 625 chance of dying in a car

396
00:09:38,410 --> 00:09:38,420
one in 625 chance of dying in a car
 

397
00:09:38,420 --> 00:09:42,430
one in 625 chance of dying in a car
crash in your lifetime interesting side

398
00:09:42,430 --> 00:09:42,440
crash in your lifetime interesting side
 

399
00:09:42,440 --> 00:09:45,010
crash in your lifetime interesting side
fact for anyone in the United States

400
00:09:45,010 --> 00:09:45,020
fact for anyone in the United States
 

401
00:09:45,020 --> 00:09:48,250
fact for anyone in the United States
folks who live in Massachusetts are the

402
00:09:48,250 --> 00:09:48,260
folks who live in Massachusetts are the
 

403
00:09:48,260 --> 00:09:51,270
folks who live in Massachusetts are the
least likely to die in a car crash

404
00:09:51,270 --> 00:09:51,280
least likely to die in a car crash
 

405
00:09:51,280 --> 00:09:56,710
least likely to die in a car crash
Montana is the most likely so for every

406
00:09:56,710 --> 00:09:56,720
Montana is the most likely so for every
 

407
00:09:56,720 --> 00:10:00,130
Montana is the most likely so for every
one that thinks of Boston drives is

408
00:10:00,130 --> 00:10:00,140
one that thinks of Boston drives is
 

409
00:10:00,140 --> 00:10:02,890
one that thinks of Boston drives is
terrible maybe that adds some

410
00:10:02,890 --> 00:10:02,900
terrible maybe that adds some
 

411
00:10:02,900 --> 00:10:05,200
terrible maybe that adds some
perspective here's a visualization of

412
00:10:05,200 --> 00:10:05,210
perspective here's a visualization of
 

413
00:10:05,210 --> 00:10:07,990
perspective here's a visualization of
ways data across a period of a day

414
00:10:07,990 --> 00:10:08,000
ways data across a period of a day
 

415
00:10:08,000 --> 00:10:10,330
ways data across a period of a day
showing you the rich blood of the city

416
00:10:10,330 --> 00:10:10,340
showing you the rich blood of the city
 

417
00:10:10,340 --> 00:10:12,640
showing you the rich blood of the city
that the the traffic flow of the city

418
00:10:12,640 --> 00:10:12,650
that the the traffic flow of the city
 

419
00:10:12,650 --> 00:10:15,610
that the the traffic flow of the city
the people getting from A to B and a

420
00:10:15,610 --> 00:10:15,620
the people getting from A to B and a
 

421
00:10:15,620 --> 00:10:19,870
the people getting from A to B and a
mass scale and doing it surviving doing

422
00:10:19,870 --> 00:10:19,880
mass scale and doing it surviving doing
 

423
00:10:19,880 --> 00:10:25,330
mass scale and doing it surviving doing
it okay humans are amazing but they're

424
00:10:25,330 --> 00:10:25,340
it okay humans are amazing but they're
 

425
00:10:25,340 --> 00:10:29,200
it okay humans are amazing but they're
also flawed texting sources of

426
00:10:29,200 --> 00:10:29,210
also flawed texting sources of
 

427
00:10:29,210 --> 00:10:31,330
also flawed texting sources of
distraction with a smartphone the eating

428
00:10:31,330 --> 00:10:31,340
distraction with a smartphone the eating
 

429
00:10:31,340 --> 00:10:33,400
distraction with a smartphone the eating
the secondary tasks of talking to other

430
00:10:33,400 --> 00:10:33,410
the secondary tasks of talking to other
 

431
00:10:33,410 --> 00:10:36,730
the secondary tasks of talking to other
passengers grooming reading using

432
00:10:36,730 --> 00:10:36,740
passengers grooming reading using
 

433
00:10:36,740 --> 00:10:39,880
passengers grooming reading using
navigation system yes sometimes watching

434
00:10:39,880 --> 00:10:39,890
navigation system yes sometimes watching
 

435
00:10:39,890 --> 00:10:43,120
navigation system yes sometimes watching
video and manually adjusting or

436
00:10:43,120 --> 00:10:43,130
video and manually adjusting or
 

437
00:10:43,130 --> 00:10:47,050
video and manually adjusting or
adjusting the radio and 3,000 people

438
00:10:47,050 --> 00:10:47,060
adjusting the radio and 3,000 people
 

439
00:10:47,060 --> 00:10:52,420
adjusting the radio and 3,000 people
were killed and 400,000 were injured in

440
00:10:52,420 --> 00:10:52,430
were killed and 400,000 were injured in
 

441
00:10:52,430 --> 00:10:54,640
were killed and 400,000 were injured in
motor vehicle crashes vaulted involving

442
00:10:54,640 --> 00:10:54,650
motor vehicle crashes vaulted involving
 

443
00:10:54,650 --> 00:10:55,920
motor vehicle crashes vaulted involving
distraction

444
00:10:55,920 --> 00:10:55,930
distraction
 

445
00:10:55,930 --> 00:11:00,300
distraction
in 2014 distraction is a it's a very

446
00:11:00,300 --> 00:11:00,310
in 2014 distraction is a it's a very
 

447
00:11:00,310 --> 00:11:05,040
in 2014 distraction is a it's a very
serious issue for safety texting every

448
00:11:05,040 --> 00:11:05,050
serious issue for safety texting every
 

449
00:11:05,050 --> 00:11:06,600
serious issue for safety texting every
day more and more people text

450
00:11:06,600 --> 00:11:06,610
day more and more people text
 

451
00:11:06,610 --> 00:11:08,100
day more and more people text
smartphones are proliferating our

452
00:11:08,100 --> 00:11:08,110
smartphones are proliferating our
 

453
00:11:08,110 --> 00:11:11,700
smartphones are proliferating our
society 170 billion text messages are

454
00:11:11,700 --> 00:11:11,710
society 170 billion text messages are
 

455
00:11:11,710 --> 00:11:13,380
society 170 billion text messages are
sent in the United States every month

456
00:11:13,380 --> 00:11:13,390
sent in the United States every month
 

457
00:11:13,390 --> 00:11:16,470
sent in the United States every month
that's in 2014 you can only imagine what

458
00:11:16,470 --> 00:11:16,480
that's in 2014 you can only imagine what
 

459
00:11:16,480 --> 00:11:17,420
that's in 2014 you can only imagine what
it is today

460
00:11:17,420 --> 00:11:17,430
it is today
 

461
00:11:17,430 --> 00:11:20,910
it is today
eyes off road for five seconds is the

462
00:11:20,910 --> 00:11:20,920
eyes off road for five seconds is the
 

463
00:11:20,920 --> 00:11:22,320
eyes off road for five seconds is the
average time your eyes off the road

464
00:11:22,320 --> 00:11:22,330
average time your eyes off the road
 

465
00:11:22,330 --> 00:11:25,980
average time your eyes off the road
while texting five seconds if you're

466
00:11:25,980 --> 00:11:25,990
while texting five seconds if you're
 

467
00:11:25,990 --> 00:11:28,230
while texting five seconds if you're
traveling 55 miles an hour in that five

468
00:11:28,230 --> 00:11:28,240
traveling 55 miles an hour in that five
 

469
00:11:28,240 --> 00:11:30,360
traveling 55 miles an hour in that five
seconds that's enough time to cover the

470
00:11:30,360 --> 00:11:30,370
seconds that's enough time to cover the
 

471
00:11:30,370 --> 00:11:32,120
seconds that's enough time to cover the
length of a football field

472
00:11:32,120 --> 00:11:32,130
length of a football field
 

473
00:11:32,130 --> 00:11:34,710
length of a football field
so you're blindfolded you're not looking

474
00:11:34,710 --> 00:11:34,720
so you're blindfolded you're not looking
 

475
00:11:34,720 --> 00:11:36,930
so you're blindfolded you're not looking
at the road in five seconds the average

476
00:11:36,930 --> 00:11:36,940
at the road in five seconds the average
 

477
00:11:36,940 --> 00:11:39,000
at the road in five seconds the average
time of texting you're covering the

478
00:11:39,000 --> 00:11:39,010
time of texting you're covering the
 

479
00:11:39,010 --> 00:11:41,790
time of texting you're covering the
entire football field eight so many

480
00:11:41,790 --> 00:11:41,800
entire football field eight so many
 

481
00:11:41,800 --> 00:11:44,310
entire football field eight so many
things can happen in that moment of time

482
00:11:44,310 --> 00:11:44,320
things can happen in that moment of time
 

483
00:11:44,320 --> 00:11:51,060
things can happen in that moment of time
that's distraction drunk driving 31% of

484
00:11:51,060 --> 00:11:51,070
that's distraction drunk driving 31% of
 

485
00:11:51,070 --> 00:11:52,890
that's distraction drunk driving 31% of
traffic fatalities involve a drunk

486
00:11:52,890 --> 00:11:52,900
traffic fatalities involve a drunk
 

487
00:11:52,900 --> 00:11:56,400
traffic fatalities involve a drunk
driver drunk driving 23% of nighttime

488
00:11:56,400 --> 00:11:56,410
driver drunk driving 23% of nighttime
 

489
00:11:56,410 --> 00:11:58,650
driver drunk driving 23% of nighttime
drivers tested positive for a legal

490
00:11:58,650 --> 00:11:58,660
drivers tested positive for a legal
 

491
00:11:58,660 --> 00:11:59,840
drivers tested positive for a legal
prescription or over-the-counter

492
00:11:59,840 --> 00:11:59,850
prescription or over-the-counter
 

493
00:11:59,850 --> 00:12:03,300
prescription or over-the-counter
medication distracted driving as I said

494
00:12:03,300 --> 00:12:03,310
medication distracted driving as I said
 

495
00:12:03,310 --> 00:12:05,880
medication distracted driving as I said
is a huge safety risk drowsy driving

496
00:12:05,880 --> 00:12:05,890
is a huge safety risk drowsy driving
 

497
00:12:05,890 --> 00:12:08,579
is a huge safety risk drowsy driving
people driving tired nearly three

498
00:12:08,579 --> 00:12:08,589
people driving tired nearly three
 

499
00:12:08,589 --> 00:12:10,380
people driving tired nearly three
percent of all traffic fatalities

500
00:12:10,380 --> 00:12:10,390
percent of all traffic fatalities
 

501
00:12:10,390 --> 00:12:15,260
percent of all traffic fatalities
involve a drowsy driver if you are

502
00:12:15,260 --> 00:12:15,270
involve a drowsy driver if you are
 

503
00:12:15,270 --> 00:12:18,540
involve a drowsy driver if you are
uncomfortable with videos that involve

504
00:12:18,540 --> 00:12:18,550
uncomfortable with videos that involve
 

505
00:12:18,550 --> 00:12:21,360
uncomfortable with videos that involve
risk I urge you to look away these are

506
00:12:21,360 --> 00:12:21,370
risk I urge you to look away these are
 

507
00:12:21,370 --> 00:12:23,329
risk I urge you to look away these are
videos collected by Triple A of

508
00:12:23,329 --> 00:12:23,339
videos collected by Triple A of
 

509
00:12:23,339 --> 00:12:25,350
videos collected by Triple A of
teenagers a very large-scale

510
00:12:25,350 --> 00:12:25,360
teenagers a very large-scale
 

511
00:12:25,360 --> 00:12:27,510
teenagers a very large-scale
naturalistic driving data set and it's

512
00:12:27,510 --> 00:12:27,520
naturalistic driving data set and it's
 

513
00:12:27,520 --> 00:12:29,280
naturalistic driving data set and it's
capturing clips of teenagers being

514
00:12:29,280 --> 00:12:29,290
capturing clips of teenagers being
 

515
00:12:29,290 --> 00:12:35,110
capturing clips of teenagers being
distracted on their smartphone

516
00:12:35,110 --> 00:12:35,120

 

517
00:12:35,120 --> 00:13:24,160

[Music]

518
00:13:24,160 --> 00:13:24,170

 

519
00:13:24,170 --> 00:13:27,080

once you take it in the problem we're

520
00:13:27,080 --> 00:13:27,090
once you take it in the problem we're
 

521
00:13:27,090 --> 00:13:39,530
once you take it in the problem we're
against

522
00:13:39,530 --> 00:13:39,540

 

523
00:13:39,540 --> 00:13:41,380

so in the cutting

524
00:13:41,380 --> 00:13:41,390
so in the cutting
 

525
00:13:41,390 --> 00:13:44,740
so in the cutting
context of human imperfections we have

526
00:13:44,740 --> 00:13:44,750
context of human imperfections we have
 

527
00:13:44,750 --> 00:13:47,440
context of human imperfections we have
to ask ourselves is the human centered

528
00:13:47,440 --> 00:13:47,450
to ask ourselves is the human centered
 

529
00:13:47,450 --> 00:13:49,660
to ask ourselves is the human centered
approach to autonomy in systems

530
00:13:49,660 --> 00:13:49,670
approach to autonomy in systems
 

531
00:13:49,670 --> 00:13:51,850
approach to autonomy in systems
autonomous vehicles that are using

532
00:13:51,850 --> 00:13:51,860
autonomous vehicles that are using
 

533
00:13:51,860 --> 00:13:53,680
autonomous vehicles that are using
artificial intelligence to aid the

534
00:13:53,680 --> 00:13:53,690
artificial intelligence to aid the
 

535
00:13:53,690 --> 00:13:56,320
artificial intelligence to aid the
driving task do we want to go as I

536
00:13:56,320 --> 00:13:56,330
driving task do we want to go as I
 

537
00:13:56,330 --> 00:13:58,450
driving task do we want to go as I
mentioned a couple of lectures ago the

538
00:13:58,450 --> 00:13:58,460
mentioned a couple of lectures ago the
 

539
00:13:58,460 --> 00:14:01,120
mentioned a couple of lectures ago the
human centered way or the full autonomy

540
00:14:01,120 --> 00:14:01,130
human centered way or the full autonomy
 

541
00:14:01,130 --> 00:14:03,430
human centered way or the full autonomy
way the tempting path is towards full

542
00:14:03,430 --> 00:14:03,440
way the tempting path is towards full
 

543
00:14:03,440 --> 00:14:05,950
way the tempting path is towards full
autonomy where we removed this imperfect

544
00:14:05,950 --> 00:14:05,960
autonomy where we removed this imperfect
 

545
00:14:05,960 --> 00:14:08,410
autonomy where we removed this imperfect
flawed human from the picture altogether

546
00:14:08,410 --> 00:14:08,420
flawed human from the picture altogether
 

547
00:14:08,420 --> 00:14:11,290
flawed human from the picture altogether
and focus on the robotics problem of

548
00:14:11,290 --> 00:14:11,300
and focus on the robotics problem of
 

549
00:14:11,300 --> 00:14:13,740
and focus on the robotics problem of
perception and control and planning and

550
00:14:13,740 --> 00:14:13,750
perception and control and planning and
 

551
00:14:13,750 --> 00:14:18,490
perception and control and planning and
driving policy or do we work together

552
00:14:18,490 --> 00:14:18,500
driving policy or do we work together
 

553
00:14:18,500 --> 00:14:21,550
driving policy or do we work together
human and machine to improve the safety

554
00:14:21,550 --> 00:14:21,560
human and machine to improve the safety
 

555
00:14:21,560 --> 00:14:24,670
human and machine to improve the safety
to alleviate distraction to bring drive

556
00:14:24,670 --> 00:14:24,680
to alleviate distraction to bring drive
 

557
00:14:24,680 --> 00:14:26,140
to alleviate distraction to bring drive
our attention back to the road and use

558
00:14:26,140 --> 00:14:26,150
our attention back to the road and use
 

559
00:14:26,150 --> 00:14:28,330
our attention back to the road and use
artificial intelligence to increase

560
00:14:28,330 --> 00:14:28,340
artificial intelligence to increase
 

561
00:14:28,340 --> 00:14:31,180
artificial intelligence to increase
safety through collaboration human robot

562
00:14:31,180 --> 00:14:31,190
safety through collaboration human robot
 

563
00:14:31,190 --> 00:14:33,940
safety through collaboration human robot
interaction versus removing the human

564
00:14:33,940 --> 00:14:33,950
interaction versus removing the human
 

565
00:14:33,950 --> 00:14:38,260
interaction versus removing the human
completely from the picture as I've

566
00:14:38,260 --> 00:14:38,270
completely from the picture as I've
 

567
00:14:38,270 --> 00:14:42,490
completely from the picture as I've
mentioned as as sterling will certainly

568
00:14:42,490 --> 00:14:42,500
mentioned as as sterling will certainly
 

569
00:14:42,500 --> 00:14:45,550
mentioned as as sterling will certainly
talk about tomorrow and and rightfully

570
00:14:45,550 --> 00:14:45,560
talk about tomorrow and and rightfully
 

571
00:14:45,560 --> 00:14:50,320
talk about tomorrow and and rightfully
so and yesterday or on Tuesday Emilio

572
00:14:50,320 --> 00:14:50,330
so and yesterday or on Tuesday Emilio
 

573
00:14:50,330 --> 00:14:53,220
so and yesterday or on Tuesday Emilio
has talked about the elf four-way is

574
00:14:53,220 --> 00:14:53,230
has talked about the elf four-way is
 

575
00:14:53,230 --> 00:14:56,260
has talked about the elf four-way is
grounded in literature it's grounded in

576
00:14:56,260 --> 00:14:56,270
grounded in literature it's grounded in
 

577
00:14:56,270 --> 00:15:00,000
grounded in literature it's grounded in
common sense since in some sense it's

578
00:15:00,000 --> 00:15:00,010
common sense since in some sense it's
 

579
00:15:00,010 --> 00:15:03,150
common sense since in some sense it's
you can count on the fact that humans

580
00:15:03,150 --> 00:15:03,160
you can count on the fact that humans
 

581
00:15:03,160 --> 00:15:06,850
you can count on the fact that humans
the the natural flaws of human beings to

582
00:15:06,850 --> 00:15:06,860
the the natural flaws of human beings to
 

583
00:15:06,860 --> 00:15:10,090
the the natural flaws of human beings to
over trust to misbehave to be irrational

584
00:15:10,090 --> 00:15:10,100
over trust to misbehave to be irrational
 

585
00:15:10,100 --> 00:15:12,490
over trust to misbehave to be irrational
about their risk estimates will result

586
00:15:12,490 --> 00:15:12,500
about their risk estimates will result
 

587
00:15:12,500 --> 00:15:15,640
about their risk estimates will result
in improper use of the technology and

588
00:15:15,640 --> 00:15:15,650
in improper use of the technology and
 

589
00:15:15,650 --> 00:15:19,240
in improper use of the technology and
that leads to what I've showed before

590
00:15:19,240 --> 00:15:19,250
that leads to what I've showed before
 

591
00:15:19,250 --> 00:15:21,580
that leads to what I've showed before
the public perception of what drivers do

592
00:15:21,580 --> 00:15:21,590
the public perception of what drivers do
 

593
00:15:21,590 --> 00:15:23,500
the public perception of what drivers do
and semi autonomous vehicles they begin

594
00:15:23,500 --> 00:15:23,510
and semi autonomous vehicles they begin
 

595
00:15:23,510 --> 00:15:25,570
and semi autonomous vehicles they begin
to over trust the moment the system

596
00:15:25,570 --> 00:15:25,580
to over trust the moment the system
 

597
00:15:25,580 --> 00:15:27,910
to over trust the moment the system
works well they begin to over trust they

598
00:15:27,910 --> 00:15:27,920
works well they begin to over trust they
 

599
00:15:27,920 --> 00:15:30,220
works well they begin to over trust they
begin to do stuff they're not supposed

600
00:15:30,220 --> 00:15:30,230
begin to do stuff they're not supposed
 

601
00:15:30,230 --> 00:15:32,230
begin to do stuff they're not supposed
to be doing in the car taking it for

602
00:15:32,230 --> 00:15:32,240
to be doing in the car taking it for
 

603
00:15:32,240 --> 00:15:35,110
to be doing in the car taking it for
granted a recent video that somebody

604
00:15:35,110 --> 00:15:35,120
granted a recent video that somebody
 

605
00:15:35,120 --> 00:15:38,440
granted a recent video that somebody
posted this is a common sort of more

606
00:15:38,440 --> 00:15:38,450
posted this is a common sort of more
 

607
00:15:38,450 --> 00:15:41,250
posted this is a common sort of more
practical concern that people have is

608
00:15:41,250 --> 00:15:41,260
practical concern that people have is
 

609
00:15:41,260 --> 00:15:45,610
practical concern that people have is
while the traditional ways to ensure the

610
00:15:45,610 --> 00:15:45,620
while the traditional ways to ensure the
 

611
00:15:45,620 --> 00:15:48,550
while the traditional ways to ensure the
physical engagement of the driver is by

612
00:15:48,550 --> 00:15:48,560
physical engagement of the driver is by
 

613
00:15:48,560 --> 00:15:50,230
physical engagement of the driver is by
saying they should touch the wheel the

614
00:15:50,230 --> 00:15:50,240
saying they should touch the wheel the
 

615
00:15:50,240 --> 00:15:51,640
saying they should touch the wheel the
the steering wheel every once in a while

616
00:15:51,640 --> 00:15:51,650
the steering wheel every once in a while
 

617
00:15:51,650 --> 00:15:54,500
the steering wheel every once in a while
and of course there's ways to buy

618
00:15:54,500 --> 00:15:54,510
and of course there's ways to buy
 

619
00:15:54,510 --> 00:15:56,960
and of course there's ways to buy
the need to touch the steering wheel

620
00:15:56,960 --> 00:15:56,970
the need to touch the steering wheel
 

621
00:15:56,970 --> 00:16:00,350
the need to touch the steering wheel
some people hang objects like I can off

622
00:16:00,350 --> 00:16:00,360
some people hang objects like I can off
 

623
00:16:00,360 --> 00:16:02,090
some people hang objects like I can off
of the steering wheel in this case

624
00:16:02,090 --> 00:16:02,100
of the steering wheel in this case
 

625
00:16:02,100 --> 00:16:06,319
of the steering wheel in this case
brilliantly I have to say they shove an

626
00:16:06,319 --> 00:16:06,329
brilliantly I have to say they shove an
 

627
00:16:06,329 --> 00:16:11,120
brilliantly I have to say they shove an
orange into the into the wheel to make

628
00:16:11,120 --> 00:16:11,130
orange into the into the wheel to make
 

629
00:16:11,130 --> 00:16:13,220
orange into the into the wheel to make
the touch sensor fire and therefore be

630
00:16:13,220 --> 00:16:13,230
the touch sensor fire and therefore be
 

631
00:16:13,230 --> 00:16:15,850
the touch sensor fire and therefore be
able to take their hands off the

632
00:16:15,850 --> 00:16:15,860
able to take their hands off the
 

633
00:16:15,860 --> 00:16:19,060
able to take their hands off the
autopilot and that that kind of idea

634
00:16:19,060 --> 00:16:19,070
autopilot and that that kind of idea
 

635
00:16:19,070 --> 00:16:21,560
autopilot and that that kind of idea
makes us believe that there's no way

636
00:16:21,560 --> 00:16:21,570
makes us believe that there's no way
 

637
00:16:21,570 --> 00:16:23,990
makes us believe that there's no way
that you know humans will find a way to

638
00:16:23,990 --> 00:16:24,000
that you know humans will find a way to
 

639
00:16:24,000 --> 00:16:27,170
that you know humans will find a way to
misuse this technology however I believe

640
00:16:27,170 --> 00:16:27,180
misuse this technology however I believe
 

641
00:16:27,180 --> 00:16:31,220
misuse this technology however I believe
that that's not giving the technology

642
00:16:31,220 --> 00:16:31,230
that that's not giving the technology
 

643
00:16:31,230 --> 00:16:33,560
that that's not giving the technology
enough credit artificial intelligence

644
00:16:33,560 --> 00:16:33,570
enough credit artificial intelligence
 

645
00:16:33,570 --> 00:16:35,750
enough credit artificial intelligence
systems if are they're able to perceive

646
00:16:35,750 --> 00:16:35,760
systems if are they're able to perceive
 

647
00:16:35,760 --> 00:16:38,420
systems if are they're able to perceive
the human being are also able to work

648
00:16:38,420 --> 00:16:38,430
the human being are also able to work
 

649
00:16:38,430 --> 00:16:40,310
the human being are also able to work
with the human being and that's what I'd

650
00:16:40,310 --> 00:16:40,320
with the human being and that's what I'd
 

651
00:16:40,320 --> 00:16:44,150
with the human being and that's what I'd
like to talk about today teaching cars

652
00:16:44,150 --> 00:16:44,160
like to talk about today teaching cars
 

653
00:16:44,160 --> 00:16:47,990
like to talk about today teaching cars
to perceive the human being and it all

654
00:16:47,990 --> 00:16:48,000
to perceive the human being and it all
 

655
00:16:48,000 --> 00:16:51,470
to perceive the human being and it all
starts with data it's all about data as

656
00:16:51,470 --> 00:16:51,480
starts with data it's all about data as
 

657
00:16:51,480 --> 00:16:53,420
starts with data it's all about data as
I mentioned data is everything in these

658
00:16:53,420 --> 00:16:53,430
I mentioned data is everything in these
 

659
00:16:53,430 --> 00:16:55,970
I mentioned data is everything in these
real world systems with the MIT

660
00:16:55,970 --> 00:16:55,980
real world systems with the MIT
 

661
00:16:55,980 --> 00:16:58,730
real world systems with the MIT
naturalistic driving data set of 25

662
00:16:58,730 --> 00:16:58,740
naturalistic driving data set of 25
 

663
00:16:58,740 --> 00:17:01,280
naturalistic driving data set of 25
vehicles of which 25 and 21 and equipped

664
00:17:01,280 --> 00:17:01,290
vehicles of which 25 and 21 and equipped
 

665
00:17:01,290 --> 00:17:03,829
vehicles of which 25 and 21 and equipped
with Tesla autopilot we instrument them

666
00:17:03,829 --> 00:17:03,839
with Tesla autopilot we instrument them
 

667
00:17:03,839 --> 00:17:05,270
with Tesla autopilot we instrument them
this is what we do the data collection

668
00:17:05,270 --> 00:17:05,280
this is what we do the data collection
 

669
00:17:05,280 --> 00:17:08,600
this is what we do the data collection
two cameras on the driver will see the

670
00:17:08,600 --> 00:17:08,610
two cameras on the driver will see the
 

671
00:17:08,610 --> 00:17:10,189
two cameras on the driver will see the
cameras on the face capturing

672
00:17:10,189 --> 00:17:10,199
cameras on the face capturing
 

673
00:17:10,199 --> 00:17:12,319
cameras on the face capturing
high-definition video of the face that's

674
00:17:12,319 --> 00:17:12,329
high-definition video of the face that's
 

675
00:17:12,329 --> 00:17:14,659
high-definition video of the face that's
where we get the glance classification

676
00:17:14,659 --> 00:17:14,669
where we get the glance classification
 

677
00:17:14,669 --> 00:17:16,520
where we get the glance classification
the emotion recognition cognitive load

678
00:17:16,520 --> 00:17:16,530
the emotion recognition cognitive load
 

679
00:17:16,530 --> 00:17:18,470
the emotion recognition cognitive load
everything coming from the face that we

680
00:17:18,470 --> 00:17:18,480
everything coming from the face that we
 

681
00:17:18,480 --> 00:17:20,480
everything coming from the face that we
have another camera or a fisheye that's

682
00:17:20,480 --> 00:17:20,490
have another camera or a fisheye that's
 

683
00:17:20,490 --> 00:17:22,130
have another camera or a fisheye that's
looking at the body of the driver and

684
00:17:22,130 --> 00:17:22,140
looking at the body of the driver and
 

685
00:17:22,140 --> 00:17:24,500
looking at the body of the driver and
that from that comes the body pose

686
00:17:24,500 --> 00:17:24,510
that from that comes the body pose
 

687
00:17:24,510 --> 00:17:27,140
that from that comes the body pose
estimation hands on wheel activity

688
00:17:27,140 --> 00:17:27,150
estimation hands on wheel activity
 

689
00:17:27,150 --> 00:17:30,049
estimation hands on wheel activity
recognition and then one video looking

690
00:17:30,049 --> 00:17:30,059
recognition and then one video looking
 

691
00:17:30,059 --> 00:17:32,120
recognition and then one video looking
out for the full scene segmentation for

692
00:17:32,120 --> 00:17:32,130
out for the full scene segmentation for
 

693
00:17:32,130 --> 00:17:33,799
out for the full scene segmentation for
all the scene perception tasks and

694
00:17:33,799 --> 00:17:33,809
all the scene perception tasks and
 

695
00:17:33,809 --> 00:17:35,270
all the scene perception tasks and
everything is being recorded

696
00:17:35,270 --> 00:17:35,280
everything is being recorded
 

697
00:17:35,280 --> 00:17:37,280
everything is being recorded
synchronized together with GPS with

698
00:17:37,280 --> 00:17:37,290
synchronized together with GPS with
 

699
00:17:37,290 --> 00:17:39,169
synchronized together with GPS with
audio with all the can covered from the

700
00:17:39,169 --> 00:17:39,179
audio with all the can covered from the
 

701
00:17:39,179 --> 00:17:42,140
audio with all the can covered from the
car on a single device synchronization

702
00:17:42,140 --> 00:17:42,150
car on a single device synchronization
 

703
00:17:42,150 --> 00:17:48,860
car on a single device synchronization
of this data is critical so that's one

704
00:17:48,860 --> 00:17:48,870
of this data is critical so that's one
 

705
00:17:48,870 --> 00:17:53,000
of this data is critical so that's one
road trip in the data where thousands

706
00:17:53,000 --> 00:17:53,010
road trip in the data where thousands
 

707
00:17:53,010 --> 00:17:55,549
road trip in the data where thousands
like it traveling hundreds of miles

708
00:17:55,549 --> 00:17:55,559
like it traveling hundreds of miles
 

709
00:17:55,559 --> 00:17:57,799
like it traveling hundreds of miles
sometimes hundreds of miles under

710
00:17:57,799 --> 00:17:57,809
sometimes hundreds of miles under
 

711
00:17:57,809 --> 00:18:02,750
sometimes hundreds of miles under
automated control and autopilot that's

712
00:18:02,750 --> 00:18:02,760
automated control and autopilot that's
 

713
00:18:02,760 --> 00:18:03,409
automated control and autopilot that's
the data

714
00:18:03,409 --> 00:18:03,419
the data
 

715
00:18:03,419 --> 00:18:07,039
the data
again as I said data is everything and

716
00:18:07,039 --> 00:18:07,049
again as I said data is everything and
 

717
00:18:07,049 --> 00:18:09,469
again as I said data is everything and
from this data we can both gain

718
00:18:09,469 --> 00:18:09,479
from this data we can both gain
 

719
00:18:09,479 --> 00:18:12,289
from this data we can both gain
understanding what people do which is

720
00:18:12,289 --> 00:18:12,299
understanding what people do which is
 

721
00:18:12,299 --> 00:18:14,779
understanding what people do which is
really important to understand how

722
00:18:14,779 --> 00:18:14,789
really important to understand how
 

723
00:18:14,789 --> 00:18:17,180
really important to understand how
autonomy successful autonomy can be

724
00:18:17,180 --> 00:18:17,190
autonomy successful autonomy can be
 

725
00:18:17,190 --> 00:18:20,060
autonomy successful autonomy can be
deployed in the real world and to design

726
00:18:20,060 --> 00:18:20,070
deployed in the real world and to design
 

727
00:18:20,070 --> 00:18:23,810
deployed in the real world and to design
algorithms as for training for training

728
00:18:23,810 --> 00:18:23,820
algorithms as for training for training
 

729
00:18:23,820 --> 00:18:25,940
algorithms as for training for training
the deep learning the deep neural

730
00:18:25,940 --> 00:18:25,950
the deep learning the deep neural
 

731
00:18:25,950 --> 00:18:28,129
the deep learning the deep neural
networks in order to perform the

732
00:18:28,129 --> 00:18:28,139
networks in order to perform the
 

733
00:18:28,139 --> 00:18:32,690
networks in order to perform the
perception tasks better twenty five

734
00:18:32,690 --> 00:18:32,700
perception tasks better twenty five
 

735
00:18:32,700 --> 00:18:39,379
perception tasks better twenty five
beagles 21 Tesla's Model S Model X and

736
00:18:39,379 --> 00:18:39,389
beagles 21 Tesla's Model S Model X and
 

737
00:18:39,389 --> 00:18:42,709
beagles 21 Tesla's Model S Model X and
now model three over a thousand miles

738
00:18:42,709 --> 00:18:42,719
now model three over a thousand miles
 

739
00:18:42,719 --> 00:18:44,930
now model three over a thousand miles
collected a day every single day we have

740
00:18:44,930 --> 00:18:44,940
collected a day every single day we have
 

741
00:18:44,940 --> 00:18:46,489
collected a day every single day we have
thousands of miles in the Boston

742
00:18:46,489 --> 00:18:46,499
thousands of miles in the Boston
 

743
00:18:46,499 --> 00:18:48,409
thousands of miles in the Boston
Massachusetts area driving around all of

744
00:18:48,409 --> 00:18:48,419
Massachusetts area driving around all of
 

745
00:18:48,419 --> 00:18:51,739
Massachusetts area driving around all of
that video being recorded now over five

746
00:18:51,739 --> 00:18:51,749
that video being recorded now over five
 

747
00:18:51,749 --> 00:18:57,049
that video being recorded now over five
billion video frames there are several

748
00:18:57,049 --> 00:18:57,059
billion video frames there are several
 

749
00:18:57,059 --> 00:19:01,879
billion video frames there are several
ways to look at autonomy one of the big

750
00:19:01,879 --> 00:19:01,889
ways to look at autonomy one of the big
 

751
00:19:01,889 --> 00:19:07,729
ways to look at autonomy one of the big
ones is safety that's what everybody

752
00:19:07,729 --> 00:19:07,739
ones is safety that's what everybody
 

753
00:19:07,739 --> 00:19:09,079
ones is safety that's what everybody
talks about how do we make these things

754
00:19:09,079 --> 00:19:09,089
talks about how do we make these things
 

755
00:19:09,089 --> 00:19:14,149
talks about how do we make these things
safe but the other one is enjoyment do

756
00:19:14,149 --> 00:19:14,159
safe but the other one is enjoyment do
 

757
00:19:14,159 --> 00:19:17,899
safe but the other one is enjoyment do
people actually want to use it it we can

758
00:19:17,899 --> 00:19:17,909
people actually want to use it it we can
 

759
00:19:17,909 --> 00:19:20,989
people actually want to use it it we can
create a perfectly safe system we can

760
00:19:20,989 --> 00:19:20,999
create a perfectly safe system we can
 

761
00:19:20,999 --> 00:19:23,239
create a perfectly safe system we can
create it right now we've had it for

762
00:19:23,239 --> 00:19:23,249
create it right now we've had it for
 

763
00:19:23,249 --> 00:19:27,409
create it right now we've had it for
ever before even cars a car that never

764
00:19:27,409 --> 00:19:27,419
ever before even cars a car that never
 

765
00:19:27,419 --> 00:19:29,569
ever before even cars a car that never
moves is a perfectly safe system well

766
00:19:29,569 --> 00:19:29,579
moves is a perfectly safe system well
 

767
00:19:29,579 --> 00:19:33,440
moves is a perfectly safe system well
not perfectly but almost and but it

768
00:19:33,440 --> 00:19:33,450
not perfectly but almost and but it
 

769
00:19:33,450 --> 00:19:35,539
not perfectly but almost and but it
doesn't provide a service that's

770
00:19:35,539 --> 00:19:35,549
doesn't provide a service that's
 

771
00:19:35,549 --> 00:19:37,699
doesn't provide a service that's
valuable it doesn't provide an enjoyable

772
00:19:37,699 --> 00:19:37,709
valuable it doesn't provide an enjoyable
 

773
00:19:37,709 --> 00:19:40,519
valuable it doesn't provide an enjoyable
driving experience so okay what about

774
00:19:40,519 --> 00:19:40,529
driving experience so okay what about
 

775
00:19:40,529 --> 00:19:42,769
driving experience so okay what about
slow moving vehicles that's an open

776
00:19:42,769 --> 00:19:42,779
slow moving vehicles that's an open
 

777
00:19:42,779 --> 00:19:45,799
slow moving vehicles that's an open
question the reality is with these Tesla

778
00:19:45,799 --> 00:19:45,809
question the reality is with these Tesla
 

779
00:19:45,809 --> 00:19:48,349
question the reality is with these Tesla
vehicles and l2 systems doing automated

780
00:19:48,349 --> 00:19:48,359
vehicles and l2 systems doing automated
 

781
00:19:48,359 --> 00:19:51,259
vehicles and l2 systems doing automated
driving people are driving 33% of miles

782
00:19:51,259 --> 00:19:51,269
driving people are driving 33% of miles
 

783
00:19:51,269 --> 00:19:54,469
driving people are driving 33% of miles
using Tesla autopilot what does that

784
00:19:54,469 --> 00:19:54,479
using Tesla autopilot what does that
 

785
00:19:54,479 --> 00:19:57,199
using Tesla autopilot what does that
mean that means that people are getting

786
00:19:57,199 --> 00:19:57,209
mean that means that people are getting
 

787
00:19:57,209 --> 00:19:59,479
mean that means that people are getting
value from it they a large fraction of

788
00:19:59,479 --> 00:19:59,489
value from it they a large fraction of
 

789
00:19:59,489 --> 00:20:02,229
value from it they a large fraction of
their driving is done an automated way

790
00:20:02,229 --> 00:20:02,239
their driving is done an automated way
 

791
00:20:02,239 --> 00:20:08,250
their driving is done an automated way
that's value that's enjoyment the glance

792
00:20:08,250 --> 00:20:08,260
that's value that's enjoyment the glance
 

793
00:20:08,260 --> 00:20:10,410
that's value that's enjoyment the glance
suffocation algorithm we'll talk about

794
00:20:10,410 --> 00:20:10,420
suffocation algorithm we'll talk about
 

795
00:20:10,420 --> 00:20:14,520
suffocation algorithm we'll talk about
today is used as one example that we use

796
00:20:14,520 --> 00:20:14,530
today is used as one example that we use
 

797
00:20:14,530 --> 00:20:16,890
today is used as one example that we use
to understand what's in this data shown

798
00:20:16,890 --> 00:20:16,900
to understand what's in this data shown
 

799
00:20:16,900 --> 00:20:18,600
to understand what's in this data shown
with the bar graphs there and the red

800
00:20:18,600 --> 00:20:18,610
with the bar graphs there and the red
 

801
00:20:18,610 --> 00:20:20,580
with the bar graphs there and the red
and the blue red is during manual

802
00:20:20,580 --> 00:20:20,590
and the blue red is during manual
 

803
00:20:20,590 --> 00:20:22,560
and the blue red is during manual
driving blues during autopilot driving

804
00:20:22,560 --> 00:20:22,570
driving blues during autopilot driving
 

805
00:20:22,570 --> 00:20:24,720
driving blues during autopilot driving
and we look at glance classification

806
00:20:24,720 --> 00:20:24,730
and we look at glance classification
 

807
00:20:24,730 --> 00:20:26,430
and we look at glance classification
regions of where drivers are looking on

808
00:20:26,430 --> 00:20:26,440
regions of where drivers are looking on
 

809
00:20:26,440 --> 00:20:28,560
regions of where drivers are looking on
road and off-road and if that

810
00:20:28,560 --> 00:20:28,570
road and off-road and if that
 

811
00:20:28,570 --> 00:20:30,720
road and off-road and if that
distribution changes with automated

812
00:20:30,720 --> 00:20:30,730
distribution changes with automated
 

813
00:20:30,730 --> 00:20:34,350
distribution changes with automated
driving or manual driving and would

814
00:20:34,350 --> 00:20:34,360
driving or manual driving and would
 

815
00:20:34,360 --> 00:20:36,300
driving or manual driving and would
these glass classification methods we

816
00:20:36,300 --> 00:20:36,310
these glass classification methods we
 

817
00:20:36,310 --> 00:20:37,920
these glass classification methods we
can determine that there's not much

818
00:20:37,920 --> 00:20:37,930
can determine that there's not much
 

819
00:20:37,930 --> 00:20:40,410
can determine that there's not much
difference at least until you dig into

820
00:20:40,410 --> 00:20:40,420
difference at least until you dig into
 

821
00:20:40,420 --> 00:20:42,540
difference at least until you dig into
the details which we haven't done and

822
00:20:42,540 --> 00:20:42,550
the details which we haven't done and
 

823
00:20:42,550 --> 00:20:44,820
the details which we haven't done and
the aggregate there's not a significant

824
00:20:44,820 --> 00:20:44,830
the aggregate there's not a significant
 

825
00:20:44,830 --> 00:20:49,800
the aggregate there's not a significant
difference that means people are getting

826
00:20:49,800 --> 00:20:49,810
difference that means people are getting
 

827
00:20:49,810 --> 00:20:52,940
difference that means people are getting
value enjoying using these technologies

828
00:20:52,940 --> 00:20:52,950
value enjoying using these technologies
 

829
00:20:52,950 --> 00:20:56,850
value enjoying using these technologies
but yet they're staying attentive or at

830
00:20:56,850 --> 00:20:56,860
but yet they're staying attentive or at
 

831
00:20:56,860 --> 00:21:00,570
but yet they're staying attentive or at
least not attentive but physically

832
00:21:00,570 --> 00:21:00,580
least not attentive but physically
 

833
00:21:00,580 --> 00:21:03,000
least not attentive but physically
engaged when your eyes are on the road

834
00:21:03,000 --> 00:21:03,010
engaged when your eyes are on the road
 

835
00:21:03,010 --> 00:21:05,460
engaged when your eyes are on the road
you might not be attentive but you're at

836
00:21:05,460 --> 00:21:05,470
you might not be attentive but you're at
 

837
00:21:05,470 --> 00:21:08,070
you might not be attentive but you're at
the very least physically your body's

838
00:21:08,070 --> 00:21:08,080
the very least physically your body's
 

839
00:21:08,080 --> 00:21:09,810
the very least physically your body's
position in such a way your head is

840
00:21:09,810 --> 00:21:09,820
position in such a way your head is
 

841
00:21:09,820 --> 00:21:11,490
position in such a way your head is
looking at the forward roadway that

842
00:21:11,490 --> 00:21:11,500
looking at the forward roadway that
 

843
00:21:11,500 --> 00:21:13,830
looking at the forward roadway that
you're physically in position to be

844
00:21:13,830 --> 00:21:13,840
you're physically in position to be
 

845
00:21:13,840 --> 00:21:16,910
you're physically in position to be
alert and to take in the forward roadway

846
00:21:16,910 --> 00:21:16,920
alert and to take in the forward roadway
 

847
00:21:16,920 --> 00:21:22,590
alert and to take in the forward roadway
so they're using it and they don't over

848
00:21:22,590 --> 00:21:22,600
so they're using it and they don't over
 

849
00:21:22,600 --> 00:21:25,590
so they're using it and they don't over
trust it and that's I think the sweet

850
00:21:25,590 --> 00:21:25,600
trust it and that's I think the sweet
 

851
00:21:25,600 --> 00:21:28,620
trust it and that's I think the sweet
spot that human-robot interaction needs

852
00:21:28,620 --> 00:21:28,630
spot that human-robot interaction needs
 

853
00:21:28,630 --> 00:21:33,930
spot that human-robot interaction needs
to achieve is the human gaining through

854
00:21:33,930 --> 00:21:33,940
to achieve is the human gaining through
 

855
00:21:33,940 --> 00:21:36,210
to achieve is the human gaining through
experience through exploration through

856
00:21:36,210 --> 00:21:36,220
experience through exploration through
 

857
00:21:36,220 --> 00:21:38,640
experience through exploration through
trial and error exploring and

858
00:21:38,640 --> 00:21:38,650
trial and error exploring and
 

859
00:21:38,650 --> 00:21:40,140
trial and error exploring and
understanding the limitation of the

860
00:21:40,140 --> 00:21:40,150
understanding the limitation of the
 

861
00:21:40,150 --> 00:21:42,690
understanding the limitation of the
system to a degree that over trust can

862
00:21:42,690 --> 00:21:42,700
system to a degree that over trust can
 

863
00:21:42,700 --> 00:21:44,790
system to a degree that over trust can
occur that seems to be happening in this

864
00:21:44,790 --> 00:21:44,800
occur that seems to be happening in this
 

865
00:21:44,800 --> 00:21:48,000
occur that seems to be happening in this
system and using the computer vision

866
00:21:48,000 --> 00:21:48,010
system and using the computer vision
 

867
00:21:48,010 --> 00:21:50,040
system and using the computer vision
methods I'll talk about we can continue

868
00:21:50,040 --> 00:21:50,050
methods I'll talk about we can continue
 

869
00:21:50,050 --> 00:21:52,380
methods I'll talk about we can continue
to explore how that can be achieved in

870
00:21:52,380 --> 00:21:52,390
to explore how that can be achieved in
 

871
00:21:52,390 --> 00:21:56,220
to explore how that can be achieved in
other systems when the when the when the

872
00:21:56,220 --> 00:21:56,230
other systems when the when the when the
 

873
00:21:56,230 --> 00:21:58,410
other systems when the when the when the
fraction of automated driving increases

874
00:21:58,410 --> 00:21:58,420
fraction of automated driving increases
 

875
00:21:58,420 --> 00:22:06,510
fraction of automated driving increases
from 30% to 40% to 50% and so on it's

876
00:22:06,510 --> 00:22:06,520
from 30% to 40% to 50% and so on it's
 

877
00:22:06,520 --> 00:22:07,110
from 30% to 40% to 50% and so on it's
all

878
00:22:07,110 --> 00:22:07,120
all
 

879
00:22:07,120 --> 00:22:09,150
all
about the data and I'll I'll harp on

880
00:22:09,150 --> 00:22:09,160
about the data and I'll I'll harp on
 

881
00:22:09,160 --> 00:22:11,460
about the data and I'll I'll harp on
this again the algorithms are

882
00:22:11,460 --> 00:22:11,470
this again the algorithms are
 

883
00:22:11,470 --> 00:22:13,230
this again the algorithms are
interesting you know I will mention of

884
00:22:13,230 --> 00:22:13,240
interesting you know I will mention of
 

885
00:22:13,240 --> 00:22:15,690
interesting you know I will mention of
course it's the same convolution neural

886
00:22:15,690 --> 00:22:15,700
course it's the same convolution neural
 

887
00:22:15,700 --> 00:22:18,570
course it's the same convolution neural
networks it's the same networks that

888
00:22:18,570 --> 00:22:18,580
networks it's the same networks that
 

889
00:22:18,580 --> 00:22:22,080
networks it's the same networks that
take in raw pixels and extract features

890
00:22:22,080 --> 00:22:22,090
take in raw pixels and extract features
 

891
00:22:22,090 --> 00:22:25,200
take in raw pixels and extract features
of interest it's 3d convolutional neural

892
00:22:25,200 --> 00:22:25,210
of interest it's 3d convolutional neural
 

893
00:22:25,210 --> 00:22:27,180
of interest it's 3d convolutional neural
networks that take into sequences of

894
00:22:27,180 --> 00:22:27,190
networks that take into sequences of
 

895
00:22:27,190 --> 00:22:29,790
networks that take into sequences of
images and extract the temporal dynamics

896
00:22:29,790 --> 00:22:29,800
images and extract the temporal dynamics
 

897
00:22:29,800 --> 00:22:31,770
images and extract the temporal dynamics
along with the visual characteristic for

898
00:22:31,770 --> 00:22:31,780
along with the visual characteristic for
 

899
00:22:31,780 --> 00:22:34,110
along with the visual characteristic for
the individual images it's RN and

900
00:22:34,110 --> 00:22:34,120
the individual images it's RN and
 

901
00:22:34,120 --> 00:22:36,960
the individual images it's RN and
zoella's TMS that use the convolutional

902
00:22:36,960 --> 00:22:36,970
zoella's TMS that use the convolutional
 

903
00:22:36,970 --> 00:22:39,090
zoella's TMS that use the convolutional
neural networks to extract features and

904
00:22:39,090 --> 00:22:39,100
neural networks to extract features and
 

905
00:22:39,100 --> 00:22:42,030
neural networks to extract features and
over time look at the dynamics and the

906
00:22:42,030 --> 00:22:42,040
over time look at the dynamics and the
 

907
00:22:42,040 --> 00:22:43,890
over time look at the dynamics and the
images these are pretty basic

908
00:22:43,890 --> 00:22:43,900
images these are pretty basic
 

909
00:22:43,900 --> 00:22:46,260
images these are pretty basic
architecture is the same kind of deep

910
00:22:46,260 --> 00:22:46,270
architecture is the same kind of deep
 

911
00:22:46,270 --> 00:22:49,530
architecture is the same kind of deep
neural network architectures but they

912
00:22:49,530 --> 00:22:49,540
neural network architectures but they
 

913
00:22:49,540 --> 00:22:51,810
neural network architectures but they
rely fundamentally and deeply on the

914
00:22:51,810 --> 00:22:51,820
rely fundamentally and deeply on the
 

915
00:22:51,820 --> 00:22:57,600
rely fundamentally and deeply on the
data on real-world data so let's start

916
00:22:57,600 --> 00:22:57,610
data on real-world data so let's start
 

917
00:22:57,610 --> 00:23:00,030
data on real-world data so let's start
where perhaps on the human sensing side

918
00:23:00,030 --> 00:23:00,040
where perhaps on the human sensing side
 

919
00:23:00,040 --> 00:23:01,830
where perhaps on the human sensing side
it all began which is pedestrian

920
00:23:01,830 --> 00:23:01,840
it all began which is pedestrian
 

921
00:23:01,840 --> 00:23:09,529
it all began which is pedestrian
detection decades ago to put it in con

922
00:23:09,529 --> 00:23:09,539
detection decades ago to put it in con
 

923
00:23:09,539 --> 00:23:11,359
detection decades ago to put it in con
texe pedestrian detection here shown

924
00:23:11,359 --> 00:23:11,369
texe pedestrian detection here shown
 

925
00:23:11,369 --> 00:23:13,700
texe pedestrian detection here shown
from left to right on the left is green

926
00:23:13,700 --> 00:23:13,710
from left to right on the left is green
 

927
00:23:13,710 --> 00:23:17,710
from left to right on the left is green
showing the easier human sensing tasks

928
00:23:17,710 --> 00:23:17,720
showing the easier human sensing tasks
 

929
00:23:17,720 --> 00:23:20,389
showing the easier human sensing tasks
tasks of sensing some aspect to a human

930
00:23:20,389 --> 00:23:20,399
tasks of sensing some aspect to a human
 

931
00:23:20,399 --> 00:23:22,519
tasks of sensing some aspect to a human
being but as for your detection which is

932
00:23:22,519 --> 00:23:22,529
being but as for your detection which is
 

933
00:23:22,529 --> 00:23:25,759
being but as for your detection which is
detecting the full body of a human being

934
00:23:25,759 --> 00:23:25,769
detecting the full body of a human being
 

935
00:23:25,769 --> 00:23:29,180
detecting the full body of a human being
in an image or video is one of the

936
00:23:29,180 --> 00:23:29,190
in an image or video is one of the
 

937
00:23:29,190 --> 00:23:31,759
in an image or video is one of the
easier computer vision tasks and on the

938
00:23:31,759 --> 00:23:31,769
easier computer vision tasks and on the
 

939
00:23:31,769 --> 00:23:34,940
easier computer vision tasks and on the
right under in the red microcircuits

940
00:23:34,940 --> 00:23:34,950
right under in the red microcircuits
 

941
00:23:34,950 --> 00:23:36,830
right under in the red microcircuits
these are the tremors of the eye or

942
00:23:36,830 --> 00:23:36,840
these are the tremors of the eye or
 

943
00:23:36,840 --> 00:23:39,109
these are the tremors of the eye or
measuring the pupil diameter or

944
00:23:39,109 --> 00:23:39,119
measuring the pupil diameter or
 

945
00:23:39,119 --> 00:23:41,330
measuring the pupil diameter or
measuring the cognitive load or the fine

946
00:23:41,330 --> 00:23:41,340
measuring the cognitive load or the fine
 

947
00:23:41,340 --> 00:23:44,719
measuring the cognitive load or the fine
blink dynamics of the eye the velocity

948
00:23:44,719 --> 00:23:44,729
blink dynamics of the eye the velocity
 

949
00:23:44,729 --> 00:23:48,469
blink dynamics of the eye the velocity
of the blink micro glances and I pose

950
00:23:48,469 --> 00:23:48,479
of the blink micro glances and I pose
 

951
00:23:48,479 --> 00:23:50,269
of the blink micro glances and I pose
are much harder problems

952
00:23:50,269 --> 00:23:50,279
are much harder problems
 

953
00:23:50,279 --> 00:23:51,950
are much harder problems
so you think body pose estimation

954
00:23:51,950 --> 00:23:51,960
so you think body pose estimation
 

955
00:23:51,960 --> 00:23:54,080
so you think body pose estimation
pedestrian detection phase

956
00:23:54,080 --> 00:23:54,090
pedestrian detection phase
 

957
00:23:54,090 --> 00:23:56,149
pedestrian detection phase
classification detection recognition

958
00:23:56,149 --> 00:23:56,159
classification detection recognition
 

959
00:23:56,159 --> 00:23:58,159
classification detection recognition
head pose estimation all those are

960
00:23:58,159 --> 00:23:58,169
head pose estimation all those are
 

961
00:23:58,169 --> 00:24:00,259
head pose estimation all those are
easier tasks anything that starts

962
00:24:00,259 --> 00:24:00,269
easier tasks anything that starts
 

963
00:24:00,269 --> 00:24:02,950
easier tasks anything that starts
getting smaller looking at the eye and

964
00:24:02,950 --> 00:24:02,960
getting smaller looking at the eye and
 

965
00:24:02,960 --> 00:24:04,839
getting smaller looking at the eye and
everything that start getting

966
00:24:04,839 --> 00:24:04,849
everything that start getting
 

967
00:24:04,849 --> 00:24:07,729
everything that start getting
fine-grained there's much more difficult

968
00:24:07,729 --> 00:24:07,739
fine-grained there's much more difficult
 

969
00:24:07,739 --> 00:24:09,919
fine-grained there's much more difficult
so we start at the easiest pedestrian

970
00:24:09,919 --> 00:24:09,929
so we start at the easiest pedestrian
 

971
00:24:09,929 --> 00:24:13,820
so we start at the easiest pedestrian
detection and as the usual challenges of

972
00:24:13,820 --> 00:24:13,830
detection and as the usual challenges of
 

973
00:24:13,830 --> 00:24:15,109
detection and as the usual challenges of
all of computer vision we've talked

974
00:24:15,109 --> 00:24:15,119
all of computer vision we've talked
 

975
00:24:15,119 --> 00:24:16,909
all of computer vision we've talked
about as the various styles of

976
00:24:16,909 --> 00:24:16,919
about as the various styles of
 

977
00:24:16,919 --> 00:24:20,359
about as the various styles of
appearance so the inter class variation

978
00:24:20,359 --> 00:24:20,369
appearance so the inter class variation
 

979
00:24:20,369 --> 00:24:22,879
appearance so the inter class variation
the different possible articulations

980
00:24:22,879 --> 00:24:22,889
the different possible articulations
 

981
00:24:22,889 --> 00:24:27,109
the different possible articulations
of put it of our bodies superseded only

982
00:24:27,109 --> 00:24:27,119
of put it of our bodies superseded only
 

983
00:24:27,119 --> 00:24:30,259
of put it of our bodies superseded only
perhaps by cats but as humans are pretty

984
00:24:30,259 --> 00:24:30,269
perhaps by cats but as humans are pretty
 

985
00:24:30,269 --> 00:24:32,389
perhaps by cats but as humans are pretty
flexible as well the presence of

986
00:24:32,389 --> 00:24:32,399
flexible as well the presence of
 

987
00:24:32,399 --> 00:24:34,580
flexible as well the presence of
occlusion from the accessories that we

988
00:24:34,580 --> 00:24:34,590
occlusion from the accessories that we
 

989
00:24:34,590 --> 00:24:36,710
occlusion from the accessories that we
wear to occluding self occlusion and

990
00:24:36,710 --> 00:24:36,720
wear to occluding self occlusion and
 

991
00:24:36,720 --> 00:24:39,589
wear to occluding self occlusion and
including each other but that crowded

992
00:24:39,589 --> 00:24:39,599
including each other but that crowded
 

993
00:24:39,599 --> 00:24:41,930
including each other but that crowded
scenes have a lot of humans in them and

994
00:24:41,930 --> 00:24:41,940
scenes have a lot of humans in them and
 

995
00:24:41,940 --> 00:24:44,419
scenes have a lot of humans in them and
they include each other and therefore to

996
00:24:44,419 --> 00:24:44,429
they include each other and therefore to
 

997
00:24:44,429 --> 00:24:46,519
they include each other and therefore to
be able to disambiguate to figure out

998
00:24:46,519 --> 00:24:46,529
be able to disambiguate to figure out
 

999
00:24:46,529 --> 00:24:48,560
be able to disambiguate to figure out
each individual pedestrians is a very

1000
00:24:48,560 --> 00:24:48,570
each individual pedestrians is a very
 

1001
00:24:48,570 --> 00:24:50,570
each individual pedestrians is a very
challenging problem so how do people

1002
00:24:50,570 --> 00:24:50,580
challenging problem so how do people
 

1003
00:24:50,580 --> 00:24:53,779
challenging problem so how do people
approach this problem well there is I

1004
00:24:53,779 --> 00:24:53,789
approach this problem well there is I
 

1005
00:24:53,789 --> 00:24:59,830
approach this problem well there is I
need to extract features from raw pixels

1006
00:24:59,830 --> 00:24:59,840
need to extract features from raw pixels
 

1007
00:24:59,840 --> 00:25:03,979
need to extract features from raw pixels
whether that was hot cascades hog or CNN

1008
00:25:03,979 --> 00:25:03,989
whether that was hot cascades hog or CNN
 

1009
00:25:03,989 --> 00:25:09,320
whether that was hot cascades hog or CNN
the through the decades the sliding

1010
00:25:09,320 --> 00:25:09,330
the through the decades the sliding
 

1011
00:25:09,330 --> 00:25:11,359
the through the decades the sliding
window approach was used because the

1012
00:25:11,359 --> 00:25:11,369
window approach was used because the
 

1013
00:25:11,369 --> 00:25:13,310
window approach was used because the
pedestrians can be small in an image or

1014
00:25:13,310 --> 00:25:13,320
pedestrians can be small in an image or
 

1015
00:25:13,320 --> 00:25:15,320
pedestrians can be small in an image or
big so there's the problem of scale so

1016
00:25:15,320 --> 00:25:15,330
big so there's the problem of scale so
 

1017
00:25:15,330 --> 00:25:17,839
big so there's the problem of scale so
you use a sliding window to detect where

1018
00:25:17,839 --> 00:25:17,849
you use a sliding window to detect where
 

1019
00:25:17,849 --> 00:25:20,359
you use a sliding window to detect where
that pedestrian is you have a classifier

1020
00:25:20,359 --> 00:25:20,369
that pedestrian is you have a classifier
 

1021
00:25:20,369 --> 00:25:22,490
that pedestrian is you have a classifier
that's given a single image such as this

1022
00:25:22,490 --> 00:25:22,500
that's given a single image such as this
 

1023
00:25:22,500 --> 00:25:24,560
that's given a single image such as this
that's you're not you take that classify

1024
00:25:24,560 --> 00:25:24,570
that's you're not you take that classify
 

1025
00:25:24,570 --> 00:25:27,620
that's you're not you take that classify
you slide across the image to find where

1026
00:25:27,620 --> 00:25:27,630
you slide across the image to find where
 

1027
00:25:27,630 --> 00:25:29,510
you slide across the image to find where
all the pedestrians of scene are so you

1028
00:25:29,510 --> 00:25:29,520
all the pedestrians of scene are so you
 

1029
00:25:29,520 --> 00:25:32,420
all the pedestrians of scene are so you
can use non neural network methods or

1030
00:25:32,420 --> 00:25:32,430
can use non neural network methods or
 

1031
00:25:32,430 --> 00:25:34,250
can use non neural network methods or
you can use convolution neural networks

1032
00:25:34,250 --> 00:25:34,260
you can use convolution neural networks
 

1033
00:25:34,260 --> 00:25:36,860
you can use convolution neural networks
for that classifier it's extremely

1034
00:25:36,860 --> 00:25:36,870
for that classifier it's extremely
 

1035
00:25:36,870 --> 00:25:40,250
for that classifier it's extremely
inefficient then came along our CNN fast

1036
00:25:40,250 --> 00:25:40,260
inefficient then came along our CNN fast
 

1037
00:25:40,260 --> 00:25:42,920
inefficient then came along our CNN fast
our CNN fast our CNN these are networks

1038
00:25:42,920 --> 00:25:42,930
our CNN fast our CNN these are networks
 

1039
00:25:42,930 --> 00:25:46,190
our CNN fast our CNN these are networks
that as opposed to doing a complete

1040
00:25:46,190 --> 00:25:46,200
that as opposed to doing a complete
 

1041
00:25:46,200 --> 00:25:48,320
that as opposed to doing a complete
sliding window approach are much more

1042
00:25:48,320 --> 00:25:48,330
sliding window approach are much more
 

1043
00:25:48,330 --> 00:25:51,380
sliding window approach are much more
intelligent clever about generating the

1044
00:25:51,380 --> 00:25:51,390
intelligent clever about generating the
 

1045
00:25:51,390 --> 00:25:53,750
intelligent clever about generating the
candidates to consider so as opposed to

1046
00:25:53,750 --> 00:25:53,760
candidates to consider so as opposed to
 

1047
00:25:53,760 --> 00:25:55,550
candidates to consider so as opposed to
considering every possible position of a

1048
00:25:55,550 --> 00:25:55,560
considering every possible position of a
 

1049
00:25:55,560 --> 00:25:57,290
considering every possible position of a
window different scales of the window

1050
00:25:57,290 --> 00:25:57,300
window different scales of the window
 

1051
00:25:57,300 --> 00:26:01,340
window different scales of the window
they generate more a small subset of

1052
00:26:01,340 --> 00:26:01,350
they generate more a small subset of
 

1053
00:26:01,350 --> 00:26:03,790
they generate more a small subset of
candidates that are more likely and

1054
00:26:03,790 --> 00:26:03,800
candidates that are more likely and
 

1055
00:26:03,800 --> 00:26:06,440
candidates that are more likely and
finally using a CNN classify for those

1056
00:26:06,440 --> 00:26:06,450
finally using a CNN classify for those
 

1057
00:26:06,450 --> 00:26:07,700
finally using a CNN classify for those
candidates whether there's a pedestrian

1058
00:26:07,700 --> 00:26:07,710
candidates whether there's a pedestrian
 

1059
00:26:07,710 --> 00:26:10,430
candidates whether there's a pedestrian
or not whether the there's an object of

1060
00:26:10,430 --> 00:26:10,440
or not whether the there's an object of
 

1061
00:26:10,440 --> 00:26:14,120
or not whether the there's an object of
interest or not a face or not and using

1062
00:26:14,120 --> 00:26:14,130
interest or not a face or not and using
 

1063
00:26:14,130 --> 00:26:15,800
interest or not a face or not and using
that maximum suppression because there's

1064
00:26:15,800 --> 00:26:15,810
that maximum suppression because there's
 

1065
00:26:15,810 --> 00:26:18,110
that maximum suppression because there's
overlapping bounding boxes to figure out

1066
00:26:18,110 --> 00:26:18,120
overlapping bounding boxes to figure out
 

1067
00:26:18,120 --> 00:26:19,820
overlapping bounding boxes to figure out
what is the most likely bounding box

1068
00:26:19,820 --> 00:26:19,830
what is the most likely bounding box
 

1069
00:26:19,830 --> 00:26:21,680
what is the most likely bounding box
around this pedestrian around this

1070
00:26:21,680 --> 00:26:21,690
around this pedestrian around this
 

1071
00:26:21,690 --> 00:26:24,410
around this pedestrian around this
object that's our CNN and there's a lot

1072
00:26:24,410 --> 00:26:24,420
object that's our CNN and there's a lot
 

1073
00:26:24,420 --> 00:26:26,900
object that's our CNN and there's a lot
of variants now with masks our CNN

1074
00:26:26,900 --> 00:26:26,910
of variants now with masks our CNN
 

1075
00:26:26,910 --> 00:26:29,510
of variants now with masks our CNN
really the state-of-the-art localization

1076
00:26:29,510 --> 00:26:29,520
really the state-of-the-art localization
 

1077
00:26:29,520 --> 00:26:34,160
really the state-of-the-art localization
Network mask also adds to this on top of

1078
00:26:34,160 --> 00:26:34,170
Network mask also adds to this on top of
 

1079
00:26:34,170 --> 00:26:36,200
Network mask also adds to this on top of
the body box also performed segmentation

1080
00:26:36,200 --> 00:26:36,210
the body box also performed segmentation
 

1081
00:26:36,210 --> 00:26:37,790
the body box also performed segmentation
there's voxel net which does

1082
00:26:37,790 --> 00:26:37,800
there's voxel net which does
 

1083
00:26:37,800 --> 00:26:39,470
there's voxel net which does
three-dimensional and light our data

1084
00:26:39,470 --> 00:26:39,480
three-dimensional and light our data
 

1085
00:26:39,480 --> 00:26:42,530
three-dimensional and light our data
uses localization and point clouds so

1086
00:26:42,530 --> 00:26:42,540
uses localization and point clouds so
 

1087
00:26:42,540 --> 00:26:44,330
uses localization and point clouds so
it's not just using it to the images but

1088
00:26:44,330 --> 00:26:44,340
it's not just using it to the images but
 

1089
00:26:44,340 --> 00:26:47,570
it's not just using it to the images but
in 3d but it's it's it's all kind of

1090
00:26:47,570 --> 00:26:47,580
in 3d but it's it's it's all kind of
 

1091
00:26:47,580 --> 00:26:51,740
in 3d but it's it's it's all kind of
grounded in the our CNN framework ok

1092
00:26:51,740 --> 00:26:51,750
grounded in the our CNN framework ok
 

1093
00:26:51,750 --> 00:26:56,000
grounded in the our CNN framework ok
data so we have large-scale data

1094
00:26:56,000 --> 00:26:56,010
data so we have large-scale data
 

1095
00:26:56,010 --> 00:26:58,640
data so we have large-scale data
collection going on here in Cambridge if

1096
00:26:58,640 --> 00:26:58,650
collection going on here in Cambridge if
 

1097
00:26:58,650 --> 00:27:00,410
collection going on here in Cambridge if
you've seen cameras a lidar various

1098
00:27:00,410 --> 00:27:00,420
you've seen cameras a lidar various
 

1099
00:27:00,420 --> 00:27:03,020
you've seen cameras a lidar various
intersections throughout MIT we're part

1100
00:27:03,020 --> 00:27:03,030
intersections throughout MIT we're part
 

1101
00:27:03,030 --> 00:27:05,180
intersections throughout MIT we're part
of that so for example here's one of the

1102
00:27:05,180 --> 00:27:05,190
of that so for example here's one of the
 

1103
00:27:05,190 --> 00:27:07,220
of that so for example here's one of the
intersections to collecting about 10

1104
00:27:07,220 --> 00:27:07,230
intersections to collecting about 10
 

1105
00:27:07,230 --> 00:27:11,200
intersections to collecting about 10
hours a day instrumenting it with

1106
00:27:11,200 --> 00:27:11,210
hours a day instrumenting it with
 

1107
00:27:11,210 --> 00:27:14,630
hours a day instrumenting it with
various sensors I'll mention but we see

1108
00:27:14,630 --> 00:27:14,640
various sensors I'll mention but we see
 

1109
00:27:14,640 --> 00:27:18,800
various sensors I'll mention but we see
about 12,000 pedestrians a day across

1110
00:27:18,800 --> 00:27:18,810
about 12,000 pedestrians a day across
 

1111
00:27:18,810 --> 00:27:22,490
about 12,000 pedestrians a day across
that particular intersection using 4k

1112
00:27:22,490 --> 00:27:22,500
that particular intersection using 4k
 

1113
00:27:22,500 --> 00:27:27,650
that particular intersection using 4k
cameras using stereo vision cameras 360

1114
00:27:27,650 --> 00:27:27,660
cameras using stereo vision cameras 360
 

1115
00:27:27,660 --> 00:27:30,470
cameras using stereo vision cameras 360
now the insta 360 which is an 8k 360

1116
00:27:30,470 --> 00:27:30,480
now the insta 360 which is an 8k 360
 

1117
00:27:30,480 --> 00:27:34,640
now the insta 360 which is an 8k 360
camera gopro lidar various sizes the 64

1118
00:27:34,640 --> 00:27:34,650
camera gopro lidar various sizes the 64
 

1119
00:27:34,650 --> 00:27:37,020
camera gopro lidar various sizes the 64
channel of the 6

1120
00:27:37,020 --> 00:27:37,030
channel of the 6
 

1121
00:27:37,030 --> 00:27:43,330
channel of the 6
and recording this is where this is the

1122
00:27:43,330 --> 00:27:43,340
and recording this is where this is the
 

1123
00:27:43,340 --> 00:27:45,100
and recording this is where this is the
this is where the data comes from this

1124
00:27:45,100 --> 00:27:45,110
this is where the data comes from this
 

1125
00:27:45,110 --> 00:27:49,330
this is where the data comes from this
is from the 360 video this is from the

1126
00:27:49,330 --> 00:27:49,340
is from the 360 video this is from the
 

1127
00:27:49,340 --> 00:27:52,720
is from the 360 video this is from the
lidar data of the same intersection this

1128
00:27:52,720 --> 00:27:52,730
lidar data of the same intersection this
 

1129
00:27:52,730 --> 00:27:56,560
lidar data of the same intersection this
is for the 4k camcorders pointing at a

1130
00:27:56,560 --> 00:27:56,570
is for the 4k camcorders pointing at a
 

1131
00:27:56,570 --> 00:28:00,210
is for the 4k camcorders pointing at a
different intersection and the different

1132
00:28:00,210 --> 00:28:00,220
different intersection and the different
 

1133
00:28:00,220 --> 00:28:03,190
different intersection and the different
than capturing the entire 360 view with

1134
00:28:03,190 --> 00:28:03,200
than capturing the entire 360 view with
 

1135
00:28:03,200 --> 00:28:04,240
than capturing the entire 360 view with
the vehicles approaching in the

1136
00:28:04,240 --> 00:28:04,250
the vehicles approaching in the
 

1137
00:28:04,250 --> 00:28:07,919
the vehicles approaching in the
pedestrians making crossing decisions

1138
00:28:07,919 --> 00:28:07,929
pedestrians making crossing decisions
 

1139
00:28:07,929 --> 00:28:10,690
pedestrians making crossing decisions
this is understanding the negotiation

1140
00:28:10,690 --> 00:28:10,700
this is understanding the negotiation
 

1141
00:28:10,700 --> 00:28:12,159
this is understanding the negotiation
that pedestrian is the nonverbal

1142
00:28:12,159 --> 00:28:12,169
that pedestrian is the nonverbal
 

1143
00:28:12,169 --> 00:28:14,140
that pedestrian is the nonverbal
negotiation that pedestrians perform and

1144
00:28:14,140 --> 00:28:14,150
negotiation that pedestrians perform and
 

1145
00:28:14,150 --> 00:28:16,000
negotiation that pedestrians perform and
choosing to cross or not especially when

1146
00:28:16,000 --> 00:28:16,010
choosing to cross or not especially when
 

1147
00:28:16,010 --> 00:28:17,860
choosing to cross or not especially when
they're jaywalking and everybody

1148
00:28:17,860 --> 00:28:17,870
they're jaywalking and everybody
 

1149
00:28:17,870 --> 00:28:22,480
they're jaywalking and everybody
jaywalks especially if you're familiar

1150
00:28:22,480 --> 00:28:22,490
jaywalks especially if you're familiar
 

1151
00:28:22,490 --> 00:28:23,549
jaywalks especially if you're familiar
with this particular intersection

1152
00:28:23,549 --> 00:28:23,559
with this particular intersection
 

1153
00:28:23,559 --> 00:28:25,840
with this particular intersection
there's more Jay walkers than non

1154
00:28:25,840 --> 00:28:25,850
there's more Jay walkers than non
 

1155
00:28:25,850 --> 00:28:28,810
there's more Jay walkers than non
jaywalkers it's a fascinating one and so

1156
00:28:28,810 --> 00:28:28,820
jaywalkers it's a fascinating one and so
 

1157
00:28:28,820 --> 00:28:30,250
jaywalkers it's a fascinating one and so
we record everything about the driver

1158
00:28:30,250 --> 00:28:30,260
we record everything about the driver
 

1159
00:28:30,260 --> 00:28:33,840
we record everything about the driver
and everything about the pedestrians

1160
00:28:33,840 --> 00:28:33,850
and everything about the pedestrians
 

1161
00:28:33,850 --> 00:28:36,700
and everything about the pedestrians
again our CNN this is where it comes in

1162
00:28:36,700 --> 00:28:36,710
again our CNN this is where it comes in
 

1163
00:28:36,710 --> 00:28:39,159
again our CNN this is where it comes in
is you do Bonney box detection of the

1164
00:28:39,159 --> 00:28:39,169
is you do Bonney box detection of the
 

1165
00:28:39,169 --> 00:28:40,720
is you do Bonney box detection of the
pedestrians here are the vehicles as

1166
00:28:40,720 --> 00:28:40,730
pedestrians here are the vehicles as
 

1167
00:28:40,730 --> 00:28:42,880
pedestrians here are the vehicles as
well and allows you to convert this raw

1168
00:28:42,880 --> 00:28:42,890
well and allows you to convert this raw
 

1169
00:28:42,890 --> 00:28:48,669
well and allows you to convert this raw
data into hours of pedestrian crossing

1170
00:28:48,669 --> 00:28:48,679
data into hours of pedestrian crossing
 

1171
00:28:48,679 --> 00:28:52,049
data into hours of pedestrian crossing
decisions and begin to interpret it

1172
00:28:52,049 --> 00:28:52,059
decisions and begin to interpret it
 

1173
00:28:52,059 --> 00:28:55,180
decisions and begin to interpret it
that's pedestrian detection bounding box

1174
00:28:55,180 --> 00:28:55,190
that's pedestrian detection bounding box
 

1175
00:28:55,190 --> 00:29:01,270
that's pedestrian detection bounding box
for body pose estimation is the more

1176
00:29:01,270 --> 00:29:01,280
for body pose estimation is the more
 

1177
00:29:01,280 --> 00:29:03,820
for body pose estimation is the more
difficult task body pose estimation is

1178
00:29:03,820 --> 00:29:03,830
difficult task body pose estimation is
 

1179
00:29:03,830 --> 00:29:07,270
difficult task body pose estimation is
also finding the joints the hands the

1180
00:29:07,270 --> 00:29:07,280
also finding the joints the hands the
 

1181
00:29:07,280 --> 00:29:10,740
also finding the joints the hands the
elbows the shoulders the hips knees feet

1182
00:29:10,740 --> 00:29:10,750
elbows the shoulders the hips knees feet
 

1183
00:29:10,750 --> 00:29:14,529
elbows the shoulders the hips knees feet
the landmark points in the image XY

1184
00:29:14,529 --> 00:29:14,539
the landmark points in the image XY
 

1185
00:29:14,539 --> 00:29:17,529
the landmark points in the image XY
position that marked that those joints

1186
00:29:17,529 --> 00:29:17,539
position that marked that those joints
 

1187
00:29:17,539 --> 00:29:20,799
position that marked that those joints
that's body pose estimation so why is

1188
00:29:20,799 --> 00:29:20,809
that's body pose estimation so why is
 

1189
00:29:20,809 --> 00:29:22,000
that's body pose estimation so why is
that important in driving for example

1190
00:29:22,000 --> 00:29:22,010
that important in driving for example
 

1191
00:29:22,010 --> 00:29:24,370
that important in driving for example
it's it's important to determine the

1192
00:29:24,370 --> 00:29:24,380
it's it's important to determine the
 

1193
00:29:24,380 --> 00:29:26,110
it's it's important to determine the
vertical position or the alignment of

1194
00:29:26,110 --> 00:29:26,120
vertical position or the alignment of
 

1195
00:29:26,120 --> 00:29:29,169
vertical position or the alignment of
the driver the seatbelts and the sort of

1196
00:29:29,169 --> 00:29:29,179
the driver the seatbelts and the sort of
 

1197
00:29:29,179 --> 00:29:32,020
the driver the seatbelts and the sort of
the the airbag testing is always

1198
00:29:32,020 --> 00:29:32,030
the the airbag testing is always
 

1199
00:29:32,030 --> 00:29:33,430
the the airbag testing is always
performing the seatbelt testing is

1200
00:29:33,430 --> 00:29:33,440
performing the seatbelt testing is
 

1201
00:29:33,440 --> 00:29:35,230
performing the seatbelt testing is
performed with the dummy considering the

1202
00:29:35,230 --> 00:29:35,240
performed with the dummy considering the
 

1203
00:29:35,240 --> 00:29:37,299
performed with the dummy considering the
frontal position in a standard dummy

1204
00:29:37,299 --> 00:29:37,309
frontal position in a standard dummy
 

1205
00:29:37,309 --> 00:29:41,260
frontal position in a standard dummy
position the the greater greater degrees

1206
00:29:41,260 --> 00:29:41,270
position the the greater greater degrees
 

1207
00:29:41,270 --> 00:29:44,409
position the the greater greater degrees
of automation comes more capability and

1208
00:29:44,409 --> 00:29:44,419
of automation comes more capability and
 

1209
00:29:44,419 --> 00:29:45,990
of automation comes more capability and
flexibility for the driver to get

1210
00:29:45,990 --> 00:29:46,000
flexibility for the driver to get
 

1211
00:29:46,000 --> 00:29:48,259
flexibility for the driver to get
misaligned from the standard corner

1212
00:29:48,259 --> 00:29:48,269
misaligned from the standard corner
 

1213
00:29:48,269 --> 00:29:51,589
misaligned from the standard corner
dummy position and so body pose or at

1214
00:29:51,589 --> 00:29:51,599
dummy position and so body pose or at
 

1215
00:29:51,599 --> 00:29:53,599
dummy position and so body pose or at
least upper body pose estimation allows

1216
00:29:53,599 --> 00:29:53,609
least upper body pose estimation allows
 

1217
00:29:53,609 --> 00:29:55,669
least upper body pose estimation allows
you to determine how often these drivers

1218
00:29:55,669 --> 00:29:55,679
you to determine how often these drivers
 

1219
00:29:55,679 --> 00:29:59,269
you to determine how often these drivers
get out of line from the standard

1220
00:29:59,269 --> 00:29:59,279
get out of line from the standard
 

1221
00:29:59,279 --> 00:30:01,789
get out of line from the standard
position the general movement and then

1222
00:30:01,789 --> 00:30:01,799
position the general movement and then
 

1223
00:30:01,799 --> 00:30:03,729
position the general movement and then
you can look at hands on wheel

1224
00:30:03,729 --> 00:30:03,739
you can look at hands on wheel
 

1225
00:30:03,739 --> 00:30:08,180
you can look at hands on wheel
smartphone smartphone detection activity

1226
00:30:08,180 --> 00:30:08,190
smartphone smartphone detection activity
 

1227
00:30:08,190 --> 00:30:11,209
smartphone smartphone detection activity
and help add context to glance

1228
00:30:11,209 --> 00:30:11,219
and help add context to glance
 

1229
00:30:11,219 --> 00:30:14,320
and help add context to glance
estimation that which we'll talk about

1230
00:30:14,320 --> 00:30:14,330
estimation that which we'll talk about
 

1231
00:30:14,330 --> 00:30:17,029
estimation that which we'll talk about
so some of the more traditional methods

1232
00:30:17,029 --> 00:30:17,039
so some of the more traditional methods
 

1233
00:30:17,039 --> 00:30:20,509
so some of the more traditional methods
were sequential is detecting first the

1234
00:30:20,509 --> 00:30:20,519
were sequential is detecting first the
 

1235
00:30:20,519 --> 00:30:22,459
were sequential is detecting first the
head and then stepping detecting the

1236
00:30:22,459 --> 00:30:22,469
head and then stepping detecting the
 

1237
00:30:22,469 --> 00:30:28,029
head and then stepping detecting the
shoulders the elbows the hands the

1238
00:30:28,029 --> 00:30:28,039
shoulders the elbows the hands the
 

1239
00:30:28,039 --> 00:30:32,989
shoulders the elbows the hands the
depot's holistic view which has been the

1240
00:30:32,989 --> 00:30:32,999
depot's holistic view which has been the
 

1241
00:30:32,999 --> 00:30:36,549
depot's holistic view which has been the
very powerful successful way for multi

1242
00:30:36,549 --> 00:30:36,559
very powerful successful way for multi
 

1243
00:30:36,559 --> 00:30:41,239
very powerful successful way for multi
person pose estimation is performing a

1244
00:30:41,239 --> 00:30:41,249
person pose estimation is performing a
 

1245
00:30:41,249 --> 00:30:45,560
person pose estimation is performing a
regression of detecting body parts from

1246
00:30:45,560 --> 00:30:45,570
regression of detecting body parts from
 

1247
00:30:45,570 --> 00:30:48,649
regression of detecting body parts from
the entire image it's not sequentially

1248
00:30:48,649 --> 00:30:48,659
the entire image it's not sequentially
 

1249
00:30:48,659 --> 00:30:50,719
the entire image it's not sequentially
stitching bodies together it's detecting

1250
00:30:50,719 --> 00:30:50,729
stitching bodies together it's detecting
 

1251
00:30:50,729 --> 00:30:53,029
stitching bodies together it's detecting
the left elbow the right elbow the hands

1252
00:30:53,029 --> 00:30:53,039
the left elbow the right elbow the hands
 

1253
00:30:53,039 --> 00:30:56,299
the left elbow the right elbow the hands
individually it's performing that

1254
00:30:56,299 --> 00:30:56,309
individually it's performing that
 

1255
00:30:56,309 --> 00:30:57,979
individually it's performing that
detection and then stitching everything

1256
00:30:57,979 --> 00:30:57,989
detection and then stitching everything
 

1257
00:30:57,989 --> 00:31:03,649
detection and then stitching everything
together afterwards allowing you to deal

1258
00:31:03,649 --> 00:31:03,659
together afterwards allowing you to deal
 

1259
00:31:03,659 --> 00:31:06,109
together afterwards allowing you to deal
with the crazy deformations of the body

1260
00:31:06,109 --> 00:31:06,119
with the crazy deformations of the body
 

1261
00:31:06,119 --> 00:31:08,659
with the crazy deformations of the body
that happened the occlusions and so on

1262
00:31:08,659 --> 00:31:08,669
that happened the occlusions and so on
 

1263
00:31:08,669 --> 00:31:11,180
that happened the occlusions and so on
because you don't need all the joints to

1264
00:31:11,180 --> 00:31:11,190
because you don't need all the joints to
 

1265
00:31:11,190 --> 00:31:16,909
because you don't need all the joints to
be visible and with this cascade of pose

1266
00:31:16,909 --> 00:31:16,919
be visible and with this cascade of pose
 

1267
00:31:16,919 --> 00:31:19,249
be visible and with this cascade of pose
regressors meaning these are

1268
00:31:19,249 --> 00:31:19,259
regressors meaning these are
 

1269
00:31:19,259 --> 00:31:20,810
regressors meaning these are
convolutional neural networks had taken

1270
00:31:20,810 --> 00:31:20,820
convolutional neural networks had taken
 

1271
00:31:20,820 --> 00:31:23,930
convolutional neural networks had taken
a raw image and produce an XY position

1272
00:31:23,930 --> 00:31:23,940
a raw image and produce an XY position
 

1273
00:31:23,940 --> 00:31:25,879
a raw image and produce an XY position
of their estimate of each individual

1274
00:31:25,879 --> 00:31:25,889
of their estimate of each individual
 

1275
00:31:25,889 --> 00:31:28,999
of their estimate of each individual
joint input as an image output is an

1276
00:31:28,999 --> 00:31:29,009
joint input as an image output is an
 

1277
00:31:29,009 --> 00:31:33,129
joint input as an image output is an
estimate of a joint of elbow shoulder

1278
00:31:33,129 --> 00:31:33,139
estimate of a joint of elbow shoulder
 

1279
00:31:33,139 --> 00:31:36,469
estimate of a joint of elbow shoulder
whatever one of several landmarks and

1280
00:31:36,469 --> 00:31:36,479
whatever one of several landmarks and
 

1281
00:31:36,479 --> 00:31:40,119
whatever one of several landmarks and
then you can build on top of that every

1282
00:31:40,119 --> 00:31:40,129
then you can build on top of that every
 

1283
00:31:40,129 --> 00:31:42,829
then you can build on top of that every
estimation zooms in on that particular

1284
00:31:42,829 --> 00:31:42,839
estimation zooms in on that particular
 

1285
00:31:42,839 --> 00:31:46,549
estimation zooms in on that particular
area and performs a finer and finer

1286
00:31:46,549 --> 00:31:46,559
area and performs a finer and finer
 

1287
00:31:46,559 --> 00:31:48,709
area and performs a finer and finer
grain estimation of the exact position

1288
00:31:48,709 --> 00:31:48,719
grain estimation of the exact position
 

1289
00:31:48,719 --> 00:31:52,129
grain estimation of the exact position
of the Joye repeating it over and over

1290
00:31:52,129 --> 00:31:52,139
of the Joye repeating it over and over
 

1291
00:31:52,139 --> 00:31:55,129
of the Joye repeating it over and over
and over so through this process we can

1292
00:31:55,129 --> 00:31:55,139
and over so through this process we can
 

1293
00:31:55,139 --> 00:31:58,119
and over so through this process we can
do part detection and multi-person and

1294
00:31:58,119 --> 00:31:58,129
do part detection and multi-person and
 

1295
00:31:58,129 --> 00:32:00,169
do part detection and multi-person and
multi-person scene that contain multiple

1296
00:32:00,169 --> 00:32:00,179
multi-person scene that contain multiple
 

1297
00:32:00,179 --> 00:32:03,229
multi-person scene that contain multiple
people so we can detect the the head the

1298
00:32:03,229 --> 00:32:03,239
people so we can detect the the head the
 

1299
00:32:03,239 --> 00:32:05,959
people so we can detect the the head the
neck here the hands the elbows shown in

1300
00:32:05,959 --> 00:32:05,969
neck here the hands the elbows shown in
 

1301
00:32:05,969 --> 00:32:08,389
neck here the hands the elbows shown in
the various images on the right that

1302
00:32:08,389 --> 00:32:08,399
the various images on the right that
 

1303
00:32:08,399 --> 00:32:10,489
the various images on the right that
don't have an understanding who the head

1304
00:32:10,489 --> 00:32:10,499
don't have an understanding who the head
 

1305
00:32:10,499 --> 00:32:12,889
don't have an understanding who the head
the elbows the the hands belong to

1306
00:32:12,889 --> 00:32:12,899
the elbows the the hands belong to
 

1307
00:32:12,899 --> 00:32:16,009
the elbows the the hands belong to
it's just performing a detection without

1308
00:32:16,009 --> 00:32:16,019
it's just performing a detection without
 

1309
00:32:16,019 --> 00:32:18,169
it's just performing a detection without
trying to do individual person detection

1310
00:32:18,169 --> 00:32:18,179
trying to do individual person detection
 

1311
00:32:18,179 --> 00:32:25,249
trying to do individual person detection
first and then finally connecting or not

1312
00:32:25,249 --> 00:32:25,259
first and then finally connecting or not
 

1313
00:32:25,259 --> 00:32:27,289
first and then finally connecting or not
finally but next step is connecting with

1314
00:32:27,289 --> 00:32:27,299
finally but next step is connecting with
 

1315
00:32:27,299 --> 00:32:30,549
finally but next step is connecting with
part affinity fields is connecting those

1316
00:32:30,549 --> 00:32:30,559
part affinity fields is connecting those
 

1317
00:32:30,559 --> 00:32:33,200
part affinity fields is connecting those
parts together so first you detect

1318
00:32:33,200 --> 00:32:33,210
parts together so first you detect
 

1319
00:32:33,210 --> 00:32:34,549
parts together so first you detect
individual parts then you connect them

1320
00:32:34,549 --> 00:32:34,559
individual parts then you connect them
 

1321
00:32:34,559 --> 00:32:36,979
individual parts then you connect them
together and then through bipartite

1322
00:32:36,979 --> 00:32:36,989
together and then through bipartite
 

1323
00:32:36,989 --> 00:32:40,009
together and then through bipartite
matching you determine which is who is

1324
00:32:40,009 --> 00:32:40,019
matching you determine which is who is
 

1325
00:32:40,019 --> 00:32:41,869
matching you determine which is who is
that each individual body part most

1326
00:32:41,869 --> 00:32:41,879
that each individual body part most
 

1327
00:32:41,879 --> 00:32:43,579
that each individual body part most
likely belonging to so you kind of

1328
00:32:43,579 --> 00:32:43,589
likely belonging to so you kind of
 

1329
00:32:43,589 --> 00:32:45,289
likely belonging to so you kind of
stitch the different people together in

1330
00:32:45,289 --> 00:32:45,299
stitch the different people together in
 

1331
00:32:45,299 --> 00:32:46,400
stitch the different people together in
the scene after

1332
00:32:46,400 --> 00:32:46,410
the scene after
 

1333
00:32:46,410 --> 00:32:52,030
the scene after
the detection is performed with the CNN

1334
00:32:52,030 --> 00:32:52,040

 

1335
00:32:52,040 --> 00:32:55,820

we use this approach for detecting the

1336
00:32:55,820 --> 00:32:55,830
we use this approach for detecting the
 

1337
00:32:55,830 --> 00:32:57,710
we use this approach for detecting the
upper body specifically the shoulders

1338
00:32:57,710 --> 00:32:57,720
upper body specifically the shoulders
 

1339
00:32:57,720 --> 00:33:02,470
upper body specifically the shoulders
the neck and the head eyes nose ears

1340
00:33:02,470 --> 00:33:02,480
the neck and the head eyes nose ears
 

1341
00:33:02,480 --> 00:33:06,890
the neck and the head eyes nose ears
that is used to determine the the

1342
00:33:06,890 --> 00:33:06,900
that is used to determine the the
 

1343
00:33:06,900 --> 00:33:09,140
that is used to determine the the
position of the driver relative to the

1344
00:33:09,140 --> 00:33:09,150
position of the driver relative to the
 

1345
00:33:09,150 --> 00:33:11,390
position of the driver relative to the
standard dummy position for example

1346
00:33:11,390 --> 00:33:11,400
standard dummy position for example
 

1347
00:33:11,400 --> 00:33:13,600
standard dummy position for example
looking during autopilot driving

1348
00:33:13,600 --> 00:33:13,610
looking during autopilot driving
 

1349
00:33:13,610 --> 00:33:17,180
looking during autopilot driving
30-minute periods we can look at on the

1350
00:33:17,180 --> 00:33:17,190
30-minute periods we can look at on the
 

1351
00:33:17,190 --> 00:33:19,160
30-minute periods we can look at on the
x-axis is time and the y-axis is the

1352
00:33:19,160 --> 00:33:19,170
x-axis is time and the y-axis is the
 

1353
00:33:19,170 --> 00:33:20,900
x-axis is time and the y-axis is the
position of the neck point that I

1354
00:33:20,900 --> 00:33:20,910
position of the neck point that I
 

1355
00:33:20,910 --> 00:33:23,120
position of the neck point that I
pointed out in the previous slide that

1356
00:33:23,120 --> 00:33:23,130
pointed out in the previous slide that
 

1357
00:33:23,130 --> 00:33:27,410
pointed out in the previous slide that
the the the midpoint between the two

1358
00:33:27,410 --> 00:33:27,420
the the the midpoint between the two
 

1359
00:33:27,420 --> 00:33:30,500
the the the midpoint between the two
shoulders the neck is the position over

1360
00:33:30,500 --> 00:33:30,510
shoulders the neck is the position over
 

1361
00:33:30,510 --> 00:33:32,930
shoulders the neck is the position over
time relative to where it began this is

1362
00:33:32,930 --> 00:33:32,940
time relative to where it began this is
 

1363
00:33:32,940 --> 00:33:36,970
time relative to where it began this is
the slouching the sinking into the seat

1364
00:33:36,970 --> 00:33:36,980
the slouching the sinking into the seat
 

1365
00:33:36,980 --> 00:33:38,810
the slouching the sinking into the seat
allowing the car to know that

1366
00:33:38,810 --> 00:33:38,820
allowing the car to know that
 

1367
00:33:38,820 --> 00:33:41,150
allowing the car to know that
information and allowing us or the

1368
00:33:41,150 --> 00:33:41,160
information and allowing us or the
 

1369
00:33:41,160 --> 00:33:42,890
information and allowing us or the
designers of safety systems and all that

1370
00:33:42,890 --> 00:33:42,900
designers of safety systems and all that
 

1371
00:33:42,900 --> 00:33:46,340
designers of safety systems and all that
information is really important we can

1372
00:33:46,340 --> 00:33:46,350
information is really important we can
 

1373
00:33:46,350 --> 00:33:48,740
information is really important we can
use the same body pose algorithm to from

1374
00:33:48,740 --> 00:33:48,750
use the same body pose algorithm to from
 

1375
00:33:48,750 --> 00:33:50,810
use the same body pose algorithm to from
the perspective of the vehicle outside

1376
00:33:50,810 --> 00:33:50,820
the perspective of the vehicle outside
 

1377
00:33:50,820 --> 00:33:52,880
the perspective of the vehicle outside
the vehicle perspective so the vehicle

1378
00:33:52,880 --> 00:33:52,890
the vehicle perspective so the vehicle
 

1379
00:33:52,890 --> 00:33:54,980
the vehicle perspective so the vehicle
looking out is doing the as opposed to

1380
00:33:54,980 --> 00:33:54,990
looking out is doing the as opposed to
 

1381
00:33:54,990 --> 00:33:56,900
looking out is doing the as opposed to
just plain pedestrian detection using

1382
00:33:56,900 --> 00:33:56,910
just plain pedestrian detection using
 

1383
00:33:56,910 --> 00:34:01,730
just plain pedestrian detection using
body pose estimation again here in

1384
00:34:01,730 --> 00:34:01,740
body pose estimation again here in
 

1385
00:34:01,740 --> 00:34:05,410
body pose estimation again here in
Kendall Square vehicles crossing

1386
00:34:05,410 --> 00:34:05,420
Kendall Square vehicles crossing
 

1387
00:34:05,420 --> 00:34:07,730
Kendall Square vehicles crossing
observing pedestrians making crossing

1388
00:34:07,730 --> 00:34:07,740
observing pedestrians making crossing
 

1389
00:34:07,740 --> 00:34:10,159
observing pedestrians making crossing
decisions and performing body pose

1390
00:34:10,159 --> 00:34:10,169
decisions and performing body pose
 

1391
00:34:10,169 --> 00:34:16,240
decisions and performing body pose
estimation which allows you to then

1392
00:34:16,240 --> 00:34:16,250

 

1393
00:34:16,250 --> 00:34:19,369

generate visualizations like this and

1394
00:34:19,369 --> 00:34:19,379
generate visualizations like this and
 

1395
00:34:19,379 --> 00:34:21,619
generate visualizations like this and
gain understanding like this on the

1396
00:34:21,619 --> 00:34:21,629
gain understanding like this on the
 

1397
00:34:21,629 --> 00:34:26,030
gain understanding like this on the
x-axis is time on the y-axis is on the

1398
00:34:26,030 --> 00:34:26,040
x-axis is time on the y-axis is on the
 

1399
00:34:26,040 --> 00:34:28,399
x-axis is time on the y-axis is on the
top plot in blue is the speed of the

1400
00:34:28,399 --> 00:34:28,409
top plot in blue is the speed of the
 

1401
00:34:28,409 --> 00:34:31,070
top plot in blue is the speed of the
vehicle the speed of the vehicle the ego

1402
00:34:31,070 --> 00:34:31,080
vehicle the speed of the vehicle the ego
 

1403
00:34:31,080 --> 00:34:33,460
vehicle the speed of the vehicle the ego
vehicle from which the camera is

1404
00:34:33,460 --> 00:34:33,470
vehicle from which the camera is
 

1405
00:34:33,470 --> 00:34:36,770
vehicle from which the camera is
observing the scene and on the bottom in

1406
00:34:36,770 --> 00:34:36,780
observing the scene and on the bottom in
 

1407
00:34:36,780 --> 00:34:40,629
observing the scene and on the bottom in
green up and down as a binary value

1408
00:34:40,629 --> 00:34:40,639
green up and down as a binary value
 

1409
00:34:40,639 --> 00:34:43,250
green up and down as a binary value
whether the Podesta when the pedestrian

1410
00:34:43,250 --> 00:34:43,260
whether the Podesta when the pedestrian
 

1411
00:34:43,260 --> 00:34:45,290
whether the Podesta when the pedestrian
is not looking at the car one when the

1412
00:34:45,290 --> 00:34:45,300
is not looking at the car one when the
 

1413
00:34:45,300 --> 00:34:48,110
is not looking at the car one when the
pedestrian is looking at the car so we

1414
00:34:48,110 --> 00:34:48,120
pedestrian is looking at the car so we
 

1415
00:34:48,120 --> 00:34:50,060
pedestrian is looking at the car so we
can look at thousands of episodes like

1416
00:34:50,060 --> 00:34:50,070
can look at thousands of episodes like
 

1417
00:34:50,070 --> 00:34:51,770
can look at thousands of episodes like
this crossing decisions nonverbal

1418
00:34:51,770 --> 00:34:51,780
this crossing decisions nonverbal
 

1419
00:34:51,780 --> 00:34:53,899
this crossing decisions nonverbal
communication decisions and determine

1420
00:34:53,899 --> 00:34:53,909
communication decisions and determine
 

1421
00:34:53,909 --> 00:34:58,340
communication decisions and determine
using body pose estimation the dynamics

1422
00:34:58,340 --> 00:34:58,350
using body pose estimation the dynamics
 

1423
00:34:58,350 --> 00:34:59,970
using body pose estimation the dynamics
of this nonverbal

1424
00:34:59,970 --> 00:34:59,980
of this nonverbal
 

1425
00:34:59,980 --> 00:35:04,470
of this nonverbal
here just nearby by media lab crossing

1426
00:35:04,470 --> 00:35:04,480
here just nearby by media lab crossing
 

1427
00:35:04,480 --> 00:35:06,660
here just nearby by media lab crossing
there's a pedestrian approaches we can

1428
00:35:06,660 --> 00:35:06,670
there's a pedestrian approaches we can
 

1429
00:35:06,670 --> 00:35:08,160
there's a pedestrian approaches we can
look in green there when the pedestrian

1430
00:35:08,160 --> 00:35:08,170
look in green there when the pedestrian
 

1431
00:35:08,170 --> 00:35:11,280
look in green there when the pedestrian
glasses looks away glasses the car looks

1432
00:35:11,280 --> 00:35:11,290
glasses looks away glasses the car looks
 

1433
00:35:11,290 --> 00:35:14,160
glasses looks away glasses the car looks
away fascinating glance behavior that

1434
00:35:14,160 --> 00:35:14,170
away fascinating glance behavior that
 

1435
00:35:14,170 --> 00:35:17,760
away fascinating glance behavior that
happens interesting most people look

1436
00:35:17,760 --> 00:35:17,770
happens interesting most people look
 

1437
00:35:17,770 --> 00:35:24,450
happens interesting most people look
away before they cross same thing here

1438
00:35:24,450 --> 00:35:24,460
away before they cross same thing here
 

1439
00:35:24,460 --> 00:35:26,730
away before they cross same thing here
this is just an example we have

1440
00:35:26,730 --> 00:35:26,740
this is just an example we have
 

1441
00:35:26,740 --> 00:35:29,040
this is just an example we have
thousands of these body pose estimation

1442
00:35:29,040 --> 00:35:29,050
thousands of these body pose estimation
 

1443
00:35:29,050 --> 00:35:31,940
thousands of these body pose estimation
allows you to get this fine-grained

1444
00:35:31,940 --> 00:35:31,950
allows you to get this fine-grained
 

1445
00:35:31,950 --> 00:35:34,560
allows you to get this fine-grained
information about the pedestrian glance

1446
00:35:34,560 --> 00:35:34,570
information about the pedestrian glance
 

1447
00:35:34,570 --> 00:35:37,080
information about the pedestrian glance
behavior pedestrian body behavior

1448
00:35:37,080 --> 00:35:37,090
behavior pedestrian body behavior
 

1449
00:35:37,090 --> 00:35:42,599
behavior pedestrian body behavior
hesitation glass classification one of

1450
00:35:42,599 --> 00:35:42,609
hesitation glass classification one of
 

1451
00:35:42,609 --> 00:35:44,640
hesitation glass classification one of
the most important things in driving is

1452
00:35:44,640 --> 00:35:44,650
the most important things in driving is
 

1453
00:35:44,650 --> 00:35:48,390
the most important things in driving is
determining where drivers are looking it

1454
00:35:48,390 --> 00:35:48,400
determining where drivers are looking it
 

1455
00:35:48,400 --> 00:35:53,790
determining where drivers are looking it
if there's any sensing that I advocate

1456
00:35:53,790 --> 00:35:53,800
if there's any sensing that I advocate
 

1457
00:35:53,800 --> 00:35:57,270
if there's any sensing that I advocate
and is has the most impact in the

1458
00:35:57,270 --> 00:35:57,280
and is has the most impact in the
 

1459
00:35:57,280 --> 00:35:59,870
and is has the most impact in the
driving context is for the car to know

1460
00:35:59,870 --> 00:35:59,880
driving context is for the car to know
 

1461
00:35:59,880 --> 00:36:03,180
driving context is for the car to know
where the driver is looking and at the

1462
00:36:03,180 --> 00:36:03,190
where the driver is looking and at the
 

1463
00:36:03,190 --> 00:36:08,130
where the driver is looking and at the
very crude region level information of

1464
00:36:08,130 --> 00:36:08,140
very crude region level information of
 

1465
00:36:08,140 --> 00:36:10,230
very crude region level information of
is the driver looking on road or off

1466
00:36:10,230 --> 00:36:10,240
is the driver looking on road or off
 

1467
00:36:10,240 --> 00:36:11,970
is the driver looking on road or off
road that's what we mean by glance

1468
00:36:11,970 --> 00:36:11,980
road that's what we mean by glance
 

1469
00:36:11,980 --> 00:36:14,640
road that's what we mean by glance
classification it's not the standard

1470
00:36:14,640 --> 00:36:14,650
classification it's not the standard
 

1471
00:36:14,650 --> 00:36:16,770
classification it's not the standard
gaze estimation problem of X Y Z

1472
00:36:16,770 --> 00:36:16,780
gaze estimation problem of X Y Z
 

1473
00:36:16,780 --> 00:36:18,990
gaze estimation problem of X Y Z
determining where the eye pose and the

1474
00:36:18,990 --> 00:36:19,000
determining where the eye pose and the
 

1475
00:36:19,000 --> 00:36:21,390
determining where the eye pose and the
head pose combined to determine where

1476
00:36:21,390 --> 00:36:21,400
head pose combined to determine where
 

1477
00:36:21,400 --> 00:36:23,460
head pose combined to determine where
the driver is looking no this is

1478
00:36:23,460 --> 00:36:23,470
the driver is looking no this is
 

1479
00:36:23,470 --> 00:36:27,000
the driver is looking no this is
classifying two regions on road off-road

1480
00:36:27,000 --> 00:36:27,010
classifying two regions on road off-road
 

1481
00:36:27,010 --> 00:36:30,720
classifying two regions on road off-road
or six regions on road off road left

1482
00:36:30,720 --> 00:36:30,730
or six regions on road off road left
 

1483
00:36:30,730 --> 00:36:33,090
or six regions on road off road left
right center stack rearview mirror and

1484
00:36:33,090 --> 00:36:33,100
right center stack rearview mirror and
 

1485
00:36:33,100 --> 00:36:36,740
right center stack rearview mirror and
instrument cluster so it's region based

1486
00:36:36,740 --> 00:36:36,750
instrument cluster so it's region based
 

1487
00:36:36,750 --> 00:36:41,070
instrument cluster so it's region based
glance allocation not the geometric gaze

1488
00:36:41,070 --> 00:36:41,080
glance allocation not the geometric gaze
 

1489
00:36:41,080 --> 00:36:43,109
glance allocation not the geometric gaze
estimation problem why is that important

1490
00:36:43,109 --> 00:36:43,119
estimation problem why is that important
 

1491
00:36:43,119 --> 00:36:46,740
estimation problem why is that important
it allows you to address it as a machine

1492
00:36:46,740 --> 00:36:46,750
it allows you to address it as a machine
 

1493
00:36:46,750 --> 00:36:49,410
it allows you to address it as a machine
learning problem it's a subtle but

1494
00:36:49,410 --> 00:36:49,420
learning problem it's a subtle but
 

1495
00:36:49,420 --> 00:36:51,720
learning problem it's a subtle but
critical point every problem we try to

1496
00:36:51,720 --> 00:36:51,730
critical point every problem we try to
 

1497
00:36:51,730 --> 00:36:54,750
critical point every problem we try to
solve in human sensing in driver sensing

1498
00:36:54,750 --> 00:36:54,760
solve in human sensing in driver sensing
 

1499
00:36:54,760 --> 00:36:57,720
solve in human sensing in driver sensing
has to be learn about from data

1500
00:36:57,720 --> 00:36:57,730
has to be learn about from data
 

1501
00:36:57,730 --> 00:37:02,150
has to be learn about from data
otherwise it's not it's not amenable to

1502
00:37:02,150 --> 00:37:02,160
otherwise it's not it's not amenable to
 

1503
00:37:02,160 --> 00:37:04,920
otherwise it's not it's not amenable to
application in the real world we can't

1504
00:37:04,920 --> 00:37:04,930
application in the real world we can't
 

1505
00:37:04,930 --> 00:37:07,200
application in the real world we can't
design systems in the lab that are

1506
00:37:07,200 --> 00:37:07,210
design systems in the lab that are
 

1507
00:37:07,210 --> 00:37:09,480
design systems in the lab that are
deployed without learning if they

1508
00:37:09,480 --> 00:37:09,490
deployed without learning if they
 

1509
00:37:09,490 --> 00:37:13,070
deployed without learning if they
involve a human it's possible to do slam

1510
00:37:13,070 --> 00:37:13,080
involve a human it's possible to do slam
 

1511
00:37:13,080 --> 00:37:16,640
involve a human it's possible to do slam
localization by having really good

1512
00:37:16,640 --> 00:37:16,650
localization by having really good
 

1513
00:37:16,650 --> 00:37:19,550
localization by having really good
sensors and doing localization using

1514
00:37:19,550 --> 00:37:19,560
sensors and doing localization using
 

1515
00:37:19,560 --> 00:37:21,920
sensors and doing localization using
those sensors without much learning it's

1516
00:37:21,920 --> 00:37:21,930
those sensors without much learning it's
 

1517
00:37:21,930 --> 00:37:24,140
those sensors without much learning it's
not possible to design systems that deal

1518
00:37:24,140 --> 00:37:24,150
not possible to design systems that deal
 

1519
00:37:24,150 --> 00:37:26,420
not possible to design systems that deal
with lighting variability and the full

1520
00:37:26,420 --> 00:37:26,430
with lighting variability and the full
 

1521
00:37:26,430 --> 00:37:29,450
with lighting variability and the full
variability of human behavior without

1522
00:37:29,450 --> 00:37:29,460
variability of human behavior without
 

1523
00:37:29,460 --> 00:37:31,850
variability of human behavior without
being able to learn so gaze estimation

1524
00:37:31,850 --> 00:37:31,860
being able to learn so gaze estimation
 

1525
00:37:31,860 --> 00:37:34,550
being able to learn so gaze estimation
the geometric approach of finding the

1526
00:37:34,550 --> 00:37:34,560
the geometric approach of finding the
 

1527
00:37:34,560 --> 00:37:36,290
the geometric approach of finding the
landmarks in the face and from those

1528
00:37:36,290 --> 00:37:36,300
landmarks in the face and from those
 

1529
00:37:36,300 --> 00:37:39,140
landmarks in the face and from those
landmarks determining the the Jeremie

1530
00:37:39,140 --> 00:37:39,150
landmarks determining the the Jeremie
 

1531
00:37:39,150 --> 00:37:41,090
landmarks determining the the Jeremie
the orientation of the head and the

1532
00:37:41,090 --> 00:37:41,100
the orientation of the head and the
 

1533
00:37:41,100 --> 00:37:43,010
the orientation of the head and the
orientation of the eyes there's no

1534
00:37:43,010 --> 00:37:43,020
orientation of the eyes there's no
 

1535
00:37:43,020 --> 00:37:45,830
orientation of the eyes there's no
learning there outside of actually

1536
00:37:45,830 --> 00:37:45,840
learning there outside of actually
 

1537
00:37:45,840 --> 00:37:47,870
learning there outside of actually
training the systems to detect the

1538
00:37:47,870 --> 00:37:47,880
training the systems to detect the
 

1539
00:37:47,880 --> 00:37:50,930
training the systems to detect the
different landmarks if we convert this

1540
00:37:50,930 --> 00:37:50,940
different landmarks if we convert this
 

1541
00:37:50,940 --> 00:37:52,880
different landmarks if we convert this
into a gaze classification problem shown

1542
00:37:52,880 --> 00:37:52,890
into a gaze classification problem shown
 

1543
00:37:52,890 --> 00:37:57,950
into a gaze classification problem shown
here glass classification is when taking

1544
00:37:57,950 --> 00:37:57,960
here glass classification is when taking
 

1545
00:37:57,960 --> 00:38:01,790
here glass classification is when taking
the raw video stream determining in post

1546
00:38:01,790 --> 00:38:01,800
the raw video stream determining in post
 

1547
00:38:01,800 --> 00:38:04,280
the raw video stream determining in post
so humans are annotating this video is

1548
00:38:04,280 --> 00:38:04,290
so humans are annotating this video is
 

1549
00:38:04,290 --> 00:38:06,470
so humans are annotating this video is
the driver which region the driver is

1550
00:38:06,470 --> 00:38:06,480
the driver which region the driver is
 

1551
00:38:06,480 --> 00:38:11,150
the driver which region the driver is
looking at that's we're able to do by

1552
00:38:11,150 --> 00:38:11,160
looking at that's we're able to do by
 

1553
00:38:11,160 --> 00:38:12,770
looking at that's we're able to do by
converting the problem into a simple

1554
00:38:12,770 --> 00:38:12,780
converting the problem into a simple
 

1555
00:38:12,780 --> 00:38:15,770
converting the problem into a simple
variant of classification on-road

1556
00:38:15,770 --> 00:38:15,780
variant of classification on-road
 

1557
00:38:15,780 --> 00:38:18,200
variant of classification on-road
off-road left-right the same can be done

1558
00:38:18,200 --> 00:38:18,210
off-road left-right the same can be done
 

1559
00:38:18,210 --> 00:38:22,070
off-road left-right the same can be done
for pedestrians left forward right it

1560
00:38:22,070 --> 00:38:22,080
for pedestrians left forward right it
 

1561
00:38:22,080 --> 00:38:24,710
for pedestrians left forward right it
can annotate regions of where they are

1562
00:38:24,710 --> 00:38:24,720
can annotate regions of where they are
 

1563
00:38:24,720 --> 00:38:28,310
can annotate regions of where they are
looking and using that kind of

1564
00:38:28,310 --> 00:38:28,320
looking and using that kind of
 

1565
00:38:28,320 --> 00:38:30,290
looking and using that kind of
classification approach determine are

1566
00:38:30,290 --> 00:38:30,300
classification approach determine are
 

1567
00:38:30,300 --> 00:38:32,660
classification approach determine are
they looking at the cars or not are they

1568
00:38:32,660 --> 00:38:32,670
they looking at the cars or not are they
 

1569
00:38:32,670 --> 00:38:34,220
they looking at the cars or not are they
looking away are they looking at their

1570
00:38:34,220 --> 00:38:34,230
looking away are they looking at their
 

1571
00:38:34,230 --> 00:38:36,680
looking away are they looking at their
smartphone without doing the 3d gaze

1572
00:38:36,680 --> 00:38:36,690
smartphone without doing the 3d gaze
 

1573
00:38:36,690 --> 00:38:39,410
smartphone without doing the 3d gaze
estimation again it's a subtle point but

1574
00:38:39,410 --> 00:38:39,420
estimation again it's a subtle point but
 

1575
00:38:39,420 --> 00:38:41,180
estimation again it's a subtle point but
think about it if you wanted to estimate

1576
00:38:41,180 --> 00:38:41,190
think about it if you wanted to estimate
 

1577
00:38:41,190 --> 00:38:42,950
think about it if you wanted to estimate
exactly where they're looking

1578
00:38:42,950 --> 00:38:42,960
exactly where they're looking
 

1579
00:38:42,960 --> 00:38:46,400
exactly where they're looking
you need that ground truth you don't

1580
00:38:46,400 --> 00:38:46,410
you need that ground truth you don't
 

1581
00:38:46,410 --> 00:38:49,280
you need that ground truth you don't
have that ground truth unless you there

1582
00:38:49,280 --> 00:38:49,290
have that ground truth unless you there
 

1583
00:38:49,290 --> 00:38:50,990
have that ground truth unless you there
there's no in the real world data

1584
00:38:50,990 --> 00:38:51,000
there's no in the real world data
 

1585
00:38:51,000 --> 00:38:52,640
there's no in the real world data
there's no way to get the information

1586
00:38:52,640 --> 00:38:52,650
there's no way to get the information
 

1587
00:38:52,650 --> 00:38:54,320
there's no way to get the information
about where exactly people were looking

1588
00:38:54,320 --> 00:38:54,330
about where exactly people were looking
 

1589
00:38:54,330 --> 00:38:57,740
about where exactly people were looking
you're only inferring so you have to

1590
00:38:57,740 --> 00:38:57,750
you're only inferring so you have to
 

1591
00:38:57,750 --> 00:38:59,060
you're only inferring so you have to
convert it into a region based

1592
00:38:59,060 --> 00:38:59,070
convert it into a region based
 

1593
00:38:59,070 --> 00:39:00,770
convert it into a region based
classification problem in order to be

1594
00:39:00,770 --> 00:39:00,780
classification problem in order to be
 

1595
00:39:00,780 --> 00:39:03,050
classification problem in order to be
able to train your networks on this and

1596
00:39:03,050 --> 00:39:03,060
able to train your networks on this and
 

1597
00:39:03,060 --> 00:39:05,900
able to train your networks on this and
the pipeline is the same the source

1598
00:39:05,900 --> 00:39:05,910
the pipeline is the same the source
 

1599
00:39:05,910 --> 00:39:10,760
the pipeline is the same the source
video here the face the the 30 frames a

1600
00:39:10,760 --> 00:39:10,770
video here the face the the 30 frames a
 

1601
00:39:10,770 --> 00:39:12,590
video here the face the the 30 frames a
second video coming in of the drivers

1602
00:39:12,590 --> 00:39:12,600
second video coming in of the drivers
 

1603
00:39:12,600 --> 00:39:15,320
second video coming in of the drivers
face of the human face there is some

1604
00:39:15,320 --> 00:39:15,330
face of the human face there is some
 

1605
00:39:15,330 --> 00:39:16,940
face of the human face there is some
degree of calibration that's required

1606
00:39:16,940 --> 00:39:16,950
degree of calibration that's required
 

1607
00:39:16,950 --> 00:39:19,010
degree of calibration that's required
you have to determine approximately

1608
00:39:19,010 --> 00:39:19,020
you have to determine approximately
 

1609
00:39:19,020 --> 00:39:21,620
you have to determine approximately
where the sensor is that's taking in the

1610
00:39:21,620 --> 00:39:21,630
where the sensor is that's taking in the
 

1611
00:39:21,630 --> 00:39:23,960
where the sensor is that's taking in the
image especially for the glance

1612
00:39:23,960 --> 00:39:23,970
image especially for the glance
 

1613
00:39:23,970 --> 00:39:26,060
image especially for the glance
classification task because its region

1614
00:39:26,060 --> 00:39:26,070
classification task because its region
 

1615
00:39:26,070 --> 00:39:26,779
classification task because its region
based

1616
00:39:26,779 --> 00:39:26,789
based
 

1617
00:39:26,789 --> 00:39:29,509
based
needs to be able to estimate where the

1618
00:39:29,509 --> 00:39:29,519
needs to be able to estimate where the
 

1619
00:39:29,519 --> 00:39:32,900
needs to be able to estimate where the
forward roadway is where the the camera

1620
00:39:32,900 --> 00:39:32,910
forward roadway is where the the camera
 

1621
00:39:32,910 --> 00:39:36,620
forward roadway is where the the camera
frame is relative the world frame the

1622
00:39:36,620 --> 00:39:36,630
frame is relative the world frame the
 

1623
00:39:36,630 --> 00:39:39,079
frame is relative the world frame the
video stabilization and the face front

1624
00:39:39,079 --> 00:39:39,089
video stabilization and the face front
 

1625
00:39:39,089 --> 00:39:40,849
video stabilization and the face front
elevation all the basic processing

1626
00:39:40,849 --> 00:39:40,859
elevation all the basic processing
 

1627
00:39:40,859 --> 00:39:42,319
elevation all the basic processing
they've removed the vibration of the

1628
00:39:42,319 --> 00:39:42,329
they've removed the vibration of the
 

1629
00:39:42,329 --> 00:39:45,199
they've removed the vibration of the
noise that remove the physical movement

1630
00:39:45,199 --> 00:39:45,209
noise that remove the physical movement
 

1631
00:39:45,209 --> 00:39:47,809
noise that remove the physical movement
of the head that removed the shaking of

1632
00:39:47,809 --> 00:39:47,819
of the head that removed the shaking of
 

1633
00:39:47,819 --> 00:39:50,209
of the head that removed the shaking of
the car in order to be able to determine

1634
00:39:50,209 --> 00:39:50,219
the car in order to be able to determine
 

1635
00:39:50,219 --> 00:39:51,829
the car in order to be able to determine
stuff about eye movement and blink

1636
00:39:51,829 --> 00:39:51,839
stuff about eye movement and blink
 

1637
00:39:51,839 --> 00:39:55,069
stuff about eye movement and blink
dynamics and finally with the neural

1638
00:39:55,069 --> 00:39:55,079
dynamics and finally with the neural
 

1639
00:39:55,079 --> 00:39:59,630
dynamics and finally with the neural
networks there is nothing left except

1640
00:39:59,630 --> 00:39:59,640
networks there is nothing left except
 

1641
00:39:59,640 --> 00:40:02,809
networks there is nothing left except
taking in the raw video of the face for

1642
00:40:02,809 --> 00:40:02,819
taking in the raw video of the face for
 

1643
00:40:02,819 --> 00:40:05,299
taking in the raw video of the face for
the glass classification tasks and the

1644
00:40:05,299 --> 00:40:05,309
the glass classification tasks and the
 

1645
00:40:05,309 --> 00:40:07,729
the glass classification tasks and the
eye for the cognitive load tasks raw

1646
00:40:07,729 --> 00:40:07,739
eye for the cognitive load tasks raw
 

1647
00:40:07,739 --> 00:40:09,499
eye for the cognitive load tasks raw
pixels that's the input to these

1648
00:40:09,499 --> 00:40:09,509
pixels that's the input to these
 

1649
00:40:09,509 --> 00:40:11,599
pixels that's the input to these
networks and the output is whatever the

1650
00:40:11,599 --> 00:40:11,609
networks and the output is whatever the
 

1651
00:40:11,609 --> 00:40:15,289
networks and the output is whatever the
training data is and we'll mention each

1652
00:40:15,289 --> 00:40:15,299
training data is and we'll mention each
 

1653
00:40:15,299 --> 00:40:17,329
training data is and we'll mention each
one so whether that's cognitive load

1654
00:40:17,329 --> 00:40:17,339
one so whether that's cognitive load
 

1655
00:40:17,339 --> 00:40:22,039
one so whether that's cognitive load
glance emotion drowsiness the input is

1656
00:40:22,039 --> 00:40:22,049
glance emotion drowsiness the input is
 

1657
00:40:22,049 --> 00:40:23,839
glance emotion drowsiness the input is
the raw pixels and the output is

1658
00:40:23,839 --> 00:40:23,849
the raw pixels and the output is
 

1659
00:40:23,849 --> 00:40:26,089
the raw pixels and the output is
whatever you have data for data is

1660
00:40:26,089 --> 00:40:26,099
whatever you have data for data is
 

1661
00:40:26,099 --> 00:40:29,120
whatever you have data for data is
everything here the face an alignment

1662
00:40:29,120 --> 00:40:29,130
everything here the face an alignment
 

1663
00:40:29,130 --> 00:40:33,289
everything here the face an alignment
problem which is a traditional geometric

1664
00:40:33,289 --> 00:40:33,299
problem which is a traditional geometric
 

1665
00:40:33,299 --> 00:40:36,429
problem which is a traditional geometric
approach to this problem is designing

1666
00:40:36,429 --> 00:40:36,439
approach to this problem is designing
 

1667
00:40:36,439 --> 00:40:38,599
approach to this problem is designing
algorithms that are able to detect

1668
00:40:38,599 --> 00:40:38,609
algorithms that are able to detect
 

1669
00:40:38,609 --> 00:40:40,789
algorithms that are able to detect
accurately the individual landmarks in

1670
00:40:40,789 --> 00:40:40,799
accurately the individual landmarks in
 

1671
00:40:40,799 --> 00:40:42,620
accurately the individual landmarks in
the face and from that estimate the

1672
00:40:42,620 --> 00:40:42,630
the face and from that estimate the
 

1673
00:40:42,630 --> 00:40:48,890
the face and from that estimate the
geometry of the head pose for the class

1674
00:40:48,890 --> 00:40:48,900
geometry of the head pose for the class
 

1675
00:40:48,900 --> 00:40:49,349
geometry of the head pose for the class
of

1676
00:40:49,349 --> 00:40:49,359
of
 

1677
00:40:49,359 --> 00:40:52,079
of
in version we perform the same kind of

1678
00:40:52,079 --> 00:40:52,089
in version we perform the same kind of
 

1679
00:40:52,089 --> 00:40:54,239
in version we perform the same kind of
alignment or with the same kind of face

1680
00:40:54,239 --> 00:40:54,249
alignment or with the same kind of face
 

1681
00:40:54,249 --> 00:40:55,829
alignment or with the same kind of face
detection in alignment to determine

1682
00:40:55,829 --> 00:40:55,839
detection in alignment to determine
 

1683
00:40:55,839 --> 00:40:58,499
detection in alignment to determine
where the head is but once we have that

1684
00:40:58,499 --> 00:40:58,509
where the head is but once we have that
 

1685
00:40:58,509 --> 00:41:00,809
where the head is but once we have that
we pass in just the raw pixels and

1686
00:41:00,809 --> 00:41:00,819
we pass in just the raw pixels and
 

1687
00:41:00,819 --> 00:41:03,799
we pass in just the raw pixels and
perform the classification on that as

1688
00:41:03,799 --> 00:41:03,809
perform the classification on that as
 

1689
00:41:03,809 --> 00:41:05,880
perform the classification on that as
opposed to doing the estimation its

1690
00:41:05,880 --> 00:41:05,890
opposed to doing the estimation its
 

1691
00:41:05,890 --> 00:41:09,150
opposed to doing the estimation its
classification allowing you to perform

1692
00:41:09,150 --> 00:41:09,160
classification allowing you to perform
 

1693
00:41:09,160 --> 00:41:11,609
classification allowing you to perform
what's shown there on the bottom is the

1694
00:41:11,609 --> 00:41:11,619
what's shown there on the bottom is the
 

1695
00:41:11,619 --> 00:41:15,390
what's shown there on the bottom is the
real-time classification of where the

1696
00:41:15,390 --> 00:41:15,400
real-time classification of where the
 

1697
00:41:15,400 --> 00:41:18,120
real-time classification of where the
driver is looking Road left right center

1698
00:41:18,120 --> 00:41:18,130
driver is looking Road left right center
 

1699
00:41:18,130 --> 00:41:20,849
driver is looking Road left right center
stack instrument cluster and rearview

1700
00:41:20,849 --> 00:41:20,859
stack instrument cluster and rearview
 

1701
00:41:20,859 --> 00:41:26,940
stack instrument cluster and rearview
mirror and as I mentioned annotation

1702
00:41:26,940 --> 00:41:26,950
mirror and as I mentioned annotation
 

1703
00:41:26,950 --> 00:41:31,229
mirror and as I mentioned annotation
tooling is key so we have a total 5

1704
00:41:31,229 --> 00:41:31,239
tooling is key so we have a total 5
 

1705
00:41:31,239 --> 00:41:33,809
tooling is key so we have a total 5
billion video frames one and a half

1706
00:41:33,809 --> 00:41:33,819
billion video frames one and a half
 

1707
00:41:33,819 --> 00:41:41,190
billion video frames one and a half
billion of the face that would take tens

1708
00:41:41,190 --> 00:41:41,200
billion of the face that would take tens
 

1709
00:41:41,200 --> 00:41:43,109
billion of the face that would take tens
of millions of dollars to annotate just

1710
00:41:43,109 --> 00:41:43,119
of millions of dollars to annotate just
 

1711
00:41:43,119 --> 00:41:46,559
of millions of dollars to annotate just
for the glass classification fully so we

1712
00:41:46,559 --> 00:41:46,569
for the glass classification fully so we
 

1713
00:41:46,569 --> 00:41:49,620
for the glass classification fully so we
have to figure out what to annotate in

1714
00:41:49,620 --> 00:41:49,630
have to figure out what to annotate in
 

1715
00:41:49,630 --> 00:41:50,940
have to figure out what to annotate in
order to trade and you'll networks to

1716
00:41:50,940 --> 00:41:50,950
order to trade and you'll networks to
 

1717
00:41:50,950 --> 00:41:53,430
order to trade and you'll networks to
perform this task and what we annotate

1718
00:41:53,430 --> 00:41:53,440
perform this task and what we annotate
 

1719
00:41:53,440 --> 00:41:55,949
perform this task and what we annotate
is the things that the network is not

1720
00:41:55,949 --> 00:41:55,959
is the things that the network is not
 

1721
00:41:55,959 --> 00:41:58,259
is the things that the network is not
confident about the moments of

1722
00:41:58,259 --> 00:41:58,269
confident about the moments of
 

1723
00:41:58,269 --> 00:42:00,420
confident about the moments of
highlighting variation the partial

1724
00:42:00,420 --> 00:42:00,430
highlighting variation the partial
 

1725
00:42:00,430 --> 00:42:02,430
highlighting variation the partial
occlusions from the light or self

1726
00:42:02,430 --> 00:42:02,440
occlusions from the light or self
 

1727
00:42:02,440 --> 00:42:04,920
occlusions from the light or self
occlusion and the moving out of frame

1728
00:42:04,920 --> 00:42:04,930
occlusion and the moving out of frame
 

1729
00:42:04,930 --> 00:42:08,039
occlusion and the moving out of frame
the outer frame occlusions all the

1730
00:42:08,039 --> 00:42:08,049
the outer frame occlusions all the
 

1731
00:42:08,049 --> 00:42:10,410
the outer frame occlusions all the
difficult cases going from frame to

1732
00:42:10,410 --> 00:42:10,420
difficult cases going from frame to
 

1733
00:42:10,420 --> 00:42:12,479
difficult cases going from frame to
frame to frame here and the different

1734
00:42:12,479 --> 00:42:12,489
frame to frame here and the different
 

1735
00:42:12,489 --> 00:42:14,099
frame to frame here and the different
pipeline starting at the table going at

1736
00:42:14,099 --> 00:42:14,109
pipeline starting at the table going at
 

1737
00:42:14,109 --> 00:42:17,699
pipeline starting at the table going at
the bottom whenever the classification

1738
00:42:17,699 --> 00:42:17,709
the bottom whenever the classification
 

1739
00:42:17,709 --> 00:42:19,739
the bottom whenever the classification
has a low confidence we pass it to the

1740
00:42:19,739 --> 00:42:19,749
has a low confidence we pass it to the
 

1741
00:42:19,749 --> 00:42:22,410
has a low confidence we pass it to the
human it's simple we rely on the human

1742
00:42:22,410 --> 00:42:22,420
human it's simple we rely on the human
 

1743
00:42:22,420 --> 00:42:24,559
human it's simple we rely on the human
only when the classifier is not

1744
00:42:24,559 --> 00:42:24,569
only when the classifier is not
 

1745
00:42:24,569 --> 00:42:29,309
only when the classifier is not
confident and the fundamental trade-off

1746
00:42:29,309 --> 00:42:29,319
confident and the fundamental trade-off
 

1747
00:42:29,319 --> 00:42:32,789
confident and the fundamental trade-off
in all of these systems is what is the

1748
00:42:32,789 --> 00:42:32,799
in all of these systems is what is the
 

1749
00:42:32,799 --> 00:42:34,849
in all of these systems is what is the
accuracy we're willing to put up with

1750
00:42:34,849 --> 00:42:34,859
accuracy we're willing to put up with
 

1751
00:42:34,859 --> 00:42:37,949
accuracy we're willing to put up with
here in red and blue and red is human

1752
00:42:37,949 --> 00:42:37,959
here in red and blue and red is human
 

1753
00:42:37,959 --> 00:42:41,249
here in red and blue and red is human
choice decision and blue as a machine

1754
00:42:41,249 --> 00:42:41,259
choice decision and blue as a machine
 

1755
00:42:41,259 --> 00:42:45,779
choice decision and blue as a machine
tasks in red we select the video we want

1756
00:42:45,779 --> 00:42:45,789
tasks in red we select the video we want
 

1757
00:42:45,789 --> 00:42:51,809
tasks in red we select the video we want
to classify in blue the the the neural

1758
00:42:51,809 --> 00:42:51,819
to classify in blue the the the neural
 

1759
00:42:51,819 --> 00:42:54,049
to classify in blue the the the neural
network performs the face detection task

1760
00:42:54,049 --> 00:42:54,059
network performs the face detection task
 

1761
00:42:54,059 --> 00:42:56,579
network performs the face detection task
localizing the camera choosing what is

1762
00:42:56,579 --> 00:42:56,589
localizing the camera choosing what is
 

1763
00:42:56,589 --> 00:42:58,490
localizing the camera choosing what is
the angle of the camera

1764
00:42:58,490 --> 00:42:58,500
the angle of the camera
 

1765
00:42:58,500 --> 00:43:01,700
the angle of the camera
and provides a trade opportunity and

1766
00:43:01,700 --> 00:43:01,710
and provides a trade opportunity and
 

1767
00:43:01,710 --> 00:43:05,510
and provides a trade opportunity and
percent frames it can annotate so

1768
00:43:05,510 --> 00:43:05,520
percent frames it can annotate so
 

1769
00:43:05,520 --> 00:43:07,520
percent frames it can annotate so
certainly and you'll networking at a

1770
00:43:07,520 --> 00:43:07,530
certainly and you'll networking at a
 

1771
00:43:07,530 --> 00:43:09,770
certainly and you'll networking at a
glance for the entire data set they

1772
00:43:09,770 --> 00:43:09,780
glance for the entire data set they
 

1773
00:43:09,780 --> 00:43:12,170
glance for the entire data set they
would achieve accuracy in the case of

1774
00:43:12,170 --> 00:43:12,180
would achieve accuracy in the case of
 

1775
00:43:12,180 --> 00:43:16,540
would achieve accuracy in the case of
glass classification of nine low 90%

1776
00:43:16,540 --> 00:43:16,550
glass classification of nine low 90%
 

1777
00:43:16,550 --> 00:43:18,800
glass classification of nine low 90%
classification on the sixth glass task

1778
00:43:18,800 --> 00:43:18,810
classification on the sixth glass task
 

1779
00:43:18,810 --> 00:43:21,349
classification on the sixth glass task
now if you want a higher accuracy that

1780
00:43:21,349 --> 00:43:21,359
now if you want a higher accuracy that
 

1781
00:43:21,359 --> 00:43:23,030
now if you want a higher accuracy that
it will only be able to achieve that for

1782
00:43:23,030 --> 00:43:23,040
it will only be able to achieve that for
 

1783
00:43:23,040 --> 00:43:25,070
it will only be able to achieve that for
us for a smaller fraction of frames

1784
00:43:25,070 --> 00:43:25,080
us for a smaller fraction of frames
 

1785
00:43:25,080 --> 00:43:26,330
us for a smaller fraction of frames
that's the choice

1786
00:43:26,330 --> 00:43:26,340
that's the choice
 

1787
00:43:26,340 --> 00:43:30,109
that's the choice
and then a human has to go in and

1788
00:43:30,109 --> 00:43:30,119
and then a human has to go in and
 

1789
00:43:30,119 --> 00:43:34,580
and then a human has to go in and
perform the annotation of the frames

1790
00:43:34,580 --> 00:43:34,590
perform the annotation of the frames
 

1791
00:43:34,590 --> 00:43:36,620
perform the annotation of the frames
that the algorithm was not confident

1792
00:43:36,620 --> 00:43:36,630
that the algorithm was not confident
 

1793
00:43:36,630 --> 00:43:39,650
that the algorithm was not confident
about and it repeats over and over the

1794
00:43:39,650 --> 00:43:39,660
about and it repeats over and over the
 

1795
00:43:39,660 --> 00:43:41,630
about and it repeats over and over the
algorithm is then trained on the frames

1796
00:43:41,630 --> 00:43:41,640
algorithm is then trained on the frames
 

1797
00:43:41,640 --> 00:43:43,660
algorithm is then trained on the frames
that were annotated by the human and

1798
00:43:43,660 --> 00:43:43,670
that were annotated by the human and
 

1799
00:43:43,670 --> 00:43:45,890
that were annotated by the human and
repeats this process over and over on

1800
00:43:45,890 --> 00:43:45,900
repeats this process over and over on
 

1801
00:43:45,900 --> 00:43:47,390
repeats this process over and over on
the frames until everything is annotated

1802
00:43:47,390 --> 00:43:47,400
the frames until everything is annotated
 

1803
00:43:47,400 --> 00:43:53,030
the frames until everything is annotated
yes yes absolutely

1804
00:43:53,030 --> 00:43:53,040
yes yes absolutely
 

1805
00:43:53,040 --> 00:43:55,640
yes yes absolutely
the question was do you ever observe

1806
00:43:55,640 --> 00:43:55,650
the question was do you ever observe
 

1807
00:43:55,650 --> 00:43:57,770
the question was do you ever observe
that the classifier is highly confident

1808
00:43:57,770 --> 00:43:57,780
that the classifier is highly confident
 

1809
00:43:57,780 --> 00:44:03,440
that the classifier is highly confident
about the incorrect class yep right

1810
00:44:03,440 --> 00:44:03,450
about the incorrect class yep right
 

1811
00:44:03,450 --> 00:44:06,040
about the incorrect class yep right
question was hot well then how do you

1812
00:44:06,040 --> 00:44:06,050
question was hot well then how do you
 

1813
00:44:06,050 --> 00:44:07,880
question was hot well then how do you
how do you deal with that how do you

1814
00:44:07,880 --> 00:44:07,890
how do you deal with that how do you
 

1815
00:44:07,890 --> 00:44:10,310
how do you deal with that how do you
account for that how do you account for

1816
00:44:10,310 --> 00:44:10,320
account for that how do you account for
 

1817
00:44:10,320 --> 00:44:12,910
account for that how do you account for
the fact that highly confident

1818
00:44:12,910 --> 00:44:12,920
the fact that highly confident
 

1819
00:44:12,920 --> 00:44:17,120
the fact that highly confident
predictions can be highly wrong yeah

1820
00:44:17,120 --> 00:44:17,130
predictions can be highly wrong yeah
 

1821
00:44:17,130 --> 00:44:20,300
predictions can be highly wrong yeah
false positives false positives that

1822
00:44:20,300 --> 00:44:20,310
false positives false positives that
 

1823
00:44:20,310 --> 00:44:23,210
false positives false positives that
you're really confident in there there's

1824
00:44:23,210 --> 00:44:23,220
you're really confident in there there's
 

1825
00:44:23,220 --> 00:44:25,040
you're really confident in there there's
no at least in our experience there's no

1826
00:44:25,040 --> 00:44:25,050
no at least in our experience there's no
 

1827
00:44:25,050 --> 00:44:27,740
no at least in our experience there's no
good answer for that except more more

1828
00:44:27,740 --> 00:44:27,750
good answer for that except more more
 

1829
00:44:27,750 --> 00:44:29,030
good answer for that except more more
and more training data on the things

1830
00:44:29,030 --> 00:44:29,040
and more training data on the things
 

1831
00:44:29,040 --> 00:44:31,070
and more training data on the things
you're not confident about that usually

1832
00:44:31,070 --> 00:44:31,080
you're not confident about that usually
 

1833
00:44:31,080 --> 00:44:35,270
you're not confident about that usually
seems to deal generalize over cases we

1834
00:44:35,270 --> 00:44:35,280
seems to deal generalize over cases we
 

1835
00:44:35,280 --> 00:44:37,760
seems to deal generalize over cases we
don't encounter obvious large categories

1836
00:44:37,760 --> 00:44:37,770
don't encounter obvious large categories
 

1837
00:44:37,770 --> 00:44:42,560
don't encounter obvious large categories
of data where you're really confident

1838
00:44:42,560 --> 00:44:42,570
of data where you're really confident
 

1839
00:44:42,570 --> 00:44:46,010
of data where you're really confident
about the wrong thing usually some

1840
00:44:46,010 --> 00:44:46,020
about the wrong thing usually some
 

1841
00:44:46,020 --> 00:44:48,500
about the wrong thing usually some
degree of human annotation fixes most

1842
00:44:48,500 --> 00:44:48,510
degree of human annotation fixes most
 

1843
00:44:48,510 --> 00:44:50,710
degree of human annotation fixes most
problems

1844
00:44:50,710 --> 00:44:50,720
problems
 

1845
00:44:50,720 --> 00:44:53,620
problems
annotating the low the low confidence

1846
00:44:53,620 --> 00:44:53,630
annotating the low the low confidence
 

1847
00:44:53,630 --> 00:44:57,360
annotating the low the low confidence
part of the data

1848
00:44:57,360 --> 00:44:57,370

 

1849
00:44:57,370 --> 00:45:02,250

solves all incorrect issues but of

1850
00:45:02,250 --> 00:45:02,260
solves all incorrect issues but of
 

1851
00:45:02,260 --> 00:45:04,500
solves all incorrect issues but of
course that's not always true in the

1852
00:45:04,500 --> 00:45:04,510
course that's not always true in the
 

1853
00:45:04,510 --> 00:45:06,660
course that's not always true in the
general case that you can imagine a lot

1854
00:45:06,660 --> 00:45:06,670
general case that you can imagine a lot
 

1855
00:45:06,670 --> 00:45:11,970
general case that you can imagine a lot
of scenarios whether that's not true for

1856
00:45:11,970 --> 00:45:11,980
of scenarios whether that's not true for
 

1857
00:45:11,980 --> 00:45:14,630
of scenarios whether that's not true for
example one one one thing they always

1858
00:45:14,630 --> 00:45:14,640
example one one one thing they always
 

1859
00:45:14,640 --> 00:45:19,230
example one one one thing they always
perform is for each individual person we

1860
00:45:19,230 --> 00:45:19,240
perform is for each individual person we
 

1861
00:45:19,240 --> 00:45:21,030
perform is for each individual person we
usually entertain a large amount of the

1862
00:45:21,030 --> 00:45:21,040
usually entertain a large amount of the
 

1863
00:45:21,040 --> 00:45:23,850
usually entertain a large amount of the
data manually no matter what so we have

1864
00:45:23,850 --> 00:45:23,860
data manually no matter what so we have
 

1865
00:45:23,860 --> 00:45:25,320
data manually no matter what so we have
to make sure that the neural network has

1866
00:45:25,320 --> 00:45:25,330
to make sure that the neural network has
 

1867
00:45:25,330 --> 00:45:28,350
to make sure that the neural network has
seen that person in the various and the

1868
00:45:28,350 --> 00:45:28,360
seen that person in the various and the
 

1869
00:45:28,360 --> 00:45:30,450
seen that person in the various and the
various ways their face looks like with

1870
00:45:30,450 --> 00:45:30,460
various ways their face looks like with
 

1871
00:45:30,460 --> 00:45:33,480
various ways their face looks like with
glasses with different hair with

1872
00:45:33,480 --> 00:45:33,490
glasses with different hair with
 

1873
00:45:33,490 --> 00:45:36,990
glasses with different hair with
different a lighting variation so we

1874
00:45:36,990 --> 00:45:37,000
different a lighting variation so we
 

1875
00:45:37,000 --> 00:45:38,550
different a lighting variation so we
want to manually annotate that it's

1876
00:45:38,550 --> 00:45:38,560
want to manually annotate that it's
 

1877
00:45:38,560 --> 00:45:40,110
want to manually annotate that it's
overtime we're allowing the machine to

1878
00:45:40,110 --> 00:45:40,120
overtime we're allowing the machine to
 

1879
00:45:40,120 --> 00:45:41,360
overtime we're allowing the machine to
do more and more of the work

1880
00:45:41,360 --> 00:45:41,370
do more and more of the work
 

1881
00:45:41,370 --> 00:45:44,040
do more and more of the work
so what's resulting in this in the

1882
00:45:44,040 --> 00:45:44,050
so what's resulting in this in the
 

1883
00:45:44,050 --> 00:45:45,720
so what's resulting in this in the
glance classification cases you can do

1884
00:45:45,720 --> 00:45:45,730
glance classification cases you can do
 

1885
00:45:45,730 --> 00:45:47,280
glance classification cases you can do
real-time classification you can give

1886
00:45:47,280 --> 00:45:47,290
real-time classification you can give
 

1887
00:45:47,290 --> 00:45:49,140
real-time classification you can give
the car information about whether the

1888
00:45:49,140 --> 00:45:49,150
the car information about whether the
 

1889
00:45:49,150 --> 00:45:50,730
the car information about whether the
driver is looking on road or off road

1890
00:45:50,730 --> 00:45:50,740
driver is looking on road or off road
 

1891
00:45:50,740 --> 00:45:52,920
driver is looking on road or off road
this is critical information for the car

1892
00:45:52,920 --> 00:45:52,930
this is critical information for the car
 

1893
00:45:52,930 --> 00:45:54,750
this is critical information for the car
to understand and you want to pause for

1894
00:45:54,750 --> 00:45:54,760
to understand and you want to pause for
 

1895
00:45:54,760 --> 00:45:57,030
to understand and you want to pause for
a second to realize that when you're

1896
00:45:57,030 --> 00:45:57,040
a second to realize that when you're
 

1897
00:45:57,040 --> 00:45:59,310
a second to realize that when you're
driving a car for those our driver for

1898
00:45:59,310 --> 00:45:59,320
driving a car for those our driver for
 

1899
00:45:59,320 --> 00:46:01,050
driving a car for those our driver for
those that driven any kind of car with

1900
00:46:01,050 --> 00:46:01,060
those that driven any kind of car with
 

1901
00:46:01,060 --> 00:46:04,440
those that driven any kind of car with
any kind of automation it has no idea

1902
00:46:04,440 --> 00:46:04,450
any kind of automation it has no idea
 

1903
00:46:04,450 --> 00:46:07,050
any kind of automation it has no idea
about what you're up to at all there's

1904
00:46:07,050 --> 00:46:07,060
about what you're up to at all there's
 

1905
00:46:07,060 --> 00:46:09,150
about what you're up to at all there's
no it doesn't have any information about

1906
00:46:09,150 --> 00:46:09,160
no it doesn't have any information about
 

1907
00:46:09,160 --> 00:46:11,280
no it doesn't have any information about
the driver except if they're touching

1908
00:46:11,280 --> 00:46:11,290
the driver except if they're touching
 

1909
00:46:11,290 --> 00:46:13,350
the driver except if they're touching
the steering wheel or not more and more

1910
00:46:13,350 --> 00:46:13,360
the steering wheel or not more and more
 

1911
00:46:13,360 --> 00:46:15,690
the steering wheel or not more and more
now with the GM supercruise vehicle and

1912
00:46:15,690 --> 00:46:15,700
now with the GM supercruise vehicle and
 

1913
00:46:15,700 --> 00:46:18,000
now with the GM supercruise vehicle and
Tesla now has added a dryer facing

1914
00:46:18,000 --> 00:46:18,010
Tesla now has added a dryer facing
 

1915
00:46:18,010 --> 00:46:20,220
Tesla now has added a dryer facing
camera that slowly started to think

1916
00:46:20,220 --> 00:46:20,230
camera that slowly started to think
 

1917
00:46:20,230 --> 00:46:23,340
camera that slowly started to think
about moving towards perceiving the

1918
00:46:23,340 --> 00:46:23,350
about moving towards perceiving the
 

1919
00:46:23,350 --> 00:46:25,410
about moving towards perceiving the
driver but most vehicles on the road

1920
00:46:25,410 --> 00:46:25,420
driver but most vehicles on the road
 

1921
00:46:25,420 --> 00:46:27,090
driver but most vehicles on the road
today have no knowledge of the driver

1922
00:46:27,090 --> 00:46:27,100
today have no knowledge of the driver
 

1923
00:46:27,100 --> 00:46:29,970
today have no knowledge of the driver
this knowledge is almost common sense

1924
00:46:29,970 --> 00:46:29,980
this knowledge is almost common sense
 

1925
00:46:29,980 --> 00:46:33,600
this knowledge is almost common sense
and trivial for the car to have the it's

1926
00:46:33,600 --> 00:46:33,610
and trivial for the car to have the it's
 

1927
00:46:33,610 --> 00:46:35,040
and trivial for the car to have the it's
common sense how important this

1928
00:46:35,040 --> 00:46:35,050
common sense how important this
 

1929
00:46:35,050 --> 00:46:37,440
common sense how important this
information is where the driver is

1930
00:46:37,440 --> 00:46:37,450
information is where the driver is
 

1931
00:46:37,450 --> 00:46:39,390
information is where the driver is
looking that's the glance classification

1932
00:46:39,390 --> 00:46:39,400
looking that's the glance classification
 

1933
00:46:39,400 --> 00:46:43,320
looking that's the glance classification
problem and again emphasizing that we've

1934
00:46:43,320 --> 00:46:43,330
problem and again emphasizing that we've
 

1935
00:46:43,330 --> 00:46:46,650
problem and again emphasizing that we've
converted it's been three decades of

1936
00:46:46,650 --> 00:46:46,660
converted it's been three decades of
 

1937
00:46:46,660 --> 00:46:48,780
converted it's been three decades of
work on gaze estimation yet gaze

1938
00:46:48,780 --> 00:46:48,790
work on gaze estimation yet gaze
 

1939
00:46:48,790 --> 00:46:50,460
work on gaze estimation yet gaze
estimation is doing head pose estimation

1940
00:46:50,460 --> 00:46:50,470
estimation is doing head pose estimation
 

1941
00:46:50,470 --> 00:46:53,070
estimation is doing head pose estimation
so the geometric orientation of the head

1942
00:46:53,070 --> 00:46:53,080
so the geometric orientation of the head
 

1943
00:46:53,080 --> 00:46:55,320
so the geometric orientation of the head
combining the orientation of the eyes

1944
00:46:55,320 --> 00:46:55,330
combining the orientation of the eyes
 

1945
00:46:55,330 --> 00:46:57,990
combining the orientation of the eyes
and using that combined information to

1946
00:46:57,990 --> 00:46:58,000
and using that combined information to
 

1947
00:46:58,000 --> 00:46:59,840
and using that combined information to
determine where the person is looking

1948
00:46:59,840 --> 00:46:59,850
determine where the person is looking
 

1949
00:46:59,850 --> 00:47:02,340
determine where the person is looking
will convert that into a classification

1950
00:47:02,340 --> 00:47:02,350
will convert that into a classification
 

1951
00:47:02,350 --> 00:47:04,830
will convert that into a classification
problem so the standard gaze estimation

1952
00:47:04,830 --> 00:47:04,840
problem so the standard gaze estimation
 

1953
00:47:04,840 --> 00:47:06,510
problem so the standard gaze estimation
definition is not a machine learning

1954
00:47:06,510 --> 00:47:06,520
definition is not a machine learning
 

1955
00:47:06,520 --> 00:47:08,960
definition is not a machine learning
problem

1956
00:47:08,960 --> 00:47:08,970

 

1957
00:47:08,970 --> 00:47:10,339

classification is a machine learning

1958
00:47:10,339 --> 00:47:10,349
classification is a machine learning
 

1959
00:47:10,349 --> 00:47:13,089
classification is a machine learning
problem this transformation is key

1960
00:47:13,089 --> 00:47:13,099
problem this transformation is key
 

1961
00:47:13,099 --> 00:47:17,810
problem this transformation is key
emotion human emotion is a fascinating

1962
00:47:17,810 --> 00:47:17,820
emotion human emotion is a fascinating
 

1963
00:47:17,820 --> 00:47:22,030
emotion human emotion is a fascinating
thing so the same kind of pipeline

1964
00:47:22,030 --> 00:47:22,040
thing so the same kind of pipeline
 

1965
00:47:22,040 --> 00:47:24,589
thing so the same kind of pipeline
stabilization cleaning of the data raw

1966
00:47:24,589 --> 00:47:24,599
stabilization cleaning of the data raw
 

1967
00:47:24,599 --> 00:47:27,140
stabilization cleaning of the data raw
pixels in and then the classification is

1968
00:47:27,140 --> 00:47:27,150
pixels in and then the classification is
 

1969
00:47:27,150 --> 00:47:30,950
pixels in and then the classification is
emotion the problem with emotion if I

1970
00:47:30,950 --> 00:47:30,960
emotion the problem with emotion if I
 

1971
00:47:30,960 --> 00:47:36,740
emotion the problem with emotion if I
may speak as an expert human not am NOT

1972
00:47:36,740 --> 00:47:36,750
may speak as an expert human not am NOT
 

1973
00:47:36,750 --> 00:47:38,210
may speak as an expert human not am NOT
an expert in emotion is just an expert

1974
00:47:38,210 --> 00:47:38,220
an expert in emotion is just an expert
 

1975
00:47:38,220 --> 00:47:41,480
an expert in emotion is just an expert
of being human is that there is a lot of

1976
00:47:41,480 --> 00:47:41,490
of being human is that there is a lot of
 

1977
00:47:41,490 --> 00:47:43,580
of being human is that there is a lot of
ways that's a sodomize emotion to

1978
00:47:43,580 --> 00:47:43,590
ways that's a sodomize emotion to
 

1979
00:47:43,590 --> 00:47:47,589
ways that's a sodomize emotion to
categorize emotion to define emotion

1980
00:47:47,589 --> 00:47:47,599
categorize emotion to define emotion
 

1981
00:47:47,599 --> 00:47:50,540
categorize emotion to define emotion
whether that's for the the primary

1982
00:47:50,540 --> 00:47:50,550
whether that's for the the primary
 

1983
00:47:50,550 --> 00:47:52,400
whether that's for the the primary
emotion of the para scale would love joy

1984
00:47:52,400 --> 00:47:52,410
emotion of the para scale would love joy
 

1985
00:47:52,410 --> 00:47:55,190
emotion of the para scale would love joy
surprise anger sadness fear there's a

1986
00:47:55,190 --> 00:47:55,200
surprise anger sadness fear there's a
 

1987
00:47:55,200 --> 00:47:57,500
surprise anger sadness fear there's a
lot of ways to mix those together to

1988
00:47:57,500 --> 00:47:57,510
lot of ways to mix those together to
 

1989
00:47:57,510 --> 00:47:59,120
lot of ways to mix those together to
break those apart into hierarchical

1990
00:47:59,120 --> 00:47:59,130
break those apart into hierarchical
 

1991
00:47:59,130 --> 00:48:02,900
break those apart into hierarchical
taxonomies and the way we think about it

1992
00:48:02,900 --> 00:48:02,910
taxonomies and the way we think about it
 

1993
00:48:02,910 --> 00:48:05,420
taxonomies and the way we think about it
in the driving context at least there is

1994
00:48:05,420 --> 00:48:05,430
in the driving context at least there is
 

1995
00:48:05,430 --> 00:48:09,080
in the driving context at least there is
a general emotion recognition task sort

1996
00:48:09,080 --> 00:48:09,090
a general emotion recognition task sort
 

1997
00:48:09,090 --> 00:48:12,290
a general emotion recognition task sort
of I mentioned I'll mention it but it's

1998
00:48:12,290 --> 00:48:12,300
of I mentioned I'll mention it but it's
 

1999
00:48:12,300 --> 00:48:14,150
of I mentioned I'll mention it but it's
kind of how we think about primary

2000
00:48:14,150 --> 00:48:14,160
kind of how we think about primary
 

2001
00:48:14,160 --> 00:48:17,900
kind of how we think about primary
emotions is detecting the the broad

2002
00:48:17,900 --> 00:48:17,910
emotions is detecting the the broad
 

2003
00:48:17,910 --> 00:48:20,480
emotions is detecting the the broad
categories of emotion of joy and anger

2004
00:48:20,480 --> 00:48:20,490
categories of emotion of joy and anger
 

2005
00:48:20,490 --> 00:48:24,200
categories of emotion of joy and anger
of disgust and surprise and then there

2006
00:48:24,200 --> 00:48:24,210
of disgust and surprise and then there
 

2007
00:48:24,210 --> 00:48:26,810
of disgust and surprise and then there
is application specific emotion

2008
00:48:26,810 --> 00:48:26,820
is application specific emotion
 

2009
00:48:26,820 --> 00:48:29,089
is application specific emotion
recognition where you're using the

2010
00:48:29,089 --> 00:48:29,099
recognition where you're using the
 

2011
00:48:29,099 --> 00:48:31,730
recognition where you're using the
facial expressions that all the various

2012
00:48:31,730 --> 00:48:31,740
facial expressions that all the various
 

2013
00:48:31,740 --> 00:48:33,460
facial expressions that all the various
ways that we can deform our face to

2014
00:48:33,460 --> 00:48:33,470
ways that we can deform our face to
 

2015
00:48:33,470 --> 00:48:38,770
ways that we can deform our face to
communicate information to determine the

2016
00:48:38,770 --> 00:48:38,780
communicate information to determine the
 

2017
00:48:38,780 --> 00:48:41,990
communicate information to determine the
specific question about the interaction

2018
00:48:41,990 --> 00:48:42,000
specific question about the interaction
 

2019
00:48:42,000 --> 00:48:45,079
specific question about the interaction
of the driver so I'll first for the

2020
00:48:45,079 --> 00:48:45,089
of the driver so I'll first for the
 

2021
00:48:45,089 --> 00:48:47,270
of the driver so I'll first for the
general case these are the building

2022
00:48:47,270 --> 00:48:47,280
general case these are the building
 

2023
00:48:47,280 --> 00:48:49,670
general case these are the building
blocks I mean there's there's countless

2024
00:48:49,670 --> 00:48:49,680
blocks I mean there's there's countless
 

2025
00:48:49,680 --> 00:48:53,240
blocks I mean there's there's countless
ways of deforming the face that we use

2026
00:48:53,240 --> 00:48:53,250
ways of deforming the face that we use
 

2027
00:48:53,250 --> 00:48:54,980
ways of deforming the face that we use
to communicate with each other there's

2028
00:48:54,980 --> 00:48:54,990
to communicate with each other there's
 

2029
00:48:54,990 --> 00:48:59,700
to communicate with each other there's
42 individual facial muscles that can be

2030
00:48:59,700 --> 00:48:59,710
42 individual facial muscles that can be
 

2031
00:48:59,710 --> 00:49:06,060
42 individual facial muscles that can be
used to form those expressions one of

2032
00:49:06,060 --> 00:49:06,070
used to form those expressions one of
 

2033
00:49:06,070 --> 00:49:06,810
used to form those expressions one of
our favorite

2034
00:49:06,810 --> 00:49:06,820
our favorite
 

2035
00:49:06,820 --> 00:49:09,480
our favorite
work with is the effective SDK this is

2036
00:49:09,480 --> 00:49:09,490
work with is the effective SDK this is
 

2037
00:49:09,490 --> 00:49:11,400
work with is the effective SDK this is
their their their task with the general

2038
00:49:11,400 --> 00:49:11,410
their their their task with the general
 

2039
00:49:11,410 --> 00:49:15,140
their their their task with the general
emotion recognition task is taking in

2040
00:49:15,140 --> 00:49:15,150
emotion recognition task is taking in
 

2041
00:49:15,150 --> 00:49:18,390
emotion recognition task is taking in
raw pixels and determining categories of

2042
00:49:18,390 --> 00:49:18,400
raw pixels and determining categories of
 

2043
00:49:18,400 --> 00:49:20,850
raw pixels and determining categories of
emotion very subtleties of that emotion

2044
00:49:20,850 --> 00:49:20,860
emotion very subtleties of that emotion
 

2045
00:49:20,860 --> 00:49:23,310
emotion very subtleties of that emotion
in the general case producing a

2046
00:49:23,310 --> 00:49:23,320
in the general case producing a
 

2047
00:49:23,320 --> 00:49:25,860
in the general case producing a
classification of anger disgust fear

2048
00:49:25,860 --> 00:49:25,870
classification of anger disgust fear
 

2049
00:49:25,870 --> 00:49:30,540
classification of anger disgust fear
surprise so on and then mapping I mean

2050
00:49:30,540 --> 00:49:30,550
surprise so on and then mapping I mean
 

2051
00:49:30,550 --> 00:49:31,890
surprise so on and then mapping I mean
essentially what these algorithms are

2052
00:49:31,890 --> 00:49:31,900
essentially what these algorithms are
 

2053
00:49:31,900 --> 00:49:33,480
essentially what these algorithms are
doing whether whether they using deep

2054
00:49:33,480 --> 00:49:33,490
doing whether whether they using deep
 

2055
00:49:33,490 --> 00:49:35,460
doing whether whether they using deep
neural networks or not whether using

2056
00:49:35,460 --> 00:49:35,470
neural networks or not whether using
 

2057
00:49:35,470 --> 00:49:37,170
neural networks or not whether using
face alignment to do the landmark

2058
00:49:37,170 --> 00:49:37,180
face alignment to do the landmark
 

2059
00:49:37,180 --> 00:49:39,000
face alignment to do the landmark
detection and then tracking those

2060
00:49:39,000 --> 00:49:39,010
detection and then tracking those
 

2061
00:49:39,010 --> 00:49:40,830
detection and then tracking those
landmarks over time to do the facial

2062
00:49:40,830 --> 00:49:40,840
landmarks over time to do the facial
 

2063
00:49:40,840 --> 00:49:43,200
landmarks over time to do the facial
actions they're determined they're

2064
00:49:43,200 --> 00:49:43,210
actions they're determined they're
 

2065
00:49:43,210 --> 00:49:46,440
actions they're determined they're
mapping the expressions the component

2066
00:49:46,440 --> 00:49:46,450
mapping the expressions the component
 

2067
00:49:46,450 --> 00:49:47,850
mapping the expressions the component
their various expressions who can make

2068
00:49:47,850 --> 00:49:47,860
their various expressions who can make
 

2069
00:49:47,860 --> 00:49:49,380
their various expressions who can make
with their eyebrows or their nose and

2070
00:49:49,380 --> 00:49:49,390
with their eyebrows or their nose and
 

2071
00:49:49,390 --> 00:49:54,150
with their eyebrows or their nose and
mouth and eyes to map them to the

2072
00:49:54,150 --> 00:49:54,160
mouth and eyes to map them to the
 

2073
00:49:54,160 --> 00:49:56,220
mouth and eyes to map them to the
emotion so I'd like to highlight one

2074
00:49:56,220 --> 00:49:56,230
emotion so I'd like to highlight one
 

2075
00:49:56,230 --> 00:49:57,870
emotion so I'd like to highlight one
because I think it's an illustrative one

2076
00:49:57,870 --> 00:49:57,880
because I think it's an illustrative one
 

2077
00:49:57,880 --> 00:50:02,270
because I think it's an illustrative one
for joy an expression of joy is smiling

2078
00:50:02,270 --> 00:50:02,280
for joy an expression of joy is smiling
 

2079
00:50:02,280 --> 00:50:05,100
for joy an expression of joy is smiling
so there's an increased likelihood that

2080
00:50:05,100 --> 00:50:05,110
so there's an increased likelihood that
 

2081
00:50:05,110 --> 00:50:07,770
so there's an increased likelihood that
you observe a smiling expression on the

2082
00:50:07,770 --> 00:50:07,780
you observe a smiling expression on the
 

2083
00:50:07,780 --> 00:50:10,440
you observe a smiling expression on the
face when joy is experienced or vice

2084
00:50:10,440 --> 00:50:10,450
face when joy is experienced or vice
 

2085
00:50:10,450 --> 00:50:12,180
face when joy is experienced or vice
versa if there's an increased

2086
00:50:12,180 --> 00:50:12,190
versa if there's an increased
 

2087
00:50:12,190 --> 00:50:15,510
versa if there's an increased
probability of a smile there's an

2088
00:50:15,510 --> 00:50:15,520
probability of a smile there's an
 

2089
00:50:15,520 --> 00:50:17,280
probability of a smile there's an
increased probability of emotion of joy

2090
00:50:17,280 --> 00:50:17,290
increased probability of emotion of joy
 

2091
00:50:17,290 --> 00:50:20,610
increased probability of emotion of joy
being experienced and then joy an

2092
00:50:20,610 --> 00:50:20,620
being experienced and then joy an
 

2093
00:50:20,620 --> 00:50:22,710
being experienced and then joy an
experience has a decreased probability

2094
00:50:22,710 --> 00:50:22,720
experience has a decreased probability
 

2095
00:50:22,720 --> 00:50:25,530
experience has a decreased probability
likelihood of brow raising and brow

2096
00:50:25,530 --> 00:50:25,540
likelihood of brow raising and brow
 

2097
00:50:25,540 --> 00:50:30,180
likelihood of brow raising and brow
following so if you see a smile that's a

2098
00:50:30,180 --> 00:50:30,190
following so if you see a smile that's a
 

2099
00:50:30,190 --> 00:50:33,420
following so if you see a smile that's a
that's a plus for joy if you see brow

2100
00:50:33,420 --> 00:50:33,430
that's a plus for joy if you see brow
 

2101
00:50:33,430 --> 00:50:34,500
that's a plus for joy if you see brow
raised bright for Oh

2102
00:50:34,500 --> 00:50:34,510
raised bright for Oh
 

2103
00:50:34,510 --> 00:50:38,100
raised bright for Oh
brow furrow is a minus for joy that's

2104
00:50:38,100 --> 00:50:38,110
brow furrow is a minus for joy that's
 

2105
00:50:38,110 --> 00:50:39,480
brow furrow is a minus for joy that's
for the general emotional recognition

2106
00:50:39,480 --> 00:50:39,490
for the general emotional recognition
 

2107
00:50:39,490 --> 00:50:41,160
for the general emotional recognition
task that's been well studied that's

2108
00:50:41,160 --> 00:50:41,170
task that's been well studied that's
 

2109
00:50:41,170 --> 00:50:42,720
task that's been well studied that's
sort of the core of affective computing

2110
00:50:42,720 --> 00:50:42,730
sort of the core of affective computing
 

2111
00:50:42,730 --> 00:50:44,370
sort of the core of affective computing
movement from from the visual

2112
00:50:44,370 --> 00:50:44,380
movement from from the visual
 

2113
00:50:44,380 --> 00:50:45,630
movement from from the visual
perspective again from the computer

2114
00:50:45,630 --> 00:50:45,640
perspective again from the computer
 

2115
00:50:45,640 --> 00:50:48,000
perspective again from the computer
vision perspective from the application

2116
00:50:48,000 --> 00:50:48,010
vision perspective from the application
 

2117
00:50:48,010 --> 00:50:50,760
vision perspective from the application
of specific perspective which were

2118
00:50:50,760 --> 00:50:50,770
of specific perspective which were
 

2119
00:50:50,770 --> 00:50:53,100
of specific perspective which were
really focused on again data is

2120
00:50:53,100 --> 00:50:53,110
really focused on again data is
 

2121
00:50:53,110 --> 00:50:55,140
really focused on again data is
everything what what are you annotating

2122
00:50:55,140 --> 00:50:55,150
everything what what are you annotating
 

2123
00:50:55,150 --> 00:50:58,110
everything what what are you annotating
we can take here we have a large-scale

2124
00:50:58,110 --> 00:50:58,120
we can take here we have a large-scale
 

2125
00:50:58,120 --> 00:51:00,360
we can take here we have a large-scale
data set of drivers interacting with a

2126
00:51:00,360 --> 00:51:00,370
data set of drivers interacting with a
 

2127
00:51:00,370 --> 00:51:03,330
data set of drivers interacting with a
voice based navigation system so they're

2128
00:51:03,330 --> 00:51:03,340
voice based navigation system so they're
 

2129
00:51:03,340 --> 00:51:05,880
voice based navigation system so they're
tasked with in various vehicles to enter

2130
00:51:05,880 --> 00:51:05,890
tasked with in various vehicles to enter
 

2131
00:51:05,890 --> 00:51:09,030
tasked with in various vehicles to enter
a navigation so with they're talking to

2132
00:51:09,030 --> 00:51:09,040
a navigation so with they're talking to
 

2133
00:51:09,040 --> 00:51:11,610
a navigation so with they're talking to
their GPS using their voice this is for

2134
00:51:11,610 --> 00:51:11,620
their GPS using their voice this is for
 

2135
00:51:11,620 --> 00:51:13,050
their GPS using their voice this is for
depending on the vehicle depending on

2136
00:51:13,050 --> 00:51:13,060
depending on the vehicle depending on
 

2137
00:51:13,060 --> 00:51:15,270
depending on the vehicle depending on
the system in most cases an incredibly

2138
00:51:15,270 --> 00:51:15,280
the system in most cases an incredibly
 

2139
00:51:15,280 --> 00:51:17,460
the system in most cases an incredibly
frustrating experience so we have them

2140
00:51:17,460 --> 00:51:17,470
frustrating experience so we have them
 

2141
00:51:17,470 --> 00:51:19,030
frustrating experience so we have them
perform this task and then

2142
00:51:19,030 --> 00:51:19,040
perform this task and then
 

2143
00:51:19,040 --> 00:51:22,420
perform this task and then
the annotation is self-report after the

2144
00:51:22,420 --> 00:51:22,430
the annotation is self-report after the
 

2145
00:51:22,430 --> 00:51:24,810
the annotation is self-report after the
task they say on a scale of 1 to 10 how

2146
00:51:24,810 --> 00:51:24,820
task they say on a scale of 1 to 10 how
 

2147
00:51:24,820 --> 00:51:27,730
task they say on a scale of 1 to 10 how
frustrating was this experience and when

2148
00:51:27,730 --> 00:51:27,740
frustrating was this experience and when
 

2149
00:51:27,740 --> 00:51:32,140
frustrating was this experience and when
you see on top is is the expressions

2150
00:51:32,140 --> 00:51:32,150
you see on top is is the expressions
 

2151
00:51:32,150 --> 00:51:35,350
you see on top is is the expressions
detected and associated with a satisfied

2152
00:51:35,350 --> 00:51:35,360
detected and associated with a satisfied
 

2153
00:51:35,360 --> 00:51:38,620
detected and associated with a satisfied
a person who said a a 10 on the

2154
00:51:38,620 --> 00:51:38,630
a person who said a a 10 on the
 

2155
00:51:38,630 --> 00:51:41,680
a person who said a a 10 on the
satisfaction so a 1 in the frustration

2156
00:51:41,680 --> 00:51:41,690
satisfaction so a 1 in the frustration
 

2157
00:51:41,690 --> 00:51:44,740
satisfaction so a 1 in the frustration
scale was perfectly satisfied with a

2158
00:51:44,740 --> 00:51:44,750
scale was perfectly satisfied with a
 

2159
00:51:44,750 --> 00:51:47,760
scale was perfectly satisfied with a
voice based interaction on the bottom is

2160
00:51:47,760 --> 00:51:47,770
voice based interaction on the bottom is
 

2161
00:51:47,770 --> 00:51:51,940
voice based interaction on the bottom is
frustrated as a believin 9 on the

2162
00:51:51,940 --> 00:51:51,950
frustrated as a believin 9 on the
 

2163
00:51:51,950 --> 00:51:56,350
frustrated as a believin 9 on the
frustration scale so the feature the

2164
00:51:56,350 --> 00:51:56,360
frustration scale so the feature the
 

2165
00:51:56,360 --> 00:51:58,360
frustration scale so the feature the
strongest there the expression remember

2166
00:51:58,360 --> 00:51:58,370
strongest there the expression remember
 

2167
00:51:58,370 --> 00:52:01,810
strongest there the expression remember
joy smile was the strongest indicator of

2168
00:52:01,810 --> 00:52:01,820
joy smile was the strongest indicator of
 

2169
00:52:01,820 --> 00:52:03,910
joy smile was the strongest indicator of
frustration for all our subjects that

2170
00:52:03,910 --> 00:52:03,920
frustration for all our subjects that
 

2171
00:52:03,920 --> 00:52:06,070
frustration for all our subjects that
was the strongest expression smile was

2172
00:52:06,070 --> 00:52:06,080
was the strongest expression smile was
 

2173
00:52:06,080 --> 00:52:08,250
was the strongest expression smile was
the thing that was always there for

2174
00:52:08,250 --> 00:52:08,260
the thing that was always there for
 

2175
00:52:08,260 --> 00:52:12,150
the thing that was always there for
frustration there's other various

2176
00:52:12,150 --> 00:52:12,160
frustration there's other various
 

2177
00:52:12,160 --> 00:52:14,530
frustration there's other various
frowning that followed and shaking the

2178
00:52:14,530 --> 00:52:14,540
frowning that followed and shaking the
 

2179
00:52:14,540 --> 00:52:17,500
frowning that followed and shaking the
head and so on but smiles were there so

2180
00:52:17,500 --> 00:52:17,510
head and so on but smiles were there so
 

2181
00:52:17,510 --> 00:52:19,240
head and so on but smiles were there so
that shows you the kind of clean

2182
00:52:19,240 --> 00:52:19,250
that shows you the kind of clean
 

2183
00:52:19,250 --> 00:52:21,640
that shows you the kind of clean
difference between general emotion

2184
00:52:21,640 --> 00:52:21,650
difference between general emotion
 

2185
00:52:21,650 --> 00:52:23,020
difference between general emotion
recognition tasks and the

2186
00:52:23,020 --> 00:52:23,030
recognition tasks and the
 

2187
00:52:23,030 --> 00:52:24,190
recognition tasks and the
application-specific

2188
00:52:24,190 --> 00:52:24,200
application-specific
 

2189
00:52:24,200 --> 00:52:27,690
application-specific
here perhaps they enjoyed an absurd

2190
00:52:27,690 --> 00:52:27,700
here perhaps they enjoyed an absurd
 

2191
00:52:27,700 --> 00:52:31,000
here perhaps they enjoyed an absurd
moment of joy at the frustration that

2192
00:52:31,000 --> 00:52:31,010
moment of joy at the frustration that
 

2193
00:52:31,010 --> 00:52:32,260
moment of joy at the frustration that
were experiencing you can sort of get

2194
00:52:32,260 --> 00:52:32,270
were experiencing you can sort of get
 

2195
00:52:32,270 --> 00:52:33,910
were experiencing you can sort of get
philosophical about it but the practical

2196
00:52:33,910 --> 00:52:33,920
philosophical about it but the practical
 

2197
00:52:33,920 --> 00:52:35,620
philosophical about it but the practical
nature is they were frustrated with the

2198
00:52:35,620 --> 00:52:35,630
nature is they were frustrated with the
 

2199
00:52:35,630 --> 00:52:38,200
nature is they were frustrated with the
experience and we're using the 42 most

2200
00:52:38,200 --> 00:52:38,210
experience and we're using the 42 most
 

2201
00:52:38,210 --> 00:52:40,470
experience and we're using the 42 most
of the face to make expressions to do

2202
00:52:40,470 --> 00:52:40,480
of the face to make expressions to do
 

2203
00:52:40,480 --> 00:52:44,040
of the face to make expressions to do
classification of frustrated or not and

2204
00:52:44,040 --> 00:52:44,050
classification of frustrated or not and
 

2205
00:52:44,050 --> 00:52:46,450
classification of frustrated or not and
their data does the work not the

2206
00:52:46,450 --> 00:52:46,460
their data does the work not the
 

2207
00:52:46,460 --> 00:52:49,900
their data does the work not the
algorithms it's the annotation a quick

2208
00:52:49,900 --> 00:52:49,910
algorithms it's the annotation a quick
 

2209
00:52:49,910 --> 00:52:53,350
algorithms it's the annotation a quick
mention for the AGI class next week for

2210
00:52:53,350 --> 00:52:53,360
mention for the AGI class next week for
 

2211
00:52:53,360 --> 00:52:54,100
mention for the AGI class next week for
the artificial general intelligence

2212
00:52:54,100 --> 00:52:54,110
the artificial general intelligence
 

2213
00:52:54,110 --> 00:52:56,800
the artificial general intelligence
class one of the competition's we're

2214
00:52:56,800 --> 00:52:56,810
class one of the competition's we're
 

2215
00:52:56,810 --> 00:53:01,890
class one of the competition's we're
doing is we have a JavaScript face

2216
00:53:01,890 --> 00:53:01,900
doing is we have a JavaScript face
 

2217
00:53:01,900 --> 00:53:05,200
doing is we have a JavaScript face
that's trained with a neural network to

2218
00:53:05,200 --> 00:53:05,210
that's trained with a neural network to
 

2219
00:53:05,210 --> 00:53:10,050
that's trained with a neural network to
form various expressions to communicate

2220
00:53:10,050 --> 00:53:10,060
form various expressions to communicate
 

2221
00:53:10,060 --> 00:53:14,350
form various expressions to communicate
with the observer so we're interested in

2222
00:53:14,350 --> 00:53:14,360
with the observer so we're interested in
 

2223
00:53:14,360 --> 00:53:18,280
with the observer so we're interested in
creating emotion which is a nice mirror

2224
00:53:18,280 --> 00:53:18,290
creating emotion which is a nice mirror
 

2225
00:53:18,290 --> 00:53:20,440
creating emotion which is a nice mirror
coupling of the emotional recognition

2226
00:53:20,440 --> 00:53:20,450
coupling of the emotional recognition
 

2227
00:53:20,450 --> 00:53:23,970
coupling of the emotional recognition
problem it's gonna be super cool

2228
00:53:23,970 --> 00:53:23,980
problem it's gonna be super cool
 

2229
00:53:23,980 --> 00:53:27,990
problem it's gonna be super cool
cognitive load we're starting to get to

2230
00:53:27,990 --> 00:53:28,000
cognitive load we're starting to get to
 

2231
00:53:28,000 --> 00:53:30,789
cognitive load we're starting to get to
the eyes

2232
00:53:30,789 --> 00:53:30,799
the eyes
 

2233
00:53:30,799 --> 00:53:34,669
the eyes
cognitive load is the degree to which a

2234
00:53:34,669 --> 00:53:34,679
cognitive load is the degree to which a
 

2235
00:53:34,679 --> 00:53:38,179
cognitive load is the degree to which a
human being is accessing their memory or

2236
00:53:38,179 --> 00:53:38,189
human being is accessing their memory or
 

2237
00:53:38,189 --> 00:53:41,299
human being is accessing their memory or
as Lawson thought how hard they're

2238
00:53:41,299 --> 00:53:41,309
as Lawson thought how hard they're
 

2239
00:53:41,309 --> 00:53:43,969
as Lawson thought how hard they're
working in their mind to recollect

2240
00:53:43,969 --> 00:53:43,979
working in their mind to recollect
 

2241
00:53:43,979 --> 00:53:46,489
working in their mind to recollect
something to think about something as

2242
00:53:46,489 --> 00:53:46,499
something to think about something as
 

2243
00:53:46,499 --> 00:53:50,089
something to think about something as
cognitive load and to do a quick pause

2244
00:53:50,089 --> 00:53:50,099
cognitive load and to do a quick pause
 

2245
00:53:50,099 --> 00:53:53,179
cognitive load and to do a quick pause
of eyes as the window to cognitive load

2246
00:53:53,179 --> 00:53:53,189
of eyes as the window to cognitive load
 

2247
00:53:53,189 --> 00:53:56,059
of eyes as the window to cognitive load
eyes the window to the mind there's a

2248
00:53:56,059 --> 00:53:56,069
eyes the window to the mind there's a
 

2249
00:53:56,069 --> 00:53:58,009
eyes the window to the mind there's a
different ways the eyes move so there's

2250
00:53:58,009 --> 00:53:58,019
different ways the eyes move so there's
 

2251
00:53:58,019 --> 00:54:00,019
different ways the eyes move so there's
pupils the black part of the eye they

2252
00:54:00,019 --> 00:54:00,029
pupils the black part of the eye they
 

2253
00:54:00,029 --> 00:54:03,079
pupils the black part of the eye they
can expand and and contract based on

2254
00:54:03,079 --> 00:54:03,089
can expand and and contract based on
 

2255
00:54:03,089 --> 00:54:05,359
can expand and and contract based on
various factors including the lighting

2256
00:54:05,359 --> 00:54:05,369
various factors including the lighting
 

2257
00:54:05,369 --> 00:54:07,519
various factors including the lighting
variations in the scene but they also

2258
00:54:07,519 --> 00:54:07,529
variations in the scene but they also
 

2259
00:54:07,529 --> 00:54:09,619
variations in the scene but they also
expand and contract based on cognitive

2260
00:54:09,619 --> 00:54:09,629
expand and contract based on cognitive
 

2261
00:54:09,629 --> 00:54:12,409
expand and contract based on cognitive
load that's a that's a strong signal

2262
00:54:12,409 --> 00:54:12,419
load that's a that's a strong signal
 

2263
00:54:12,419 --> 00:54:14,029
load that's a that's a strong signal
they can also move around

2264
00:54:14,029 --> 00:54:14,039
they can also move around
 

2265
00:54:14,039 --> 00:54:16,129
they can also move around
there's ballistic movement saccades when

2266
00:54:16,129 --> 00:54:16,139
there's ballistic movement saccades when
 

2267
00:54:16,139 --> 00:54:17,989
there's ballistic movement saccades when
we look around eyes jump around the

2268
00:54:17,989 --> 00:54:17,999
we look around eyes jump around the
 

2269
00:54:17,999 --> 00:54:20,959
we look around eyes jump around the
scene they can also do something called

2270
00:54:20,959 --> 00:54:20,969
scene they can also do something called
 

2271
00:54:20,969 --> 00:54:23,779
scene they can also do something called
smooth pursuit when you and connecting

2272
00:54:23,779 --> 00:54:23,789
smooth pursuit when you and connecting
 

2273
00:54:23,789 --> 00:54:25,969
smooth pursuit when you and connecting
to our animal past you can see a

2274
00:54:25,969 --> 00:54:25,979
to our animal past you can see a
 

2275
00:54:25,979 --> 00:54:28,129
to our animal past you can see a
delicious meal

2276
00:54:28,129 --> 00:54:28,139
delicious meal
 

2277
00:54:28,139 --> 00:54:31,729
delicious meal
flying by or running by that your eyes

2278
00:54:31,729 --> 00:54:31,739
flying by or running by that your eyes
 

2279
00:54:31,739 --> 00:54:33,469
flying by or running by that your eyes
can follow it perfectly they're not

2280
00:54:33,469 --> 00:54:33,479
can follow it perfectly they're not
 

2281
00:54:33,479 --> 00:54:35,839
can follow it perfectly they're not
jumping around so when we read a book

2282
00:54:35,839 --> 00:54:35,849
jumping around so when we read a book
 

2283
00:54:35,849 --> 00:54:38,749
jumping around so when we read a book
our eyes are using saccadic movements

2284
00:54:38,749 --> 00:54:38,759
our eyes are using saccadic movements
 

2285
00:54:38,759 --> 00:54:41,449
our eyes are using saccadic movements
where they jump around and when the

2286
00:54:41,449 --> 00:54:41,459
where they jump around and when the
 

2287
00:54:41,459 --> 00:54:43,039
where they jump around and when the
purse muth pursuit the eye is moving

2288
00:54:43,039 --> 00:54:43,049
purse muth pursuit the eye is moving
 

2289
00:54:43,049 --> 00:54:44,779
purse muth pursuit the eye is moving
perfectly smoothly those are the kinds

2290
00:54:44,779 --> 00:54:44,789
perfectly smoothly those are the kinds
 

2291
00:54:44,789 --> 00:54:48,069
perfectly smoothly those are the kinds
of movements who have to work with and

2292
00:54:48,069 --> 00:54:48,079
of movements who have to work with and
 

2293
00:54:48,079 --> 00:54:50,859
of movements who have to work with and
cognitive load can be detected by

2294
00:54:50,859 --> 00:54:50,869
cognitive load can be detected by
 

2295
00:54:50,869 --> 00:54:53,469
cognitive load can be detected by
looking at various factors of the eye

2296
00:54:53,469 --> 00:54:53,479
looking at various factors of the eye
 

2297
00:54:53,479 --> 00:54:56,629
looking at various factors of the eye
the blink dynamics the eye movement and

2298
00:54:56,629 --> 00:54:56,639
the blink dynamics the eye movement and
 

2299
00:54:56,639 --> 00:55:01,129
the blink dynamics the eye movement and
the eye the pupil diameter the problem

2300
00:55:01,129 --> 00:55:01,139
the eye the pupil diameter the problem
 

2301
00:55:01,139 --> 00:55:03,739
the eye the pupil diameter the problem
is in the real world and real world data

2302
00:55:03,739 --> 00:55:03,749
is in the real world and real world data
 

2303
00:55:03,749 --> 00:55:06,259
is in the real world and real world data
with lighting variations everything goes

2304
00:55:06,259 --> 00:55:06,269
with lighting variations everything goes
 

2305
00:55:06,269 --> 00:55:07,849
with lighting variations everything goes
out the window in terms of using pupil

2306
00:55:07,849 --> 00:55:07,859
out the window in terms of using pupil
 

2307
00:55:07,859 --> 00:55:09,769
out the window in terms of using pupil
diameter which is the standard way to

2308
00:55:09,769 --> 00:55:09,779
diameter which is the standard way to
 

2309
00:55:09,779 --> 00:55:12,049
diameter which is the standard way to
measure non-contact way to measure

2310
00:55:12,049 --> 00:55:12,059
measure non-contact way to measure
 

2311
00:55:12,059 --> 00:55:13,669
measure non-contact way to measure
cognitive load in the lab when you can

2312
00:55:13,669 --> 00:55:13,679
cognitive load in the lab when you can
 

2313
00:55:13,679 --> 00:55:15,139
cognitive load in the lab when you can
control lighting conditions and use

2314
00:55:15,139 --> 00:55:15,149
control lighting conditions and use
 

2315
00:55:15,149 --> 00:55:18,169
control lighting conditions and use
infrared cameras when you can't all that

2316
00:55:18,169 --> 00:55:18,179
infrared cameras when you can't all that
 

2317
00:55:18,179 --> 00:55:19,789
infrared cameras when you can't all that
goes out the window and all you have is

2318
00:55:19,789 --> 00:55:19,799
goes out the window and all you have is
 

2319
00:55:19,799 --> 00:55:21,619
goes out the window and all you have is
the blink dynamics and the eye movement

2320
00:55:21,619 --> 00:55:21,629
the blink dynamics and the eye movement
 

2321
00:55:21,629 --> 00:55:24,309
the blink dynamics and the eye movement
so neural networks to the rescue

2322
00:55:24,309 --> 00:55:24,319
so neural networks to the rescue
 

2323
00:55:24,319 --> 00:55:26,509
so neural networks to the rescue
3d convolutional neural networks in this

2324
00:55:26,509 --> 00:55:26,519
3d convolutional neural networks in this
 

2325
00:55:26,519 --> 00:55:28,519
3d convolutional neural networks in this
case we take a sequences of images that

2326
00:55:28,519 --> 00:55:28,529
case we take a sequences of images that
 

2327
00:55:28,529 --> 00:55:32,239
case we take a sequences of images that
I through time and use 3d convolutions

2328
00:55:32,239 --> 00:55:32,249
I through time and use 3d convolutions
 

2329
00:55:32,249 --> 00:55:34,129
I through time and use 3d convolutions
as opposed to 2d convolutions on the

2330
00:55:34,129 --> 00:55:34,139
as opposed to 2d convolutions on the
 

2331
00:55:34,139 --> 00:55:36,039
as opposed to 2d convolutions on the
left is everything we've talked about

2332
00:55:36,039 --> 00:55:36,049
left is everything we've talked about
 

2333
00:55:36,049 --> 00:55:39,169
left is everything we've talked about
previous to this as 2d convolutions when

2334
00:55:39,169 --> 00:55:39,179
previous to this as 2d convolutions when
 

2335
00:55:39,179 --> 00:55:41,119
previous to this as 2d convolutions when
the convolution filter is operating on

2336
00:55:41,119 --> 00:55:41,129
the convolution filter is operating on
 

2337
00:55:41,129 --> 00:55:41,910
the convolution filter is operating on
the

2338
00:55:41,910 --> 00:55:41,920
the
 

2339
00:55:41,920 --> 00:55:46,410
the
XY 2d image every channel is operated on

2340
00:55:46,410 --> 00:55:46,420
XY 2d image every channel is operated on
 

2341
00:55:46,420 --> 00:55:49,920
XY 2d image every channel is operated on
by the filter individual separately 3d

2342
00:55:49,920 --> 00:55:49,930
by the filter individual separately 3d
 

2343
00:55:49,930 --> 00:55:54,300
by the filter individual separately 3d
convolutions combine those convolve

2344
00:55:54,300 --> 00:55:54,310
convolutions combine those convolve
 

2345
00:55:54,310 --> 00:55:57,000
convolutions combine those convolve
across the across multiple images across

2346
00:55:57,000 --> 00:55:57,010
across the across multiple images across
 

2347
00:55:57,010 --> 00:56:01,200
across the across multiple images across
multiple channels therefore being able

2348
00:56:01,200 --> 00:56:01,210
multiple channels therefore being able
 

2349
00:56:01,210 --> 00:56:04,470
multiple channels therefore being able
to learn the dynamics of the scene

2350
00:56:04,470 --> 00:56:04,480
to learn the dynamics of the scene
 

2351
00:56:04,480 --> 00:56:07,670
to learn the dynamics of the scene
through time as well not just spatially

2352
00:56:07,670 --> 00:56:07,680
through time as well not just spatially
 

2353
00:56:07,680 --> 00:56:12,780
through time as well not just spatially
temporal and data data is everything for

2354
00:56:12,780 --> 00:56:12,790
temporal and data data is everything for
 

2355
00:56:12,790 --> 00:56:16,680
temporal and data data is everything for
a cognitive load we have in this case 92

2356
00:56:16,680 --> 00:56:16,690
a cognitive load we have in this case 92
 

2357
00:56:16,690 --> 00:56:20,190
a cognitive load we have in this case 92
drivers so how do we sort of perform the

2358
00:56:20,190 --> 00:56:20,200
drivers so how do we sort of perform the
 

2359
00:56:20,200 --> 00:56:22,500
drivers so how do we sort of perform the
cognitive load classification task we

2360
00:56:22,500 --> 00:56:22,510
cognitive load classification task we
 

2361
00:56:22,510 --> 00:56:24,150
cognitive load classification task we
have these drivers driving on the

2362
00:56:24,150 --> 00:56:24,160
have these drivers driving on the
 

2363
00:56:24,160 --> 00:56:26,250
have these drivers driving on the
highway and performing the what's called

2364
00:56:26,250 --> 00:56:26,260
highway and performing the what's called
 

2365
00:56:26,260 --> 00:56:28,440
highway and performing the what's called
the n-back task zero back one back to

2366
00:56:28,440 --> 00:56:28,450
the n-back task zero back one back to
 

2367
00:56:28,450 --> 00:56:32,070
the n-back task zero back one back to
back and that task involves hearing

2368
00:56:32,070 --> 00:56:32,080
back and that task involves hearing
 

2369
00:56:32,080 --> 00:56:34,020
back and that task involves hearing
numbers being read to you and then

2370
00:56:34,020 --> 00:56:34,030
numbers being read to you and then
 

2371
00:56:34,030 --> 00:56:37,860
numbers being read to you and then
recalling those numbers one at a time so

2372
00:56:37,860 --> 00:56:37,870
recalling those numbers one at a time so
 

2373
00:56:37,870 --> 00:56:40,500
recalling those numbers one at a time so
one zero back the system gives you a

2374
00:56:40,500 --> 00:56:40,510
one zero back the system gives you a
 

2375
00:56:40,510 --> 00:56:42,630
one zero back the system gives you a
number seven and then you have to just

2376
00:56:42,630 --> 00:56:42,640
number seven and then you have to just
 

2377
00:56:42,640 --> 00:56:45,870
number seven and then you have to just
say that number back seven and it keeps

2378
00:56:45,870 --> 00:56:45,880
say that number back seven and it keeps
 

2379
00:56:45,880 --> 00:56:47,430
say that number back seven and it keeps
repeating that's easy it's supposed to

2380
00:56:47,430 --> 00:56:47,440
repeating that's easy it's supposed to
 

2381
00:56:47,440 --> 00:56:49,920
repeating that's easy it's supposed to
be the easy task one back is when you

2382
00:56:49,920 --> 00:56:49,930
be the easy task one back is when you
 

2383
00:56:49,930 --> 00:56:51,930
be the easy task one back is when you
hear number you have to remember it and

2384
00:56:51,930 --> 00:56:51,940
hear number you have to remember it and
 

2385
00:56:51,940 --> 00:56:55,050
hear number you have to remember it and
then that for the next number you have

2386
00:56:55,050 --> 00:56:55,060
then that for the next number you have
 

2387
00:56:55,060 --> 00:56:58,530
then that for the next number you have
to say the number previous to that so

2388
00:56:58,530 --> 00:56:58,540
to say the number previous to that so
 

2389
00:56:58,540 --> 00:56:59,940
to say the number previous to that so
you kind of have to keep one number in

2390
00:56:59,940 --> 00:56:59,950
you kind of have to keep one number in
 

2391
00:56:59,950 --> 00:57:01,740
you kind of have to keep one number in
your memory always and not get

2392
00:57:01,740 --> 00:57:01,750
your memory always and not get
 

2393
00:57:01,750 --> 00:57:04,410
your memory always and not get
distracted by the new information coming

2394
00:57:04,410 --> 00:57:04,420
distracted by the new information coming
 

2395
00:57:04,420 --> 00:57:06,840
distracted by the new information coming
up but to back you have to do that two

2396
00:57:06,840 --> 00:57:06,850
up but to back you have to do that two
 

2397
00:57:06,850 --> 00:57:08,790
up but to back you have to do that two
numbers back so you have to use memory

2398
00:57:08,790 --> 00:57:08,800
numbers back so you have to use memory
 

2399
00:57:08,800 --> 00:57:11,340
numbers back so you have to use memory
more and more went to back so cognitive

2400
00:57:11,340 --> 00:57:11,350
more and more went to back so cognitive
 

2401
00:57:11,350 --> 00:57:13,980
more and more went to back so cognitive
load is higher and higher okay so what

2402
00:57:13,980 --> 00:57:13,990
load is higher and higher okay so what
 

2403
00:57:13,990 --> 00:57:17,610
load is higher and higher okay so what
do we do we use face alignment face

2404
00:57:17,610 --> 00:57:17,620
do we do we use face alignment face
 

2405
00:57:17,620 --> 00:57:19,860
do we do we use face alignment face
front elevation and detecting the eye

2406
00:57:19,860 --> 00:57:19,870
front elevation and detecting the eye
 

2407
00:57:19,870 --> 00:57:22,140
front elevation and detecting the eye
closest to the camera and extract the

2408
00:57:22,140 --> 00:57:22,150
closest to the camera and extract the
 

2409
00:57:22,150 --> 00:57:25,440
closest to the camera and extract the
eye region and now we have this nice raw

2410
00:57:25,440 --> 00:57:25,450
eye region and now we have this nice raw
 

2411
00:57:25,450 --> 00:57:28,350
eye region and now we have this nice raw
pixels of the eye region across six

2412
00:57:28,350 --> 00:57:28,360
pixels of the eye region across six
 

2413
00:57:28,360 --> 00:57:31,950
pixels of the eye region across six
seconds of video and we take that and

2414
00:57:31,950 --> 00:57:31,960
seconds of video and we take that and
 

2415
00:57:31,960 --> 00:57:33,600
seconds of video and we take that and
put that in as a 3d convolutional neural

2416
00:57:33,600 --> 00:57:33,610
put that in as a 3d convolutional neural
 

2417
00:57:33,610 --> 00:57:37,260
put that in as a 3d convolutional neural
network and classify simply one of three

2418
00:57:37,260 --> 00:57:37,270
network and classify simply one of three
 

2419
00:57:37,270 --> 00:57:39,210
network and classify simply one of three
classes zero back one back and two back

2420
00:57:39,210 --> 00:57:39,220
classes zero back one back and two back
 

2421
00:57:39,220 --> 00:57:41,850
classes zero back one back and two back
so we have a ton of data of people on

2422
00:57:41,850 --> 00:57:41,860
so we have a ton of data of people on
 

2423
00:57:41,860 --> 00:57:43,470
so we have a ton of data of people on
the highway performing these tasks and

2424
00:57:43,470 --> 00:57:43,480
the highway performing these tasks and
 

2425
00:57:43,480 --> 00:57:45,420
the highway performing these tasks and
back tasks and that forms the

2426
00:57:45,420 --> 00:57:45,430
back tasks and that forms the
 

2427
00:57:45,430 --> 00:57:47,640
back tasks and that forms the
classification supervised learning

2428
00:57:47,640 --> 00:57:47,650
classification supervised learning
 

2429
00:57:47,650 --> 00:57:52,440
classification supervised learning
training data that's it the input is 90

2430
00:57:52,440 --> 00:57:52,450
training data that's it the input is 90
 

2431
00:57:52,450 --> 00:57:55,240
training data that's it the input is 90
images it's at 15 frames a second

2432
00:57:55,240 --> 00:57:55,250
images it's at 15 frames a second
 

2433
00:57:55,250 --> 00:58:01,170
images it's at 15 frames a second
and the output is one of three classes

2434
00:58:01,170 --> 00:58:01,180

 

2435
00:58:01,180 --> 00:58:03,910

face fronto ization i should mention is

2436
00:58:03,910 --> 00:58:03,920
face fronto ization i should mention is
 

2437
00:58:03,920 --> 00:58:06,070
face fronto ization i should mention is
the technique developed under for face

2438
00:58:06,070 --> 00:58:06,080
the technique developed under for face
 

2439
00:58:06,080 --> 00:58:07,780
the technique developed under for face
recognition because most face

2440
00:58:07,780 --> 00:58:07,790
recognition because most face
 

2441
00:58:07,790 --> 00:58:10,240
recognition because most face
recognition tasks require frontal face

2442
00:58:10,240 --> 00:58:10,250
recognition tasks require frontal face
 

2443
00:58:10,250 --> 00:58:12,609
recognition tasks require frontal face
orientation is also what we use here to

2444
00:58:12,609 --> 00:58:12,619
orientation is also what we use here to
 

2445
00:58:12,619 --> 00:58:14,589
orientation is also what we use here to
normalize everything that we can focus

2446
00:58:14,589 --> 00:58:14,599
normalize everything that we can focus
 

2447
00:58:14,599 --> 00:58:18,510
normalize everything that we can focus
in on the exact blink it's taking the

2448
00:58:18,510 --> 00:58:18,520
in on the exact blink it's taking the
 

2449
00:58:18,520 --> 00:58:20,890
in on the exact blink it's taking the
it's taking whatever the orientation of

2450
00:58:20,890 --> 00:58:20,900
it's taking whatever the orientation of
 

2451
00:58:20,900 --> 00:58:22,599
it's taking whatever the orientation of
the face and projecting into the frontal

2452
00:58:22,599 --> 00:58:22,609
the face and projecting into the frontal
 

2453
00:58:22,609 --> 00:58:27,700
the face and projecting into the frontal
position taking the raw pixels of the

2454
00:58:27,700 --> 00:58:27,710
position taking the raw pixels of the
 

2455
00:58:27,710 --> 00:58:30,310
position taking the raw pixels of the
face is detecting the eye region zooming

2456
00:58:30,310 --> 00:58:30,320
face is detecting the eye region zooming
 

2457
00:58:30,320 --> 00:58:37,150
face is detecting the eye region zooming
in and grabbing the eye where you find

2458
00:58:37,150 --> 00:58:37,160
in and grabbing the eye where you find
 

2459
00:58:37,160 --> 00:58:39,540
in and grabbing the eye where you find
and this is where the intuition builds

2460
00:58:39,540 --> 00:58:39,550
and this is where the intuition builds
 

2461
00:58:39,550 --> 00:58:45,670
and this is where the intuition builds
it it's a fascinating one what's being

2462
00:58:45,670 --> 00:58:45,680
it it's a fascinating one what's being
 

2463
00:58:45,680 --> 00:58:47,290
it it's a fascinating one what's being
plotted here is the relative movement of

2464
00:58:47,290 --> 00:58:47,300
plotted here is the relative movement of
 

2465
00:58:47,300 --> 00:58:50,589
plotted here is the relative movement of
the pupil the relative movement of the

2466
00:58:50,589 --> 00:58:50,599
the pupil the relative movement of the
 

2467
00:58:50,599 --> 00:58:54,359
the pupil the relative movement of the
eye based on a different cognitive loads

2468
00:58:54,359 --> 00:58:54,369
eye based on a different cognitive loads
 

2469
00:58:54,369 --> 00:58:56,950
eye based on a different cognitive loads
for cognitive load on the left of zero

2470
00:58:56,950 --> 00:58:56,960
for cognitive load on the left of zero
 

2471
00:58:56,960 --> 00:58:58,930
for cognitive load on the left of zero
so when your mind is not that lost in

2472
00:58:58,930 --> 00:58:58,940
so when your mind is not that lost in
 

2473
00:58:58,940 --> 00:59:01,780
so when your mind is not that lost in
thought and cognitive load of two on the

2474
00:59:01,780 --> 00:59:01,790
thought and cognitive load of two on the
 

2475
00:59:01,790 --> 00:59:03,760
thought and cognitive load of two on the
right when it is lost in thought the eye

2476
00:59:03,760 --> 00:59:03,770
right when it is lost in thought the eye
 

2477
00:59:03,770 --> 00:59:06,910
right when it is lost in thought the eye
moves a lot less eye is more focused on

2478
00:59:06,910 --> 00:59:06,920
moves a lot less eye is more focused on
 

2479
00:59:06,920 --> 00:59:09,730
moves a lot less eye is more focused on
the forward roadway that's an

2480
00:59:09,730 --> 00:59:09,740
the forward roadway that's an
 

2481
00:59:09,740 --> 00:59:11,260
the forward roadway that's an
interesting finding but it's only in

2482
00:59:11,260 --> 00:59:11,270
interesting finding but it's only in
 

2483
00:59:11,270 --> 00:59:13,060
interesting finding but it's only in
aggregate and that's what the neural

2484
00:59:13,060 --> 00:59:13,070
aggregate and that's what the neural
 

2485
00:59:13,070 --> 00:59:15,570
aggregate and that's what the neural
neural network is task would do it with

2486
00:59:15,570 --> 00:59:15,580
neural network is task would do it with
 

2487
00:59:15,580 --> 00:59:18,810
neural network is task would do it with
extracting an a frame-by-frame basis

2488
00:59:18,810 --> 00:59:18,820
extracting an a frame-by-frame basis
 

2489
00:59:18,820 --> 00:59:22,079
extracting an a frame-by-frame basis
this is a standard 3d convolutional

2490
00:59:22,079 --> 00:59:22,089
this is a standard 3d convolutional
 

2491
00:59:22,089 --> 00:59:25,300
this is a standard 3d convolutional
architecture again taking in the image

2492
00:59:25,300 --> 00:59:25,310
architecture again taking in the image
 

2493
00:59:25,310 --> 00:59:27,250
architecture again taking in the image
sequence is the input cognitive load

2494
00:59:27,250 --> 00:59:27,260
sequence is the input cognitive load
 

2495
00:59:27,260 --> 00:59:29,130
sequence is the input cognitive load
classification is the output and

2496
00:59:29,130 --> 00:59:29,140
classification is the output and
 

2497
00:59:29,140 --> 00:59:33,940
classification is the output and
classifying on the right is the accuracy

2498
00:59:33,940 --> 00:59:33,950
classifying on the right is the accuracy
 

2499
00:59:33,950 --> 00:59:37,329
classifying on the right is the accuracy
that's able to achieve of 86% that's

2500
00:59:37,329 --> 00:59:37,339
that's able to achieve of 86% that's
 

2501
00:59:37,339 --> 00:59:41,470
that's able to achieve of 86% that's
pretty cool from real-world data the

2502
00:59:41,470 --> 00:59:41,480
pretty cool from real-world data the
 

2503
00:59:41,480 --> 00:59:42,760
pretty cool from real-world data the
idea is that you can just plop in a

2504
00:59:42,760 --> 00:59:42,770
idea is that you can just plop in a
 

2505
00:59:42,770 --> 00:59:46,930
idea is that you can just plop in a
webcam get the video going in going into

2506
00:59:46,930 --> 00:59:46,940
webcam get the video going in going into
 

2507
00:59:46,940 --> 00:59:50,400
webcam get the video going in going into
the neural network and this predicting

2508
00:59:50,400 --> 00:59:50,410
the neural network and this predicting
 

2509
00:59:50,410 --> 00:59:52,120
the neural network and this predicting
it continued

2510
00:59:52,120 --> 00:59:52,130
it continued
 

2511
00:59:52,130 --> 00:59:56,020
it continued
a stream from zero to two of cognitive

2512
00:59:56,020 --> 00:59:56,030
a stream from zero to two of cognitive
 

2513
00:59:56,030 --> 01:00:00,880
a stream from zero to two of cognitive
load because every single zero want back

2514
01:00:00,880 --> 01:00:00,890
load because every single zero want back
 

2515
01:00:00,890 --> 01:00:03,550
load because every single zero want back
one back to back classes are have a

2516
01:00:03,550 --> 01:00:03,560
one back to back classes are have a
 

2517
01:00:03,560 --> 01:00:05,050
one back to back classes are have a
confidence that's associated with them

2518
01:00:05,050 --> 01:00:05,060
confidence that's associated with them
 

2519
01:00:05,060 --> 01:00:07,810
confidence that's associated with them
so you can turn that into a real value

2520
01:00:07,810 --> 01:00:07,820
so you can turn that into a real value
 

2521
01:00:07,820 --> 01:00:09,790
so you can turn that into a real value
between zero and two and when you see

2522
01:00:09,790 --> 01:00:09,800
between zero and two and when you see
 

2523
01:00:09,800 --> 01:00:13,390
between zero and two and when you see
here's a plot of three of the people on

2524
01:00:13,390 --> 01:00:13,400
here's a plot of three of the people on
 

2525
01:00:13,400 --> 01:00:16,480
here's a plot of three of the people on
the team here driving a car performing a

2526
01:00:16,480 --> 01:00:16,490
the team here driving a car performing a
 

2527
01:00:16,490 --> 01:00:21,420
the team here driving a car performing a
task of conversation and in white

2528
01:00:21,420 --> 01:00:21,430
task of conversation and in white
 

2529
01:00:21,430 --> 01:00:24,040
task of conversation and in white
showing the cognitive load frame by

2530
01:00:24,040 --> 01:00:24,050
showing the cognitive load frame by
 

2531
01:00:24,050 --> 01:00:25,540
showing the cognitive load frame by
frame a thirty frames a second

2532
01:00:25,540 --> 01:00:25,550
frame a thirty frames a second
 

2533
01:00:25,550 --> 01:00:27,550
frame a thirty frames a second
estimating the cognitive load of each of

2534
01:00:27,550 --> 01:00:27,560
estimating the cognitive load of each of
 

2535
01:00:27,560 --> 01:00:30,640
estimating the cognitive load of each of
the drivers on from zero to two on the

2536
01:00:30,640 --> 01:00:30,650
the drivers on from zero to two on the
 

2537
01:00:30,650 --> 01:00:33,550
the drivers on from zero to two on the
y-axis so these are high cognitive load

2538
01:00:33,550 --> 01:00:33,560
y-axis so these are high cognitive load
 

2539
01:00:33,560 --> 01:00:37,470
y-axis so these are high cognitive load
and showing in on the bottom red and

2540
01:00:37,470 --> 01:00:37,480
and showing in on the bottom red and
 

2541
01:00:37,480 --> 01:00:41,050
and showing in on the bottom red and
yellow of high medium cognitive load and

2542
01:00:41,050 --> 01:00:41,060
yellow of high medium cognitive load and
 

2543
01:00:41,060 --> 01:00:43,030
yellow of high medium cognitive load and
when everybody's silent the cognitive

2544
01:00:43,030 --> 01:00:43,040
when everybody's silent the cognitive
 

2545
01:00:43,040 --> 01:00:45,460
when everybody's silent the cognitive
load goes down so we can perform now

2546
01:00:45,460 --> 01:00:45,470
load goes down so we can perform now
 

2547
01:00:45,470 --> 01:00:47,650
load goes down so we can perform now
with this simple neural network with the

2548
01:00:47,650 --> 01:00:47,660
with this simple neural network with the
 

2549
01:00:47,660 --> 01:00:49,540
with this simple neural network with the
training data that we formed we can

2550
01:00:49,540 --> 01:00:49,550
training data that we formed we can
 

2551
01:00:49,550 --> 01:00:51,880
training data that we formed we can
extend that to any arbitrary new data

2552
01:00:51,880 --> 01:00:51,890
extend that to any arbitrary new data
 

2553
01:00:51,890 --> 01:00:55,540
extend that to any arbitrary new data
set and generalize okay those are some

2554
01:00:55,540 --> 01:00:55,550
set and generalize okay those are some
 

2555
01:00:55,550 --> 01:00:57,010
set and generalize okay those are some
examples of Chania neural networks can

2556
01:00:57,010 --> 01:00:57,020
examples of Chania neural networks can
 

2557
01:00:57,020 --> 01:00:59,380
examples of Chania neural networks can
be applied and why is this important

2558
01:00:59,380 --> 01:00:59,390
be applied and why is this important
 

2559
01:00:59,390 --> 01:01:03,610
be applied and why is this important
again is while we focus on the sort of

2560
01:01:03,610 --> 01:01:03,620
again is while we focus on the sort of
 

2561
01:01:03,620 --> 01:01:06,220
again is while we focus on the sort of
the perception tasks of using neural

2562
01:01:06,220 --> 01:01:06,230
the perception tasks of using neural
 

2563
01:01:06,230 --> 01:01:08,620
the perception tasks of using neural
networks of using sensors and signal

2564
01:01:08,620 --> 01:01:08,630
networks of using sensors and signal
 

2565
01:01:08,630 --> 01:01:10,960
networks of using sensors and signal
processing to determine where we are in

2566
01:01:10,960 --> 01:01:10,970
processing to determine where we are in
 

2567
01:01:10,970 --> 01:01:12,250
processing to determine where we are in
the world where the different obstacles

2568
01:01:12,250 --> 01:01:12,260
the world where the different obstacles
 

2569
01:01:12,260 --> 01:01:13,930
the world where the different obstacles
are informed trajectories around those

2570
01:01:13,930 --> 01:01:13,940
are informed trajectories around those
 

2571
01:01:13,940 --> 01:01:17,260
are informed trajectories around those
obstacles we are still far away from

2572
01:01:17,260 --> 01:01:17,270
obstacles we are still far away from
 

2573
01:01:17,270 --> 01:01:21,190
obstacles we are still far away from
completely solving that problem I would

2574
01:01:21,190 --> 01:01:21,200
completely solving that problem I would
 

2575
01:01:21,200 --> 01:01:24,370
completely solving that problem I would
argue 20 plus years away the human will

2576
01:01:24,370 --> 01:01:24,380
argue 20 plus years away the human will
 

2577
01:01:24,380 --> 01:01:27,790
argue 20 plus years away the human will
have to be involved and so when it's the

2578
01:01:27,790 --> 01:01:27,800
have to be involved and so when it's the
 

2579
01:01:27,800 --> 01:01:30,190
have to be involved and so when it's the
system is not able to control when the

2580
01:01:30,190 --> 01:01:30,200
system is not able to control when the
 

2581
01:01:30,200 --> 01:01:31,750
system is not able to control when the
system is not able to perceive when

2582
01:01:31,750 --> 01:01:31,760
system is not able to perceive when
 

2583
01:01:31,760 --> 01:01:33,340
system is not able to perceive when
there's some flawed aspect about the

2584
01:01:33,340 --> 01:01:33,350
there's some flawed aspect about the
 

2585
01:01:33,350 --> 01:01:36,070
there's some flawed aspect about the
perception or the driving policy the

2586
01:01:36,070 --> 01:01:36,080
perception or the driving policy the
 

2587
01:01:36,080 --> 01:01:37,900
perception or the driving policy the
human has to be involved and that's

2588
01:01:37,900 --> 01:01:37,910
human has to be involved and that's
 

2589
01:01:37,910 --> 01:01:40,180
human has to be involved and that's
where we have to know let the car know

2590
01:01:40,180 --> 01:01:40,190
where we have to know let the car know
 

2591
01:01:40,190 --> 01:01:43,180
where we have to know let the car know
what the human is doing that's the

2592
01:01:43,180 --> 01:01:43,190
what the human is doing that's the
 

2593
01:01:43,190 --> 01:01:44,980
what the human is doing that's the
essential element of human robot

2594
01:01:44,980 --> 01:01:44,990
essential element of human robot
 

2595
01:01:44,990 --> 01:01:49,540
essential element of human robot
interaction the most popular car in the

2596
01:01:49,540 --> 01:01:49,550
interaction the most popular car in the
 

2597
01:01:49,550 --> 01:01:52,780
interaction the most popular car in the
United States today is the Ford f-150 no

2598
01:01:52,780 --> 01:01:52,790
United States today is the Ford f-150 no
 

2599
01:01:52,790 --> 01:01:55,660
United States today is the Ford f-150 no
automation the thing that sort of

2600
01:01:55,660 --> 01:01:55,670
automation the thing that sort of
 

2601
01:01:55,670 --> 01:01:59,880
automation the thing that sort of
inspires us and makes us think that

2602
01:01:59,880 --> 01:01:59,890
inspires us and makes us think that
 

2603
01:01:59,890 --> 01:02:02,110
inspires us and makes us think that
transportation can be fundamentally

2604
01:02:02,110 --> 01:02:02,120
transportation can be fundamentally
 

2605
01:02:02,120 --> 01:02:03,760
transportation can be fundamentally
transformed is the Google self-driving

2606
01:02:03,760 --> 01:02:03,770
transformed is the Google self-driving
 

2607
01:02:03,770 --> 01:02:05,230
transformed is the Google self-driving
mo

2608
01:02:05,230 --> 01:02:05,240
mo
 

2609
01:02:05,240 --> 01:02:07,330
mo
our and although our guest speakers and

2610
01:02:07,330 --> 01:02:07,340
our and although our guest speakers and
 

2611
01:02:07,340 --> 01:02:08,440
our and although our guest speakers and
all the folks work in the autonomous

2612
01:02:08,440 --> 01:02:08,450
all the folks work in the autonomous
 

2613
01:02:08,450 --> 01:02:12,400
all the folks work in the autonomous
vehicles but if you look at it the only

2614
01:02:12,400 --> 01:02:12,410
vehicles but if you look at it the only
 

2615
01:02:12,410 --> 01:02:14,200
vehicles but if you look at it the only
people who are at a mass scale or

2616
01:02:14,200 --> 01:02:14,210
people who are at a mass scale or
 

2617
01:02:14,210 --> 01:02:17,290
people who are at a mass scale or
beginning to are actually injecting

2618
01:02:17,290 --> 01:02:17,300
beginning to are actually injecting
 

2619
01:02:17,300 --> 01:02:20,350
beginning to are actually injecting
automation into our daily lives is the

2620
01:02:20,350 --> 01:02:20,360
automation into our daily lives is the
 

2621
01:02:20,360 --> 01:02:21,910
automation into our daily lives is the
ones in between

2622
01:02:21,910 --> 01:02:21,920
ones in between
 

2623
01:02:21,920 --> 01:02:24,790
ones in between
it's the Tesla's the l2 systems it's the

2624
01:02:24,790 --> 01:02:24,800
it's the Tesla's the l2 systems it's the
 

2625
01:02:24,800 --> 01:02:29,010
it's the Tesla's the l2 systems it's the
tesla system the supercruise the audio

2626
01:02:29,010 --> 01:02:29,020
tesla system the supercruise the audio
 

2627
01:02:29,020 --> 01:02:33,190
tesla system the supercruise the audio
as 90s the the vehicles that are slowly

2628
01:02:33,190 --> 01:02:33,200
as 90s the the vehicles that are slowly
 

2629
01:02:33,200 --> 01:02:36,780
as 90s the the vehicles that are slowly
adding to some degree of automation and

2630
01:02:36,780 --> 01:02:36,790
adding to some degree of automation and
 

2631
01:02:36,790 --> 01:02:38,980
adding to some degree of automation and
teaching human beings how to interact

2632
01:02:38,980 --> 01:02:38,990
teaching human beings how to interact
 

2633
01:02:38,990 --> 01:02:43,109
teaching human beings how to interact
with that automation and here's again

2634
01:02:43,109 --> 01:02:43,119
with that automation and here's again
 

2635
01:02:43,119 --> 01:02:51,070
with that automation and here's again
the the the path towards mass scale

2636
01:02:51,070 --> 01:02:51,080
the the the path towards mass scale
 

2637
01:02:51,080 --> 01:02:54,730
the the the path towards mass scale
automation we're steering wheels removed

2638
01:02:54,730 --> 01:02:54,740
automation we're steering wheels removed
 

2639
01:02:54,740 --> 01:02:57,370
automation we're steering wheels removed
the consideration that humans removed I

2640
01:02:57,370 --> 01:02:57,380
the consideration that humans removed I
 

2641
01:02:57,380 --> 01:03:01,650
the consideration that humans removed I
believe is more than two decades away on

2642
01:03:01,650 --> 01:03:01,660
believe is more than two decades away on
 

2643
01:03:01,660 --> 01:03:05,440
believe is more than two decades away on
the path to that we have to understand

2644
01:03:05,440 --> 01:03:05,450
the path to that we have to understand
 

2645
01:03:05,450 --> 01:03:07,720
the path to that we have to understand
and create successful human robot

2646
01:03:07,720 --> 01:03:07,730
and create successful human robot
 

2647
01:03:07,730 --> 01:03:11,340
and create successful human robot
interaction approach autonomous vehicles

2648
01:03:11,340 --> 01:03:11,350
interaction approach autonomous vehicles
 

2649
01:03:11,350 --> 01:03:14,020
interaction approach autonomous vehicles
autonomous systems in a human centered

2650
01:03:14,020 --> 01:03:14,030
autonomous systems in a human centered
 

2651
01:03:14,030 --> 01:03:17,349
autonomous systems in a human centered
way the mass scale integration of these

2652
01:03:17,349 --> 01:03:17,359
way the mass scale integration of these
 

2653
01:03:17,359 --> 01:03:20,050
way the mass scale integration of these
systems of the human center systems like

2654
01:03:20,050 --> 01:03:20,060
systems of the human center systems like
 

2655
01:03:20,060 --> 01:03:22,090
systems of the human center systems like
to test the vehicles a Tesla is just a

2656
01:03:22,090 --> 01:03:22,100
to test the vehicles a Tesla is just a
 

2657
01:03:22,100 --> 01:03:24,430
to test the vehicles a Tesla is just a
small company right now the the kind of

2658
01:03:24,430 --> 01:03:24,440
small company right now the the kind of
 

2659
01:03:24,440 --> 01:03:26,620
small company right now the the kind of
l2 technologies have not truly

2660
01:03:26,620 --> 01:03:26,630
l2 technologies have not truly
 

2661
01:03:26,630 --> 01:03:28,870
l2 technologies have not truly
penetrated the the market have not

2662
01:03:28,870 --> 01:03:28,880
penetrated the the market have not
 

2663
01:03:28,880 --> 01:03:30,700
penetrated the the market have not
penetrated that our vehicles even the

2664
01:03:30,700 --> 01:03:30,710
penetrated that our vehicles even the
 

2665
01:03:30,710 --> 01:03:32,109
penetrated that our vehicles even the
Brittain the new vehicles being released

2666
01:03:32,109 --> 01:03:32,119
Brittain the new vehicles being released
 

2667
01:03:32,119 --> 01:03:34,060
Brittain the new vehicles being released
today I believe that happens in the

2668
01:03:34,060 --> 01:03:34,070
today I believe that happens in the
 

2669
01:03:34,070 --> 01:03:38,290
today I believe that happens in the
early 2020s and that's going to form the

2670
01:03:38,290 --> 01:03:38,300
early 2020s and that's going to form the
 

2671
01:03:38,300 --> 01:03:41,440
early 2020s and that's going to form the
core of our algorithms that will

2672
01:03:41,440 --> 01:03:41,450
core of our algorithms that will
 

2673
01:03:41,450 --> 01:03:43,960
core of our algorithms that will
eventually lead to the full autonomy all

2674
01:03:43,960 --> 01:03:43,970
eventually lead to the full autonomy all
 

2675
01:03:43,970 --> 01:03:46,090
eventually lead to the full autonomy all
of that data what I mentioned with Tesla

2676
01:03:46,090 --> 01:03:46,100
of that data what I mentioned with Tesla
 

2677
01:03:46,100 --> 01:03:49,300
of that data what I mentioned with Tesla
with a 32% miles being driven all of

2678
01:03:49,300 --> 01:03:49,310
with a 32% miles being driven all of
 

2679
01:03:49,310 --> 01:03:50,920
with a 32% miles being driven all of
that is training data for the algorithms

2680
01:03:50,920 --> 01:03:50,930
that is training data for the algorithms
 

2681
01:03:50,930 --> 01:03:53,380
that is training data for the algorithms
the edge cases arise there that's where

2682
01:03:53,380 --> 01:03:53,390
the edge cases arise there that's where
 

2683
01:03:53,390 --> 01:03:55,930
the edge cases arise there that's where
we get all this data in our data set at

2684
01:03:55,930 --> 01:03:55,940
we get all this data in our data set at
 

2685
01:03:55,940 --> 01:04:00,700
we get all this data in our data set at
MIT is 400,000 miles Tesla has a billion

2686
01:04:00,700 --> 01:04:00,710
MIT is 400,000 miles Tesla has a billion
 

2687
01:04:00,710 --> 01:04:03,550
MIT is 400,000 miles Tesla has a billion
miles so that that's all training data

2688
01:04:03,550 --> 01:04:03,560
miles so that that's all training data
 

2689
01:04:03,560 --> 01:04:07,000
miles so that that's all training data
on the way on the stairway to mass scale

2690
01:04:07,000 --> 01:04:07,010
on the way on the stairway to mass scale
 

2691
01:04:07,010 --> 01:04:10,890
on the way on the stairway to mass scale
automation why is this

2692
01:04:10,890 --> 01:04:10,900
automation why is this
 

2693
01:04:10,900 --> 01:04:14,370
automation why is this
important beautiful and fundamental to

2694
01:04:14,370 --> 01:04:14,380
important beautiful and fundamental to
 

2695
01:04:14,380 --> 01:04:16,589
important beautiful and fundamental to
the role of AI in society I believe that

2696
01:04:16,589 --> 01:04:16,599
the role of AI in society I believe that
 

2697
01:04:16,599 --> 01:04:18,779
the role of AI in society I believe that
self-driving cars when they're in this

2698
01:04:18,779 --> 01:04:18,789
self-driving cars when they're in this
 

2699
01:04:18,789 --> 01:04:21,150
self-driving cars when they're in this
way are focused on a human robot

2700
01:04:21,150 --> 01:04:21,160
way are focused on a human robot
 

2701
01:04:21,160 --> 01:04:24,450
way are focused on a human robot
interaction our personal robots they're

2702
01:04:24,450 --> 01:04:24,460
interaction our personal robots they're
 

2703
01:04:24,460 --> 01:04:27,240
interaction our personal robots they're
not perception control systems tools

2704
01:04:27,240 --> 01:04:27,250
not perception control systems tools
 

2705
01:04:27,250 --> 01:04:30,210
not perception control systems tools
like a Roomba performing a particular

2706
01:04:30,210 --> 01:04:30,220
like a Roomba performing a particular
 

2707
01:04:30,220 --> 01:04:33,870
like a Roomba performing a particular
task when human life is a steak when

2708
01:04:33,870 --> 01:04:33,880
task when human life is a steak when
 

2709
01:04:33,880 --> 01:04:35,279
task when human life is a steak when
there's a fundamental transfer between

2710
01:04:35,279 --> 01:04:35,289
there's a fundamental transfer between
 

2711
01:04:35,289 --> 01:04:39,450
there's a fundamental transfer between
of life of a human being giving their

2712
01:04:39,450 --> 01:04:39,460
of life of a human being giving their
 

2713
01:04:39,460 --> 01:04:41,910
of life of a human being giving their
life over to an AI system directly one

2714
01:04:41,910 --> 01:04:41,920
life over to an AI system directly one
 

2715
01:04:41,920 --> 01:04:46,470
life over to an AI system directly one
on one is a transfer that is kind of a

2716
01:04:46,470 --> 01:04:46,480
on one is a transfer that is kind of a
 

2717
01:04:46,480 --> 01:04:50,370
on one is a transfer that is kind of a
relationship that is one indicative of a

2718
01:04:50,370 --> 01:04:50,380
relationship that is one indicative of a
 

2719
01:04:50,380 --> 01:04:54,870
relationship that is one indicative of a
personal robot this is it requires all

2720
01:04:54,870 --> 01:04:54,880
personal robot this is it requires all
 

2721
01:04:54,880 --> 01:04:56,190
personal robot this is it requires all
the things of understanding

2722
01:04:56,190 --> 01:04:56,200
the things of understanding
 

2723
01:04:56,200 --> 01:05:00,019
the things of understanding
communication of trust these are

2724
01:05:00,019 --> 01:05:00,029
communication of trust these are
 

2725
01:05:00,029 --> 01:05:03,210
communication of trust these are
fascinating to understand how a human

2726
01:05:03,210 --> 01:05:03,220
fascinating to understand how a human
 

2727
01:05:03,220 --> 01:05:05,789
fascinating to understand how a human
and robot can form trust enough to

2728
01:05:05,789 --> 01:05:05,799
and robot can form trust enough to
 

2729
01:05:05,799 --> 01:05:10,200
and robot can form trust enough to
create a really an almost

2730
01:05:10,200 --> 01:05:10,210
create a really an almost
 

2731
01:05:10,210 --> 01:05:12,690
create a really an almost
one-to-one understanding of each other's

2732
01:05:12,690 --> 01:05:12,700
one-to-one understanding of each other's
 

2733
01:05:12,700 --> 01:05:15,500
one-to-one understanding of each other's
mental state learn from each other oh

2734
01:05:15,500 --> 01:05:15,510
mental state learn from each other oh
 

2735
01:05:15,510 --> 01:05:19,790
mental state learn from each other oh
boy

2736
01:05:19,790 --> 01:05:19,800

 

2737
01:05:19,800 --> 01:05:23,400

so one of my favorite movies Good Will

2738
01:05:23,400 --> 01:05:23,410
so one of my favorite movies Good Will
 

2739
01:05:23,410 --> 01:05:25,260
so one of my favorite movies Good Will
Hunting we're in Boston Cambridge have

2740
01:05:25,260 --> 01:05:25,270
Hunting we're in Boston Cambridge have
 

2741
01:05:25,270 --> 01:05:29,790
Hunting we're in Boston Cambridge have
two have two gonna regret this one this

2742
01:05:29,790 --> 01:05:29,800
two have two gonna regret this one this
 

2743
01:05:29,800 --> 01:05:34,140
two have two gonna regret this one this
is Robin Williams speaking about human

2744
01:05:34,140 --> 01:05:34,150
is Robin Williams speaking about human
 

2745
01:05:34,150 --> 01:05:36,150
is Robin Williams speaking about human
imperfections so I'd like you to take

2746
01:05:36,150 --> 01:05:36,160
imperfections so I'd like you to take
 

2747
01:05:36,160 --> 01:05:39,270
imperfections so I'd like you to take
this quote and replace every time you

2748
01:05:39,270 --> 01:05:39,280
this quote and replace every time you
 

2749
01:05:39,280 --> 01:05:44,310
this quote and replace every time you
mentioned girl with car people call

2750
01:05:44,310 --> 01:05:44,320
mentioned girl with car people call
 

2751
01:05:44,320 --> 01:05:47,220
mentioned girl with car people call
those things imperfections Robin

2752
01:05:47,220 --> 01:05:47,230
those things imperfections Robin
 

2753
01:05:47,230 --> 01:05:48,780
those things imperfections Robin
Williams is talking about his wife who

2754
01:05:48,780 --> 01:05:48,790
Williams is talking about his wife who
 

2755
01:05:48,790 --> 01:05:52,109
Williams is talking about his wife who
passed away in the movie talking about

2756
01:05:52,109 --> 01:05:52,119
passed away in the movie talking about
 

2757
01:05:52,119 --> 01:05:54,570
passed away in the movie talking about
her imperfections they call these things

2758
01:05:54,570 --> 01:05:54,580
her imperfections they call these things
 

2759
01:05:54,580 --> 01:05:56,760
her imperfections they call these things
imperfections but they're not that's the

2760
01:05:56,760 --> 01:05:56,770
imperfections but they're not that's the
 

2761
01:05:56,770 --> 01:05:59,550
imperfections but they're not that's the
good stuff and then we'll get to choose

2762
01:05:59,550 --> 01:05:59,560
good stuff and then we'll get to choose
 

2763
01:05:59,560 --> 01:06:02,420
good stuff and then we'll get to choose
who we let into our weird little worlds

2764
01:06:02,420 --> 01:06:02,430
who we let into our weird little worlds
 

2765
01:06:02,430 --> 01:06:05,670
who we let into our weird little worlds
you're not perfect sport and let me save

2766
01:06:05,670 --> 01:06:05,680
you're not perfect sport and let me save
 

2767
01:06:05,680 --> 01:06:08,160
you're not perfect sport and let me save
you the suspense this girl you met she

2768
01:06:08,160 --> 01:06:08,170
you the suspense this girl you met she
 

2769
01:06:08,170 --> 01:06:09,390
you the suspense this girl you met she
isn't perfect to you there you know what

2770
01:06:09,390 --> 01:06:09,400
isn't perfect to you there you know what
 

2771
01:06:09,400 --> 01:06:19,279
isn't perfect to you there you know what
let me just

2772
01:06:19,279 --> 01:06:19,289

 

2773
01:06:19,289 --> 01:06:21,719

the video sequences that only I know

2774
01:06:21,719 --> 01:06:21,729
the video sequences that only I know
 

2775
01:06:21,729 --> 01:06:22,489
the video sequences that only I know
about

2776
01:06:22,489 --> 01:06:22,499
about
 

2777
01:06:22,499 --> 01:06:26,160
about
that's what made her my wife when she

2778
01:06:26,160 --> 01:06:26,170
that's what made her my wife when she
 

2779
01:06:26,170 --> 01:06:29,120
that's what made her my wife when she
had a puts on me - she all my pet dogs

2780
01:06:29,120 --> 01:06:29,130
had a puts on me - she all my pet dogs
 

2781
01:06:29,130 --> 01:06:33,079
had a puts on me - she all my pet dogs
people call these things into fashions

2782
01:06:33,079 --> 01:06:33,089
people call these things into fashions
 

2783
01:06:33,089 --> 01:06:37,949
people call these things into fashions
suffice no need to choose we learn to

2784
01:06:37,949 --> 01:06:37,959
suffice no need to choose we learn to
 

2785
01:06:37,959 --> 01:06:43,039
suffice no need to choose we learn to
obviate the words in my breath explore

2786
01:06:43,039 --> 01:06:43,049
obviate the words in my breath explore
 

2787
01:06:43,049 --> 01:06:46,699
obviate the words in my breath explore
things in suspense

2788
01:06:46,699 --> 01:06:46,709
things in suspense
 

2789
01:06:46,709 --> 01:06:49,859
things in suspense
he has an air attack but the question is

2790
01:06:49,859 --> 01:06:49,869
he has an air attack but the question is
 

2791
01:06:49,869 --> 01:06:54,060
he has an air attack but the question is
what am i perfect for each other

2792
01:06:54,060 --> 01:06:54,070

 

2793
01:06:54,070 --> 01:07:00,240

[Music]

2794
01:07:00,240 --> 01:07:00,250

 

2795
01:07:00,250 --> 01:07:07,670

[Music]

2796
01:07:07,670 --> 01:07:07,680

 

2797
01:07:07,680 --> 01:07:12,900

so the approach we're taking in building

2798
01:07:12,900 --> 01:07:12,910
so the approach we're taking in building
 

2799
01:07:12,910 --> 01:07:15,029
so the approach we're taking in building
the autonomous vehicle we are here at

2800
01:07:15,029 --> 01:07:15,039
the autonomous vehicle we are here at
 

2801
01:07:15,039 --> 01:07:17,880
the autonomous vehicle we are here at
MIT in our group it's the human centered

2802
01:07:17,880 --> 01:07:17,890
MIT in our group it's the human centered
 

2803
01:07:17,890 --> 01:07:20,160
MIT in our group it's the human centered
approach the autonomous vehicles they

2804
01:07:20,160 --> 01:07:20,170
approach the autonomous vehicles they
 

2805
01:07:20,170 --> 01:07:22,829
approach the autonomous vehicles they
were going to release in March of 2018

2806
01:07:22,829 --> 01:07:22,839
were going to release in March of 2018
 

2807
01:07:22,839 --> 01:07:29,670
were going to release in March of 2018
in the streets of Boston those who would

2808
01:07:29,670 --> 01:07:29,680
in the streets of Boston those who would
 

2809
01:07:29,680 --> 01:07:35,910
in the streets of Boston those who would
to help please do I will talk run a

2810
01:07:35,910 --> 01:07:35,920
to help please do I will talk run a
 

2811
01:07:35,920 --> 01:07:38,339
to help please do I will talk run a
course on deep learning for

2812
01:07:38,339 --> 01:07:38,349
course on deep learning for
 

2813
01:07:38,349 --> 01:07:40,380
course on deep learning for
understanding the humans of Chi 2018

2814
01:07:40,380 --> 01:07:40,390
understanding the humans of Chi 2018
 

2815
01:07:40,390 --> 01:07:42,150
understanding the humans of Chi 2018
will be going through tutorials that go

2816
01:07:42,150 --> 01:07:42,160
will be going through tutorials that go
 

2817
01:07:42,160 --> 01:07:45,839
will be going through tutorials that go
far beyond the visual the convolutional

2818
01:07:45,839 --> 01:07:45,849
far beyond the visual the convolutional
 

2819
01:07:45,849 --> 01:07:47,760
far beyond the visual the convolutional
neural network based detection of

2820
01:07:47,760 --> 01:07:47,770
neural network based detection of
 

2821
01:07:47,770 --> 01:07:50,910
neural network based detection of
various aspects of the face and body

2822
01:07:50,910 --> 01:07:50,920
various aspects of the face and body
 

2823
01:07:50,920 --> 01:07:53,700
various aspects of the face and body
would look at natural language

2824
01:07:53,700 --> 01:07:53,710
would look at natural language
 

2825
01:07:53,710 --> 01:07:58,410
would look at natural language
processing voice recognition and Gans

2826
01:07:58,410 --> 01:07:58,420
processing voice recognition and Gans
 

2827
01:07:58,420 --> 01:08:02,549
processing voice recognition and Gans
if you're going to Chi please join next

2828
01:08:02,549 --> 01:08:02,559
if you're going to Chi please join next
 

2829
01:08:02,559 --> 01:08:07,140
if you're going to Chi please join next
week we have an incredible course that's

2830
01:08:07,140 --> 01:08:07,150
week we have an incredible course that's
 

2831
01:08:07,150 --> 01:08:12,200
week we have an incredible course that's
aims to understand to begin to explore

2832
01:08:12,200 --> 01:08:12,210
aims to understand to begin to explore
 

2833
01:08:12,210 --> 01:08:17,189
aims to understand to begin to explore
the nature of intelligence natural and

2834
01:08:17,189 --> 01:08:17,199
the nature of intelligence natural and
 

2835
01:08:17,199 --> 01:08:20,579
the nature of intelligence natural and
artificial we have Josh Tenenbaum Ray

2836
01:08:20,579 --> 01:08:20,589
artificial we have Josh Tenenbaum Ray
 

2837
01:08:20,589 --> 01:08:26,160
artificial we have Josh Tenenbaum Ray
Kurzweil Lisa Barret Nate Dubinsky

2838
01:08:26,160 --> 01:08:26,170
Kurzweil Lisa Barret Nate Dubinsky
 

2839
01:08:26,170 --> 01:08:27,360
Kurzweil Lisa Barret Nate Dubinsky
looking at cognitive modeling

2840
01:08:27,360 --> 01:08:27,370
looking at cognitive modeling
 

2841
01:08:27,370 --> 01:08:30,419
looking at cognitive modeling
architectures Andre karpati Stephen

2842
01:08:30,419 --> 01:08:30,429
architectures Andre karpati Stephen
 

2843
01:08:30,429 --> 01:08:33,030
architectures Andre karpati Stephen
Wolfram Richard Moyes talking about

2844
01:08:33,030 --> 01:08:33,040
Wolfram Richard Moyes talking about
 

2845
01:08:33,040 --> 01:08:36,919
Wolfram Richard Moyes talking about
autonomous weapon systems and AI safety

2846
01:08:36,919 --> 01:08:36,929
autonomous weapon systems and AI safety
 

2847
01:08:36,929 --> 01:08:41,130
autonomous weapon systems and AI safety
mark Robert from Boston Dynamics and the

2848
01:08:41,130 --> 01:08:41,140
mark Robert from Boston Dynamics and the
 

2849
01:08:41,140 --> 01:08:44,900
mark Robert from Boston Dynamics and the
amazing incredible robots I have and

2850
01:08:44,900 --> 01:08:44,910
amazing incredible robots I have and
 

2851
01:08:44,910 --> 01:08:51,470
amazing incredible robots I have and
Ilya sutskever from open AI and myself

2852
01:08:51,470 --> 01:08:51,480
Ilya sutskever from open AI and myself
 

2853
01:08:51,480 --> 01:08:55,530
Ilya sutskever from open AI and myself
so what next for folks register for this

2854
01:08:55,530 --> 01:08:55,540
so what next for folks register for this
 

2855
01:08:55,540 --> 01:08:59,900
so what next for folks register for this
course you have to submit by tonight a

2856
01:08:59,900 --> 01:08:59,910
course you have to submit by tonight a
 

2857
01:08:59,910 --> 01:09:03,510
course you have to submit by tonight a
deep traffic entry that achieves a speed

2858
01:09:03,510 --> 01:09:03,520
deep traffic entry that achieves a speed
 

2859
01:09:03,520 --> 01:09:07,530
deep traffic entry that achieves a speed
of 65 miles an hour and I hope you

2860
01:09:07,530 --> 01:09:07,540
of 65 miles an hour and I hope you
 

2861
01:09:07,540 --> 01:09:10,169
of 65 miles an hour and I hope you
continue to submit more that win the

2862
01:09:10,169 --> 01:09:10,179
continue to submit more that win the
 

2863
01:09:10,179 --> 01:09:13,019
continue to submit more that win the
competition the high performer award

2864
01:09:13,019 --> 01:09:13,029
competition the high performer award
 

2865
01:09:13,029 --> 01:09:15,870
competition the high performer award
will be given to folks the very few

2866
01:09:15,870 --> 01:09:15,880
will be given to folks the very few
 

2867
01:09:15,880 --> 01:09:19,110
will be given to folks the very few
folks who achieved 70 miles an hour

2868
01:09:19,110 --> 01:09:19,120
folks who achieved 70 miles an hour
 

2869
01:09:19,120 --> 01:09:23,280
folks who achieved 70 miles an hour
faster we will continue rolling out seg

2870
01:09:23,280 --> 01:09:23,290
faster we will continue rolling out seg
 

2871
01:09:23,290 --> 01:09:28,079
faster we will continue rolling out seg
fuse having hit a few snags and invested

2872
01:09:28,079 --> 01:09:28,089
fuse having hit a few snags and invested
 

2873
01:09:28,089 --> 01:09:31,289
fuse having hit a few snags and invested
a few thousands of dollars in the

2874
01:09:31,289 --> 01:09:31,299
a few thousands of dollars in the
 

2875
01:09:31,299 --> 01:09:34,590
a few thousands of dollars in the
sanitation process of annotating a

2876
01:09:34,590 --> 01:09:34,600
sanitation process of annotating a
 

2877
01:09:34,600 --> 01:09:37,979
sanitation process of annotating a
large-scale data set for you guys we'll

2878
01:09:37,979 --> 01:09:37,989
large-scale data set for you guys we'll
 

2879
01:09:37,989 --> 01:09:39,870
large-scale data set for you guys we'll
continue this competition that will take

2880
01:09:39,870 --> 01:09:39,880
continue this competition that will take
 

2881
01:09:39,880 --> 01:09:41,380
continue this competition that will take
us into

2882
01:09:41,380 --> 01:09:41,390
us into
 

2883
01:09:41,390 --> 01:09:44,500
us into
into a submission to his nips where we'd

2884
01:09:44,500 --> 01:09:44,510
into a submission to his nips where we'd
 

2885
01:09:44,510 --> 01:09:46,120
into a submission to his nips where we'd
hope to submit the results for this

2886
01:09:46,120 --> 01:09:46,130
hope to submit the results for this
 

2887
01:09:46,130 --> 01:09:48,700
hope to submit the results for this
competition and deep crash the deeper

2888
01:09:48,700 --> 01:09:48,710
competition and deep crash the deeper
 

2889
01:09:48,710 --> 01:09:50,590
competition and deep crash the deeper
enforcement learning these competitions

2890
01:09:50,590 --> 01:09:50,600
enforcement learning these competitions
 

2891
01:09:50,600 --> 01:09:53,260
enforcement learning these competitions
will continue through May 2018 I hope

2892
01:09:53,260 --> 01:09:53,270
will continue through May 2018 I hope
 

2893
01:09:53,270 --> 01:09:54,990
will continue through May 2018 I hope
you stay tuned and participate

2894
01:09:54,990 --> 01:09:55,000
you stay tuned and participate
 

2895
01:09:55,000 --> 01:09:59,080
you stay tuned and participate
there's upcoming classes the a GI class

2896
01:09:59,080 --> 01:09:59,090
there's upcoming classes the a GI class
 

2897
01:09:59,090 --> 01:10:01,660
there's upcoming classes the a GI class
I encourage you to come to is going to

2898
01:10:01,660 --> 01:10:01,670
I encourage you to come to is going to
 

2899
01:10:01,670 --> 01:10:05,260
I encourage you to come to is going to
be fascinating and there's so many cool

2900
01:10:05,260 --> 01:10:05,270
be fascinating and there's so many cool
 

2901
01:10:05,270 --> 01:10:06,760
be fascinating and there's so many cool
interesting ideas that we're going to

2902
01:10:06,760 --> 01:10:06,770
interesting ideas that we're going to
 

2903
01:10:06,770 --> 01:10:08,440
interesting ideas that we're going to
explore it's gonna be awesome

2904
01:10:08,440 --> 01:10:08,450
explore it's gonna be awesome
 

2905
01:10:08,450 --> 01:10:10,450
explore it's gonna be awesome
there's an introduction to deep learning

2906
01:10:10,450 --> 01:10:10,460
there's an introduction to deep learning
 

2907
01:10:10,460 --> 01:10:13,030
there's an introduction to deep learning
course that I'm also part of will get a

2908
01:10:13,030 --> 01:10:13,040
course that I'm also part of will get a
 

2909
01:10:13,040 --> 01:10:15,700
course that I'm also part of will get a
little bit more applied and get folks

2910
01:10:15,700 --> 01:10:15,710
little bit more applied and get folks
 

2911
01:10:15,710 --> 01:10:18,180
little bit more applied and get folks
who are interested in the the very basic

2912
01:10:18,180 --> 01:10:18,190
who are interested in the the very basic
 

2913
01:10:18,190 --> 01:10:20,860
who are interested in the the very basic
algorithms of deep learning how to get

2914
01:10:20,860 --> 01:10:20,870
algorithms of deep learning how to get
 

2915
01:10:20,870 --> 01:10:25,120
algorithms of deep learning how to get
started with those hands-on and there's

2916
01:10:25,120 --> 01:10:25,130
started with those hands-on and there's
 

2917
01:10:25,130 --> 01:10:26,920
started with those hands-on and there's
an awesome class that ran last year for

2918
01:10:26,920 --> 01:10:26,930
an awesome class that ran last year for
 

2919
01:10:26,930 --> 01:10:28,960
an awesome class that ran last year for
those who took this class last year we

2920
01:10:28,960 --> 01:10:28,970
those who took this class last year we
 

2921
01:10:28,970 --> 01:10:32,350
those who took this class last year we
also talked about it on the the global

2922
01:10:32,350 --> 01:10:32,360
also talked about it on the the global
 

2923
01:10:32,360 --> 01:10:34,690
also talked about it on the the global
business of AI and robotics the slides

2924
01:10:34,690 --> 01:10:34,700
business of AI and robotics the slides
 

2925
01:10:34,700 --> 01:10:36,430
business of AI and robotics the slides
are online I encourage you to click a

2926
01:10:36,430 --> 01:10:36,440
are online I encourage you to click a
 

2927
01:10:36,440 --> 01:10:38,290
are online I encourage you to click a
link on there and register it's in the

2928
01:10:38,290 --> 01:10:38,300
link on there and register it's in the
 

2929
01:10:38,300 --> 01:10:41,890
link on there and register it's in the
spring it's once a week and it's truly

2930
01:10:41,890 --> 01:10:41,900
spring it's once a week and it's truly
 

2931
01:10:41,900 --> 01:10:43,120
spring it's once a week and it's truly
brings together a lot of

2932
01:10:43,120 --> 01:10:43,130
brings together a lot of
 

2933
01:10:43,130 --> 01:10:45,520
brings together a lot of
cross-disciplinary folks to talk about

2934
01:10:45,520 --> 01:10:45,530
cross-disciplinary folks to talk about
 

2935
01:10:45,530 --> 01:10:47,710
cross-disciplinary folks to talk about
ideas of artificial intelligence and the

2936
01:10:47,710 --> 01:10:47,720
ideas of artificial intelligence and the
 

2937
01:10:47,720 --> 01:10:49,930
ideas of artificial intelligence and the
role of AI and robotics and society it's

2938
01:10:49,930 --> 01:10:49,940
role of AI and robotics and society it's
 

2939
01:10:49,940 --> 01:10:53,730
role of AI and robotics and society it's
an awesome class and if you're

2940
01:10:53,730 --> 01:10:53,740
an awesome class and if you're
 

2941
01:10:53,740 --> 01:10:56,230
an awesome class and if you're
interested in applying deep learning

2942
01:10:56,230 --> 01:10:56,240
interested in applying deep learning
 

2943
01:10:56,240 --> 01:10:58,630
interested in applying deep learning
methods in the automotive space come

2944
01:10:58,630 --> 01:10:58,640
methods in the automotive space come
 

2945
01:10:58,640 --> 01:11:01,150
methods in the automotive space come
work with us we have a lot of

2946
01:11:01,150 --> 01:11:01,160
work with us we have a lot of
 

2947
01:11:01,160 --> 01:11:03,400
work with us we have a lot of
fascinating problems to to solve or

2948
01:11:03,400 --> 01:11:03,410
fascinating problems to to solve or
 

2949
01:11:03,410 --> 01:11:07,900
fascinating problems to to solve or
collaborate so with that I'd like to

2950
01:11:07,900 --> 01:11:07,910
collaborate so with that I'd like to
 

2951
01:11:07,910 --> 01:11:11,010
collaborate so with that I'd like to
thank everybody here everybody across

2952
01:11:11,010 --> 01:11:11,020
thank everybody here everybody across
 

2953
01:11:11,020 --> 01:11:13,720
thank everybody here everybody across
the community that's been contributing

2954
01:11:13,720 --> 01:11:13,730
the community that's been contributing
 

2955
01:11:13,730 --> 01:11:16,030
the community that's been contributing
we have thousands of submissions coming

2956
01:11:16,030 --> 01:11:16,040
we have thousands of submissions coming
 

2957
01:11:16,040 --> 01:11:18,310
we have thousands of submissions coming
in for deep traffic and I'm just truly

2958
01:11:18,310 --> 01:11:18,320
in for deep traffic and I'm just truly
 

2959
01:11:18,320 --> 01:11:20,290
in for deep traffic and I'm just truly
humbled by the support we've been

2960
01:11:20,290 --> 01:11:20,300
humbled by the support we've been
 

2961
01:11:20,300 --> 01:11:22,090
humbled by the support we've been
getting and the team behind this class

2962
01:11:22,090 --> 01:11:22,100
getting and the team behind this class
 

2963
01:11:22,100 --> 01:11:24,400
getting and the team behind this class
is incredible thank you to Nvidia Google

2964
01:11:24,400 --> 01:11:24,410
is incredible thank you to Nvidia Google
 

2965
01:11:24,410 --> 01:11:27,340
is incredible thank you to Nvidia Google
Amazon Alexa auto live in Toyota and

2966
01:11:27,340 --> 01:11:27,350
Amazon Alexa auto live in Toyota and
 

2967
01:11:27,350 --> 01:11:33,760
Amazon Alexa auto live in Toyota and
today we have shirts extra large extra

2968
01:11:33,760 --> 01:11:33,770
today we have shirts extra large extra
 

2969
01:11:33,770 --> 01:11:36,490
today we have shirts extra large extra
extra large medium over there small and

2970
01:11:36,490 --> 01:11:36,500
extra large medium over there small and
 

2971
01:11:36,500 --> 01:11:39,340
extra large medium over there small and
large over there the big and small

2972
01:11:39,340 --> 01:11:39,350
large over there the big and small
 

2973
01:11:39,350 --> 01:11:40,480
large over there the big and small
people over here and then the

2974
01:11:40,480 --> 01:11:40,490
people over here and then the
 

2975
01:11:40,490 --> 01:11:43,720
people over here and then the
medium-sized people over here so just

2976
01:11:43,720 --> 01:11:43,730
medium-sized people over here so just
 

2977
01:11:43,730 --> 01:11:46,930
medium-sized people over here so just
grab it grab one and enjoy thank you

2978
01:11:46,930 --> 01:11:46,940
grab it grab one and enjoy thank you
 

2979
01:11:46,940 --> 01:11:47,470
grab it grab one and enjoy thank you
very much

2980
01:11:47,470 --> 01:11:47,480
very much
 

2981
01:11:47,480 --> 01:11:51,660
very much
[Applause]

